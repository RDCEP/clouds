{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sklearn\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from scipy import interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\"))\n",
    "sys.path.append('../../')\n",
    "from reproduction.pipeline.load import load_data\n",
    "from reproduction import analysis\n",
    "\n",
    "# Disable Warnings\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "tf.logging.set_verbosity(tf.logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(start, step, stop, max_samples=5000, sample_steps=4, trials=30):\n",
    "    with open(ENCODER_DEF,\"r\") as f:\n",
    "            encoder = tf.keras.models.model_from_json(f.read())\n",
    "    encoder.load_weights(ENCODER_WEIGHTS)\n",
    "    \n",
    "    samples = np.logspace(np.log10(start+2), np.log10(max_samples), num=sample_steps).astype(int)\n",
    "    search_results = [] # Force initialization\n",
    "    # iterate on sampling \n",
    "    for i in samples:\n",
    "        # iterate on clustering\n",
    "        for j in range(start, stop, step):\n",
    "                if i/j > 2: # Agglomerative clustering must have leaves with at least 2 elements\n",
    "                    print('Samples: ', i,' Clusters: ',j)\n",
    "                    minfoac = []\n",
    "                    for trial in range(trials):\n",
    "                        data = analysis.AEData(load_data(DATA, encoder.input_shape[1:]), n=i)\n",
    "                        data.add_encoder(encoder)\n",
    "                        N_CLUSTERS = j\n",
    "                        ag1 = AgglomerativeClustering(n_clusters=N_CLUSTERS).fit_predict(data.encs[:int(i/2)])\n",
    "                        ag2 = AgglomerativeClustering(n_clusters=N_CLUSTERS).fit_predict(data.encs)\n",
    "                        minfoac.append(sklearn.metrics.adjusted_mutual_info_score(ag1, ag2[:int(i/2)]))\n",
    "                    minfo_mean = np.nanmean(minfoac)\n",
    "                    minfo_std = np.nanstd(minfoac)\n",
    "                    search_results.append((i, N_CLUSTERS, minfo_mean, minfo_std))\n",
    "                    print('Average Mutual information: ', minfo_mean, 'MI_STD: ', minfo_std, 'Precision: ', np.count_nonzero(~np.isnan(minfoac)))\n",
    "    return search_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"/project/foster/clouds/data/2015_05/*.tfrecord\"\n",
    "ENCODER_DEF = \"/home/rlourenco/rdcep_clouds/output/m9-22_oceans/encoder.json\"\n",
    "ENCODER_WEIGHTS = \"/home/rlourenco/rdcep_clouds/output/m9-22_oceans/encoder.h5\"\n",
    "# N_CLUSTERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  9  Clusters:  2\n",
      "WARNING:tensorflow:From ../../reproduction/pipeline/load.py:152: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "Average Mutual information:  0.5444444444444445 MI_STD:  0.5269291422835278 Precision:  30\n",
      "Samples:  9  Clusters:  3\n",
      "Average Mutual information:  0.5354398544495964 MI_STD:  0.3789628814819357 Precision:  30\n",
      "Samples:  9  Clusters:  4\n",
      "Average Mutual information:  -4.7090467064810746e-18 MI_STD:  8.994920560887689e-17 Precision:  27\n",
      "Samples:  22  Clusters:  2\n",
      "Average Mutual information:  0.6087440135861429 MI_STD:  0.3990821932635022 Precision:  30\n",
      "Samples:  22  Clusters:  3\n"
     ]
    }
   ],
   "source": [
    "result = gridsearch(2,1,40,max_samples=10000, sample_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.columns = [\"Samples\", \"Clusters\", \"MInfo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Information Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28 Samples, 13 clusters maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.xlim(0,40)\n",
    "plt.ylim(0,1)\n",
    "y_28 =  df.loc[df['Samples'] == 28]\n",
    "x_28 = y_28['Clusters']\n",
    "plt.plot(x_28, y_28[\"MInfo\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 200 Samples, 40 clusters maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.xlim(0,40)\n",
    "plt.ylim(0,1)\n",
    "y_200 =  df.loc[df['Samples'] == 200]\n",
    "x_200 = y_200['Clusters']\n",
    "plt.plot(x_200, y_200[\"MInfo\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1414 Samples, 40 clusters maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.xlim(0,40)\n",
    "plt.ylim(0,1)\n",
    "y_200 =  df.loc[df['Samples'] == 1414]\n",
    "x_200 = y_200['Clusters']\n",
    "plt.plot(x_200, y_200[\"MInfo\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10000 Samples, 13 clusters maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.xlim(0,40)\n",
    "plt.ylim(0,1)\n",
    "y_200 =  df.loc[df['Samples'] == 10000]\n",
    "x_200 = y_200['Clusters']\n",
    "plt.plot(x_200, y_200[\"MInfo\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best result seems to be when using 200 samples, with 9 clusters, with a MI score of 0.84."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = gridsearch(2,1,500)\n",
    "N_CLUSTERS = 9 #result[0]\n",
    "# HiMI = #result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ENCODER_DEF,\"r\") as f:\n",
    "    encoder = tf.keras.models.model_from_json(f.read())\n",
    "encoder.load_weights(ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = analysis.AEData(load_data(DATA, encoder.input_shape[1:]), n=200)\n",
    "data.add_encoder(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = AgglomerativeClustering(n_clusters=N_CLUSTERS)\n",
    "m1.fit(data.encs[:100])\n",
    "ag1 = AgglomerativeClustering(n_clusters=N_CLUSTERS).fit_predict(data.encs[:100])\n",
    "\n",
    "m2 = AgglomerativeClustering(n_clusters=N_CLUSTERS)\n",
    "m2.fit(data.encs)\n",
    "ag2 = AgglomerativeClustering(n_clusters=N_CLUSTERS).fit_predict(data.encs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of bins\n",
    "nbins=N_CLUSTERS\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.hist2d(ag1, ag2[:100], bins=nbins);\n",
    "plt.title(\"Cluster overlap\")\n",
    "plt.xticks(range(0, nbins, 5)); plt.yticks(range(0, nbins, 5));\n",
    "plt.xlabel(\"ag 10000\"); plt.ylabel(\"ag 5000\");\n",
    "plt.colorbar()\n",
    "print('Mutual Information score: ',sklearn.metrics.adjusted_mutual_info_score(ag1, ag2[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = data.imgs[:100,:,:,0][ag1 == ag2[:100]]\n",
    "overlap_c = ag1[ag1 == ag2[:100]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 8, figsize=(16, 10))\n",
    "\n",
    "clu = data.imgs[:100,:,:,0][ag1 == 2]\n",
    "\n",
    "for i, a in enumerate(ax.ravel()):\n",
    "    a.imshow(clu[i], cmap=\"bone\")\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.cluster.hierarchy import dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "\n",
    "    # Children of hierarchical clustering\n",
    "    children = model.children_\n",
    "\n",
    "    # Distances between each pair of children\n",
    "    # Since we don't have this information, we can use a uniform one for plotting\n",
    "    distance = np.arange(children.shape[0])\n",
    "\n",
    "    # The number of observations contained in each cluster level\n",
    "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
    "\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's hard to interpretate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(500,100))\n",
    "plot_dendrogram(m2, labels=m2.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
