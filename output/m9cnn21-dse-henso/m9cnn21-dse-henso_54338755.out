/software/openmpi-3.1.2-el7-x86_64/bin/mpirun
/software/Anaconda3-5.3.0-el7-x86_64/bin/python
/software/cuda-9.0-el7-x86_64/bin/nvcc
Parsing Inputs...
Parsing Inputs...
Parsing Inputs...
Parsing Inputs...
midway2-gpu03:34059:34504 [0] INFO NET : Using interface ib0:172.25.221.193<0>
midway2-gpu03:34059:34504 [0] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu03:34059:34504 [0] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu03:34059:34504 [0] INFO Using internal Network IB
midway2-gpu03:34059:34504 [0] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu03:34059:34504 [0] INFO NET : Using interface ib0:172.25.221.193<0>
midway2-gpu03:34059:34504 [0] INFO NET/Socket : 1 interfaces found
NCCL version 2.2.13+cuda9.0
midway2-gpu03:34061:34501 [2] INFO NET : Using interface ib0:172.25.221.193<0>
midway2-gpu03:34061:34501 [2] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu03:34062:34502 [3] INFO NET : Using interface ib0:172.25.221.193<0>
midway2-gpu03:34062:34502 [3] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu03:34060:34503 [1] INFO NET : Using interface ib0:172.25.221.193<0>
midway2-gpu03:34060:34503 [1] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu03:34061:34501 [2] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu03:34060:34503 [1] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu03:34060:34503 [1] INFO Using internal Network IB
midway2-gpu03:34060:34503 [1] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu03:34061:34501 [2] INFO Using internal Network IB
midway2-gpu03:34061:34501 [2] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu03:34062:34502 [3] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu03:34062:34502 [3] INFO Using internal Network IB
midway2-gpu03:34062:34502 [3] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu03:34059:34504 [0] INFO comm 0x7f8bbc888a40 rank 0 nranks 4
midway2-gpu03:34059:34504 [0] INFO CUDA Dev 0, IB Ports : mlx5_0/1(SOC) 
midway2-gpu03:34060:34503 [1] INFO comm 0x7fbb708708b0 rank 1 nranks 4
midway2-gpu03:34060:34503 [1] INFO NET : Using interface ib0:172.25.221.193<0>
midway2-gpu03:34060:34503 [1] INFO NET/Socket : 1 interfaces found
midway2-gpu03:34062:34502 [3] INFO comm 0x7f177c86f310 rank 3 nranks 4
midway2-gpu03:34060:34503 [1] INFO CUDA Dev 1, IB Ports : mlx5_0/1(SOC) 
midway2-gpu03:34062:34502 [3] INFO NET : Using interface ib0:172.25.221.193<0>
midway2-gpu03:34062:34502 [3] INFO NET/Socket : 1 interfaces found
midway2-gpu03:34062:34502 [3] INFO CUDA Dev 3, IB Ports : mlx5_0/1(PHB) 
midway2-gpu03:34061:34501 [2] INFO comm 0x7eff2c86f250 rank 2 nranks 4
midway2-gpu03:34061:34501 [2] INFO NET : Using interface ib0:172.25.221.193<0>
midway2-gpu03:34061:34501 [2] INFO NET/Socket : 1 interfaces found
midway2-gpu03:34061:34501 [2] INFO CUDA Dev 2, IB Ports : mlx5_0/1(PHB) 
midway2-gpu03:34059:34504 [0] INFO Using 128 threads
midway2-gpu03:34059:34504 [0] INFO Min Comp Cap 3
midway2-gpu03:34059:34504 [0] INFO NCCL_SINGLE_RING_THRESHOLD=131072
midway2-gpu03:34059:34504 [0] INFO Ring 00 :    0   1   2   3
midway2-gpu03:34059:34504 [0] INFO Ring 01 :    0   1   2   3
midway2-gpu03:34060:34503 [1] INFO 1[34060] -> 2[34061] via direct shared memory
midway2-gpu03:34062:34502 [3] INFO 3[34062] -> 0[34059] via direct shared memory
midway2-gpu03:34059:34504 [0] INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC
midway2-gpu03:34061:34501 [2] INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC
midway2-gpu03:34062:34502 [3] INFO 3[34062] -> 0[34059] via direct shared memory
midway2-gpu03:34060:34503 [1] INFO 1[34060] -> 2[34061] via direct shared memory
midway2-gpu03:34059:34504 [0] INFO Ring 01 : 0[0] -> 1[1] via P2P/IPC
midway2-gpu03:34061:34501 [2] INFO Ring 01 : 2[2] -> 3[3] via P2P/IPC
midway2-gpu03:34059:34504 [0] INFO Launch mode Parallel
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_10000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 6.65sec, accelerator: 0us, total: 6.65sec (83.74%)
top 2 operation type: HistogramSummary, cpu: 634.57ms, accelerator: 0us, total: 634.57ms (8.00%)
top 3 operation type: ImageSummary, cpu: 344.58ms, accelerator: 0us, total: 344.58ms (4.34%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 155.30ms, accelerator: 0us, total: 155.30ms
top 3 graph node: original, cpu: 110.03ms, accelerator: 0us, total: 110.03ms
train.py:511:<module>, cpu: 6.66sec, accelerator: 7.62ms, total: 6.66sec
  __init__.py:194:compute_gradients, cpu: 6.65sec, accelerator: 847us, total: 6.65sec
    __init__.py:83:allreduce, cpu: 6.65sec, accelerator: 0us, total: 6.65sec
    __init__.py:86:allreduce, cpu: 1.83ms, accelerator: 847us, total: 2.68ms
  __init__.py:185:compute_gradients, cpu: 6.95ms, accelerator: 6.77ms, total: 13.72ms
train.py:515:<module>, cpu: 633.08ms, accelerator: 0us, total: 633.08ms
train.py:448:<module>, cpu: 155.30ms, accelerator: 0us, total: 155.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.73
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1370.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_10250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.62

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.75sec, accelerator: 0us, total: 7.75sec (82.14%)
top 2 operation type: HistogramSummary, cpu: 915.40ms, accelerator: 0us, total: 915.40ms (9.70%)
top 3 operation type: ImageSummary, cpu: 459.85ms, accelerator: 0us, total: 459.85ms (4.87%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 164.13ms, accelerator: 0us, total: 164.13ms
top 3 graph node: original, cpu: 157.96ms, accelerator: 0us, total: 157.96ms
train.py:511:<module>, cpu: 7.76sec, accelerator: 7.61ms, total: 7.77sec
  __init__.py:194:compute_gradients, cpu: 7.75sec, accelerator: 839us, total: 7.75sec
    __init__.py:83:allreduce, cpu: 7.75sec, accelerator: 0us, total: 7.75sec
    __init__.py:86:allreduce, cpu: 2.00ms, accelerator: 839us, total: 2.85ms
  __init__.py:185:compute_gradients, cpu: 4.33ms, accelerator: 6.77ms, total: 11.11ms
train.py:515:<module>, cpu: 913.93ms, accelerator: 0us, total: 913.93ms
train.py:448:<module>, cpu: 164.13ms, accelerator: 0us, total: 164.13ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1390.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_10500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.06sec, accelerator: 0us, total: 7.06sec (81.10%)
top 2 operation type: HistogramSummary, cpu: 897.97ms, accelerator: 0us, total: 897.97ms (10.32%)
top 3 operation type: ImageSummary, cpu: 425.19ms, accelerator: 0us, total: 425.19ms (4.89%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 161.65ms, accelerator: 0us, total: 161.65ms
top 3 graph node: original, cpu: 134.85ms, accelerator: 0us, total: 134.85ms
train.py:511:<module>, cpu: 7.07sec, accelerator: 7.59ms, total: 7.07sec
  __init__.py:194:compute_gradients, cpu: 7.06sec, accelerator: 832us, total: 7.06sec
    __init__.py:83:allreduce, cpu: 7.06sec, accelerator: 0us, total: 7.06sec
    __init__.py:86:allreduce, cpu: 7.72ms, accelerator: 832us, total: 8.57ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 6.76ms, total: 10.33ms
train.py:515:<module>, cpu: 896.36ms, accelerator: 0us, total: 896.36ms
train.py:448:<module>, cpu: 161.65ms, accelerator: 0us, total: 161.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.74
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1363.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_10750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.31sec, accelerator: 0us, total: 7.31sec (81.32%)
top 2 operation type: HistogramSummary, cpu: 930.62ms, accelerator: 0us, total: 930.62ms (10.35%)
top 3 operation type: ImageSummary, cpu: 410.10ms, accelerator: 0us, total: 410.10ms (4.56%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 153.43ms, accelerator: 0us, total: 153.43ms
top 3 graph node: original, cpu: 130.63ms, accelerator: 0us, total: 130.63ms
train.py:511:<module>, cpu: 7.32sec, accelerator: 7.59ms, total: 7.33sec
  __init__.py:194:compute_gradients, cpu: 7.32sec, accelerator: 828us, total: 7.32sec
    __init__.py:83:allreduce, cpu: 7.31sec, accelerator: 0us, total: 7.31sec
    __init__.py:86:allreduce, cpu: 7.99ms, accelerator: 828us, total: 8.84ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 6.76ms, total: 10.22ms
train.py:515:<module>, cpu: 929.06ms, accelerator: 0us, total: 929.06ms
train.py:448:<module>, cpu: 153.44ms, accelerator: 0us, total: 153.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.74
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_11000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.43sec, accelerator: 0us, total: 7.43sec (81.47%)
top 2 operation type: HistogramSummary, cpu: 966.82ms, accelerator: 0us, total: 966.82ms (10.61%)
top 3 operation type: ImageSummary, cpu: 390.05ms, accelerator: 0us, total: 390.05ms (4.28%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 147.62ms, accelerator: 0us, total: 147.62ms
top 3 graph node: original, cpu: 128.56ms, accelerator: 0us, total: 128.56ms
train.py:511:<module>, cpu: 7.44sec, accelerator: 7.59ms, total: 7.44sec
  __init__.py:194:compute_gradients, cpu: 7.43sec, accelerator: 825us, total: 7.43sec
    __init__.py:83:allreduce, cpu: 7.43sec, accelerator: 0us, total: 7.43sec
    __init__.py:86:allreduce, cpu: 7.40ms, accelerator: 825us, total: 8.24ms
  __init__.py:185:compute_gradients, cpu: 3.53ms, accelerator: 6.76ms, total: 10.31ms
train.py:515:<module>, cpu: 965.31ms, accelerator: 0us, total: 965.31ms
train.py:448:<module>, cpu: 147.62ms, accelerator: 0us, total: 147.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.77
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1404.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_11250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.81

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 6.94sec, accelerator: 0us, total: 6.94sec (80.42%)
top 2 operation type: HistogramSummary, cpu: 977.05ms, accelerator: 0us, total: 977.05ms (11.33%)
top 3 operation type: ImageSummary, cpu: 382.75ms, accelerator: 0us, total: 382.75ms (4.44%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 151.37ms, accelerator: 0us, total: 151.37ms
top 3 graph node: original, cpu: 121.63ms, accelerator: 0us, total: 121.63ms
train.py:511:<module>, cpu: 6.95sec, accelerator: 7.59ms, total: 6.95sec
  __init__.py:194:compute_gradients, cpu: 6.94sec, accelerator: 827us, total: 6.94sec
    __init__.py:83:allreduce, cpu: 6.94sec, accelerator: 0us, total: 6.94sec
    __init__.py:86:allreduce, cpu: 6.52ms, accelerator: 827us, total: 7.36ms
  __init__.py:185:compute_gradients, cpu: 3.82ms, accelerator: 6.76ms, total: 10.61ms
train.py:515:<module>, cpu: 975.56ms, accelerator: 0us, total: 975.56ms
train.py:448:<module>, cpu: 151.37ms, accelerator: 0us, total: 151.37ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1391.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_11500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 22.66sec, accelerator: 0us, total: 22.66sec (92.99%)
top 2 operation type: HistogramSummary, cpu: 988.11ms, accelerator: 0us, total: 988.11ms (4.06%)
top 3 operation type: ImageSummary, cpu: 382.76ms, accelerator: 0us, total: 382.76ms (1.57%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 154.10ms, accelerator: 0us, total: 154.10ms
top 3 graph node: original, cpu: 114.52ms, accelerator: 0us, total: 114.52ms
train.py:511:<module>, cpu: 22.67sec, accelerator: 7.59ms, total: 22.67sec
  __init__.py:194:compute_gradients, cpu: 22.66sec, accelerator: 825us, total: 22.66sec
    __init__.py:83:allreduce, cpu: 22.66sec, accelerator: 0us, total: 22.66sec
    __init__.py:86:allreduce, cpu: 6.86ms, accelerator: 825us, total: 7.71ms
  __init__.py:185:compute_gradients, cpu: 3.53ms, accelerator: 6.76ms, total: 10.31ms
train.py:515:<module>, cpu: 986.63ms, accelerator: 0us, total: 986.63ms
train.py:448:<module>, cpu: 154.10ms, accelerator: 0us, total: 154.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.11
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1386.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_11750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 44.79sec, accelerator: 0us, total: 44.79sec (96.13%)
top 2 operation type: HistogramSummary, cpu: 1.07sec, accelerator: 0us, total: 1.07sec (2.30%)
top 3 operation type: ImageSummary, cpu: 399.37ms, accelerator: 0us, total: 399.37ms (0.86%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 164.28ms, accelerator: 0us, total: 164.28ms
top 3 graph node: difference, cpu: 121.68ms, accelerator: 0us, total: 121.68ms
train.py:511:<module>, cpu: 44.80sec, accelerator: 7.59ms, total: 44.80sec
  __init__.py:194:compute_gradients, cpu: 44.79sec, accelerator: 825us, total: 44.79sec
    __init__.py:83:allreduce, cpu: 44.79sec, accelerator: 0us, total: 44.79sec
    __init__.py:86:allreduce, cpu: 6.16ms, accelerator: 825us, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 3.34ms, accelerator: 6.76ms, total: 10.12ms
train.py:515:<module>, cpu: 1.07sec, accelerator: 0us, total: 1.07sec
train.py:448:<module>, cpu: 164.29ms, accelerator: 0us, total: 164.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.07
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1394.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_12000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 43.78sec, accelerator: 0us, total: 43.78sec (96.03%)
top 2 operation type: HistogramSummary, cpu: 1.06sec, accelerator: 0us, total: 1.06sec (2.33%)
top 3 operation type: ImageSummary, cpu: 411.90ms, accelerator: 0us, total: 411.90ms (0.90%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 170.54ms, accelerator: 0us, total: 170.54ms
top 3 graph node: difference, cpu: 125.03ms, accelerator: 0us, total: 125.03ms
train.py:511:<module>, cpu: 43.79sec, accelerator: 7.58ms, total: 43.80sec
  __init__.py:194:compute_gradients, cpu: 43.79sec, accelerator: 826us, total: 43.79sec
    __init__.py:83:allreduce, cpu: 43.78sec, accelerator: 0us, total: 43.78sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 826us, total: 6.48ms
  __init__.py:185:compute_gradients, cpu: 3.40ms, accelerator: 6.76ms, total: 10.19ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 170.54ms, accelerator: 0us, total: 170.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.29
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1404.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_12250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 40.15sec, accelerator: 0us, total: 40.15sec (95.68%)
top 2 operation type: HistogramSummary, cpu: 1.04sec, accelerator: 0us, total: 1.04sec (2.49%)
top 3 operation type: ImageSummary, cpu: 431.31ms, accelerator: 0us, total: 431.31ms (1.03%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 179.24ms, accelerator: 0us, total: 179.24ms
top 3 graph node: difference, cpu: 133.61ms, accelerator: 0us, total: 133.61ms
train.py:511:<module>, cpu: 40.16sec, accelerator: 7.58ms, total: 40.16sec
  __init__.py:194:compute_gradients, cpu: 40.15sec, accelerator: 826us, total: 40.15sec
    __init__.py:83:allreduce, cpu: 40.15sec, accelerator: 0us, total: 40.15sec
    __init__.py:86:allreduce, cpu: 6.36ms, accelerator: 826us, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.24ms, accelerator: 6.76ms, total: 10.03ms
train.py:515:<module>, cpu: 1.04sec, accelerator: 0us, total: 1.04sec
train.py:448:<module>, cpu: 179.24ms, accelerator: 0us, total: 179.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.68
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1390.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_12500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 52.64sec, accelerator: 0us, total: 52.64sec (96.63%)
top 2 operation type: HistogramSummary, cpu: 1.06sec, accelerator: 0us, total: 1.06sec (1.95%)
top 3 operation type: ImageSummary, cpu: 441.50ms, accelerator: 0us, total: 441.50ms (0.81%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 181.95ms, accelerator: 0us, total: 181.95ms
top 3 graph node: difference, cpu: 136.50ms, accelerator: 0us, total: 136.50ms
train.py:511:<module>, cpu: 52.65sec, accelerator: 7.59ms, total: 52.66sec
  __init__.py:194:compute_gradients, cpu: 52.65sec, accelerator: 826us, total: 52.65sec
    __init__.py:83:allreduce, cpu: 52.64sec, accelerator: 0us, total: 52.64sec
    __init__.py:86:allreduce, cpu: 6.02ms, accelerator: 826us, total: 6.86ms
  __init__.py:185:compute_gradients, cpu: 3.11ms, accelerator: 6.76ms, total: 9.90ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 181.95ms, accelerator: 0us, total: 181.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.08
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1388.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_12750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 48.65sec, accelerator: 0us, total: 48.65sec (96.32%)
top 2 operation type: HistogramSummary, cpu: 1.08sec, accelerator: 0us, total: 1.08sec (2.14%)
top 3 operation type: ImageSummary, cpu: 445.23ms, accelerator: 0us, total: 445.23ms (0.88%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 182.05ms, accelerator: 0us, total: 182.05ms
top 3 graph node: difference, cpu: 137.42ms, accelerator: 0us, total: 137.42ms
train.py:511:<module>, cpu: 48.66sec, accelerator: 7.59ms, total: 48.67sec
  __init__.py:194:compute_gradients, cpu: 48.66sec, accelerator: 826us, total: 48.66sec
    __init__.py:83:allreduce, cpu: 48.65sec, accelerator: 0us, total: 48.65sec
    __init__.py:86:allreduce, cpu: 5.85ms, accelerator: 826us, total: 6.69ms
  __init__.py:185:compute_gradients, cpu: 3.00ms, accelerator: 6.76ms, total: 9.79ms
train.py:515:<module>, cpu: 1.08sec, accelerator: 0us, total: 1.08sec
train.py:448:<module>, cpu: 182.06ms, accelerator: 0us, total: 182.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.84
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1380.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_13000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 45.30sec, accelerator: 0us, total: 45.30sec (96.10%)
top 2 operation type: HistogramSummary, cpu: 1.06sec, accelerator: 0us, total: 1.06sec (2.26%)
top 3 operation type: ImageSummary, cpu: 438.94ms, accelerator: 0us, total: 438.94ms (0.93%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 176.17ms, accelerator: 0us, total: 176.17ms
top 3 graph node: difference, cpu: 138.95ms, accelerator: 0us, total: 138.95ms
train.py:511:<module>, cpu: 45.30sec, accelerator: 7.59ms, total: 45.31sec
  __init__.py:194:compute_gradients, cpu: 45.30sec, accelerator: 826us, total: 45.30sec
    __init__.py:83:allreduce, cpu: 45.30sec, accelerator: 0us, total: 45.30sec
    __init__.py:86:allreduce, cpu: 5.60ms, accelerator: 826us, total: 6.44ms
  __init__.py:185:compute_gradients, cpu: 2.90ms, accelerator: 6.76ms, total: 9.69ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 176.17ms, accelerator: 0us, total: 176.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.85
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_13250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 66.91sec, accelerator: 0us, total: 66.91sec (97.33%)
top 2 operation type: HistogramSummary, cpu: 1.06sec, accelerator: 0us, total: 1.06sec (1.54%)
top 3 operation type: ImageSummary, cpu: 434.19ms, accelerator: 0us, total: 434.19ms (0.63%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 174.86ms, accelerator: 0us, total: 174.86ms
top 3 graph node: difference, cpu: 136.26ms, accelerator: 0us, total: 136.26ms
train.py:511:<module>, cpu: 66.91sec, accelerator: 7.59ms, total: 66.92sec
  __init__.py:194:compute_gradients, cpu: 66.91sec, accelerator: 826us, total: 66.91sec
    __init__.py:83:allreduce, cpu: 66.91sec, accelerator: 0us, total: 66.91sec
    __init__.py:86:allreduce, cpu: 5.75ms, accelerator: 826us, total: 6.59ms
  __init__.py:185:compute_gradients, cpu: 3.29ms, accelerator: 6.76ms, total: 10.07ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 174.86ms, accelerator: 0us, total: 174.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.04
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1404.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_13500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.15

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 68.09sec, accelerator: 0us, total: 68.09sec (97.37%)
top 2 operation type: HistogramSummary, cpu: 1.06sec, accelerator: 0us, total: 1.06sec (1.52%)
top 3 operation type: ImageSummary, cpu: 435.14ms, accelerator: 0us, total: 435.14ms (0.62%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 175.81ms, accelerator: 0us, total: 175.81ms
top 3 graph node: difference, cpu: 135.71ms, accelerator: 0us, total: 135.71ms
train.py:511:<module>, cpu: 68.10sec, accelerator: 7.59ms, total: 68.10sec
  __init__.py:194:compute_gradients, cpu: 68.09sec, accelerator: 825us, total: 68.09sec
    __init__.py:83:allreduce, cpu: 68.09sec, accelerator: 0us, total: 68.09sec
    __init__.py:86:allreduce, cpu: 5.93ms, accelerator: 825us, total: 6.78ms
  __init__.py:185:compute_gradients, cpu: 3.19ms, accelerator: 6.76ms, total: 9.98ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 175.81ms, accelerator: 0us, total: 175.81ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1395.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_13750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 64.15sec, accelerator: 0us, total: 64.15sec (97.22%)
top 2 operation type: HistogramSummary, cpu: 1.05sec, accelerator: 0us, total: 1.05sec (1.60%)
top 3 operation type: ImageSummary, cpu: 437.70ms, accelerator: 0us, total: 437.70ms (0.66%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 177.84ms, accelerator: 0us, total: 177.84ms
top 3 graph node: difference, cpu: 135.84ms, accelerator: 0us, total: 135.84ms
train.py:511:<module>, cpu: 64.16sec, accelerator: 7.59ms, total: 64.17sec
  __init__.py:194:compute_gradients, cpu: 64.16sec, accelerator: 825us, total: 64.16sec
    __init__.py:83:allreduce, cpu: 64.15sec, accelerator: 0us, total: 64.15sec
    __init__.py:86:allreduce, cpu: 5.66ms, accelerator: 825us, total: 6.50ms
  __init__.py:185:compute_gradients, cpu: 3.10ms, accelerator: 6.76ms, total: 9.89ms
train.py:515:<module>, cpu: 1.05sec, accelerator: 0us, total: 1.05sec
train.py:448:<module>, cpu: 177.85ms, accelerator: 0us, total: 177.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.79
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1390.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_14000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 60.75sec, accelerator: 0us, total: 60.75sec (97.03%)
top 2 operation type: HistogramSummary, cpu: 1.07sec, accelerator: 0us, total: 1.07sec (1.70%)
top 3 operation type: ImageSummary, cpu: 452.70ms, accelerator: 0us, total: 452.70ms (0.72%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 183.13ms, accelerator: 0us, total: 183.13ms
top 3 graph node: difference, cpu: 140.72ms, accelerator: 0us, total: 140.72ms
train.py:511:<module>, cpu: 60.76sec, accelerator: 7.59ms, total: 60.77sec
  __init__.py:194:compute_gradients, cpu: 60.75sec, accelerator: 825us, total: 60.76sec
    __init__.py:83:allreduce, cpu: 60.75sec, accelerator: 0us, total: 60.75sec
    __init__.py:86:allreduce, cpu: 5.55ms, accelerator: 825us, total: 6.40ms
  __init__.py:185:compute_gradients, cpu: 3.03ms, accelerator: 6.76ms, total: 9.82ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 183.14ms, accelerator: 0us, total: 183.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.66
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_14250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 57.77sec, accelerator: 0us, total: 57.77sec (96.88%)
top 2 operation type: HistogramSummary, cpu: 1.06sec, accelerator: 0us, total: 1.06sec (1.78%)
top 3 operation type: ImageSummary, cpu: 454.40ms, accelerator: 0us, total: 454.40ms (0.76%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 185.34ms, accelerator: 0us, total: 185.34ms
top 3 graph node: difference, cpu: 139.48ms, accelerator: 0us, total: 139.48ms
train.py:511:<module>, cpu: 57.77sec, accelerator: 7.59ms, total: 57.78sec
  __init__.py:194:compute_gradients, cpu: 57.77sec, accelerator: 825us, total: 57.77sec
    __init__.py:83:allreduce, cpu: 57.77sec, accelerator: 0us, total: 57.77sec
    __init__.py:86:allreduce, cpu: 5.91ms, accelerator: 825us, total: 6.76ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 6.76ms, total: 9.75ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 185.35ms, accelerator: 0us, total: 185.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.69
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1398.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_14500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 64.01sec, accelerator: 0us, total: 64.01sec (97.15%)
top 2 operation type: HistogramSummary, cpu: 1.07sec, accelerator: 0us, total: 1.07sec (1.63%)
top 3 operation type: ImageSummary, cpu: 460.00ms, accelerator: 0us, total: 460.00ms (0.70%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 186.90ms, accelerator: 0us, total: 186.90ms
top 3 graph node: difference, cpu: 142.34ms, accelerator: 0us, total: 142.34ms
train.py:511:<module>, cpu: 64.01sec, accelerator: 7.58ms, total: 64.02sec
  __init__.py:194:compute_gradients, cpu: 64.01sec, accelerator: 825us, total: 64.01sec
    __init__.py:83:allreduce, cpu: 64.01sec, accelerator: 0us, total: 64.01sec
    __init__.py:86:allreduce, cpu: 5.71ms, accelerator: 825us, total: 6.55ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 6.76ms, total: 10.23ms
train.py:515:<module>, cpu: 1.07sec, accelerator: 0us, total: 1.07sec
train.py:448:<module>, cpu: 186.90ms, accelerator: 0us, total: 186.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.08
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_14750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 61.07sec, accelerator: 0us, total: 61.07sec (97.03%)
top 2 operation type: HistogramSummary, cpu: 1.07sec, accelerator: 0us, total: 1.07sec (1.70%)
top 3 operation type: ImageSummary, cpu: 469.08ms, accelerator: 0us, total: 469.08ms (0.75%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 192.65ms, accelerator: 0us, total: 192.65ms
top 3 graph node: difference, cpu: 143.79ms, accelerator: 0us, total: 143.79ms
train.py:511:<module>, cpu: 61.08sec, accelerator: 7.19ms, total: 61.09sec
  __init__.py:194:compute_gradients, cpu: 61.07sec, accelerator: 786us, total: 61.07sec
    __init__.py:83:allreduce, cpu: 61.07sec, accelerator: 0us, total: 61.07sec
    __init__.py:86:allreduce, cpu: 5.52ms, accelerator: 786us, total: 6.32ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 6.40ms, total: 10.22ms
train.py:515:<module>, cpu: 1.07sec, accelerator: 0us, total: 1.07sec
train.py:448:<module>, cpu: 192.65ms, accelerator: 0us, total: 192.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1393.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_15000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 61.79sec, accelerator: 0us, total: 61.79sec (97.10%)
top 2 operation type: HistogramSummary, cpu: 1.07sec, accelerator: 0us, total: 1.07sec (1.68%)
top 3 operation type: ImageSummary, cpu: 464.61ms, accelerator: 0us, total: 464.61ms (0.73%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 192.10ms, accelerator: 0us, total: 192.10ms
top 3 graph node: difference, cpu: 143.88ms, accelerator: 0us, total: 143.88ms
train.py:511:<module>, cpu: 61.80sec, accelerator: 6.84ms, total: 61.80sec
  __init__.py:194:compute_gradients, cpu: 61.79sec, accelerator: 740us, total: 61.79sec
    __init__.py:83:allreduce, cpu: 61.79sec, accelerator: 0us, total: 61.79sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 740us, total: 6.26ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 6.10ms, total: 9.83ms
train.py:515:<module>, cpu: 1.07sec, accelerator: 0us, total: 1.07sec
train.py:448:<module>, cpu: 192.11ms, accelerator: 0us, total: 192.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1395.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_15250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 61.60sec, accelerator: 0us, total: 61.60sec (97.12%)
top 2 operation type: HistogramSummary, cpu: 1.07sec, accelerator: 0us, total: 1.07sec (1.68%)
top 3 operation type: ImageSummary, cpu: 460.88ms, accelerator: 0us, total: 460.88ms (0.73%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 189.70ms, accelerator: 0us, total: 189.70ms
top 3 graph node: difference, cpu: 143.86ms, accelerator: 0us, total: 143.86ms
train.py:511:<module>, cpu: 61.61sec, accelerator: 6.54ms, total: 61.62sec
  __init__.py:194:compute_gradients, cpu: 61.61sec, accelerator: 705us, total: 61.61sec
    __init__.py:83:allreduce, cpu: 61.60sec, accelerator: 0us, total: 61.60sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 705us, total: 6.07ms
  __init__.py:185:compute_gradients, cpu: 4.19ms, accelerator: 5.83ms, total: 10.06ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 189.71ms, accelerator: 0us, total: 189.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1381.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_15500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 68.38sec, accelerator: 0us, total: 68.38sec (97.41%)
top 2 operation type: HistogramSummary, cpu: 1.07sec, accelerator: 0us, total: 1.07sec (1.53%)
top 3 operation type: ImageSummary, cpu: 456.40ms, accelerator: 0us, total: 456.40ms (0.65%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 190.84ms, accelerator: 0us, total: 190.84ms
top 3 graph node: difference, cpu: 141.18ms, accelerator: 0us, total: 141.18ms
train.py:511:<module>, cpu: 68.39sec, accelerator: 6.26ms, total: 68.39sec
  __init__.py:194:compute_gradients, cpu: 68.38sec, accelerator: 679us, total: 68.38sec
    __init__.py:83:allreduce, cpu: 68.38sec, accelerator: 0us, total: 68.38sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 679us, total: 5.85ms
  __init__.py:185:compute_gradients, cpu: 4.10ms, accelerator: 5.58ms, total: 9.71ms
train.py:515:<module>, cpu: 1.07sec, accelerator: 0us, total: 1.07sec
train.py:448:<module>, cpu: 190.85ms, accelerator: 0us, total: 190.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1381.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_15750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 78.56sec, accelerator: 0us, total: 78.56sec (97.76%)
top 2 operation type: HistogramSummary, cpu: 1.06sec, accelerator: 0us, total: 1.06sec (1.32%)
top 3 operation type: ImageSummary, cpu: 454.23ms, accelerator: 0us, total: 454.23ms (0.57%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 188.60ms, accelerator: 0us, total: 188.60ms
top 3 graph node: difference, cpu: 141.55ms, accelerator: 0us, total: 141.55ms
train.py:511:<module>, cpu: 78.57sec, accelerator: 6.01ms, total: 78.58sec
  __init__.py:194:compute_gradients, cpu: 78.57sec, accelerator: 658us, total: 78.57sec
    __init__.py:83:allreduce, cpu: 78.56sec, accelerator: 0us, total: 78.56sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 658us, total: 5.68ms
  __init__.py:185:compute_gradients, cpu: 4.00ms, accelerator: 5.35ms, total: 9.38ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 188.60ms, accelerator: 0us, total: 188.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1390.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_16000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 82.40sec, accelerator: 0us, total: 82.40sec (97.86%)
top 2 operation type: HistogramSummary, cpu: 1.07sec, accelerator: 0us, total: 1.07sec (1.27%)
top 3 operation type: ImageSummary, cpu: 458.27ms, accelerator: 0us, total: 458.27ms (0.54%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 191.61ms, accelerator: 0us, total: 191.61ms
top 3 graph node: difference, cpu: 142.02ms, accelerator: 0us, total: 142.02ms
train.py:511:<module>, cpu: 82.41sec, accelerator: 5.77ms, total: 82.41sec
  __init__.py:194:compute_gradients, cpu: 82.40sec, accelerator: 633us, total: 82.41sec
    __init__.py:83:allreduce, cpu: 82.40sec, accelerator: 0us, total: 82.40sec
    __init__.py:86:allreduce, cpu: 5.24ms, accelerator: 633us, total: 5.89ms
  __init__.py:185:compute_gradients, cpu: 3.91ms, accelerator: 5.14ms, total: 9.08ms
train.py:515:<module>, cpu: 1.07sec, accelerator: 0us, total: 1.07sec
train.py:448:<module>, cpu: 191.62ms, accelerator: 0us, total: 191.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_16250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 79.59sec, accelerator: 0us, total: 79.59sec (97.79%)
top 2 operation type: HistogramSummary, cpu: 1.07sec, accelerator: 0us, total: 1.07sec (1.32%)
top 3 operation type: ImageSummary, cpu: 462.91ms, accelerator: 0us, total: 462.91ms (0.57%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 194.62ms, accelerator: 0us, total: 194.62ms
top 3 graph node: difference, cpu: 143.87ms, accelerator: 0us, total: 143.87ms
train.py:511:<module>, cpu: 79.60sec, accelerator: 5.55ms, total: 79.60sec
  __init__.py:194:compute_gradients, cpu: 79.59sec, accelerator: 614us, total: 79.59sec
    __init__.py:83:allreduce, cpu: 79.59sec, accelerator: 0us, total: 79.59sec
    __init__.py:86:allreduce, cpu: 5.11ms, accelerator: 614us, total: 5.74ms
  __init__.py:185:compute_gradients, cpu: 3.83ms, accelerator: 4.93ms, total: 8.81ms
train.py:515:<module>, cpu: 1.07sec, accelerator: 0us, total: 1.07sec
train.py:448:<module>, cpu: 194.62ms, accelerator: 0us, total: 194.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_16500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 76.99sec, accelerator: 0us, total: 76.99sec (97.74%)
top 2 operation type: HistogramSummary, cpu: 1.06sec, accelerator: 0us, total: 1.06sec (1.35%)
top 3 operation type: ImageSummary, cpu: 465.22ms, accelerator: 0us, total: 465.22ms (0.59%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 195.25ms, accelerator: 0us, total: 195.25ms
top 3 graph node: difference, cpu: 144.67ms, accelerator: 0us, total: 144.67ms
train.py:511:<module>, cpu: 77.00sec, accelerator: 5.34ms, total: 77.01sec
  __init__.py:194:compute_gradients, cpu: 77.00sec, accelerator: 588us, total: 77.00sec
    __init__.py:83:allreduce, cpu: 76.99sec, accelerator: 0us, total: 76.99sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 588us, total: 5.77ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 4.75ms, total: 8.56ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 195.25ms, accelerator: 0us, total: 195.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1362.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_16750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 92.77sec, accelerator: 0us, total: 92.77sec (98.12%)
top 2 operation type: HistogramSummary, cpu: 1.06sec, accelerator: 0us, total: 1.06sec (1.12%)
top 3 operation type: ImageSummary, cpu: 470.02ms, accelerator: 0us, total: 470.02ms (0.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 196.73ms, accelerator: 0us, total: 196.73ms
top 3 graph node: difference, cpu: 146.52ms, accelerator: 0us, total: 146.52ms
train.py:511:<module>, cpu: 92.78sec, accelerator: 5.15ms, total: 92.78sec
  __init__.py:194:compute_gradients, cpu: 92.77sec, accelerator: 562us, total: 92.77sec
    __init__.py:83:allreduce, cpu: 92.77sec, accelerator: 0us, total: 92.77sec
    __init__.py:86:allreduce, cpu: 5.07ms, accelerator: 562us, total: 5.67ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 4.58ms, total: 8.32ms
train.py:515:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
train.py:448:<module>, cpu: 196.74ms, accelerator: 0us, total: 196.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1376.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_17000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 89.91sec, accelerator: 0us, total: 89.91sec (98.05%)
top 2 operation type: HistogramSummary, cpu: 1.08sec, accelerator: 0us, total: 1.08sec (1.18%)
top 3 operation type: ImageSummary, cpu: 471.81ms, accelerator: 0us, total: 471.81ms (0.51%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 196.73ms, accelerator: 0us, total: 196.73ms
top 3 graph node: difference, cpu: 146.74ms, accelerator: 0us, total: 146.74ms
train.py:511:<module>, cpu: 89.92sec, accelerator: 4.97ms, total: 89.92sec
  __init__.py:194:compute_gradients, cpu: 89.91sec, accelerator: 540us, total: 89.91sec
    __init__.py:83:allreduce, cpu: 89.91sec, accelerator: 0us, total: 89.91sec
    __init__.py:86:allreduce, cpu: 4.97ms, accelerator: 540us, total: 5.54ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 4.43ms, total: 8.10ms
train.py:515:<module>, cpu: 1.08sec, accelerator: 0us, total: 1.08sec
train.py:448:<module>, cpu: 196.73ms, accelerator: 0us, total: 196.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_17250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 90.56sec, accelerator: 0us, total: 90.56sec (98.05%)
top 2 operation type: HistogramSummary, cpu: 1.09sec, accelerator: 0us, total: 1.09sec (1.18%)
top 3 operation type: ImageSummary, cpu: 478.65ms, accelerator: 0us, total: 478.65ms (0.52%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 200.15ms, accelerator: 0us, total: 200.15ms
top 3 graph node: difference, cpu: 149.31ms, accelerator: 0us, total: 149.31ms
train.py:511:<module>, cpu: 90.56sec, accelerator: 4.81ms, total: 90.57sec
  __init__.py:194:compute_gradients, cpu: 90.56sec, accelerator: 524us, total: 90.56sec
    __init__.py:83:allreduce, cpu: 90.56sec, accelerator: 0us, total: 90.56sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 524us, total: 5.69ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 4.28ms, total: 7.94ms
train.py:515:<module>, cpu: 1.09sec, accelerator: 0us, total: 1.09sec
train.py:448:<module>, cpu: 200.15ms, accelerator: 0us, total: 200.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_17500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 100.42sec, accelerator: 0us, total: 100.42sec (98.24%)
top 2 operation type: HistogramSummary, cpu: 1.09sec, accelerator: 0us, total: 1.09sec (1.07%)
top 3 operation type: ImageSummary, cpu: 478.17ms, accelerator: 0us, total: 478.17ms (0.47%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 199.41ms, accelerator: 0us, total: 199.41ms
top 3 graph node: difference, cpu: 149.20ms, accelerator: 0us, total: 149.20ms
train.py:511:<module>, cpu: 100.43sec, accelerator: 4.66ms, total: 100.44sec
  __init__.py:194:compute_gradients, cpu: 100.43sec, accelerator: 507us, total: 100.43sec
    __init__.py:83:allreduce, cpu: 100.42sec, accelerator: 0us, total: 100.42sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 507us, total: 5.60ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 4.15ms, total: 7.77ms
train.py:515:<module>, cpu: 1.09sec, accelerator: 0us, total: 1.09sec
train.py:448:<module>, cpu: 199.41ms, accelerator: 0us, total: 199.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1394.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_17750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 108.91sec, accelerator: 0us, total: 108.91sec (98.37%)
top 2 operation type: HistogramSummary, cpu: 1.11sec, accelerator: 0us, total: 1.11sec (1.00%)
top 3 operation type: ImageSummary, cpu: 478.55ms, accelerator: 0us, total: 478.55ms (0.43%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 199.14ms, accelerator: 0us, total: 199.14ms
top 3 graph node: difference, cpu: 149.62ms, accelerator: 0us, total: 149.62ms
train.py:511:<module>, cpu: 108.92sec, accelerator: 4.52ms, total: 108.92sec
  __init__.py:194:compute_gradients, cpu: 108.91sec, accelerator: 494us, total: 108.91sec
    __init__.py:83:allreduce, cpu: 108.91sec, accelerator: 0us, total: 108.91sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 494us, total: 5.52ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.02ms, total: 7.59ms
train.py:515:<module>, cpu: 1.11sec, accelerator: 0us, total: 1.11sec
train.py:448:<module>, cpu: 199.14ms, accelerator: 0us, total: 199.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1380.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_18000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 114.17sec, accelerator: 0us, total: 114.17sec (98.45%)
top 2 operation type: HistogramSummary, cpu: 1.10sec, accelerator: 0us, total: 1.10sec (0.95%)
top 3 operation type: ImageSummary, cpu: 479.59ms, accelerator: 0us, total: 479.59ms (0.41%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 200.38ms, accelerator: 0us, total: 200.38ms
top 3 graph node: difference, cpu: 150.11ms, accelerator: 0us, total: 150.11ms
train.py:511:<module>, cpu: 114.18sec, accelerator: 4.38ms, total: 114.18sec
  __init__.py:194:compute_gradients, cpu: 114.17sec, accelerator: 480us, total: 114.17sec
    __init__.py:83:allreduce, cpu: 114.17sec, accelerator: 0us, total: 114.17sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 480us, total: 5.49ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 3.90ms, total: 7.54ms
train.py:515:<module>, cpu: 1.10sec, accelerator: 0us, total: 1.10sec
train.py:448:<module>, cpu: 200.38ms, accelerator: 0us, total: 200.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1389.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_18250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 115.57sec, accelerator: 0us, total: 115.57sec (98.47%)
top 2 operation type: HistogramSummary, cpu: 1.11sec, accelerator: 0us, total: 1.11sec (0.94%)
top 3 operation type: ImageSummary, cpu: 481.63ms, accelerator: 0us, total: 481.63ms (0.41%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 202.02ms, accelerator: 0us, total: 202.02ms
top 3 graph node: difference, cpu: 150.26ms, accelerator: 0us, total: 150.26ms
train.py:511:<module>, cpu: 115.58sec, accelerator: 4.26ms, total: 115.59sec
  __init__.py:194:compute_gradients, cpu: 115.58sec, accelerator: 470us, total: 115.58sec
    __init__.py:83:allreduce, cpu: 115.57sec, accelerator: 0us, total: 115.57sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 470us, total: 5.40ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 3.79ms, total: 7.37ms
train.py:515:<module>, cpu: 1.11sec, accelerator: 0us, total: 1.11sec
train.py:448:<module>, cpu: 202.02ms, accelerator: 0us, total: 202.02ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_18500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 121.83sec, accelerator: 0us, total: 121.83sec (98.55%)
top 2 operation type: HistogramSummary, cpu: 1.11sec, accelerator: 0us, total: 1.11sec (0.90%)
top 3 operation type: ImageSummary, cpu: 480.91ms, accelerator: 0us, total: 480.91ms (0.39%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 201.99ms, accelerator: 0us, total: 201.99ms
top 3 graph node: difference, cpu: 150.07ms, accelerator: 0us, total: 150.07ms
train.py:511:<module>, cpu: 121.84sec, accelerator: 4.14ms, total: 121.84sec
  __init__.py:194:compute_gradients, cpu: 121.83sec, accelerator: 460us, total: 121.83sec
    __init__.py:83:allreduce, cpu: 121.83sec, accelerator: 0us, total: 121.83sec
    __init__.py:86:allreduce, cpu: 4.80ms, accelerator: 460us, total: 5.29ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 3.68ms, total: 7.30ms
train.py:515:<module>, cpu: 1.11sec, accelerator: 0us, total: 1.11sec
train.py:448:<module>, cpu: 201.99ms, accelerator: 0us, total: 201.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1387.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9cnn21-dse-henso/timelines/t.json_18750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 118.70sec, accelerator: 0us, total: 118.70sec (98.52%)
top 2 operation type: HistogramSummary, cpu: 1.10sec, accelerator: 0us, total: 1.10sec (0.91%)
top 3 operation type: ImageSummary, cpu: 477.86ms, accelerator: 0us, total: 477.86ms (0.40%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 201.41ms, accelerator: 0us, total: 201.41ms
top 3 graph node: difference, cpu: 148.85ms, accelerator: 0us, total: 148.85ms
train.py:511:<module>, cpu: 118.71sec, accelerator: 4.03ms, total: 118.71sec
  __init__.py:194:compute_gradients, cpu: 118.71sec, accelerator: 451us, total: 118.71sec
    __init__.py:83:allreduce, cpu: 118.70sec, accelerator: 0us, total: 118.70sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 451us, total: 5.29ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 3.58ms, total: 7.16ms
train.py:515:<module>, cpu: 1.10sec, accelerator: 0us, total: 1.10sec
train.py:448:<module>, cpu: 201.41ms, accelerator: 0us, total: 201.41ms
