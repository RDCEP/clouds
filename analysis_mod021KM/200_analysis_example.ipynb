{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to practice inference & clustering & stats analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pyhdf.SD import SD, SDC \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches as mpl_patches\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Prerequisites\n",
    "Libraries below are necessary to download on you laptop (If disk amount is issue, we can move to Midway cluster-computer where the analysis is much easier if you have already got the access)\n",
    "\n",
    "1. Tensorflow 1.12.0 for CPU [stackoverflow How to install CPU version of Tnesorflow](https://stackoverflow.com/questions/53614262/how-to-install-cpu-version-of-tensorflow-using-conda)\n",
    "2. Agglometative clustering from scikit-learn.  \n",
    " How to donwload agglomerative [sklearn aggl](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)  \n",
    "\n",
    "`from sklearn.cluster import AgglomerativeClustering`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful resource\n",
    "- `clouds/analysis_mod021KM/017_m2_02_clustering-stats_with-without_DNNprocessing.ipynb`\n",
    "- `clouds/analysis_mod021KM/016_m2_02_clustering_with-without_CloudFlags.ipynb`  \n",
    "These notebooks contain lot of original function/analysis (especially 017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a trained DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model directory path\n",
    "modeldir = \"\"\n",
    "step = 100000 # DO NOT CHANGE so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_def = modeldir+'/encoder.json'\n",
    "encoder_weight = modeldir+'/encoder-'+str(step)+'.h5'\n",
    "with open(encoder_def, \"r\") as f:\n",
    "    encoder = tf.keras.models.model_from_json(f.read())\n",
    "encoder.load_weights(encoder_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MODIS 02, 35 data below\n",
    "- Try to code by yourself based on practice notebook (firstly look into notebooks, and then if anything questions you havev, ask Takuya how to do this.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "1. Start at N = 12  (N is number of clusters)\n",
    "2. Next try N = 48\n",
    "3. Next vary the N. Apply N = 4, 8, 12, ... 52 (every4) or 4,6,8,...,50(every2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats analysis\n",
    "At first from N = 12 case.\n",
    "0. Compute mean value of each patch with respect to 4 clouds physics parameters as follwoing\n",
    " - optical thickness\n",
    " - water path\n",
    " - particle phase\n",
    " - top pressure\n",
    " \n",
    "1. compute distributions, mean, stdv of these clouds physics parameters \n",
    "\n",
    "2. Plot histogram about the distribution. Add mean and std information on these figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
