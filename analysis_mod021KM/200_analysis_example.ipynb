{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to practice inference & clustering & stats analysis \n",
    "\n",
    "You can ask question to Takuya when you have stacked at some parts. Accurate job is necessary rather than just finishing fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pyhdf.SD import SD, SDC \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches as mpl_patches\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Prerequisites\n",
    "Libraries below are necessary to download on you laptop (If disk amount is issue, we can move to Midway cluster-computer where the analysis is much easier if you have already got the access)\n",
    "\n",
    "1. Tensorflow 1.12.0 for CPU [stackoverflow How to install CPU version of Tnesorflow](https://stackoverflow.com/questions/53614262/how-to-install-cpu-version-of-tensorflow-using-conda)\n",
    "2. Agglometative clustering from scikit-learn.  \n",
    " How to donwload agglomerative [sklearn aggl](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)  \n",
    "\n",
    "`from sklearn.cluster import AgglomerativeClustering`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful resource\n",
    "- `clouds/analysis_mod021KM/017_m2_02_clustering-stats_with-without_DNNprocessing.ipynb`  (Workflow in your task is almost same as this 017 notebook)\n",
    "- `clouds/analysis_mod021KM/016_m2_02_clustering_with-without_CloudFlags.ipynb`  \n",
    "These notebooks contain lot of original function/analysis (especially 017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a trained DNN model\n",
    "Model name: `m2_04_global_2000_2018_band28_29_31`  \n",
    "Model Directory: ```/project2/foster/clouds/model/m2_04_global_2000_2018_band28_29_31```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model directory path\n",
    "modeldir = \"\"\n",
    "step = 100000 # DO NOT CHANGE so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_def = modeldir+'/encoder.json'\n",
    "encoder_weight = modeldir+'/encoder-'+str(step)+'.h5'\n",
    "with open(encoder_def, \"r\") as f:\n",
    "    encoder = tf.keras.models.model_from_json(f.read())\n",
    "encoder.load_weights(encoder_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "Test image can be any date of hdf file.  \n",
    "However, it is interesting to use same dataset which I used in 017 notebook. These data are placed at  \n",
    "   - MOD02 ```/project2/foster/clouds/data/shared/test_img/MOD02/20150628```\n",
    "   - MOD35 ```/project2/foster/clouds/data/shared/test_img/MOD35/20150628```\n",
    "   - MOD06 ```/project2/foster/clouds/data/shared/test_img/MOD06/20150628```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Files\n",
    "##### MOD02\n",
    "Using band: Following band information is necessary.\n",
    "*Visible bands*  \n",
    "- Band 6 : XXX_EV_500_Aggr1km_RefSB_4.hdf\n",
    "- Band 7 : XXX_EV_500_Aggr1km_RefSB_5.hdf\n",
    "*Thermal bands*  \n",
    "- Band 20: YYY_.EV_1KM_Emissive_1.hdf\n",
    "- Band 28: YYY_EV_1KM_Emissive_8.hdf\n",
    "- Band 29: YYY_EV_1KM_Emissive_9.hdf\n",
    "- Band 31: YYY_EV_1KM_Emissive_11.hdf\n",
    "\n",
    "##### MOD35\n",
    "- Layer 0: ZZZ_Cloud_Mask_1.hdf  \n",
    "(IN general, MOD35 has 6 layers-3D array. But here, each layer splits into each file. So Mask_1 corresponds to layer 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MODIS 02, 35 data below\n",
    "- Try to code by yourself based on practice notebook (firstly look into notebooks, and then if anything questions you havev, ask Takuya how to do this.)\n",
    "\n",
    "\n",
    "- (**IMPORTANT**) These files are separated by each variable s.t. temperature data is downloaded as XXX_Clouds_top_temperature.hdf. So, you may need to modify loading functions you have coded until yesterday for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment MOD02 + MOD35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "1. Start at N = 12  (N is number of clusters)\n",
    "2. Next try N = 48\n",
    "3. Next vary the N. Apply N = 4, 8, 12, ... 80 (every4) or you can do every (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with MOD06\n",
    "0. Decode MOD06\n",
    "1. Compute patch-wise mean (mean of physics parameter within a patch) with respect to 4 clouds physics parameters as follwoing\n",
    " - optical thickness\n",
    " - water path\n",
    " - particle phase\n",
    " - top pressure\n",
    " \n",
    "2. About `Cloud Phase Infrared`, you should compute mode. Ask me if you have trouble.\n",
    "\n",
    "3. compute distributions, mean, stdv of these clouds physics parameters \n",
    "\n",
    "4. Plot histogram about the distribution. Add mean and std information on these figures\n",
    "\n",
    "At first from N = 12 case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine intensity (radiation of original data)\n",
    "Compute mean radiation and plot its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
