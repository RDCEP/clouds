{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for Open/Closed label clustering\n",
    "\n",
    "Model : m2_normed \n",
    "\n",
    "m2_normed_model was trained by patches with standardized at mean 0 stdv ~1\n",
    "\n",
    "\n",
    "`Where is the global Mean and Std\n",
    "/project2/foster/clouds/data/clouds_laads_preprocessed_2000_2018_band28_29_31/global_mean_std\n",
    "`\n",
    "\n",
    "` How to load\n",
    "modeldir = \"/project2/foster/clouds/model/m2_02_global_2000_2018_band28_29_31_normed\"  \n",
    "step = 100000 # DO NOT CHANGE so far  \n",
    "encoder = load_model(model_dir=modeldir, epoch=step, mtype='encoder')  \n",
    "`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pyhdf.SD import SD, SDC \n",
    "from scipy import stats\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import patches as mpl_patches\n",
    "\n",
    "# clusterings\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# TSNE\n",
    "from sklearn.manifold import TSNE as TSNEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir, epoch, mtype):\n",
    "    print(\" Load {} at {} epoch\".format(mtype, epoch))\n",
    "    model_def = model_dir+'/'+mtype+'.json'\n",
    "    model_weight = model_dir+'/'+mtype+'-'+str(epoch)+'.h5'\n",
    "    with open(model_def, \"r\") as f:\n",
    "        model = tf.keras.models.model_from_json(f.read())\n",
    "    model.load_weights(model_weight)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_agl(encoder, patches_list,n_cluster = 12):\n",
    "    encs_list = []\n",
    "    for i in patches_list:\n",
    "        encs = encoder.predict(i.reshape(1,128,128,6))\n",
    "        encs_list += [encs.mean(axis=(1,2))]\n",
    "    features = np.concatenate(encs_list, axis=0)\n",
    "    method = AgglomerativeClustering(n_clusters=n_cluster)\n",
    "    _patches_labels = method.fit(features)\n",
    "    return _patches_labels.labels_, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load label data\n",
    "Maybe Ruby's notebook is helpful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here, you should write script to load your labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-score standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_dir = \"/project2/foster/clouds/data/clouds_laads_preprocessed_2000_2018_band28_29_31/global_mean_std\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmean = np.load(os.path.join(mean_std_dir, \"m2_02_band28_29_31_gmean.npy\"))\n",
    "gstdv = np.load(os.path.join(mean_std_dir, \"m2_02_band28_29_31_gstdv.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here you normalized by global mena and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster =  # iterate from 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_list = # list of patches e.g. [  array(128,128,6), ...., array(128,128,6) ] array is numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer `clouds/src_analysis/cloud_label/visualize_patches.ipynb`  \n",
    "\n",
    "###### visualization item\n",
    "- clustering result open and closed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_patches():\n",
    "    \"\"\"\n",
    "    creates a grid of displaying which patches are in which clusters, visualization tool\n",
    "    \n",
    "    NOTE: Sometimes there are large gaps between patches, this problem can be solved by playing around with figsize \n",
    "    (if there are large horizontal gaps between columns, decrease x value, vice versa for y)\n",
    "    \n",
    "    Inputs: \n",
    "    None\n",
    "    \n",
    "    Outputs:\n",
    "    None, displayes a grid of patches organized by cluster\n",
    "    \"\"\"\n",
    "    #set rows to the max amount of patches in any of the clusters\n",
    "    #set cols to the number of clusters (one column for each cluster)\n",
    "    rows = len(max(list_clusters, key=lambda c: len(c.patches)).patches)\n",
    "    cols = num_clusters\n",
    "    \n",
    "    #create plot\n",
    "    f, axarr = plt.subplots(rows,cols,figsize=(20,10))\n",
    "\n",
    "    for c in range(cols):\n",
    "        axarr[0,c].set_title(str(c), fontsize=18)\n",
    "        arr = get_open_patches(c) + get_closed_patches(c)\n",
    "\n",
    "        if len(arr) == 1:\n",
    "            axarr[0,c].imshow(arr[0])\n",
    "            axarr[0,c].axis('off')\n",
    "            for r in range(1, rows):\n",
    "                plt.delaxes(axarr[r][c])\n",
    "        else:\n",
    "            arr_iter = iter(arr)\n",
    "            for r in range(rows):\n",
    "                try:\n",
    "                    axarr[r,c].imshow(next(arr_iter))\n",
    "                    axarr[r,c].axis('off')\n",
    "                except:\n",
    "                    while r < rows:\n",
    "                        plt.delaxes(axarr[r][c])\n",
    "                        r += 1\n",
    "                    break\n",
    "    plt.savefig(to_save + '%d_patch_pics.png'%(num_clusters))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
