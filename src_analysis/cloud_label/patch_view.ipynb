{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches as mpl_patches\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.patheffects as PathEffects\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# pyspark libs\n",
    "#import pyspark\n",
    "#from pyspark import SparkContext \n",
    "#from pyspark.mllib.clustering import BisectingKMeans, BisectingKMeansModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## directory where your put lib_hdfs\n",
    "libdir='/home/rubywerman/scratch-midway2/lib_hdfs'\n",
    "\n",
    "sys.path.insert(1,os.path.join(sys.path[0],libdir)) # this line helps you to use your own functions in another directory\n",
    "from alignment_lib import _gen_patches\n",
    "from alignment_lib import const_clouds_array\n",
    "from alignment_lib import gen_mod02_img_sigle,  gen_mod35_img_single\n",
    "from alignment_lib import mod02_proc_sds_single\n",
    "from alignment_lib import _gen_patches\n",
    "from alignment_lib import const_clouds_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homedir = libdir\n",
    "datadir = homedir+\"/model/m2_02_global_2000_2018_band28_29_31\"\n",
    "step = 100000 # DONOT change so far\n",
    "\n",
    "encoder_def = datadir+'/encoder.json'\n",
    "encoder_weight = datadir+'/encoder-'+str(step)+'.h5'\n",
    "with open(encoder_def, \"r\") as f:\n",
    "    encoder = tf.keras.models.model_from_json(f.read())\n",
    "encoder.load_weights(encoder_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from pyhdf.SD import SD, SDC\n",
    "\n",
    "# directory where your put lib_hdfs\n",
    "# e.g. /home/tkurihana/src/src_share/lib_hdfs\n",
    "homedir='/home/rubywerman/scratch-midway2/lib_hdfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0712 16:35:03.127253 140297144956736 deprecation.py:506] From /home/rubywerman/.conda/envs/clouds/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0712 16:35:03.129428 140297144956736 deprecation.py:506] From /home/rubywerman/.conda/envs/clouds/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "/home/rubywerman/.conda/envs/clouds/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:891: UserWarning: models is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  , UserWarning)\n",
      "W0712 16:35:03.179719 140297144956736 deprecation.py:506] From /home/rubywerman/.conda/envs/clouds/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0712 16:35:03.420542 140297144956736 deprecation_wrapper.py:119] From /scratch/midway2/tkurihana/clouds/reproduction/models.py:64: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(1,os.path.join(sys.path[0],homedir)) # this line helps you to use your own functinos in another directory\n",
    "from alignment_lib import gen_mod02_img_sigle,  gen_mod35_img_single\n",
    "from alignment_lib import mod02_proc_sds_single\n",
    "from alignment_lib import _gen_patches\n",
    "from alignment_lib import const_clouds_array\n",
    "\n",
    "\n",
    "# enter name of text file containing the dates of the closed patches\n",
    "closed_file_name = \"/home/rubywerman/clouds/src_analysis/close_cells_mod02/close_dates.txt\"\n",
    "closed_text_file = open(closed_file_name, \"r\")\n",
    "closed_dates = closed_text_file.read().split('\\n')\n",
    "\n",
    "# enter name of text file containing the dates of the open patches\n",
    "open_file_name = \"/home/rubywerman/clouds/src_analysis/open_cells_mod02/open_dates.txt\"\n",
    "open_text_file = open(open_file_name, \"r\")\n",
    "open_dates = open_text_file.read().split('\\n')\n",
    "\n",
    "#select directory path for given date\n",
    "def get_data(d):\n",
    "    return (homedir+'/mod02/open_chile_3/' + d, homedir+'/mod35/open_chile_3/' + d, get_coded_date(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patch:        \n",
    "    def __init__(self, date, isOpen, thirtyFive, zeroTwo, label=None, feature=None, has_coord=False, coords=None):\n",
    "        self.date = date\n",
    "        self.isOpen = isOpen\n",
    "        self.thirtyFive = thirtyFive\n",
    "        self.zeroTwo = zeroTwo\n",
    "        self.label = label\n",
    "        self.feature = feature\n",
    "        self.has_coord = has_coord\n",
    "        self.coords = coords\n",
    "        \n",
    "    def print_attr(self):\n",
    "        print(\"date: \" + self.date)\n",
    "        print(\"isOpen: \" + str(self.isOpen))\n",
    "        print(\"label: \" + str(self.label))\n",
    "        if len(self.coords) > 0:\n",
    "            print(\"coords: \")\n",
    "            for i in self.coords:\n",
    "                print(str(i))\n",
    "        \n",
    "        \n",
    "class Cluster:\n",
    "    def __init__(self, label, patches=None, means=None, std=None, num_open=0):\n",
    "        self.label = label\n",
    "        self.patches = patches\n",
    "        self.means = means\n",
    "        self.std = std\n",
    "        self.num_open = num_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patches recorded: 239\n"
     ]
    }
   ],
   "source": [
    "#generates list of 6 means for each band in the patch list \n",
    "def get_band_means(patch_list):\n",
    "    mean_list = []\n",
    "    for i in range(6):\n",
    "        mean_list.append(np.nanmean([patch.zeroTwo[0,0,:,:,:][:,:,i] for patch in patch_list]))\n",
    "    return mean_list\n",
    "\n",
    "#generates list of 6 stds for each band in the patch list \n",
    "def get_band_std(patch_list):\n",
    "    std_list = []\n",
    "    for i in range(6):\n",
    "        std_list.append(np.nanstd([patch.zeroTwo[0,0,:,:,:][:,:,i] for patch in patch_list]))\n",
    "    return std_list\n",
    "\n",
    "#collect close patch 35 and 02 data\n",
    "closed_patch_class_list = []\n",
    "#closed_clouds_mask_img_data = []\n",
    "for d in closed_dates:\n",
    "    if d:\n",
    "        file_name_a = '/home/rubywerman/clouds/src_analysis/close_cells_mod02/closed_'+ d +'.npy'\n",
    "        #closed_date_data = np.load(file_name_a[:72] + file_name_a[-4:])\n",
    "        closed_date_data = np.load(file_name_a)\n",
    "        #file_name_b = '/home/rubywerman/clouds/src_analysis/close_cells_coords/closed_coords'+ d +'.npy'\n",
    "        #thirtyFive = np.load('/home/rubywerman/clouds/src_analysis/close_35/close_35_'+ d +'.npy')\n",
    "        #coords = np.load(file_name_b[:79] + file_name_b[-4:])\n",
    "        #ccloud_img = np.load('/home/rubywerman/clouds/src_analysis/close_cells_mod35/closed_35_'+ d +'.npy')\n",
    "        #closed_clouds_mask_img_data.append(ccloud_img)\n",
    "        for patch in range(len(closed_date_data)):\n",
    "            closed_patch_class_list.append(Patch(date=d, isOpen=False, thirtyFive=None, zeroTwo=closed_date_data[patch], label=None, feature=None, has_coord=True, coords=None))\n",
    "#collect open patch 35 and 02 data\n",
    "#open_clouds_mask_img_data = []\n",
    "open_patch_class_list = []\n",
    "for d in open_dates:\n",
    "    if d:\n",
    "        file_name_a = '/home/rubywerman/clouds/src_analysis/open_cells_mod02/open_'+ d +'.npy'\n",
    "        #open_date_data = np.load(file_name_a[:69] + file_name_a[-4:])\n",
    "        open_date_data = np.load(file_name_a)\n",
    "        #file_name_b = '/home/rubywerman/clouds/src_analysis/open_cells_coords/open_coords'+ d +'.npy'\n",
    "        #coords = np.load(file_name_b[:76] + file_name_b[-4:])\n",
    "        #thirtyFive = np.load('/home/rubywerman/clouds/src_analysis/open_35/open_35_'+ d +'.npy')\n",
    "        #ccloud_img = np.load('/home/rubywerman/clouds/src_analysis/close_cells_mod35/closed_35_'+ d +'.npy')\n",
    "        #closed_clouds_mask_img_data.append(ccloud_img)\n",
    "        for patch in range(len(open_date_data)):\n",
    "            open_patch_class_list.append(Patch(date=d, isOpen=True, thirtyFive=None, zeroTwo=open_date_data[patch], label=None, feature=None, has_coord=True, coords=None))\n",
    "# here make patches list\n",
    "class_patch_list = open_patch_class_list + closed_patch_class_list\n",
    "lenn = len(open_patch_class_list)\n",
    "print(\"Number of patches recorded: \" + str(len(class_patch_list)))            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encs_list = []\n",
    "for patch in class_patch_list:\n",
    "    i = patch.zeroTwo\n",
    "    if type(i) is not list:\n",
    "        ix, iy = i.shape[:2]\n",
    "        encs = encoder.predict(i.reshape(ix * iy, 128,128,6))\n",
    "        encs_list += [encs.mean(axis=(1,2))]\n",
    "features = np.concatenate(encs_list, axis=0)\n",
    "print(features.shape)  # make sure, the shape is [#number of patches, 128]\n",
    "#the first %num_open_features rows in features are open cells \n",
    "num_open_features = len(open_patch_class_list)\n",
    "#starting at row %num_open_features in features they are closed cells \n",
    "num_closed_features = len(closed_patch_class_list)\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "num_clusters = 2\n",
    "clustering = AgglomerativeClustering(num_clusters)\n",
    "#turns any NAN values to 0 so code doesn't crash\n",
    "cleaned_features = np.nan_to_num(features)\n",
    "#generate clustering data\n",
    "label = clustering.fit_predict(cleaned_features)\n",
    "open_labels = label[:num_closed_features]\n",
    "closed_labels = label[num_closed_features:]\n",
    "#assign each patch instance its correct label\n",
    "for i in range(len(class_patch_list)):\n",
    "    class_patch_list[i].label = label[i]\n",
    "    \n",
    "#make a list of clusters\n",
    "list_clusters = [Cluster(label=i) for i in range(num_clusters)]\n",
    "#add patches to cluster objects\n",
    "for p in class_patch_list:\n",
    "    matching_cluster = list_clusters[p.label]\n",
    "    if p.isOpen:\n",
    "        matching_cluster.num_open += 1\n",
    "    if not matching_cluster.patches:\n",
    "        matching_cluster.patches = [p]\n",
    "    else:\n",
    "        matching_cluster.patches.append(p)\n",
    "#add patch mean and std to cluster objects\n",
    "for c in list_clusters:\n",
    "    c.means = get_band_means(c.patches)\n",
    "    c.std = get_band_std(c.patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate number of open and closed patches in each cluster\n",
    "open_clusters = [i.num_open for i in list_clusters]\n",
    "closed_clusters = [len(i.patches) - i.num_open for i in list_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_in_0 = [patch for patch in list_clusters[0].patches if patch.isOpen]\n",
    "o_list_pics = []\n",
    "for i in range(len(open_in_0)):\n",
    "    p = open_in_0[i]\n",
    "    o_list_pics.append(p.thirtyFive[p.coords[0]*128:p.coords[1]*128,p.coords[2]*128:p.coords[3]*128])\n",
    "len(o_list_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_in_0 = [patch for patch in list_clusters[0].patches if not patch.isOpen]\n",
    "c_list_pics = []\n",
    "for i in range(len(closed_in_0)):\n",
    "    p = closed_in_0[i]\n",
    "    c_list_pics.append(p.thirtyFive[p.coords[0]*128:p.coords[1]*128,p.coords[2]*128:p.coords[3]*128])\n",
    "len(c_list_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=16\n",
    "h=16\n",
    "fig1=plt.figure(figsize=(8, 8))\n",
    "columns1 = len(o_list_pics)\n",
    "rows1 = 1 \n",
    "for i in range(1, columns1*rows1 +1):\n",
    "    fig1.add_subplot(rows1, columns1, i)\n",
    "    plt.imshow(o_list_pics[i-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=16\n",
    "h=16\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = len(c_list_pics)//8\n",
    "rows = columns + 1\n",
    "for i in range(1, columns*rows +1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(c_list_pics[i-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
