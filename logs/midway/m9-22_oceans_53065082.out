Parsing Inputs...
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_0.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.68

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 134.79ms, accelerator: 0us, total: 134.79ms (23.87%)
top 2 operation type: HistogramSummary, cpu: 57.44ms, accelerator: 0us, total: 57.44ms (10.17%)
top 3 operation type: DepthwiseConv2dNative, cpu: 381us, accelerator: 46.92ms, total: 47.30ms (8.38%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: original, cpu: 52.60ms, accelerator: 0us, total: 52.60ms
train.py:441:<module> (gradient), cpu: 4.58ms, accelerator: 68.09ms, total: 72.66ms
train.py:442:<module>, cpu: 3.67ms, accelerator: 63.78ms, total: 67.45ms
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 56.27ms, total: 59.19ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 56.27ms, total: 59.17ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 56.26ms, total: 59.11ms
  train.py:359:image_losses, cpu: 541us, accelerator: 6.45ms, total: 6.99ms
    train.py:322:loss_fn, cpu: 535us, accelerator: 6.45ms, total: 6.98ms
      train.py:342:hfe, cpu: 197us, accelerator: 2.41ms, total: 2.61ms
      train.py:343:hfe, cpu: 201us, accelerator: 2.41ms, total: 2.61ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.62ms, total: 1.76ms
train.py:442:<module> (gradient), cpu: 3.28ms, accelerator: 53.25ms, total: 56.53ms
  train.py:360:image_losses (gradient), cpu: 2.85ms, accelerator: 47.53ms, total: 50.38ms
  train.py:359:image_losses (gradient), cpu: 335us, accelerator: 4.30ms, total: 4.64ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 149.23ms, accelerator: 0us, total: 149.23ms (26.74%)
top 2 operation type: HistogramSummary, cpu: 58.79ms, accelerator: 0us, total: 58.79ms (10.53%)
top 3 operation type: AddN, cpu: 1.74ms, accelerator: 24.12ms, total: 25.88ms (4.64%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: original, cpu: 52.02ms, accelerator: 0us, total: 52.02ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 59.77ms, total: 65.17ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 55.01ms, total: 58.83ms
  train.py:360:image_losses (gradient), cpu: 3.34ms, accelerator: 50.62ms, total: 53.98ms
  train.py:359:image_losses (gradient), cpu: 359us, accelerator: 2.80ms, total: 3.16ms
  train.py:358:image_losses (gradient), cpu: 48us, accelerator: 1.26ms, total: 1.31ms
train.py:447:<module>, cpu: 52.03ms, accelerator: 0us, total: 52.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 151.94ms, accelerator: 0us, total: 151.94ms (28.06%)
top 2 operation type: HistogramSummary, cpu: 58.02ms, accelerator: 0us, total: 58.02ms (10.71%)
top 3 operation type: AddN, cpu: 1.59ms, accelerator: 25.55ms, total: 27.17ms (5.02%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 57.18ms, accelerator: 0us, total: 57.18ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.12ms, accelerator: 67.08ms, total: 72.22ms
train.py:448:<module>, cpu: 57.18ms, accelerator: 0us, total: 57.18ms
train.py:447:<module>, cpu: 50.02ms, accelerator: 0us, total: 50.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 152.97ms, accelerator: 0us, total: 152.97ms (28.39%)
top 2 operation type: HistogramSummary, cpu: 56.84ms, accelerator: 0us, total: 56.84ms (10.55%)
top 3 operation type: AddN, cpu: 1.58ms, accelerator: 22.41ms, total: 24.02ms (4.46%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 59.85ms, accelerator: 0us, total: 59.85ms
top 3 graph node: original, cpu: 48.81ms, accelerator: 0us, total: 48.81ms
train.py:441:<module> (gradient), cpu: 5.00ms, accelerator: 59.64ms, total: 64.67ms
train.py:448:<module>, cpu: 59.85ms, accelerator: 0us, total: 59.85ms
train.py:436:<module> (gradient), cpu: 5.27ms, accelerator: 48.23ms, total: 53.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_1000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 156.59ms, accelerator: 0us, total: 156.59ms (28.77%)
top 2 operation type: HistogramSummary, cpu: 57.12ms, accelerator: 0us, total: 57.12ms (10.50%)
top 3 operation type: Mul, cpu: 2.05ms, accelerator: 22.53ms, total: 24.61ms (4.52%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 62.92ms, accelerator: 0us, total: 62.92ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 62.93ms, accelerator: 0us, total: 62.93ms
train.py:441:<module> (gradient), cpu: 5.07ms, accelerator: 50.84ms, total: 55.95ms
train.py:436:<module> (gradient), cpu: 5.37ms, accelerator: 46.94ms, total: 52.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_1250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 161.36ms, accelerator: 0us, total: 161.36ms (29.51%)
top 2 operation type: HistogramSummary, cpu: 56.92ms, accelerator: 0us, total: 56.92ms (10.41%)
top 3 operation type: Mul, cpu: 2.04ms, accelerator: 24.50ms, total: 26.58ms (4.86%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 66.73ms, accelerator: 0us, total: 66.73ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 66.74ms, accelerator: 0us, total: 66.74ms
train.py:441:<module> (gradient), cpu: 4.96ms, accelerator: 53.72ms, total: 58.72ms
train.py:436:<module> (gradient), cpu: 5.42ms, accelerator: 43.30ms, total: 48.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_1500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 161.81ms, accelerator: 0us, total: 161.81ms (29.74%)
top 2 operation type: HistogramSummary, cpu: 56.92ms, accelerator: 0us, total: 56.92ms (10.46%)
top 3 operation type: Mul, cpu: 2.04ms, accelerator: 24.79ms, total: 26.86ms (4.94%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 68.00ms, accelerator: 0us, total: 68.00ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 68.01ms, accelerator: 0us, total: 68.01ms
train.py:441:<module> (gradient), cpu: 4.89ms, accelerator: 56.60ms, total: 61.53ms
train.py:436:<module> (gradient), cpu: 5.37ms, accelerator: 47.53ms, total: 52.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_1750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 164.40ms, accelerator: 0us, total: 164.40ms (30.12%)
top 2 operation type: HistogramSummary, cpu: 57.11ms, accelerator: 0us, total: 57.11ms (10.46%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.48ms, accelerator: 25.45ms, total: 26.93ms (4.93%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 70.02ms, accelerator: 0us, total: 70.02ms
top 3 graph node: original, cpu: 48.23ms, accelerator: 0us, total: 48.23ms
train.py:448:<module>, cpu: 70.03ms, accelerator: 0us, total: 70.03ms
train.py:441:<module> (gradient), cpu: 4.96ms, accelerator: 54.69ms, total: 59.69ms
train.py:436:<module> (gradient), cpu: 5.40ms, accelerator: 50.40ms, total: 55.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_2000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 167.37ms, accelerator: 0us, total: 167.37ms (30.48%)
top 2 operation type: HistogramSummary, cpu: 57.15ms, accelerator: 0us, total: 57.15ms (10.41%)
top 3 operation type: Mul, cpu: 2.02ms, accelerator: 24.94ms, total: 27.01ms (4.92%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 71.46ms, accelerator: 0us, total: 71.46ms
top 3 graph node: original, cpu: 48.76ms, accelerator: 0us, total: 48.76ms
train.py:448:<module>, cpu: 71.46ms, accelerator: 0us, total: 71.46ms
train.py:441:<module> (gradient), cpu: 4.92ms, accelerator: 50.28ms, total: 55.24ms
train.py:436:<module> (gradient), cpu: 5.40ms, accelerator: 48.62ms, total: 54.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_2250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 168.43ms, accelerator: 0us, total: 168.43ms (30.61%)
top 2 operation type: HistogramSummary, cpu: 57.14ms, accelerator: 0us, total: 57.14ms (10.38%)
top 3 operation type: Mul, cpu: 2.03ms, accelerator: 25.15ms, total: 27.21ms (4.95%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 71.53ms, accelerator: 0us, total: 71.53ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 71.54ms, accelerator: 0us, total: 71.54ms
train.py:441:<module> (gradient), cpu: 4.90ms, accelerator: 50.24ms, total: 55.17ms
train.py:436:<module> (gradient), cpu: 5.46ms, accelerator: 45.55ms, total: 51.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_2500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 170.26ms, accelerator: 0us, total: 170.26ms (30.98%)
top 2 operation type: HistogramSummary, cpu: 56.65ms, accelerator: 0us, total: 56.65ms (10.31%)
top 3 operation type: Mul, cpu: 2.03ms, accelerator: 25.09ms, total: 27.17ms (4.94%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 73.26ms, accelerator: 0us, total: 73.26ms
top 3 graph node: original, cpu: 48.77ms, accelerator: 0us, total: 48.77ms
train.py:448:<module>, cpu: 73.26ms, accelerator: 0us, total: 73.26ms
train.py:441:<module> (gradient), cpu: 4.95ms, accelerator: 52.20ms, total: 57.20ms
train.py:436:<module> (gradient), cpu: 5.43ms, accelerator: 48.30ms, total: 53.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_2750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 172.13ms, accelerator: 0us, total: 172.13ms (31.24%)
top 2 operation type: HistogramSummary, cpu: 56.60ms, accelerator: 0us, total: 56.60ms (10.27%)
top 3 operation type: Mul, cpu: 2.02ms, accelerator: 24.86ms, total: 26.93ms (4.89%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 74.35ms, accelerator: 0us, total: 74.35ms
top 3 graph node: original, cpu: 48.95ms, accelerator: 0us, total: 48.95ms
train.py:448:<module>, cpu: 74.35ms, accelerator: 0us, total: 74.35ms
train.py:441:<module> (gradient), cpu: 4.94ms, accelerator: 51.30ms, total: 56.28ms
train.py:436:<module> (gradient), cpu: 5.42ms, accelerator: 49.99ms, total: 55.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_3000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 172.09ms, accelerator: 0us, total: 172.09ms (31.24%)
top 2 operation type: HistogramSummary, cpu: 56.45ms, accelerator: 0us, total: 56.45ms (10.25%)
top 3 operation type: Mul, cpu: 2.03ms, accelerator: 25.57ms, total: 27.64ms (5.02%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 74.92ms, accelerator: 0us, total: 74.92ms
top 3 graph node: difference, cpu: 48.66ms, accelerator: 0us, total: 48.66ms
train.py:448:<module>, cpu: 74.93ms, accelerator: 0us, total: 74.93ms
train.py:436:<module> (gradient), cpu: 5.38ms, accelerator: 48.64ms, total: 54.06ms
train.py:441:<module> (gradient), cpu: 4.97ms, accelerator: 48.52ms, total: 53.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_3250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 173.43ms, accelerator: 0us, total: 173.43ms (31.46%)
top 2 operation type: HistogramSummary, cpu: 56.19ms, accelerator: 0us, total: 56.19ms (10.19%)
top 3 operation type: Mul, cpu: 2.03ms, accelerator: 25.27ms, total: 27.34ms (4.96%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 75.74ms, accelerator: 0us, total: 75.74ms
top 3 graph node: difference, cpu: 49.69ms, accelerator: 0us, total: 49.69ms
train.py:448:<module>, cpu: 75.74ms, accelerator: 0us, total: 75.74ms
train.py:441:<module> (gradient), cpu: 5.00ms, accelerator: 48.95ms, total: 54.00ms
train.py:436:<module> (gradient), cpu: 5.37ms, accelerator: 45.96ms, total: 51.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_3500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 173.31ms, accelerator: 0us, total: 173.31ms (31.54%)
top 2 operation type: HistogramSummary, cpu: 56.17ms, accelerator: 0us, total: 56.17ms (10.22%)
top 3 operation type: Mul, cpu: 2.01ms, accelerator: 24.66ms, total: 26.71ms (4.86%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 75.78ms, accelerator: 0us, total: 75.78ms
top 3 graph node: difference, cpu: 49.85ms, accelerator: 0us, total: 49.85ms
train.py:448:<module>, cpu: 75.79ms, accelerator: 0us, total: 75.79ms
train.py:441:<module> (gradient), cpu: 4.96ms, accelerator: 50.98ms, total: 55.98ms
train.py:436:<module> (gradient), cpu: 5.36ms, accelerator: 47.49ms, total: 52.88ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_3750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 174.47ms, accelerator: 0us, total: 174.47ms (31.72%)
top 2 operation type: HistogramSummary, cpu: 56.13ms, accelerator: 0us, total: 56.13ms (10.21%)
top 3 operation type: Mul, cpu: 2.01ms, accelerator: 24.58ms, total: 26.63ms (4.84%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 76.45ms, accelerator: 0us, total: 76.45ms
top 3 graph node: difference, cpu: 50.36ms, accelerator: 0us, total: 50.36ms
train.py:448:<module>, cpu: 76.45ms, accelerator: 0us, total: 76.45ms
train.py:441:<module> (gradient), cpu: 4.96ms, accelerator: 50.29ms, total: 55.28ms
train.py:436:<module> (gradient), cpu: 5.37ms, accelerator: 49.50ms, total: 54.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_4000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 175.35ms, accelerator: 0us, total: 175.35ms (31.82%)
top 2 operation type: HistogramSummary, cpu: 56.08ms, accelerator: 0us, total: 56.08ms (10.18%)
top 3 operation type: Mul, cpu: 1.99ms, accelerator: 23.90ms, total: 25.94ms (4.71%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 77.50ms, accelerator: 0us, total: 77.50ms
top 3 graph node: difference, cpu: 50.29ms, accelerator: 0us, total: 50.29ms
train.py:448:<module>, cpu: 77.50ms, accelerator: 0us, total: 77.50ms
train.py:436:<module> (gradient), cpu: 5.34ms, accelerator: 48.51ms, total: 53.90ms
train.py:441:<module> (gradient), cpu: 4.93ms, accelerator: 48.35ms, total: 53.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_4250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 176.86ms, accelerator: 0us, total: 176.86ms (32.01%)
top 2 operation type: HistogramSummary, cpu: 56.06ms, accelerator: 0us, total: 56.06ms (10.14%)
top 3 operation type: Mul, cpu: 2.00ms, accelerator: 24.06ms, total: 26.10ms (4.72%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 78.58ms, accelerator: 0us, total: 78.58ms
top 3 graph node: difference, cpu: 50.89ms, accelerator: 0us, total: 50.89ms
train.py:448:<module>, cpu: 78.58ms, accelerator: 0us, total: 78.58ms
train.py:441:<module> (gradient), cpu: 4.92ms, accelerator: 49.38ms, total: 54.33ms
train.py:436:<module> (gradient), cpu: 5.34ms, accelerator: 46.65ms, total: 52.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_4500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 177.37ms, accelerator: 0us, total: 177.37ms (32.10%)
top 2 operation type: HistogramSummary, cpu: 56.05ms, accelerator: 0us, total: 56.05ms (10.14%)
top 3 operation type: Mul, cpu: 2.01ms, accelerator: 23.60ms, total: 25.65ms (4.64%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 79.08ms, accelerator: 0us, total: 79.08ms
top 3 graph node: difference, cpu: 50.81ms, accelerator: 0us, total: 50.81ms
train.py:448:<module>, cpu: 79.08ms, accelerator: 0us, total: 79.08ms
train.py:441:<module> (gradient), cpu: 4.93ms, accelerator: 50.30ms, total: 55.27ms
train.py:436:<module> (gradient), cpu: 5.34ms, accelerator: 47.75ms, total: 53.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_4750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 177.90ms, accelerator: 0us, total: 177.90ms (32.21%)
top 2 operation type: HistogramSummary, cpu: 56.16ms, accelerator: 0us, total: 56.16ms (10.17%)
top 3 operation type: Mul, cpu: 2.01ms, accelerator: 23.28ms, total: 25.34ms (4.59%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 79.53ms, accelerator: 0us, total: 79.53ms
top 3 graph node: difference, cpu: 50.97ms, accelerator: 0us, total: 50.97ms
train.py:448:<module>, cpu: 79.54ms, accelerator: 0us, total: 79.54ms
train.py:441:<module> (gradient), cpu: 4.91ms, accelerator: 49.58ms, total: 54.53ms
train.py:436:<module> (gradient), cpu: 5.33ms, accelerator: 49.05ms, total: 54.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_5000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 178.83ms, accelerator: 0us, total: 178.83ms (32.32%)
top 2 operation type: HistogramSummary, cpu: 56.07ms, accelerator: 0us, total: 56.07ms (10.13%)
top 3 operation type: Mul, cpu: 2.02ms, accelerator: 23.21ms, total: 25.26ms (4.57%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 80.29ms, accelerator: 0us, total: 80.29ms
top 3 graph node: difference, cpu: 50.85ms, accelerator: 0us, total: 50.85ms
train.py:448:<module>, cpu: 80.30ms, accelerator: 0us, total: 80.30ms
train.py:436:<module> (gradient), cpu: 5.32ms, accelerator: 48.56ms, total: 53.93ms
train.py:441:<module> (gradient), cpu: 4.92ms, accelerator: 47.85ms, total: 52.80ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_5250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 179.66ms, accelerator: 0us, total: 179.66ms (32.44%)
top 2 operation type: HistogramSummary, cpu: 55.82ms, accelerator: 0us, total: 55.82ms (10.08%)
top 3 operation type: Mul, cpu: 2.01ms, accelerator: 23.20ms, total: 25.26ms (4.56%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 81.02ms, accelerator: 0us, total: 81.02ms
top 3 graph node: difference, cpu: 50.80ms, accelerator: 0us, total: 50.80ms
train.py:448:<module>, cpu: 81.02ms, accelerator: 0us, total: 81.02ms
train.py:441:<module> (gradient), cpu: 4.94ms, accelerator: 49.25ms, total: 54.23ms
train.py:436:<module> (gradient), cpu: 5.31ms, accelerator: 47.07ms, total: 52.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_5500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 179.91ms, accelerator: 0us, total: 179.91ms (32.46%)
top 2 operation type: HistogramSummary, cpu: 55.95ms, accelerator: 0us, total: 55.95ms (10.09%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.49ms, accelerator: 23.92ms, total: 25.41ms (4.59%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 81.51ms, accelerator: 0us, total: 81.51ms
top 3 graph node: difference, cpu: 50.73ms, accelerator: 0us, total: 50.73ms
train.py:448:<module>, cpu: 81.52ms, accelerator: 0us, total: 81.52ms
train.py:441:<module> (gradient), cpu: 4.92ms, accelerator: 50.92ms, total: 55.88ms
train.py:436:<module> (gradient), cpu: 5.31ms, accelerator: 48.73ms, total: 54.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_5750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 180.77ms, accelerator: 0us, total: 180.77ms (32.61%)
top 2 operation type: HistogramSummary, cpu: 55.73ms, accelerator: 0us, total: 55.73ms (10.05%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.49ms, accelerator: 24.16ms, total: 25.65ms (4.63%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 82.13ms, accelerator: 0us, total: 82.13ms
top 3 graph node: difference, cpu: 50.92ms, accelerator: 0us, total: 50.92ms
train.py:448:<module>, cpu: 82.13ms, accelerator: 0us, total: 82.13ms
train.py:441:<module> (gradient), cpu: 4.90ms, accelerator: 50.59ms, total: 55.53ms
train.py:436:<module> (gradient), cpu: 5.31ms, accelerator: 49.20ms, total: 54.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_6000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 181.76ms, accelerator: 0us, total: 181.76ms (32.70%)
top 2 operation type: HistogramSummary, cpu: 55.74ms, accelerator: 0us, total: 55.74ms (10.03%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.50ms, accelerator: 23.67ms, total: 25.17ms (4.53%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 82.70ms, accelerator: 0us, total: 82.70ms
top 3 graph node: difference, cpu: 50.96ms, accelerator: 0us, total: 50.96ms
train.py:448:<module>, cpu: 82.71ms, accelerator: 0us, total: 82.71ms
train.py:441:<module> (gradient), cpu: 4.98ms, accelerator: 49.27ms, total: 54.29ms
train.py:436:<module> (gradient), cpu: 5.30ms, accelerator: 48.54ms, total: 53.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_6250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 183.08ms, accelerator: 0us, total: 183.08ms (32.86%)
top 2 operation type: HistogramSummary, cpu: 55.59ms, accelerator: 0us, total: 55.59ms (9.98%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.50ms, accelerator: 24.20ms, total: 25.70ms (4.61%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 83.41ms, accelerator: 0us, total: 83.41ms
top 3 graph node: difference, cpu: 51.30ms, accelerator: 0us, total: 51.30ms
train.py:448:<module>, cpu: 83.41ms, accelerator: 0us, total: 83.41ms
train.py:441:<module> (gradient), cpu: 4.96ms, accelerator: 50.74ms, total: 55.75ms
train.py:436:<module> (gradient), cpu: 5.28ms, accelerator: 47.28ms, total: 52.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_6500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 183.45ms, accelerator: 0us, total: 183.45ms (32.92%)
top 2 operation type: HistogramSummary, cpu: 55.66ms, accelerator: 0us, total: 55.66ms (9.99%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.49ms, accelerator: 24.21ms, total: 25.71ms (4.61%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 83.95ms, accelerator: 0us, total: 83.95ms
top 3 graph node: difference, cpu: 51.20ms, accelerator: 0us, total: 51.20ms
train.py:448:<module>, cpu: 83.96ms, accelerator: 0us, total: 83.96ms
train.py:441:<module> (gradient), cpu: 4.95ms, accelerator: 51.25ms, total: 56.23ms
train.py:436:<module> (gradient), cpu: 5.28ms, accelerator: 47.48ms, total: 52.79ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_6750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 183.83ms, accelerator: 0us, total: 183.83ms (33.05%)
top 2 operation type: HistogramSummary, cpu: 55.55ms, accelerator: 0us, total: 55.55ms (9.99%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.49ms, accelerator: 24.00ms, total: 25.49ms (4.58%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 84.30ms, accelerator: 0us, total: 84.30ms
top 3 graph node: difference, cpu: 51.30ms, accelerator: 0us, total: 51.30ms
train.py:448:<module>, cpu: 84.31ms, accelerator: 0us, total: 84.31ms
train.py:441:<module> (gradient), cpu: 4.93ms, accelerator: 50.78ms, total: 55.75ms
train.py:436:<module> (gradient), cpu: 5.28ms, accelerator: 48.43ms, total: 53.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_7000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 184.12ms, accelerator: 0us, total: 184.12ms (33.06%)
top 2 operation type: HistogramSummary, cpu: 55.53ms, accelerator: 0us, total: 55.53ms (9.97%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.49ms, accelerator: 23.40ms, total: 24.89ms (4.47%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 84.65ms, accelerator: 0us, total: 84.65ms
top 3 graph node: difference, cpu: 51.39ms, accelerator: 0us, total: 51.39ms
train.py:448:<module>, cpu: 84.66ms, accelerator: 0us, total: 84.66ms
train.py:441:<module> (gradient), cpu: 4.92ms, accelerator: 49.46ms, total: 54.42ms
train.py:436:<module> (gradient), cpu: 5.28ms, accelerator: 48.12ms, total: 53.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_7250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 184.34ms, accelerator: 0us, total: 184.34ms (33.09%)
top 2 operation type: HistogramSummary, cpu: 55.57ms, accelerator: 0us, total: 55.57ms (9.98%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.49ms, accelerator: 23.41ms, total: 24.91ms (4.47%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 85.06ms, accelerator: 0us, total: 85.06ms
top 3 graph node: difference, cpu: 51.30ms, accelerator: 0us, total: 51.30ms
train.py:448:<module>, cpu: 85.06ms, accelerator: 0us, total: 85.06ms
train.py:441:<module> (gradient), cpu: 4.94ms, accelerator: 50.04ms, total: 55.03ms
train.py:436:<module> (gradient), cpu: 5.28ms, accelerator: 47.09ms, total: 52.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_7500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 184.54ms, accelerator: 0us, total: 184.54ms (33.14%)
top 2 operation type: HistogramSummary, cpu: 55.51ms, accelerator: 0us, total: 55.51ms (9.97%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.49ms, accelerator: 24.07ms, total: 25.56ms (4.59%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 85.41ms, accelerator: 0us, total: 85.41ms
top 3 graph node: difference, cpu: 51.05ms, accelerator: 0us, total: 51.05ms
train.py:448:<module>, cpu: 85.41ms, accelerator: 0us, total: 85.41ms
train.py:441:<module> (gradient), cpu: 4.97ms, accelerator: 50.87ms, total: 55.88ms
train.py:436:<module> (gradient), cpu: 5.28ms, accelerator: 48.27ms, total: 53.59ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_7750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 184.76ms, accelerator: 0us, total: 184.76ms (33.23%)
top 2 operation type: HistogramSummary, cpu: 55.46ms, accelerator: 0us, total: 55.46ms (9.98%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.50ms, accelerator: 24.10ms, total: 25.60ms (4.61%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 85.79ms, accelerator: 0us, total: 85.79ms
top 3 graph node: difference, cpu: 51.21ms, accelerator: 0us, total: 51.21ms
train.py:448:<module>, cpu: 85.79ms, accelerator: 0us, total: 85.79ms
train.py:441:<module> (gradient), cpu: 5.01ms, accelerator: 50.62ms, total: 55.66ms
train.py:436:<module> (gradient), cpu: 5.28ms, accelerator: 48.65ms, total: 53.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_8000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 185.21ms, accelerator: 0us, total: 185.21ms (33.31%)
top 2 operation type: HistogramSummary, cpu: 55.29ms, accelerator: 0us, total: 55.29ms (9.94%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.49ms, accelerator: 23.64ms, total: 25.14ms (4.52%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 86.14ms, accelerator: 0us, total: 86.14ms
top 3 graph node: difference, cpu: 51.47ms, accelerator: 0us, total: 51.47ms
train.py:448:<module>, cpu: 86.15ms, accelerator: 0us, total: 86.15ms
train.py:441:<module> (gradient), cpu: 4.99ms, accelerator: 49.51ms, total: 54.52ms
train.py:436:<module> (gradient), cpu: 5.27ms, accelerator: 48.28ms, total: 53.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_8250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 185.41ms, accelerator: 0us, total: 185.41ms (33.34%)
top 2 operation type: HistogramSummary, cpu: 55.33ms, accelerator: 0us, total: 55.33ms (9.95%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.49ms, accelerator: 23.21ms, total: 24.70ms (4.44%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 86.34ms, accelerator: 0us, total: 86.34ms
top 3 graph node: difference, cpu: 51.52ms, accelerator: 0us, total: 51.52ms
train.py:448:<module>, cpu: 86.34ms, accelerator: 0us, total: 86.34ms
train.py:441:<module> (gradient), cpu: 4.98ms, accelerator: 48.44ms, total: 53.46ms
train.py:436:<module> (gradient), cpu: 5.26ms, accelerator: 47.94ms, total: 53.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_8500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 185.88ms, accelerator: 0us, total: 185.88ms (33.39%)
top 2 operation type: HistogramSummary, cpu: 55.38ms, accelerator: 0us, total: 55.38ms (9.95%)
top 3 operation type: FusedBatchNormGrad, cpu: 1.49ms, accelerator: 22.80ms, total: 24.30ms (4.36%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 86.64ms, accelerator: 0us, total: 86.64ms
top 3 graph node: difference, cpu: 51.61ms, accelerator: 0us, total: 51.61ms
train.py:448:<module>, cpu: 86.64ms, accelerator: 0us, total: 86.64ms
train.py:436:<module> (gradient), cpu: 5.26ms, accelerator: 47.62ms, total: 52.91ms
train.py:441:<module> (gradient), cpu: 4.99ms, accelerator: 47.45ms, total: 52.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_8750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 186.06ms, accelerator: 0us, total: 186.06ms (33.43%)
top 2 operation type: HistogramSummary, cpu: 55.36ms, accelerator: 0us, total: 55.36ms (9.95%)
top 3 operation type: Mul, cpu: 1.98ms, accelerator: 22.18ms, total: 24.20ms (4.35%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 86.90ms, accelerator: 0us, total: 86.90ms
top 3 graph node: difference, cpu: 51.53ms, accelerator: 0us, total: 51.53ms
train.py:448:<module>, cpu: 86.91ms, accelerator: 0us, total: 86.91ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 47.15ms, total: 52.44ms
train.py:449:<module>, cpu: 51.56ms, accelerator: 352us, total: 51.91ms
  summary.py:146:image, cpu: 51.53ms, accelerator: 0us, total: 51.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_9000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 186.30ms, accelerator: 0us, total: 186.30ms (33.47%)
top 2 operation type: HistogramSummary, cpu: 55.29ms, accelerator: 0us, total: 55.29ms (9.93%)
top 3 operation type: Mul, cpu: 1.98ms, accelerator: 22.25ms, total: 24.26ms (4.36%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 87.07ms, accelerator: 0us, total: 87.07ms
top 3 graph node: difference, cpu: 51.58ms, accelerator: 0us, total: 51.58ms
train.py:448:<module>, cpu: 87.08ms, accelerator: 0us, total: 87.08ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 46.87ms, total: 52.15ms
train.py:449:<module>, cpu: 51.62ms, accelerator: 355us, total: 51.97ms
  summary.py:146:image, cpu: 51.59ms, accelerator: 0us, total: 51.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_9250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 186.50ms, accelerator: 0us, total: 186.50ms (33.51%)
top 2 operation type: HistogramSummary, cpu: 55.33ms, accelerator: 0us, total: 55.33ms (9.94%)
top 3 operation type: Mul, cpu: 1.97ms, accelerator: 22.30ms, total: 24.31ms (4.37%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 87.29ms, accelerator: 0us, total: 87.29ms
top 3 graph node: difference, cpu: 51.67ms, accelerator: 0us, total: 51.67ms
train.py:448:<module>, cpu: 87.30ms, accelerator: 0us, total: 87.30ms
train.py:449:<module>, cpu: 51.70ms, accelerator: 358us, total: 52.06ms
  summary.py:146:image, cpu: 51.67ms, accelerator: 0us, total: 51.67ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 46.39ms, total: 51.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_9500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 186.76ms, accelerator: 0us, total: 186.76ms (33.55%)
top 2 operation type: HistogramSummary, cpu: 55.23ms, accelerator: 0us, total: 55.23ms (9.92%)
top 3 operation type: Mul, cpu: 1.98ms, accelerator: 22.35ms, total: 24.37ms (4.38%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 87.57ms, accelerator: 0us, total: 87.57ms
top 3 graph node: difference, cpu: 51.58ms, accelerator: 0us, total: 51.58ms
train.py:448:<module>, cpu: 87.57ms, accelerator: 0us, total: 87.57ms
train.py:449:<module>, cpu: 51.62ms, accelerator: 362us, total: 51.98ms
  summary.py:146:image, cpu: 51.59ms, accelerator: 0us, total: 51.59ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 46.14ms, total: 51.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_9750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 186.96ms, accelerator: 0us, total: 186.96ms (33.57%)
top 2 operation type: HistogramSummary, cpu: 55.25ms, accelerator: 0us, total: 55.25ms (9.92%)
top 3 operation type: Mul, cpu: 1.98ms, accelerator: 22.40ms, total: 24.43ms (4.39%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 87.64ms, accelerator: 0us, total: 87.64ms
top 3 graph node: difference, cpu: 51.68ms, accelerator: 0us, total: 51.68ms
train.py:448:<module>, cpu: 87.64ms, accelerator: 0us, total: 87.64ms
train.py:449:<module>, cpu: 51.72ms, accelerator: 364us, total: 52.08ms
  summary.py:146:image, cpu: 51.69ms, accelerator: 0us, total: 51.69ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 45.90ms, total: 51.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_10000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.21ms, accelerator: 0us, total: 187.21ms (33.60%)
top 2 operation type: HistogramSummary, cpu: 55.16ms, accelerator: 0us, total: 55.16ms (9.90%)
top 3 operation type: Mul, cpu: 1.99ms, accelerator: 22.44ms, total: 24.48ms (4.39%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 87.85ms, accelerator: 0us, total: 87.85ms
top 3 graph node: difference, cpu: 51.83ms, accelerator: 0us, total: 51.83ms
train.py:448:<module>, cpu: 87.86ms, accelerator: 0us, total: 87.86ms
train.py:449:<module>, cpu: 51.86ms, accelerator: 367us, total: 52.23ms
  summary.py:146:image, cpu: 51.83ms, accelerator: 0us, total: 51.83ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 45.67ms, total: 50.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_10250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.62ms, accelerator: 0us, total: 187.62ms (33.65%)
top 2 operation type: HistogramSummary, cpu: 55.21ms, accelerator: 0us, total: 55.21ms (9.90%)
top 3 operation type: Mul, cpu: 1.99ms, accelerator: 22.50ms, total: 24.53ms (4.40%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.19ms, accelerator: 0us, total: 88.19ms
top 3 graph node: difference, cpu: 51.88ms, accelerator: 0us, total: 51.88ms
train.py:448:<module>, cpu: 88.20ms, accelerator: 0us, total: 88.20ms
train.py:449:<module>, cpu: 51.92ms, accelerator: 370us, total: 52.29ms
  summary.py:146:image, cpu: 51.89ms, accelerator: 0us, total: 51.89ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 45.46ms, total: 50.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_10500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.50ms, accelerator: 0us, total: 187.50ms (33.64%)
top 2 operation type: HistogramSummary, cpu: 55.07ms, accelerator: 0us, total: 55.07ms (9.88%)
top 3 operation type: Mul, cpu: 1.99ms, accelerator: 22.53ms, total: 24.56ms (4.41%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.23ms, accelerator: 0us, total: 88.23ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.23ms, accelerator: 0us, total: 88.23ms
train.py:449:<module>, cpu: 51.83ms, accelerator: 373us, total: 52.20ms
  summary.py:146:image, cpu: 51.80ms, accelerator: 0us, total: 51.80ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 45.25ms, total: 50.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_10750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.43ms, accelerator: 0us, total: 187.43ms (33.63%)
top 2 operation type: HistogramSummary, cpu: 55.08ms, accelerator: 0us, total: 55.08ms (9.88%)
top 3 operation type: Mul, cpu: 1.99ms, accelerator: 22.57ms, total: 24.60ms (4.41%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.23ms, accelerator: 0us, total: 88.23ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.23ms, accelerator: 0us, total: 88.23ms
train.py:449:<module>, cpu: 51.74ms, accelerator: 375us, total: 52.11ms
  summary.py:146:image, cpu: 51.71ms, accelerator: 0us, total: 51.71ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 45.06ms, total: 50.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_11000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.61ms, accelerator: 0us, total: 187.61ms (33.65%)
top 2 operation type: HistogramSummary, cpu: 55.06ms, accelerator: 0us, total: 55.06ms (9.88%)
top 3 operation type: Mul, cpu: 2.00ms, accelerator: 22.61ms, total: 24.64ms (4.42%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.30ms, accelerator: 0us, total: 88.30ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.31ms, accelerator: 0us, total: 88.31ms
train.py:449:<module>, cpu: 51.84ms, accelerator: 377us, total: 52.21ms
  summary.py:146:image, cpu: 51.81ms, accelerator: 0us, total: 51.81ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 44.87ms, total: 50.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_11250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.68ms, accelerator: 0us, total: 187.68ms (33.66%)
top 2 operation type: HistogramSummary, cpu: 55.05ms, accelerator: 0us, total: 55.05ms (9.87%)
top 3 operation type: Mul, cpu: 2.00ms, accelerator: 22.64ms, total: 24.68ms (4.43%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.41ms, accelerator: 0us, total: 88.41ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.42ms, accelerator: 0us, total: 88.42ms
train.py:449:<module>, cpu: 51.80ms, accelerator: 379us, total: 52.19ms
  summary.py:146:image, cpu: 51.78ms, accelerator: 0us, total: 51.78ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 44.69ms, total: 49.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_11500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.52ms, accelerator: 0us, total: 187.52ms (33.62%)
top 2 operation type: HistogramSummary, cpu: 55.06ms, accelerator: 0us, total: 55.06ms (9.87%)
top 3 operation type: Mul, cpu: 2.01ms, accelerator: 22.68ms, total: 24.73ms (4.43%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.36ms, accelerator: 0us, total: 88.36ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.36ms, accelerator: 0us, total: 88.36ms
train.py:449:<module>, cpu: 51.77ms, accelerator: 381us, total: 52.15ms
  summary.py:146:image, cpu: 51.74ms, accelerator: 0us, total: 51.74ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 44.52ms, total: 49.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_11750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.70ms, accelerator: 0us, total: 187.70ms (33.64%)
top 2 operation type: HistogramSummary, cpu: 55.05ms, accelerator: 0us, total: 55.05ms (9.87%)
top 3 operation type: Mul, cpu: 2.01ms, accelerator: 22.71ms, total: 24.77ms (4.44%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.51ms, accelerator: 0us, total: 88.51ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.52ms, accelerator: 0us, total: 88.52ms
train.py:449:<module>, cpu: 51.78ms, accelerator: 383us, total: 52.17ms
  summary.py:146:image, cpu: 51.76ms, accelerator: 0us, total: 51.76ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 44.35ms, total: 49.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_12000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.97ms, accelerator: 0us, total: 187.97ms (33.68%)
top 2 operation type: HistogramSummary, cpu: 54.97ms, accelerator: 0us, total: 54.97ms (9.85%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 23.48ms, total: 24.98ms (4.48%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.61ms, accelerator: 0us, total: 88.61ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.61ms, accelerator: 0us, total: 88.61ms
train.py:449:<module>, cpu: 51.94ms, accelerator: 385us, total: 52.33ms
  summary.py:146:image, cpu: 51.92ms, accelerator: 0us, total: 51.92ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 44.20ms, total: 49.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_12250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.19ms, accelerator: 0us, total: 188.19ms (33.71%)
top 2 operation type: HistogramSummary, cpu: 54.88ms, accelerator: 0us, total: 54.88ms (9.83%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 23.68ms, total: 25.17ms (4.51%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.79ms, accelerator: 0us, total: 88.79ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.79ms, accelerator: 0us, total: 88.79ms
train.py:449:<module>, cpu: 52.04ms, accelerator: 387us, total: 52.42ms
  summary.py:146:image, cpu: 52.01ms, accelerator: 0us, total: 52.01ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 44.04ms, total: 49.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_12500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.04ms, accelerator: 0us, total: 188.04ms (33.70%)
top 2 operation type: HistogramSummary, cpu: 54.87ms, accelerator: 0us, total: 54.87ms (9.83%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 23.86ms, total: 25.36ms (4.54%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.77ms, accelerator: 0us, total: 88.77ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.77ms, accelerator: 0us, total: 88.77ms
train.py:449:<module>, cpu: 52.04ms, accelerator: 389us, total: 52.43ms
  summary.py:146:image, cpu: 52.01ms, accelerator: 0us, total: 52.01ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 43.89ms, total: 49.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_12750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.02ms, accelerator: 0us, total: 188.02ms (33.70%)
top 2 operation type: HistogramSummary, cpu: 54.77ms, accelerator: 0us, total: 54.77ms (9.82%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 24.04ms, total: 25.55ms (4.58%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.87ms, accelerator: 0us, total: 88.87ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.88ms, accelerator: 0us, total: 88.88ms
train.py:449:<module>, cpu: 51.91ms, accelerator: 391us, total: 52.30ms
  summary.py:146:image, cpu: 51.88ms, accelerator: 0us, total: 51.88ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 43.76ms, total: 49.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_13000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.99ms, accelerator: 0us, total: 187.99ms (33.70%)
top 2 operation type: HistogramSummary, cpu: 54.79ms, accelerator: 0us, total: 54.79ms (9.82%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 24.22ms, total: 25.72ms (4.61%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.87ms, accelerator: 0us, total: 88.87ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.87ms, accelerator: 0us, total: 88.87ms
train.py:449:<module>, cpu: 51.92ms, accelerator: 392us, total: 52.32ms
  summary.py:146:image, cpu: 51.90ms, accelerator: 0us, total: 51.90ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 43.62ms, total: 48.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_13250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.15ms, accelerator: 0us, total: 188.15ms (33.72%)
top 2 operation type: HistogramSummary, cpu: 54.86ms, accelerator: 0us, total: 54.86ms (9.83%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 24.39ms, total: 25.89ms (4.64%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.97ms, accelerator: 0us, total: 88.97ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.97ms, accelerator: 0us, total: 88.97ms
train.py:449:<module>, cpu: 51.99ms, accelerator: 394us, total: 52.38ms
  summary.py:146:image, cpu: 51.96ms, accelerator: 0us, total: 51.96ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 43.49ms, total: 48.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_13500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.89ms, accelerator: 0us, total: 187.89ms (33.68%)
top 2 operation type: HistogramSummary, cpu: 54.88ms, accelerator: 0us, total: 54.88ms (9.84%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 24.55ms, total: 26.05ms (4.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.98ms, accelerator: 0us, total: 88.98ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 88.98ms, accelerator: 0us, total: 88.98ms
train.py:449:<module>, cpu: 51.82ms, accelerator: 395us, total: 52.22ms
  summary.py:146:image, cpu: 51.80ms, accelerator: 0us, total: 51.80ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 43.36ms, total: 48.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_13750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.11ms, accelerator: 0us, total: 188.11ms (33.72%)
top 2 operation type: HistogramSummary, cpu: 54.76ms, accelerator: 0us, total: 54.76ms (9.82%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 24.71ms, total: 26.21ms (4.70%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.09ms, accelerator: 0us, total: 89.09ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.10ms, accelerator: 0us, total: 89.10ms
train.py:449:<module>, cpu: 51.94ms, accelerator: 397us, total: 52.34ms
  summary.py:146:image, cpu: 51.91ms, accelerator: 0us, total: 51.91ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 43.24ms, total: 48.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_14000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.06ms, accelerator: 0us, total: 188.06ms (33.72%)
top 2 operation type: HistogramSummary, cpu: 54.69ms, accelerator: 0us, total: 54.69ms (9.81%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 24.86ms, total: 26.36ms (4.73%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.19ms, accelerator: 0us, total: 89.19ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.20ms, accelerator: 0us, total: 89.20ms
train.py:449:<module>, cpu: 51.76ms, accelerator: 398us, total: 52.16ms
  summary.py:146:image, cpu: 51.73ms, accelerator: 0us, total: 51.73ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 43.13ms, total: 48.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_14250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.18ms, accelerator: 0us, total: 188.18ms (33.74%)
top 2 operation type: HistogramSummary, cpu: 54.59ms, accelerator: 0us, total: 54.59ms (9.79%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 25.00ms, total: 26.50ms (4.75%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.27ms, accelerator: 0us, total: 89.27ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.27ms, accelerator: 0us, total: 89.27ms
train.py:449:<module>, cpu: 51.78ms, accelerator: 400us, total: 52.18ms
  summary.py:146:image, cpu: 51.76ms, accelerator: 0us, total: 51.76ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 43.02ms, total: 48.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_14500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.06ms, accelerator: 0us, total: 188.06ms (33.72%)
top 2 operation type: HistogramSummary, cpu: 54.63ms, accelerator: 0us, total: 54.63ms (9.80%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 25.14ms, total: 26.64ms (4.78%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.22ms, accelerator: 0us, total: 89.22ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.22ms, accelerator: 0us, total: 89.22ms
train.py:449:<module>, cpu: 51.74ms, accelerator: 401us, total: 52.14ms
  summary.py:146:image, cpu: 51.71ms, accelerator: 0us, total: 51.71ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 42.90ms, total: 48.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_14750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.07ms, accelerator: 0us, total: 188.07ms (33.73%)
top 2 operation type: HistogramSummary, cpu: 54.55ms, accelerator: 0us, total: 54.55ms (9.78%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 25.28ms, total: 26.77ms (4.80%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.21ms, accelerator: 0us, total: 89.21ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.21ms, accelerator: 0us, total: 89.21ms
train.py:449:<module>, cpu: 51.83ms, accelerator: 402us, total: 52.23ms
  summary.py:146:image, cpu: 51.80ms, accelerator: 0us, total: 51.80ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 42.80ms, total: 48.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_15000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.01ms, accelerator: 0us, total: 188.01ms (33.72%)
top 2 operation type: HistogramSummary, cpu: 54.54ms, accelerator: 0us, total: 54.54ms (9.78%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 25.41ms, total: 26.90ms (4.83%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.25ms, accelerator: 0us, total: 89.25ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.25ms, accelerator: 0us, total: 89.25ms
train.py:449:<module>, cpu: 51.88ms, accelerator: 403us, total: 52.28ms
  summary.py:146:image, cpu: 51.85ms, accelerator: 0us, total: 51.85ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 42.70ms, total: 47.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_15250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.09ms, accelerator: 0us, total: 188.09ms (33.73%)
top 2 operation type: HistogramSummary, cpu: 54.53ms, accelerator: 0us, total: 54.53ms (9.78%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 25.53ms, total: 27.03ms (4.85%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.28ms, accelerator: 0us, total: 89.28ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.28ms, accelerator: 0us, total: 89.28ms
train.py:449:<module>, cpu: 51.88ms, accelerator: 405us, total: 52.28ms
  summary.py:146:image, cpu: 51.85ms, accelerator: 0us, total: 51.85ms
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 42.60ms, total: 47.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_15500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 188.01ms, accelerator: 0us, total: 188.01ms (33.72%)
top 2 operation type: HistogramSummary, cpu: 54.53ms, accelerator: 0us, total: 54.53ms (9.78%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 25.66ms, total: 27.16ms (4.87%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.28ms, accelerator: 0us, total: 89.28ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.28ms, accelerator: 0us, total: 89.28ms
train.py:449:<module>, cpu: 51.84ms, accelerator: 406us, total: 52.24ms
  summary.py:146:image, cpu: 51.81ms, accelerator: 0us, total: 51.81ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 42.51ms, total: 47.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_15750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.97ms, accelerator: 0us, total: 187.97ms (33.72%)
top 2 operation type: HistogramSummary, cpu: 54.54ms, accelerator: 0us, total: 54.54ms (9.78%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 25.78ms, total: 27.28ms (4.89%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.20ms, accelerator: 0us, total: 89.20ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.20ms, accelerator: 0us, total: 89.20ms
train.py:449:<module>, cpu: 51.89ms, accelerator: 407us, total: 52.30ms
  summary.py:146:image, cpu: 51.86ms, accelerator: 0us, total: 51.86ms
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 42.42ms, total: 47.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_16000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.96ms, accelerator: 0us, total: 187.96ms (33.71%)
top 2 operation type: HistogramSummary, cpu: 54.55ms, accelerator: 0us, total: 54.55ms (9.78%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 25.89ms, total: 27.40ms (4.91%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.29ms, accelerator: 0us, total: 89.29ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.29ms, accelerator: 0us, total: 89.29ms
train.py:449:<module>, cpu: 51.84ms, accelerator: 408us, total: 52.25ms
  summary.py:146:image, cpu: 51.82ms, accelerator: 0us, total: 51.82ms
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 42.33ms, total: 47.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_16250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.67ms, accelerator: 0us, total: 187.67ms (33.68%)
top 2 operation type: HistogramSummary, cpu: 54.58ms, accelerator: 0us, total: 54.58ms (9.79%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 26.01ms, total: 27.50ms (4.94%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.25ms, accelerator: 0us, total: 89.25ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.26ms, accelerator: 0us, total: 89.26ms
train.py:449:<module>, cpu: 51.67ms, accelerator: 409us, total: 52.08ms
  summary.py:146:image, cpu: 51.64ms, accelerator: 0us, total: 51.64ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 43.47ms, total: 47.62ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 36.79ms, total: 40.16ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 36.79ms, total: 40.14ms
      train.py:349:msssim, cpu: 3.24ms, accelerator: 36.59ms, total: 39.87ms
  train.py:359:image_losses, cpu: 550us, accelerator: 5.97ms, total: 6.53ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 5.97ms, total: 6.52ms
      train.py:343:hfe, cpu: 189us, accelerator: 3.77ms, total: 3.96ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.35ms, total: 1.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_16500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.63ms, accelerator: 0us, total: 187.63ms (33.67%)
top 2 operation type: HistogramSummary, cpu: 54.56ms, accelerator: 0us, total: 54.56ms (9.79%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 26.11ms, total: 27.61ms (4.96%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.25ms, accelerator: 0us, total: 89.25ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.25ms, accelerator: 0us, total: 89.25ms
train.py:449:<module>, cpu: 51.66ms, accelerator: 410us, total: 52.07ms
  summary.py:146:image, cpu: 51.63ms, accelerator: 0us, total: 51.63ms
train.py:442:<module>, cpu: 4.10ms, accelerator: 43.58ms, total: 47.73ms
  train.py:360:image_losses, cpu: 3.34ms, accelerator: 36.88ms, total: 40.25ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 36.88ms, total: 40.23ms
      train.py:349:msssim, cpu: 3.24ms, accelerator: 36.68ms, total: 39.96ms
  train.py:359:image_losses, cpu: 551us, accelerator: 5.99ms, total: 6.55ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 5.99ms, total: 6.54ms
      train.py:343:hfe, cpu: 190us, accelerator: 3.80ms, total: 3.99ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.35ms, total: 1.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_16750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.67ms, accelerator: 0us, total: 187.67ms (33.68%)
top 2 operation type: HistogramSummary, cpu: 54.56ms, accelerator: 0us, total: 54.56ms (9.79%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 26.22ms, total: 27.72ms (4.97%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.30ms, accelerator: 0us, total: 89.30ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.30ms, accelerator: 0us, total: 89.30ms
train.py:449:<module>, cpu: 51.66ms, accelerator: 411us, total: 52.07ms
  summary.py:146:image, cpu: 51.63ms, accelerator: 0us, total: 51.63ms
train.py:442:<module>, cpu: 4.10ms, accelerator: 43.69ms, total: 47.83ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 36.97ms, total: 40.33ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 36.97ms, total: 40.31ms
      train.py:349:msssim, cpu: 3.24ms, accelerator: 36.77ms, total: 40.04ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.01ms, total: 6.57ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 6.01ms, total: 6.56ms
      train.py:343:hfe, cpu: 191us, accelerator: 3.83ms, total: 4.03ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.35ms, total: 1.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_17000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.47ms, accelerator: 0us, total: 187.47ms (33.66%)
top 2 operation type: HistogramSummary, cpu: 54.57ms, accelerator: 0us, total: 54.57ms (9.80%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 26.33ms, total: 27.82ms (5.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.25ms, accelerator: 0us, total: 89.25ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.26ms, accelerator: 0us, total: 89.26ms
train.py:449:<module>, cpu: 51.62ms, accelerator: 412us, total: 52.03ms
  summary.py:146:image, cpu: 51.59ms, accelerator: 0us, total: 51.59ms
train.py:442:<module>, cpu: 4.10ms, accelerator: 43.78ms, total: 47.94ms
  train.py:360:image_losses, cpu: 3.34ms, accelerator: 37.04ms, total: 40.42ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 37.04ms, total: 40.40ms
      train.py:349:msssim, cpu: 3.24ms, accelerator: 36.85ms, total: 40.13ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.03ms, total: 6.59ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.03ms, total: 6.58ms
      train.py:343:hfe, cpu: 190us, accelerator: 3.87ms, total: 4.06ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.35ms, total: 1.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_17250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.54ms, accelerator: 0us, total: 187.54ms (33.67%)
top 2 operation type: HistogramSummary, cpu: 54.58ms, accelerator: 0us, total: 54.58ms (9.80%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 26.43ms, total: 27.92ms (5.01%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.44ms, accelerator: 0us, total: 89.44ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.44ms, accelerator: 0us, total: 89.44ms
train.py:449:<module>, cpu: 51.52ms, accelerator: 413us, total: 51.93ms
  summary.py:146:image, cpu: 51.49ms, accelerator: 0us, total: 51.49ms
train.py:442:<module>, cpu: 4.11ms, accelerator: 43.89ms, total: 48.04ms
  train.py:360:image_losses, cpu: 3.35ms, accelerator: 37.13ms, total: 40.51ms
    train.py:322:loss_fn, cpu: 3.32ms, accelerator: 37.13ms, total: 40.49ms
      train.py:349:msssim, cpu: 3.25ms, accelerator: 36.94ms, total: 40.23ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.05ms, total: 6.61ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 6.05ms, total: 6.60ms
      train.py:343:hfe, cpu: 190us, accelerator: 3.90ms, total: 4.09ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.35ms, total: 1.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_17500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.42ms, accelerator: 0us, total: 187.42ms (33.65%)
top 2 operation type: HistogramSummary, cpu: 54.58ms, accelerator: 0us, total: 54.58ms (9.80%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 26.52ms, total: 28.02ms (5.03%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.44ms, accelerator: 0us, total: 89.44ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.44ms, accelerator: 0us, total: 89.44ms
train.py:449:<module>, cpu: 51.45ms, accelerator: 414us, total: 51.86ms
  summary.py:146:image, cpu: 51.42ms, accelerator: 0us, total: 51.42ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 43.98ms, total: 48.12ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 37.20ms, total: 40.58ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 37.20ms, total: 40.55ms
      train.py:349:msssim, cpu: 3.23ms, accelerator: 37.02ms, total: 40.29ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.07ms, total: 6.63ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.07ms, total: 6.62ms
      train.py:343:hfe, cpu: 190us, accelerator: 3.93ms, total: 4.12ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.35ms, total: 1.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_17750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.44ms, accelerator: 0us, total: 187.44ms (33.66%)
top 2 operation type: HistogramSummary, cpu: 54.61ms, accelerator: 0us, total: 54.61ms (9.81%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 26.61ms, total: 28.10ms (5.05%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.48ms, accelerator: 0us, total: 89.48ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.49ms, accelerator: 0us, total: 89.49ms
train.py:449:<module>, cpu: 51.38ms, accelerator: 415us, total: 51.80ms
  summary.py:146:image, cpu: 51.36ms, accelerator: 0us, total: 51.36ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 44.07ms, total: 48.21ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 37.28ms, total: 40.65ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 37.28ms, total: 40.62ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 37.10ms, total: 40.37ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.09ms, total: 6.65ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.09ms, total: 6.64ms
      train.py:343:hfe, cpu: 190us, accelerator: 3.96ms, total: 4.15ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.35ms, total: 1.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_18000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.41ms, accelerator: 0us, total: 187.41ms (33.66%)
top 2 operation type: HistogramSummary, cpu: 54.59ms, accelerator: 0us, total: 54.59ms (9.80%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 26.70ms, total: 28.20ms (5.06%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.45ms, accelerator: 0us, total: 89.45ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.46ms, accelerator: 0us, total: 89.46ms
train.py:449:<module>, cpu: 51.29ms, accelerator: 415us, total: 51.71ms
  summary.py:146:image, cpu: 51.27ms, accelerator: 0us, total: 51.27ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 44.17ms, total: 48.31ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 37.36ms, total: 40.73ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 37.36ms, total: 40.70ms
      train.py:349:msssim, cpu: 3.23ms, accelerator: 37.18ms, total: 40.45ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.11ms, total: 6.67ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 6.11ms, total: 6.66ms
      train.py:343:hfe, cpu: 191us, accelerator: 3.98ms, total: 4.18ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.35ms, total: 1.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_18250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.26ms, accelerator: 0us, total: 187.26ms (33.63%)
top 2 operation type: HistogramSummary, cpu: 54.59ms, accelerator: 0us, total: 54.59ms (9.81%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 26.79ms, total: 28.29ms (5.08%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.41ms, accelerator: 0us, total: 89.41ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.41ms, accelerator: 0us, total: 89.41ms
train.py:449:<module>, cpu: 51.27ms, accelerator: 416us, total: 51.69ms
  summary.py:146:image, cpu: 51.24ms, accelerator: 0us, total: 51.24ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 44.26ms, total: 48.40ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 37.43ms, total: 40.80ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 37.43ms, total: 40.78ms
      train.py:349:msssim, cpu: 3.23ms, accelerator: 37.26ms, total: 40.53ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.13ms, total: 6.69ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 6.13ms, total: 6.67ms
      train.py:343:hfe, cpu: 192us, accelerator: 4.01ms, total: 4.21ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.35ms, total: 1.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_18500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.28ms, accelerator: 0us, total: 187.28ms (33.64%)
top 2 operation type: HistogramSummary, cpu: 54.60ms, accelerator: 0us, total: 54.60ms (9.81%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 26.88ms, total: 28.37ms (5.10%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.47ms, accelerator: 0us, total: 89.47ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.48ms, accelerator: 0us, total: 89.48ms
train.py:449:<module>, cpu: 51.21ms, accelerator: 417us, total: 51.63ms
  summary.py:146:image, cpu: 51.19ms, accelerator: 0us, total: 51.19ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 44.34ms, total: 48.48ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 37.50ms, total: 40.87ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 37.50ms, total: 40.84ms
      train.py:349:msssim, cpu: 3.23ms, accelerator: 37.33ms, total: 40.59ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.14ms, total: 6.71ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.14ms, total: 6.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.04ms, total: 4.23ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.35ms, total: 1.57ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_18750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.41ms, accelerator: 0us, total: 187.41ms (33.65%)
top 2 operation type: HistogramSummary, cpu: 54.59ms, accelerator: 0us, total: 54.59ms (9.80%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 26.96ms, total: 28.46ms (5.11%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.54ms, accelerator: 0us, total: 89.54ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.54ms, accelerator: 0us, total: 89.54ms
train.py:449:<module>, cpu: 51.18ms, accelerator: 418us, total: 51.60ms
  summary.py:146:image, cpu: 51.15ms, accelerator: 0us, total: 51.15ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 44.42ms, total: 48.57ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 37.57ms, total: 40.95ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 37.57ms, total: 40.92ms
      train.py:349:msssim, cpu: 3.23ms, accelerator: 37.40ms, total: 40.67ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.16ms, total: 6.72ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.16ms, total: 6.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.07ms, total: 4.26ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.35ms, total: 1.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_19000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.28ms, accelerator: 0us, total: 187.28ms (33.64%)
top 2 operation type: HistogramSummary, cpu: 54.61ms, accelerator: 0us, total: 54.61ms (9.81%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 27.04ms, total: 28.55ms (5.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.54ms, accelerator: 0us, total: 89.54ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.54ms, accelerator: 0us, total: 89.54ms
train.py:449:<module>, cpu: 51.09ms, accelerator: 419us, total: 51.51ms
  summary.py:146:image, cpu: 51.07ms, accelerator: 0us, total: 51.07ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 44.51ms, total: 48.65ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 37.64ms, total: 41.01ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 37.64ms, total: 40.99ms
      train.py:349:msssim, cpu: 3.23ms, accelerator: 37.47ms, total: 40.74ms
  train.py:359:image_losses, cpu: 548us, accelerator: 6.18ms, total: 6.74ms
    train.py:322:loss_fn, cpu: 537us, accelerator: 6.18ms, total: 6.73ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.09ms, total: 4.29ms
      train.py:342:hfe, cpu: 210us, accelerator: 1.35ms, total: 1.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_19250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.19ms, accelerator: 0us, total: 187.19ms (33.63%)
top 2 operation type: HistogramSummary, cpu: 54.60ms, accelerator: 0us, total: 54.60ms (9.81%)
top 3 operation type: Neg, cpu: 1.46ms, accelerator: 27.12ms, total: 28.62ms (5.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.56ms, accelerator: 0us, total: 89.56ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.57ms, accelerator: 0us, total: 89.57ms
train.py:449:<module>, cpu: 51.01ms, accelerator: 419us, total: 51.43ms
  summary.py:146:image, cpu: 50.98ms, accelerator: 0us, total: 50.98ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 44.59ms, total: 48.74ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 37.71ms, total: 41.08ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 37.71ms, total: 41.06ms
      train.py:349:msssim, cpu: 3.23ms, accelerator: 37.54ms, total: 40.81ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.20ms, total: 6.76ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.20ms, total: 6.75ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.12ms, total: 4.31ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.35ms, total: 1.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_19500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.19ms, accelerator: 0us, total: 187.19ms (33.62%)
top 2 operation type: HistogramSummary, cpu: 54.62ms, accelerator: 0us, total: 54.62ms (9.81%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 27.20ms, total: 28.70ms (5.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.53ms, accelerator: 0us, total: 89.53ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.53ms, accelerator: 0us, total: 89.53ms
train.py:449:<module>, cpu: 51.03ms, accelerator: 420us, total: 51.45ms
  summary.py:146:image, cpu: 51.01ms, accelerator: 0us, total: 51.01ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 44.67ms, total: 48.81ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 37.77ms, total: 41.14ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 37.77ms, total: 41.12ms
      train.py:349:msssim, cpu: 3.24ms, accelerator: 37.61ms, total: 40.88ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.21ms, total: 6.77ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.21ms, total: 6.76ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.14ms, total: 4.33ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.35ms, total: 1.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_19750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.22ms, accelerator: 0us, total: 187.22ms (33.63%)
top 2 operation type: HistogramSummary, cpu: 54.55ms, accelerator: 0us, total: 54.55ms (9.80%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 27.14ms, total: 28.65ms (5.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.56ms, accelerator: 0us, total: 89.56ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.57ms, accelerator: 0us, total: 89.57ms
train.py:449:<module>, cpu: 51.02ms, accelerator: 415us, total: 51.43ms
  summary.py:146:image, cpu: 50.99ms, accelerator: 0us, total: 50.99ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 44.66ms, total: 48.80ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 37.83ms, total: 41.21ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 37.83ms, total: 41.19ms
      train.py:349:msssim, cpu: 3.24ms, accelerator: 37.67ms, total: 40.95ms
  train.py:359:image_losses, cpu: 549us, accelerator: 6.14ms, total: 6.70ms
    train.py:322:loss_fn, cpu: 537us, accelerator: 6.14ms, total: 6.69ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.09ms, total: 4.29ms
      train.py:342:hfe, cpu: 210us, accelerator: 1.33ms, total: 1.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_20000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.23ms, accelerator: 0us, total: 187.23ms (33.63%)
top 2 operation type: HistogramSummary, cpu: 54.59ms, accelerator: 0us, total: 54.59ms (9.80%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 27.23ms, total: 28.73ms (5.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.60ms, accelerator: 0us, total: 89.60ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.61ms, accelerator: 0us, total: 89.61ms
train.py:449:<module>, cpu: 50.96ms, accelerator: 416us, total: 51.38ms
  summary.py:146:image, cpu: 50.93ms, accelerator: 0us, total: 50.93ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 44.73ms, total: 48.88ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 37.89ms, total: 41.27ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 37.89ms, total: 41.24ms
      train.py:349:msssim, cpu: 3.24ms, accelerator: 37.73ms, total: 41.01ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.16ms, total: 6.72ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.16ms, total: 6.70ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.12ms, total: 4.31ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.33ms, total: 1.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_20250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ImageSummary, cpu: 187.34ms, accelerator: 0us, total: 187.34ms (33.64%)
top 2 operation type: HistogramSummary, cpu: 54.53ms, accelerator: 0us, total: 54.53ms (9.79%)
top 3 operation type: Neg, cpu: 1.47ms, accelerator: 27.30ms, total: 28.80ms (5.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.67ms, accelerator: 0us, total: 89.67ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:448:<module>, cpu: 89.67ms, accelerator: 0us, total: 89.67ms
train.py:449:<module>, cpu: 50.97ms, accelerator: 416us, total: 51.38ms
  summary.py:146:image, cpu: 50.94ms, accelerator: 0us, total: 50.94ms
train.py:442:<module>, cpu: 4.09ms, accelerator: 44.80ms, total: 48.95ms
  train.py:360:image_losses, cpu: 3.33ms, accelerator: 37.95ms, total: 41.33ms
    train.py:322:loss_fn, cpu: 3.31ms, accelerator: 37.95ms, total: 41.30ms
      train.py:349:msssim, cpu: 3.24ms, accelerator: 37.79ms, total: 41.07ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.17ms, total: 6.73ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.17ms, total: 6.72ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.14ms, total: 4.33ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.33ms, total: 1.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_20500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 1.00ms, accelerator: 222249927.98sec, total: 222249927.98sec (100.00%)
top 2 operation type: ImageSummary, cpu: 187.34ms, accelerator: 0us, total: 187.34ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.52ms, accelerator: 0us, total: 54.52ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.67ms, accelerator: 0us, total: 89.67ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 222249928.00sec, total: 222249928.01sec
train.py:448:<module>, cpu: 89.68ms, accelerator: 0us, total: 89.68ms
train.py:449:<module>, cpu: 51.02ms, accelerator: 417us, total: 51.44ms
  summary.py:146:image, cpu: 51.00ms, accelerator: 0us, total: 51.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.50
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_20750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 996us, accelerator: 219604095.51sec, total: 219604095.51sec (100.00%)
top 2 operation type: ImageSummary, cpu: 187.33ms, accelerator: 0us, total: 187.33ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.53ms, accelerator: 0us, total: 54.53ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.65ms, accelerator: 0us, total: 89.65ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 219604095.53sec, total: 219604095.53sec
train.py:448:<module>, cpu: 89.65ms, accelerator: 0us, total: 89.65ms
train.py:449:<module>, cpu: 51.08ms, accelerator: 418us, total: 51.50ms
  summary.py:146:image, cpu: 51.05ms, accelerator: 0us, total: 51.05ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_21000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 995us, accelerator: 217020517.91sec, total: 217020517.91sec (100.00%)
top 2 operation type: ImageSummary, cpu: 187.43ms, accelerator: 0us, total: 187.43ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.52ms, accelerator: 0us, total: 54.52ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.64ms, accelerator: 0us, total: 89.64ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 217020517.93sec, total: 217020517.94sec
train.py:448:<module>, cpu: 89.64ms, accelerator: 0us, total: 89.64ms
train.py:449:<module>, cpu: 51.14ms, accelerator: 419us, total: 51.56ms
  summary.py:146:image, cpu: 51.11ms, accelerator: 0us, total: 51.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_21250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 996us, accelerator: 214497023.52sec, total: 214497023.52sec (100.00%)
top 2 operation type: ImageSummary, cpu: 187.34ms, accelerator: 0us, total: 187.34ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.51ms, accelerator: 0us, total: 54.51ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.61ms, accelerator: 0us, total: 89.61ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 214497023.54sec, total: 214497023.54sec
train.py:448:<module>, cpu: 89.62ms, accelerator: 0us, total: 89.62ms
train.py:449:<module>, cpu: 51.11ms, accelerator: 419us, total: 51.53ms
  summary.py:146:image, cpu: 51.08ms, accelerator: 0us, total: 51.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_21500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 996us, accelerator: 212031540.49sec, total: 212031540.49sec (100.00%)
top 2 operation type: ImageSummary, cpu: 187.24ms, accelerator: 0us, total: 187.24ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.53ms, accelerator: 0us, total: 54.53ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.62ms, accelerator: 0us, total: 89.62ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 212031540.51sec, total: 212031540.51sec
train.py:448:<module>, cpu: 89.62ms, accelerator: 0us, total: 89.62ms
train.py:449:<module>, cpu: 51.00ms, accelerator: 420us, total: 51.42ms
  summary.py:146:image, cpu: 50.98ms, accelerator: 0us, total: 50.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_21750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 996us, accelerator: 209622091.17sec, total: 209622091.17sec (100.00%)
top 2 operation type: ImageSummary, cpu: 187.06ms, accelerator: 0us, total: 187.06ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.47ms, accelerator: 0us, total: 54.47ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.56ms, accelerator: 0us, total: 89.56ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 209622091.19sec, total: 209622091.19sec
train.py:448:<module>, cpu: 89.56ms, accelerator: 0us, total: 89.56ms
train.py:449:<module>, cpu: 50.96ms, accelerator: 421us, total: 51.38ms
  summary.py:146:image, cpu: 50.94ms, accelerator: 0us, total: 50.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_22000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 995us, accelerator: 207266786.77sec, total: 207266786.77sec (100.00%)
top 2 operation type: ImageSummary, cpu: 187.06ms, accelerator: 0us, total: 187.06ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.44ms, accelerator: 0us, total: 54.44ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.59ms, accelerator: 0us, total: 89.59ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.33ms, accelerator: 207266786.79sec, total: 207266786.80sec
train.py:448:<module>, cpu: 89.60ms, accelerator: 0us, total: 89.60ms
train.py:449:<module>, cpu: 50.94ms, accelerator: 421us, total: 51.36ms
  summary.py:146:image, cpu: 50.91ms, accelerator: 0us, total: 50.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_22250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 992us, accelerator: 204963822.47sec, total: 204963822.47sec (100.00%)
top 2 operation type: ImageSummary, cpu: 186.95ms, accelerator: 0us, total: 186.95ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.46ms, accelerator: 0us, total: 54.46ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.60ms, accelerator: 0us, total: 89.60ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 204963822.49sec, total: 204963822.50sec
train.py:448:<module>, cpu: 89.61ms, accelerator: 0us, total: 89.61ms
train.py:449:<module>, cpu: 50.87ms, accelerator: 422us, total: 51.29ms
  summary.py:146:image, cpu: 50.84ms, accelerator: 0us, total: 50.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_22500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 991us, accelerator: 202711472.78sec, total: 202711472.78sec (100.00%)
top 2 operation type: ImageSummary, cpu: 186.89ms, accelerator: 0us, total: 186.89ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.45ms, accelerator: 0us, total: 54.45ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.66ms, accelerator: 0us, total: 89.66ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 202711472.79sec, total: 202711472.80sec
train.py:448:<module>, cpu: 89.66ms, accelerator: 0us, total: 89.66ms
train.py:449:<module>, cpu: 50.79ms, accelerator: 422us, total: 51.21ms
  summary.py:146:image, cpu: 50.76ms, accelerator: 0us, total: 50.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_22750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 990us, accelerator: 200508087.20sec, total: 200508087.20sec (100.00%)
top 2 operation type: ImageSummary, cpu: 186.76ms, accelerator: 0us, total: 186.76ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.45ms, accelerator: 0us, total: 54.45ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.69ms, accelerator: 0us, total: 89.69ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.33ms, accelerator: 200508087.22sec, total: 200508087.23sec
train.py:448:<module>, cpu: 89.69ms, accelerator: 0us, total: 89.69ms
train.py:449:<module>, cpu: 50.73ms, accelerator: 423us, total: 51.15ms
  summary.py:146:image, cpu: 50.70ms, accelerator: 0us, total: 50.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_23000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 992us, accelerator: 198352086.26sec, total: 198352086.27sec (100.00%)
top 2 operation type: ImageSummary, cpu: 186.80ms, accelerator: 0us, total: 186.80ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.48ms, accelerator: 0us, total: 54.48ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.71ms, accelerator: 0us, total: 89.71ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 198352086.28sec, total: 198352086.29sec
train.py:448:<module>, cpu: 89.71ms, accelerator: 0us, total: 89.71ms
train.py:449:<module>, cpu: 50.72ms, accelerator: 424us, total: 51.14ms
  summary.py:146:image, cpu: 50.69ms, accelerator: 0us, total: 50.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_23250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 993us, accelerator: 196241957.69sec, total: 196241957.69sec (100.00%)
top 2 operation type: ImageSummary, cpu: 186.75ms, accelerator: 0us, total: 186.75ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.49ms, accelerator: 0us, total: 54.49ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.66ms, accelerator: 0us, total: 89.66ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 196241957.71sec, total: 196241957.71sec
train.py:448:<module>, cpu: 89.66ms, accelerator: 0us, total: 89.66ms
train.py:449:<module>, cpu: 50.76ms, accelerator: 424us, total: 51.19ms
  summary.py:146:image, cpu: 50.73ms, accelerator: 0us, total: 50.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_23500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 993us, accelerator: 194176252.87sec, total: 194176252.87sec (100.00%)
top 2 operation type: ImageSummary, cpu: 186.71ms, accelerator: 0us, total: 186.71ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.47ms, accelerator: 0us, total: 54.47ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.62ms, accelerator: 0us, total: 89.62ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 194176252.89sec, total: 194176252.89sec
train.py:448:<module>, cpu: 89.63ms, accelerator: 0us, total: 89.63ms
train.py:449:<module>, cpu: 50.78ms, accelerator: 425us, total: 51.20ms
  summary.py:146:image, cpu: 50.75ms, accelerator: 0us, total: 50.75ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_23750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 995us, accelerator: 192153583.57sec, total: 192153583.57sec (100.00%)
top 2 operation type: ImageSummary, cpu: 186.72ms, accelerator: 0us, total: 186.72ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.48ms, accelerator: 0us, total: 54.48ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.66ms, accelerator: 0us, total: 89.66ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 192153583.59sec, total: 192153583.59sec
train.py:448:<module>, cpu: 89.67ms, accelerator: 0us, total: 89.67ms
train.py:449:<module>, cpu: 50.83ms, accelerator: 425us, total: 51.25ms
  summary.py:146:image, cpu: 50.80ms, accelerator: 0us, total: 50.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_24000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 990us, accelerator: 190172618.79sec, total: 190172618.79sec (100.00%)
top 2 operation type: ImageSummary, cpu: 186.72ms, accelerator: 0us, total: 186.72ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.47ms, accelerator: 0us, total: 54.47ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.67ms, accelerator: 0us, total: 89.67ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 190172618.81sec, total: 190172618.81sec
train.py:448:<module>, cpu: 89.67ms, accelerator: 0us, total: 89.67ms
train.py:449:<module>, cpu: 50.86ms, accelerator: 426us, total: 51.29ms
  summary.py:146:image, cpu: 50.84ms, accelerator: 0us, total: 50.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_24250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: ReluGrad, cpu: 992us, accelerator: 188232081.86sec, total: 188232081.86sec (100.00%)
top 2 operation type: ImageSummary, cpu: 186.82ms, accelerator: 0us, total: 186.82ms (0.00%)
top 3 operation type: HistogramSummary, cpu: 54.46ms, accelerator: 0us, total: 54.46ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.72ms, accelerator: 0us, total: 89.72ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 188232081.88sec, total: 188232081.89sec
train.py:448:<module>, cpu: 89.73ms, accelerator: 0us, total: 89.73ms
train.py:449:<module>, cpu: 50.92ms, accelerator: 426us, total: 51.35ms
  summary.py:146:image, cpu: 50.90ms, accelerator: 0us, total: 50.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_24500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 186330747.74sec, total: 186330747.75sec (50.00%)
top 2 operation type: ReluGrad, cpu: 1.00ms, accelerator: 186330747.70sec, total: 186330747.70sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.78ms, accelerator: 0us, total: 186.78ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.73ms, accelerator: 0us, total: 89.73ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 372661495.45sec, total: 372661495.46sec
train.py:448:<module>, cpu: 89.73ms, accelerator: 0us, total: 89.73ms
train.py:449:<module>, cpu: 50.87ms, accelerator: 424us, total: 51.30ms
  summary.py:146:image, cpu: 50.85ms, accelerator: 0us, total: 50.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_24750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 184467440.27sec, total: 184467440.27sec (50.00%)
top 2 operation type: ReluGrad, cpu: 996us, accelerator: 184467440.23sec, total: 184467440.23sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.67ms, accelerator: 0us, total: 186.67ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.75ms, accelerator: 0us, total: 89.75ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 368934880.50sec, total: 368934880.50sec
train.py:448:<module>, cpu: 89.75ms, accelerator: 0us, total: 89.75ms
train.py:449:<module>, cpu: 50.84ms, accelerator: 424us, total: 51.26ms
  summary.py:146:image, cpu: 50.81ms, accelerator: 0us, total: 50.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_25000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 182641029.97sec, total: 182641029.97sec (50.00%)
top 2 operation type: ReluGrad, cpu: 994us, accelerator: 182641029.93sec, total: 182641029.93sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.69ms, accelerator: 0us, total: 186.69ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 365282059.90sec, total: 365282059.91sec
train.py:448:<module>, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
train.py:449:<module>, cpu: 50.83ms, accelerator: 425us, total: 51.25ms
  summary.py:146:image, cpu: 50.80ms, accelerator: 0us, total: 50.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_25250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 180850431.63sec, total: 180850431.64sec (50.00%)
top 2 operation type: ReluGrad, cpu: 995us, accelerator: 180850431.59sec, total: 180850431.60sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.67ms, accelerator: 0us, total: 186.67ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.87ms, accelerator: 0us, total: 89.87ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 361700863.23sec, total: 361700863.24sec
train.py:448:<module>, cpu: 89.87ms, accelerator: 0us, total: 89.87ms
train.py:449:<module>, cpu: 50.75ms, accelerator: 425us, total: 51.18ms
  summary.py:146:image, cpu: 50.73ms, accelerator: 0us, total: 50.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_25500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 179094602.20sec, total: 179094602.20sec (50.00%)
top 2 operation type: ReluGrad, cpu: 994us, accelerator: 179094602.16sec, total: 179094602.16sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.65ms, accelerator: 0us, total: 186.65ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.85ms, accelerator: 0us, total: 89.85ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 358189204.37sec, total: 358189204.37sec
train.py:448:<module>, cpu: 89.86ms, accelerator: 0us, total: 89.86ms
train.py:449:<module>, cpu: 50.74ms, accelerator: 426us, total: 51.16ms
  summary.py:146:image, cpu: 50.71ms, accelerator: 0us, total: 50.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_25750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 177372538.72sec, total: 177372538.72sec (50.00%)
top 2 operation type: ReluGrad, cpu: 994us, accelerator: 177372538.68sec, total: 177372538.68sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.54ms, accelerator: 0us, total: 186.54ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.87ms, accelerator: 0us, total: 89.87ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 354745077.40sec, total: 354745077.41sec
train.py:448:<module>, cpu: 89.88ms, accelerator: 0us, total: 89.88ms
train.py:449:<module>, cpu: 50.64ms, accelerator: 426us, total: 51.06ms
  summary.py:146:image, cpu: 50.61ms, accelerator: 0us, total: 50.61ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_26000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 175683276.44sec, total: 175683276.45sec (50.00%)
top 2 operation type: ReluGrad, cpu: 993us, accelerator: 175683276.41sec, total: 175683276.41sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.45ms, accelerator: 0us, total: 186.45ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.88ms, accelerator: 0us, total: 89.88ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 351366552.86sec, total: 351366552.86sec
train.py:448:<module>, cpu: 89.88ms, accelerator: 0us, total: 89.88ms
train.py:449:<module>, cpu: 50.62ms, accelerator: 427us, total: 51.04ms
  summary.py:146:image, cpu: 50.59ms, accelerator: 0us, total: 50.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_26250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 174025887.04sec, total: 174025887.05sec (50.00%)
top 2 operation type: ReluGrad, cpu: 993us, accelerator: 174025887.01sec, total: 174025887.01sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.39ms, accelerator: 0us, total: 186.39ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.86ms, accelerator: 0us, total: 89.86ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 348051774.06sec, total: 348051774.06sec
train.py:448:<module>, cpu: 89.87ms, accelerator: 0us, total: 89.87ms
train.py:449:<module>, cpu: 50.61ms, accelerator: 427us, total: 51.04ms
  summary.py:146:image, cpu: 50.58ms, accelerator: 0us, total: 50.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_26500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 172399476.89sec, total: 172399476.89sec (50.00%)
top 2 operation type: ReluGrad, cpu: 996us, accelerator: 172399476.85sec, total: 172399476.85sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.41ms, accelerator: 0us, total: 186.41ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 344798953.74sec, total: 344798953.74sec
train.py:448:<module>, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
train.py:449:<module>, cpu: 50.59ms, accelerator: 423us, total: 51.02ms
  summary.py:146:image, cpu: 50.57ms, accelerator: 0us, total: 50.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_26750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 170803185.43sec, total: 170803185.43sec (50.00%)
top 2 operation type: ReluGrad, cpu: 993us, accelerator: 170803185.40sec, total: 170803185.40sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.41ms, accelerator: 0us, total: 186.41ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 341606370.83sec, total: 341606370.84sec
train.py:448:<module>, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
train.py:449:<module>, cpu: 50.62ms, accelerator: 424us, total: 51.05ms
  summary.py:146:image, cpu: 50.60ms, accelerator: 0us, total: 50.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_27000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 169236183.73sec, total: 169236183.73sec (50.00%)
top 2 operation type: ReluGrad, cpu: 993us, accelerator: 169236183.69sec, total: 169236183.70sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.27ms, accelerator: 0us, total: 186.27ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.80ms, accelerator: 0us, total: 89.80ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 338472367.43sec, total: 338472367.44sec
train.py:448:<module>, cpu: 89.80ms, accelerator: 0us, total: 89.80ms
train.py:449:<module>, cpu: 50.55ms, accelerator: 424us, total: 50.98ms
  summary.py:146:image, cpu: 50.53ms, accelerator: 0us, total: 50.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_27250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 167697672.97sec, total: 167697672.97sec (50.00%)
top 2 operation type: ReluGrad, cpu: 992us, accelerator: 167697672.93sec, total: 167697672.93sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.31ms, accelerator: 0us, total: 186.31ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.80ms, accelerator: 0us, total: 89.80ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 335395345.91sec, total: 335395345.92sec
train.py:448:<module>, cpu: 89.81ms, accelerator: 0us, total: 89.81ms
train.py:449:<module>, cpu: 50.58ms, accelerator: 425us, total: 51.01ms
  summary.py:146:image, cpu: 50.55ms, accelerator: 0us, total: 50.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_27500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 166186883.12sec, total: 166186883.13sec (50.00%)
top 2 operation type: ReluGrad, cpu: 992us, accelerator: 166186883.09sec, total: 166186883.09sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.32ms, accelerator: 0us, total: 186.32ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.79ms, accelerator: 0us, total: 89.79ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 332373766.22sec, total: 332373766.22sec
train.py:448:<module>, cpu: 89.79ms, accelerator: 0us, total: 89.79ms
train.py:449:<module>, cpu: 50.52ms, accelerator: 421us, total: 50.94ms
  summary.py:146:image, cpu: 50.49ms, accelerator: 0us, total: 50.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_27750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 164703071.67sec, total: 164703071.67sec (50.00%)
top 2 operation type: ReluGrad, cpu: 990us, accelerator: 164703071.63sec, total: 164703071.63sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.32ms, accelerator: 0us, total: 186.32ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 329406143.30sec, total: 329406143.31sec
train.py:448:<module>, cpu: 89.85ms, accelerator: 0us, total: 89.85ms
train.py:449:<module>, cpu: 50.46ms, accelerator: 421us, total: 50.88ms
  summary.py:146:image, cpu: 50.43ms, accelerator: 0us, total: 50.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_28000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 163245522.36sec, total: 163245522.36sec (50.00%)
top 2 operation type: ReluGrad, cpu: 992us, accelerator: 163245522.33sec, total: 163245522.33sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.20ms, accelerator: 0us, total: 186.20ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.81ms, accelerator: 0us, total: 89.81ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 326491044.69sec, total: 326491044.70sec
train.py:448:<module>, cpu: 89.81ms, accelerator: 0us, total: 89.81ms
train.py:449:<module>, cpu: 50.45ms, accelerator: 422us, total: 50.87ms
  summary.py:146:image, cpu: 50.42ms, accelerator: 0us, total: 50.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_28250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 161813544.09sec, total: 161813544.10sec (50.00%)
top 2 operation type: ReluGrad, cpu: 991us, accelerator: 161813544.06sec, total: 161813544.06sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.20ms, accelerator: 0us, total: 186.20ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 323627088.16sec, total: 323627088.16sec
train.py:448:<module>, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
train.py:449:<module>, cpu: 50.40ms, accelerator: 422us, total: 50.82ms
  summary.py:146:image, cpu: 50.38ms, accelerator: 0us, total: 50.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_28500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 160406469.80sec, total: 160406469.80sec (50.00%)
top 2 operation type: ReluGrad, cpu: 991us, accelerator: 160406469.76sec, total: 160406469.76sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.18ms, accelerator: 0us, total: 186.18ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.85ms, accelerator: 0us, total: 89.85ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 320812939.57sec, total: 320812939.57sec
train.py:448:<module>, cpu: 89.85ms, accelerator: 0us, total: 89.85ms
train.py:449:<module>, cpu: 50.36ms, accelerator: 423us, total: 50.78ms
  summary.py:146:image, cpu: 50.34ms, accelerator: 0us, total: 50.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_28750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 159023655.40sec, total: 159023655.41sec (50.00%)
top 2 operation type: ReluGrad, cpu: 989us, accelerator: 159023655.37sec, total: 159023655.37sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.13ms, accelerator: 0us, total: 186.13ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 318047310.78sec, total: 318047310.78sec
train.py:448:<module>, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
train.py:449:<module>, cpu: 50.35ms, accelerator: 423us, total: 50.78ms
  summary.py:146:image, cpu: 50.33ms, accelerator: 0us, total: 50.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_29000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 157664478.86sec, total: 157664478.86sec (50.00%)
top 2 operation type: ReluGrad, cpu: 989us, accelerator: 157664478.83sec, total: 157664478.83sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.18ms, accelerator: 0us, total: 186.18ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.87ms, accelerator: 0us, total: 89.87ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 315328957.69sec, total: 315328957.70sec
train.py:448:<module>, cpu: 89.87ms, accelerator: 0us, total: 89.87ms
train.py:449:<module>, cpu: 50.38ms, accelerator: 424us, total: 50.80ms
  summary.py:146:image, cpu: 50.35ms, accelerator: 0us, total: 50.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_29250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 156328339.21sec, total: 156328339.21sec (50.00%)
top 2 operation type: ReluGrad, cpu: 988us, accelerator: 156328339.18sec, total: 156328339.18sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.19ms, accelerator: 0us, total: 186.19ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.88ms, accelerator: 0us, total: 89.88ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 312656678.39sec, total: 312656678.40sec
train.py:448:<module>, cpu: 89.88ms, accelerator: 0us, total: 89.88ms
train.py:449:<module>, cpu: 50.40ms, accelerator: 424us, total: 50.82ms
  summary.py:146:image, cpu: 50.37ms, accelerator: 0us, total: 50.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_29500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 155014655.69sec, total: 155014655.69sec (50.00%)
top 2 operation type: ReluGrad, cpu: 985us, accelerator: 155014655.65sec, total: 155014655.65sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.25ms, accelerator: 0us, total: 186.25ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.89ms, accelerator: 0us, total: 89.89ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 310029311.35sec, total: 310029311.35sec
train.py:448:<module>, cpu: 89.89ms, accelerator: 0us, total: 89.89ms
train.py:449:<module>, cpu: 50.40ms, accelerator: 425us, total: 50.83ms
  summary.py:146:image, cpu: 50.38ms, accelerator: 0us, total: 50.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_29750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 153722866.89sec, total: 153722866.89sec (50.00%)
top 2 operation type: ReluGrad, cpu: 985us, accelerator: 153722866.86sec, total: 153722866.86sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.23ms, accelerator: 0us, total: 186.23ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.89ms, accelerator: 0us, total: 89.89ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 307445733.75sec, total: 307445733.76sec
train.py:448:<module>, cpu: 89.89ms, accelerator: 0us, total: 89.89ms
train.py:449:<module>, cpu: 50.42ms, accelerator: 425us, total: 50.84ms
  summary.py:146:image, cpu: 50.39ms, accelerator: 0us, total: 50.39ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_30000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 152452429.97sec, total: 152452429.98sec (50.00%)
top 2 operation type: ReluGrad, cpu: 985us, accelerator: 152452429.94sec, total: 152452429.94sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.14ms, accelerator: 0us, total: 186.14ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.87ms, accelerator: 0us, total: 89.87ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 304904859.92sec, total: 304904859.92sec
train.py:448:<module>, cpu: 89.87ms, accelerator: 0us, total: 89.87ms
train.py:449:<module>, cpu: 50.41ms, accelerator: 425us, total: 50.83ms
  summary.py:146:image, cpu: 50.38ms, accelerator: 0us, total: 50.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_30250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 151202819.89sec, total: 151202819.89sec (50.00%)
top 2 operation type: ReluGrad, cpu: 985us, accelerator: 151202819.86sec, total: 151202819.86sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.02ms, accelerator: 0us, total: 186.02ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 302405639.76sec, total: 302405639.76sec
train.py:448:<module>, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
train.py:449:<module>, cpu: 50.34ms, accelerator: 426us, total: 50.76ms
  summary.py:146:image, cpu: 50.31ms, accelerator: 0us, total: 50.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_30500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 149973528.67sec, total: 149973528.68sec (50.00%)
top 2 operation type: ReluGrad, cpu: 984us, accelerator: 149973528.64sec, total: 149973528.64sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.97ms, accelerator: 0us, total: 185.97ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.81ms, accelerator: 0us, total: 89.81ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 299947057.32sec, total: 299947057.32sec
train.py:448:<module>, cpu: 89.82ms, accelerator: 0us, total: 89.82ms
train.py:449:<module>, cpu: 50.34ms, accelerator: 426us, total: 50.76ms
  summary.py:146:image, cpu: 50.31ms, accelerator: 0us, total: 50.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_30750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 148764064.73sec, total: 148764064.73sec (50.00%)
top 2 operation type: ReluGrad, cpu: 985us, accelerator: 148764064.70sec, total: 148764064.70sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.93ms, accelerator: 0us, total: 185.93ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 297528129.44sec, total: 297528129.44sec
train.py:448:<module>, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
train.py:449:<module>, cpu: 50.28ms, accelerator: 427us, total: 50.71ms
  summary.py:146:image, cpu: 50.26ms, accelerator: 0us, total: 50.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_31000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 147573952.22sec, total: 147573952.22sec (50.00%)
top 2 operation type: ReluGrad, cpu: 984us, accelerator: 147573952.18sec, total: 147573952.18sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.92ms, accelerator: 0us, total: 185.92ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.43ms, accelerator: 295147904.40sec, total: 295147904.41sec
train.py:448:<module>, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
train.py:449:<module>, cpu: 50.28ms, accelerator: 427us, total: 50.71ms
  summary.py:146:image, cpu: 50.26ms, accelerator: 0us, total: 50.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_31250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 146402730.37sec, total: 146402730.37sec (50.00%)
top 2 operation type: ReluGrad, cpu: 983us, accelerator: 146402730.34sec, total: 146402730.34sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.99ms, accelerator: 0us, total: 185.99ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.90ms, accelerator: 0us, total: 89.90ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 292805460.72sec, total: 292805460.72sec
train.py:448:<module>, cpu: 89.90ms, accelerator: 0us, total: 89.90ms
train.py:449:<module>, cpu: 50.29ms, accelerator: 427us, total: 50.72ms
  summary.py:146:image, cpu: 50.27ms, accelerator: 0us, total: 50.27ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_31500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 145249952.97sec, total: 145249952.97sec (50.00%)
top 2 operation type: ReluGrad, cpu: 984us, accelerator: 145249952.94sec, total: 145249952.94sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.01ms, accelerator: 0us, total: 186.01ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.92ms, accelerator: 0us, total: 89.92ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 290499905.91sec, total: 290499905.91sec
train.py:448:<module>, cpu: 89.92ms, accelerator: 0us, total: 89.92ms
train.py:449:<module>, cpu: 50.30ms, accelerator: 428us, total: 50.73ms
  summary.py:146:image, cpu: 50.27ms, accelerator: 0us, total: 50.27ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_31750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 144115187.71sec, total: 144115187.71sec (50.00%)
top 2 operation type: ReluGrad, cpu: 982us, accelerator: 144115187.68sec, total: 144115187.68sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.88ms, accelerator: 0us, total: 185.88ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.91ms, accelerator: 0us, total: 89.91ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 288230375.39sec, total: 288230375.40sec
train.py:448:<module>, cpu: 89.91ms, accelerator: 0us, total: 89.91ms
train.py:442:<module>, cpu: 4.06ms, accelerator: 46.58ms, total: 50.70ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.43ms, total: 42.78ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.43ms, total: 42.76ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.32ms, total: 42.57ms
  train.py:359:image_losses, cpu: 544us, accelerator: 6.49ms, total: 7.05ms
    train.py:322:loss_fn, cpu: 532us, accelerator: 6.49ms, total: 7.04ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.68ms, total: 4.88ms
      train.py:342:hfe, cpu: 210us, accelerator: 1.29ms, total: 1.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_32000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 142998015.71sec, total: 142998015.71sec (50.00%)
top 2 operation type: ReluGrad, cpu: 981us, accelerator: 142998015.68sec, total: 142998015.68sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.92ms, accelerator: 0us, total: 185.92ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.93ms, accelerator: 0us, total: 89.93ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 285996031.40sec, total: 285996031.40sec
train.py:448:<module>, cpu: 89.94ms, accelerator: 0us, total: 89.94ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 46.61ms, total: 50.74ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.46ms, total: 42.81ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.46ms, total: 42.79ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.35ms, total: 42.60ms
  train.py:359:image_losses, cpu: 544us, accelerator: 6.50ms, total: 7.06ms
    train.py:322:loss_fn, cpu: 532us, accelerator: 6.50ms, total: 7.04ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.69ms, total: 4.89ms
      train.py:342:hfe, cpu: 210us, accelerator: 1.29ms, total: 1.51ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_32250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 141898030.98sec, total: 141898030.98sec (50.00%)
top 2 operation type: ReluGrad, cpu: 981us, accelerator: 141898030.94sec, total: 141898030.95sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.86ms, accelerator: 0us, total: 185.86ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.86ms, accelerator: 0us, total: 89.86ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 283796061.93sec, total: 283796061.93sec
train.py:448:<module>, cpu: 89.86ms, accelerator: 0us, total: 89.86ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 46.59ms, total: 50.72ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.48ms, total: 42.84ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.48ms, total: 42.81ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.38ms, total: 42.63ms
  train.py:359:image_losses, cpu: 545us, accelerator: 6.45ms, total: 7.01ms
    train.py:322:loss_fn, cpu: 533us, accelerator: 6.45ms, total: 7.00ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.66ms, total: 4.85ms
      train.py:342:hfe, cpu: 210us, accelerator: 1.28ms, total: 1.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_32500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 140814839.90sec, total: 140814839.90sec (50.00%)
top 2 operation type: ReluGrad, cpu: 981us, accelerator: 140814839.87sec, total: 140814839.87sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.76ms, accelerator: 0us, total: 185.76ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.86ms, accelerator: 0us, total: 89.86ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.42ms, accelerator: 281629679.77sec, total: 281629679.78sec
train.py:448:<module>, cpu: 89.87ms, accelerator: 0us, total: 89.87ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 46.63ms, total: 50.76ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.51ms, total: 42.87ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.51ms, total: 42.85ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.40ms, total: 42.66ms
  train.py:359:image_losses, cpu: 545us, accelerator: 6.46ms, total: 7.02ms
    train.py:322:loss_fn, cpu: 533us, accelerator: 6.46ms, total: 7.00ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.67ms, total: 4.86ms
      train.py:342:hfe, cpu: 210us, accelerator: 1.29ms, total: 1.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_32750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 139748060.81sec, total: 139748060.81sec (50.00%)
top 2 operation type: ReluGrad, cpu: 983us, accelerator: 139748060.78sec, total: 139748060.78sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.78ms, accelerator: 0us, total: 185.78ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.88ms, accelerator: 0us, total: 89.88ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 279496121.59sec, total: 279496121.60sec
train.py:448:<module>, cpu: 89.88ms, accelerator: 0us, total: 89.88ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 46.65ms, total: 50.79ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.53ms, total: 42.89ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 39.53ms, total: 42.87ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.43ms, total: 42.69ms
  train.py:359:image_losses, cpu: 546us, accelerator: 6.47ms, total: 7.03ms
    train.py:322:loss_fn, cpu: 534us, accelerator: 6.47ms, total: 7.01ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.68ms, total: 4.88ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.29ms, total: 1.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_33000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 138697323.51sec, total: 138697323.51sec (50.00%)
top 2 operation type: ReluGrad, cpu: 980us, accelerator: 138697323.48sec, total: 138697323.48sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.74ms, accelerator: 0us, total: 185.74ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.86ms, accelerator: 0us, total: 89.86ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 277394647.00sec, total: 277394647.00sec
train.py:448:<module>, cpu: 89.86ms, accelerator: 0us, total: 89.86ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 46.69ms, total: 50.82ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.56ms, total: 42.92ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 39.56ms, total: 42.89ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.45ms, total: 42.71ms
  train.py:359:image_losses, cpu: 546us, accelerator: 6.47ms, total: 7.03ms
    train.py:322:loss_fn, cpu: 534us, accelerator: 6.47ms, total: 7.02ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.69ms, total: 4.88ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.29ms, total: 1.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_33250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 137662268.86sec, total: 137662268.86sec (50.00%)
top 2 operation type: ReluGrad, cpu: 980us, accelerator: 137662268.83sec, total: 137662268.83sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.65ms, accelerator: 0us, total: 185.65ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 275324537.69sec, total: 275324537.69sec
train.py:448:<module>, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 46.71ms, total: 50.84ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.58ms, total: 42.93ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.58ms, total: 42.91ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.47ms, total: 42.73ms
  train.py:359:image_losses, cpu: 547us, accelerator: 6.48ms, total: 7.04ms
    train.py:322:loss_fn, cpu: 535us, accelerator: 6.48ms, total: 7.03ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.70ms, total: 4.89ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.29ms, total: 1.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_33500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 136642548.35sec, total: 136642548.35sec (50.00%)
top 2 operation type: ReluGrad, cpu: 982us, accelerator: 136642548.32sec, total: 136642548.32sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.67ms, accelerator: 0us, total: 185.67ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.82ms, accelerator: 0us, total: 89.82ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 273285096.67sec, total: 273285096.68sec
train.py:448:<module>, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 46.73ms, total: 50.87ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.59ms, total: 42.96ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.59ms, total: 42.94ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.49ms, total: 42.75ms
  train.py:359:image_losses, cpu: 546us, accelerator: 6.49ms, total: 7.04ms
    train.py:322:loss_fn, cpu: 534us, accelerator: 6.49ms, total: 7.03ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.71ms, total: 4.90ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.29ms, total: 1.50ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_33750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 135637823.73sec, total: 135637823.73sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 135637823.70sec, total: 135637823.70sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.64ms, accelerator: 0us, total: 185.64ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 271275647.43sec, total: 271275647.43sec
train.py:448:<module>, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 46.77ms, total: 50.90ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.63ms, total: 42.98ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.63ms, total: 42.96ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.52ms, total: 42.78ms
  train.py:359:image_losses, cpu: 546us, accelerator: 6.49ms, total: 7.05ms
    train.py:322:loss_fn, cpu: 534us, accelerator: 6.49ms, total: 7.04ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.72ms, total: 4.91ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.29ms, total: 1.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_34000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 134647766.62sec, total: 134647766.62sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 134647766.59sec, total: 134647766.59sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.53ms, accelerator: 0us, total: 185.53ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.82ms, accelerator: 0us, total: 89.82ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 269295533.21sec, total: 269295533.22sec
train.py:448:<module>, cpu: 89.83ms, accelerator: 0us, total: 89.83ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 46.80ms, total: 50.93ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.65ms, total: 43.00ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.65ms, total: 42.98ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.55ms, total: 42.80ms
  train.py:359:image_losses, cpu: 546us, accelerator: 6.50ms, total: 7.06ms
    train.py:322:loss_fn, cpu: 534us, accelerator: 6.50ms, total: 7.05ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.73ms, total: 4.92ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.29ms, total: 1.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_34250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 133672058.17sec, total: 133672058.17sec (50.00%)
top 2 operation type: ReluGrad, cpu: 977us, accelerator: 133672058.14sec, total: 133672058.14sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.50ms, accelerator: 0us, total: 185.50ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.77ms, accelerator: 0us, total: 89.77ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 267344116.31sec, total: 267344116.31sec
train.py:448:<module>, cpu: 89.78ms, accelerator: 0us, total: 89.78ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 46.83ms, total: 50.95ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.67ms, total: 43.02ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.67ms, total: 43.00ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.57ms, total: 42.82ms
  train.py:359:image_losses, cpu: 546us, accelerator: 6.51ms, total: 7.07ms
    train.py:322:loss_fn, cpu: 534us, accelerator: 6.51ms, total: 7.06ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.74ms, total: 4.93ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.29ms, total: 1.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_34500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 132710388.68sec, total: 132710388.69sec (50.00%)
top 2 operation type: ReluGrad, cpu: 976us, accelerator: 132710388.65sec, total: 132710388.65sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.51ms, accelerator: 0us, total: 185.51ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.82ms, accelerator: 0us, total: 89.82ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 265420777.34sec, total: 265420777.35sec
train.py:448:<module>, cpu: 89.82ms, accelerator: 0us, total: 89.82ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 46.83ms, total: 50.96ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.53ms, total: 42.89ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.53ms, total: 42.87ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.43ms, total: 42.68ms
  train.py:359:image_losses, cpu: 546us, accelerator: 6.65ms, total: 7.22ms
    train.py:322:loss_fn, cpu: 534us, accelerator: 6.65ms, total: 7.20ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.71ms, total: 4.90ms
      train.py:342:hfe, cpu: 211us, accelerator: 1.37ms, total: 1.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_34750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 131762457.34sec, total: 131762457.34sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 131762457.31sec, total: 131762457.31sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.50ms, accelerator: 0us, total: 185.50ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.79ms, accelerator: 0us, total: 89.79ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 263524914.65sec, total: 263524914.65sec
train.py:448:<module>, cpu: 89.80ms, accelerator: 0us, total: 89.80ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 46.84ms, total: 50.97ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.54ms, total: 42.89ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.54ms, total: 42.87ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.44ms, total: 42.69ms
  train.py:359:image_losses, cpu: 548us, accelerator: 6.66ms, total: 7.22ms
    train.py:322:loss_fn, cpu: 536us, accelerator: 6.66ms, total: 7.21ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.72ms, total: 4.91ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_35000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 130827971.82sec, total: 130827971.83sec (50.00%)
top 2 operation type: ReluGrad, cpu: 977us, accelerator: 130827971.79sec, total: 130827971.79sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.61ms, accelerator: 0us, total: 185.61ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.80ms, accelerator: 0us, total: 89.80ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 261655943.62sec, total: 261655943.63sec
train.py:448:<module>, cpu: 89.80ms, accelerator: 0us, total: 89.80ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 46.87ms, total: 51.00ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.56ms, total: 42.92ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.56ms, total: 42.89ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.46ms, total: 42.71ms
  train.py:359:image_losses, cpu: 547us, accelerator: 6.67ms, total: 7.23ms
    train.py:322:loss_fn, cpu: 535us, accelerator: 6.67ms, total: 7.21ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.72ms, total: 4.92ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_35250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 129906648.08sec, total: 129906648.08sec (50.00%)
top 2 operation type: ReluGrad, cpu: 976us, accelerator: 129906648.05sec, total: 129906648.05sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.54ms, accelerator: 0us, total: 185.54ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.77ms, accelerator: 0us, total: 89.77ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 259813296.13sec, total: 259813296.14sec
train.py:448:<module>, cpu: 89.77ms, accelerator: 0us, total: 89.77ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 46.90ms, total: 51.03ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.58ms, total: 42.94ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.58ms, total: 42.92ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.48ms, total: 42.74ms
  train.py:359:image_losses, cpu: 548us, accelerator: 6.67ms, total: 7.23ms
    train.py:322:loss_fn, cpu: 536us, accelerator: 6.67ms, total: 7.22ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.73ms, total: 4.93ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_35500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 128998209.98sec, total: 128998209.98sec (50.00%)
top 2 operation type: ReluGrad, cpu: 976us, accelerator: 128998209.95sec, total: 128998209.95sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.61ms, accelerator: 0us, total: 185.61ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.79ms, accelerator: 0us, total: 89.79ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 257996419.93sec, total: 257996419.94sec
train.py:448:<module>, cpu: 89.80ms, accelerator: 0us, total: 89.80ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 46.93ms, total: 51.05ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.61ms, total: 42.96ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.61ms, total: 42.94ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.51ms, total: 42.76ms
  train.py:359:image_losses, cpu: 548us, accelerator: 6.68ms, total: 7.24ms
    train.py:322:loss_fn, cpu: 536us, accelerator: 6.68ms, total: 7.22ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.74ms, total: 4.94ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_35750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 128102389.08sec, total: 128102389.08sec (50.00%)
top 2 operation type: ReluGrad, cpu: 977us, accelerator: 128102389.05sec, total: 128102389.05sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.69ms, accelerator: 0us, total: 185.69ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 256204778.13sec, total: 256204778.13sec
train.py:448:<module>, cpu: 89.84ms, accelerator: 0us, total: 89.84ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 46.95ms, total: 51.09ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.63ms, total: 42.99ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.63ms, total: 42.97ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.53ms, total: 42.79ms
  train.py:359:image_losses, cpu: 548us, accelerator: 6.68ms, total: 7.24ms
    train.py:322:loss_fn, cpu: 536us, accelerator: 6.68ms, total: 7.23ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.75ms, total: 4.95ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_36000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 127218924.33sec, total: 127218924.33sec (50.00%)
top 2 operation type: ReluGrad, cpu: 977us, accelerator: 127218924.30sec, total: 127218924.30sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.75ms, accelerator: 0us, total: 185.75ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.86ms, accelerator: 0us, total: 89.86ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 254437848.62sec, total: 254437848.63sec
train.py:448:<module>, cpu: 89.86ms, accelerator: 0us, total: 89.86ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 46.98ms, total: 51.12ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.65ms, total: 43.01ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.65ms, total: 42.99ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.55ms, total: 42.81ms
  train.py:359:image_losses, cpu: 547us, accelerator: 6.69ms, total: 7.25ms
    train.py:322:loss_fn, cpu: 535us, accelerator: 6.69ms, total: 7.24ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.76ms, total: 4.95ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_36250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 126347561.83sec, total: 126347561.83sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 126347561.80sec, total: 126347561.80sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.84ms, accelerator: 0us, total: 185.84ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.91ms, accelerator: 0us, total: 89.91ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 252695123.63sec, total: 252695123.64sec
train.py:448:<module>, cpu: 89.92ms, accelerator: 0us, total: 89.92ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.00ms, total: 51.14ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.67ms, total: 43.03ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 39.67ms, total: 43.01ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.57ms, total: 42.83ms
  train.py:359:image_losses, cpu: 547us, accelerator: 6.69ms, total: 7.26ms
    train.py:322:loss_fn, cpu: 535us, accelerator: 6.69ms, total: 7.24ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.77ms, total: 4.96ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_36500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 125488054.61sec, total: 125488054.61sec (50.00%)
top 2 operation type: ReluGrad, cpu: 977us, accelerator: 125488054.58sec, total: 125488054.58sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.81ms, accelerator: 0us, total: 185.81ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.94ms, accelerator: 0us, total: 89.94ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 250976109.19sec, total: 250976109.19sec
train.py:448:<module>, cpu: 89.94ms, accelerator: 0us, total: 89.94ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.03ms, total: 51.16ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.69ms, total: 43.06ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 39.69ms, total: 43.03ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.59ms, total: 42.86ms
  train.py:359:image_losses, cpu: 547us, accelerator: 6.70ms, total: 7.26ms
    train.py:322:loss_fn, cpu: 535us, accelerator: 6.70ms, total: 7.24ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.78ms, total: 4.97ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_36750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 124640162.35sec, total: 124640162.35sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 124640162.32sec, total: 124640162.32sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.81ms, accelerator: 0us, total: 185.81ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.94ms, accelerator: 0us, total: 89.94ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 249280324.67sec, total: 249280324.67sec
train.py:448:<module>, cpu: 89.95ms, accelerator: 0us, total: 89.95ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.05ms, total: 51.19ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.72ms, total: 43.08ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 39.72ms, total: 43.05ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.62ms, total: 42.88ms
  train.py:359:image_losses, cpu: 547us, accelerator: 6.70ms, total: 7.26ms
    train.py:322:loss_fn, cpu: 535us, accelerator: 6.70ms, total: 7.25ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.79ms, total: 4.98ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_37000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 123803651.19sec, total: 123803651.19sec (50.00%)
top 2 operation type: ReluGrad, cpu: 982us, accelerator: 123803651.16sec, total: 123803651.16sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.89ms, accelerator: 0us, total: 185.89ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 89.99ms, accelerator: 0us, total: 89.99ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 247607302.35sec, total: 247607302.36sec
train.py:448:<module>, cpu: 90.00ms, accelerator: 0us, total: 90.00ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.07ms, total: 51.22ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.73ms, total: 43.10ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 39.73ms, total: 43.08ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.63ms, total: 42.90ms
  train.py:359:image_losses, cpu: 548us, accelerator: 6.71ms, total: 7.27ms
    train.py:322:loss_fn, cpu: 536us, accelerator: 6.71ms, total: 7.26ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.79ms, total: 4.99ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_37250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 122978293.51sec, total: 122978293.52sec (50.00%)
top 2 operation type: ReluGrad, cpu: 980us, accelerator: 122978293.49sec, total: 122978293.49sec (50.00%)
top 3 operation type: ImageSummary, cpu: 185.97ms, accelerator: 0us, total: 185.97ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.03ms, accelerator: 0us, total: 90.03ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 245956587.00sec, total: 245956587.01sec
train.py:448:<module>, cpu: 90.03ms, accelerator: 0us, total: 90.03ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.10ms, total: 51.23ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.75ms, total: 43.11ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.75ms, total: 43.09ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.66ms, total: 42.91ms
  train.py:359:image_losses, cpu: 548us, accelerator: 6.71ms, total: 7.27ms
    train.py:322:loss_fn, cpu: 536us, accelerator: 6.71ms, total: 7.26ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.80ms, total: 5.00ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_37500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 122163867.73sec, total: 122163867.73sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 122163867.70sec, total: 122163867.70sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.02ms, accelerator: 0us, total: 186.02ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.07ms, accelerator: 0us, total: 90.07ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 244327735.43sec, total: 244327735.44sec
train.py:448:<module>, cpu: 90.08ms, accelerator: 0us, total: 90.08ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.13ms, total: 51.26ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.78ms, total: 43.13ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 39.78ms, total: 43.11ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.68ms, total: 42.94ms
  train.py:359:image_losses, cpu: 548us, accelerator: 6.72ms, total: 7.28ms
    train.py:322:loss_fn, cpu: 536us, accelerator: 6.72ms, total: 7.27ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.81ms, total: 5.00ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_37750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 121360158.07sec, total: 121360158.08sec (50.00%)
top 2 operation type: ReluGrad, cpu: 980us, accelerator: 121360158.05sec, total: 121360158.05sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.04ms, accelerator: 0us, total: 186.04ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.09ms, accelerator: 0us, total: 90.09ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 242720316.12sec, total: 242720316.13sec
train.py:448:<module>, cpu: 90.10ms, accelerator: 0us, total: 90.10ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.15ms, total: 51.28ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.79ms, total: 43.15ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 39.79ms, total: 43.13ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.70ms, total: 42.96ms
  train.py:359:image_losses, cpu: 549us, accelerator: 6.72ms, total: 7.28ms
    train.py:322:loss_fn, cpu: 537us, accelerator: 6.72ms, total: 7.27ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.82ms, total: 5.01ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_38000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 120566954.43sec, total: 120566954.43sec (50.00%)
top 2 operation type: ReluGrad, cpu: 983us, accelerator: 120566954.40sec, total: 120566954.40sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.05ms, accelerator: 0us, total: 186.05ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.10ms, accelerator: 0us, total: 90.10ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 241133908.83sec, total: 241133908.83sec
train.py:448:<module>, cpu: 90.11ms, accelerator: 0us, total: 90.11ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.17ms, total: 51.31ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.81ms, total: 43.18ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 39.81ms, total: 43.15ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.72ms, total: 42.98ms
  train.py:359:image_losses, cpu: 548us, accelerator: 6.73ms, total: 7.29ms
    train.py:322:loss_fn, cpu: 536us, accelerator: 6.73ms, total: 7.28ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.83ms, total: 5.02ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_38250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 119784052.13sec, total: 119784052.13sec (50.00%)
top 2 operation type: ReluGrad, cpu: 982us, accelerator: 119784052.10sec, total: 119784052.10sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.07ms, accelerator: 0us, total: 186.07ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.14ms, accelerator: 0us, total: 90.14ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 239568104.23sec, total: 239568104.23sec
train.py:448:<module>, cpu: 90.14ms, accelerator: 0us, total: 90.14ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.20ms, total: 51.33ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.83ms, total: 43.19ms
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 39.83ms, total: 43.17ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.74ms, total: 42.99ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.73ms, total: 7.29ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.73ms, total: 7.28ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.84ms, total: 5.03ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_38500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 119011251.79sec, total: 119011251.79sec (50.00%)
top 2 operation type: ReluGrad, cpu: 982us, accelerator: 119011251.76sec, total: 119011251.76sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.18ms, accelerator: 0us, total: 186.18ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.19ms, accelerator: 0us, total: 90.19ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 238022503.55sec, total: 238022503.56sec
train.py:448:<module>, cpu: 90.20ms, accelerator: 0us, total: 90.20ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.22ms, total: 51.35ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.85ms, total: 43.21ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.85ms, total: 43.19ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.76ms, total: 43.02ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.74ms, total: 7.30ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.74ms, total: 7.28ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.84ms, total: 5.04ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.37ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_38750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 118248359.15sec, total: 118248359.15sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 118248359.12sec, total: 118248359.12sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.28ms, accelerator: 0us, total: 186.28ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.26ms, accelerator: 0us, total: 90.26ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 236496718.27sec, total: 236496718.28sec
train.py:448:<module>, cpu: 90.26ms, accelerator: 0us, total: 90.26ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.24ms, total: 51.38ms
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 39.87ms, total: 43.23ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.87ms, total: 43.21ms
      train.py:349:msssim, cpu: 3.22ms, accelerator: 39.78ms, total: 43.04ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.74ms, total: 7.30ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.74ms, total: 7.29ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.85ms, total: 5.04ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_39000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 117495184.89sec, total: 117495184.89sec (50.00%)
top 2 operation type: ReluGrad, cpu: 981us, accelerator: 117495184.86sec, total: 117495184.86sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.35ms, accelerator: 0us, total: 186.35ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.27ms, accelerator: 0us, total: 90.27ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 234990369.75sec, total: 234990369.76sec
train.py:448:<module>, cpu: 90.28ms, accelerator: 0us, total: 90.28ms
train.py:442:<module>, cpu: 4.08ms, accelerator: 47.26ms, total: 51.40ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.89ms, total: 43.25ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.89ms, total: 43.22ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.79ms, total: 43.05ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.74ms, total: 7.31ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.74ms, total: 7.30ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.86ms, total: 5.05ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_39250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 116751544.48sec, total: 116751544.48sec (50.00%)
top 2 operation type: ReluGrad, cpu: 980us, accelerator: 116751544.45sec, total: 116751544.45sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.39ms, accelerator: 0us, total: 186.39ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.30ms, accelerator: 0us, total: 90.30ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 233503088.93sec, total: 233503088.93sec
train.py:448:<module>, cpu: 90.30ms, accelerator: 0us, total: 90.30ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.28ms, total: 51.42ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.91ms, total: 43.27ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.91ms, total: 43.24ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.82ms, total: 43.07ms
  train.py:359:image_losses, cpu: 549us, accelerator: 6.75ms, total: 7.31ms
    train.py:322:loss_fn, cpu: 537us, accelerator: 6.75ms, total: 7.30ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.87ms, total: 5.06ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_39500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 116017258.03sec, total: 116017258.04sec (50.00%)
top 2 operation type: ReluGrad, cpu: 982us, accelerator: 116017258.01sec, total: 116017258.01sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.48ms, accelerator: 0us, total: 186.48ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.34ms, accelerator: 0us, total: 90.34ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 232034516.04sec, total: 232034516.05sec
train.py:448:<module>, cpu: 90.34ms, accelerator: 0us, total: 90.34ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.31ms, total: 51.44ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.93ms, total: 43.28ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.93ms, total: 43.26ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.83ms, total: 43.09ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.75ms, total: 7.32ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.75ms, total: 7.30ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.87ms, total: 5.07ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_39750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 115292150.17sec, total: 115292150.17sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 115292150.14sec, total: 115292150.14sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.50ms, accelerator: 0us, total: 186.50ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.36ms, accelerator: 0us, total: 90.36ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 230584300.32sec, total: 230584300.32sec
train.py:448:<module>, cpu: 90.37ms, accelerator: 0us, total: 90.37ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.33ms, total: 51.46ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.94ms, total: 43.30ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.94ms, total: 43.27ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.85ms, total: 43.10ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.76ms, total: 7.32ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.76ms, total: 7.31ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.88ms, total: 5.07ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_40000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 114576049.86sec, total: 114576049.86sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 114576049.83sec, total: 114576049.83sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.50ms, accelerator: 0us, total: 186.50ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.37ms, accelerator: 0us, total: 90.37ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 229152099.69sec, total: 229152099.70sec
train.py:448:<module>, cpu: 90.37ms, accelerator: 0us, total: 90.37ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.34ms, total: 51.48ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.95ms, total: 43.31ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.95ms, total: 43.29ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.86ms, total: 43.12ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.76ms, total: 7.33ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.76ms, total: 7.31ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.89ms, total: 5.08ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_40250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 113868790.29sec, total: 113868790.29sec (50.00%)
top 2 operation type: ReluGrad, cpu: 977us, accelerator: 113868790.27sec, total: 113868790.27sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.54ms, accelerator: 0us, total: 186.54ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.39ms, accelerator: 0us, total: 90.39ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 227737580.56sec, total: 227737580.57sec
train.py:448:<module>, cpu: 90.40ms, accelerator: 0us, total: 90.40ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.37ms, total: 51.49ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.97ms, total: 43.32ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 39.97ms, total: 43.30ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.88ms, total: 43.13ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.76ms, total: 7.33ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.76ms, total: 7.31ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.89ms, total: 5.09ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_40500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 113170208.76sec, total: 113170208.76sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 113170208.73sec, total: 113170208.73sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.57ms, accelerator: 0us, total: 186.57ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.41ms, accelerator: 0us, total: 90.41ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 226340417.49sec, total: 226340417.49sec
train.py:448:<module>, cpu: 90.42ms, accelerator: 0us, total: 90.42ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.38ms, total: 51.52ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 39.99ms, total: 43.34ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 39.99ms, total: 43.32ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.90ms, total: 43.15ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.76ms, total: 7.33ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.76ms, total: 7.32ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.90ms, total: 5.09ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_40750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 112480146.51sec, total: 112480146.51sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 112480146.48sec, total: 112480146.48sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.64ms, accelerator: 0us, total: 186.64ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.43ms, accelerator: 0us, total: 90.43ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 224960292.99sec, total: 224960293.00sec
train.py:448:<module>, cpu: 90.44ms, accelerator: 0us, total: 90.44ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.41ms, total: 51.54ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 40.01ms, total: 43.37ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 40.01ms, total: 43.34ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.92ms, total: 43.18ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.77ms, total: 7.34ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.77ms, total: 7.32ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.91ms, total: 5.10ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_41000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 111798448.65sec, total: 111798448.65sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 111798448.62sec, total: 111798448.63sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.68ms, accelerator: 0us, total: 186.68ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.45ms, accelerator: 0us, total: 90.45ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 223596897.28sec, total: 223596897.28sec
train.py:448:<module>, cpu: 90.45ms, accelerator: 0us, total: 90.45ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.43ms, total: 51.56ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 40.03ms, total: 43.38ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.03ms, total: 43.35ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.94ms, total: 43.19ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.78ms, total: 7.34ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.78ms, total: 7.33ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.92ms, total: 5.11ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_41250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 111124964.02sec, total: 111124964.02sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 111124963.99sec, total: 111124964.00sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.70ms, accelerator: 0us, total: 186.70ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.47ms, accelerator: 0us, total: 90.47ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 222249928.02sec, total: 222249928.02sec
train.py:448:<module>, cpu: 90.47ms, accelerator: 0us, total: 90.47ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.45ms, total: 51.58ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.05ms, total: 43.39ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.05ms, total: 43.37ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 39.96ms, total: 43.20ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.78ms, total: 7.34ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.78ms, total: 7.33ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.92ms, total: 5.12ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_41500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 110459545.07sec, total: 110459545.08sec (50.00%)
top 2 operation type: ReluGrad, cpu: 977us, accelerator: 110459545.05sec, total: 110459545.05sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.78ms, accelerator: 0us, total: 186.78ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.48ms, accelerator: 0us, total: 90.48ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 220919090.12sec, total: 220919090.13sec
train.py:448:<module>, cpu: 90.49ms, accelerator: 0us, total: 90.49ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.47ms, total: 51.60ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 40.06ms, total: 43.41ms
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 40.06ms, total: 43.39ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.97ms, total: 43.22ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.79ms, total: 7.35ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.79ms, total: 7.34ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.93ms, total: 5.12ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_41750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 109802047.78sec, total: 109802047.78sec (50.00%)
top 2 operation type: ReluGrad, cpu: 980us, accelerator: 109802047.76sec, total: 109802047.76sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.86ms, accelerator: 0us, total: 186.86ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.51ms, accelerator: 0us, total: 90.51ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 219604095.54sec, total: 219604095.55sec
train.py:448:<module>, cpu: 90.52ms, accelerator: 0us, total: 90.52ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.49ms, total: 51.61ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 40.08ms, total: 43.42ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.08ms, total: 43.40ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 39.99ms, total: 43.23ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.79ms, total: 7.35ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.79ms, total: 7.34ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.93ms, total: 5.13ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_42000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 109152331.52sec, total: 109152331.52sec (50.00%)
top 2 operation type: ReluGrad, cpu: 980us, accelerator: 109152331.50sec, total: 109152331.50sec (50.00%)
top 3 operation type: ImageSummary, cpu: 186.90ms, accelerator: 0us, total: 186.90ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.52ms, accelerator: 0us, total: 90.52ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 218304663.02sec, total: 218304663.03sec
train.py:448:<module>, cpu: 90.52ms, accelerator: 0us, total: 90.52ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.50ms, total: 51.63ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.09ms, total: 43.44ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.09ms, total: 43.41ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.00ms, total: 43.25ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.79ms, total: 7.36ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.79ms, total: 7.34ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.94ms, total: 5.13ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_42250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 108510258.98sec, total: 108510258.99sec (50.00%)
top 2 operation type: ReluGrad, cpu: 980us, accelerator: 108510258.96sec, total: 108510258.96sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.03ms, accelerator: 0us, total: 187.03ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.56ms, accelerator: 0us, total: 90.56ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 217020517.95sec, total: 217020517.95sec
train.py:448:<module>, cpu: 90.57ms, accelerator: 0us, total: 90.57ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.52ms, total: 51.65ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.10ms, total: 43.45ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.10ms, total: 43.43ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.02ms, total: 43.27ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.80ms, total: 7.36ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.80ms, total: 7.35ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.95ms, total: 5.14ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_42500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 107875696.07sec, total: 107875696.07sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 107875696.04sec, total: 107875696.04sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.09ms, accelerator: 0us, total: 187.09ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.60ms, accelerator: 0us, total: 90.60ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 215751392.11sec, total: 215751392.12sec
train.py:448:<module>, cpu: 90.61ms, accelerator: 0us, total: 90.61ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.54ms, total: 51.67ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.12ms, total: 43.47ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.12ms, total: 43.45ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.04ms, total: 43.28ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.80ms, total: 7.36ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.80ms, total: 7.35ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.95ms, total: 5.15ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_42750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 107248511.79sec, total: 107248511.79sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 107248511.76sec, total: 107248511.76sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.12ms, accelerator: 0us, total: 187.12ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.65ms, accelerator: 0us, total: 90.65ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 214497023.55sec, total: 214497023.56sec
train.py:448:<module>, cpu: 90.65ms, accelerator: 0us, total: 90.65ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.56ms, total: 51.69ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.14ms, total: 43.49ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.14ms, total: 43.46ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.05ms, total: 43.30ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.80ms, total: 7.37ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.80ms, total: 7.36ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.96ms, total: 5.16ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_43000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 106628578.19sec, total: 106628578.20sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 106628578.17sec, total: 106628578.17sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.08ms, accelerator: 0us, total: 187.08ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.64ms, accelerator: 0us, total: 90.64ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 213257156.36sec, total: 213257156.37sec
train.py:448:<module>, cpu: 90.65ms, accelerator: 0us, total: 90.65ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.58ms, total: 51.70ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.15ms, total: 43.50ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.15ms, total: 43.48ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.07ms, total: 43.31ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.81ms, total: 7.37ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.81ms, total: 7.36ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.97ms, total: 5.16ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_43250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 106015770.27sec, total: 106015770.27sec (50.00%)
top 2 operation type: ReluGrad, cpu: 977us, accelerator: 106015770.25sec, total: 106015770.25sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.11ms, accelerator: 0us, total: 187.11ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.66ms, accelerator: 0us, total: 90.66ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 212031540.52sec, total: 212031540.53sec
train.py:448:<module>, cpu: 90.67ms, accelerator: 0us, total: 90.67ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.60ms, total: 51.73ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.17ms, total: 43.52ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.17ms, total: 43.49ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.09ms, total: 43.33ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.81ms, total: 7.38ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.81ms, total: 7.36ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.97ms, total: 5.17ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.36ms, total: 1.58ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_43500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 105409965.87sec, total: 105409965.87sec (50.00%)
top 2 operation type: ReluGrad, cpu: 977us, accelerator: 105409965.85sec, total: 105409965.85sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.13ms, accelerator: 0us, total: 187.13ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.66ms, accelerator: 0us, total: 90.66ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 210819931.72sec, total: 210819931.73sec
train.py:448:<module>, cpu: 90.66ms, accelerator: 0us, total: 90.66ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.62ms, total: 51.74ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 40.18ms, total: 43.53ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.18ms, total: 43.51ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.10ms, total: 43.34ms
  train.py:359:image_losses, cpu: 552us, accelerator: 6.82ms, total: 7.38ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 6.82ms, total: 7.37ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.98ms, total: 5.17ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.36ms, total: 1.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_43750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 104811045.61sec, total: 104811045.61sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 104811045.59sec, total: 104811045.59sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.07ms, accelerator: 0us, total: 187.07ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.65ms, accelerator: 0us, total: 90.65ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 209622091.20sec, total: 209622091.20sec
train.py:448:<module>, cpu: 90.66ms, accelerator: 0us, total: 90.66ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.62ms, total: 51.75ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 40.08ms, total: 43.42ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.08ms, total: 43.40ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 39.99ms, total: 43.23ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.93ms, total: 7.49ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.93ms, total: 7.48ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.95ms, total: 5.14ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.42ms, total: 1.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_44000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 104218892.81sec, total: 104218892.81sec (50.00%)
top 2 operation type: ReluGrad, cpu: 977us, accelerator: 104218892.79sec, total: 104218892.79sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.05ms, accelerator: 0us, total: 187.05ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.65ms, accelerator: 0us, total: 90.65ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 208437785.60sec, total: 208437785.60sec
train.py:448:<module>, cpu: 90.65ms, accelerator: 0us, total: 90.65ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.63ms, total: 51.76ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.09ms, total: 43.44ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.09ms, total: 43.41ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.00ms, total: 43.25ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.93ms, total: 7.50ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.93ms, total: 7.48ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.96ms, total: 5.15ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.42ms, total: 1.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_44250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 103633393.41sec, total: 103633393.41sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 103633393.39sec, total: 103633393.39sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.09ms, accelerator: 0us, total: 187.09ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.65ms, accelerator: 0us, total: 90.65ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 207266786.80sec, total: 207266786.81sec
train.py:448:<module>, cpu: 90.65ms, accelerator: 0us, total: 90.65ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.65ms, total: 51.77ms
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 40.10ms, total: 43.45ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.10ms, total: 43.43ms
      train.py:349:msssim, cpu: 3.21ms, accelerator: 40.02ms, total: 43.26ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.93ms, total: 7.50ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.93ms, total: 7.49ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.96ms, total: 5.16ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.42ms, total: 1.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_44500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 103054435.91sec, total: 103054435.91sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 103054435.88sec, total: 103054435.88sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.14ms, accelerator: 0us, total: 187.14ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.66ms, accelerator: 0us, total: 90.66ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 206108871.79sec, total: 206108871.80sec
train.py:448:<module>, cpu: 90.67ms, accelerator: 0us, total: 90.67ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.67ms, total: 51.79ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.12ms, total: 43.46ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.12ms, total: 43.44ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.03ms, total: 43.27ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.94ms, total: 7.50ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.94ms, total: 7.49ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.97ms, total: 5.16ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.42ms, total: 1.64ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_44750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 102481911.26sec, total: 102481911.27sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 102481911.24sec, total: 102481911.24sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.13ms, accelerator: 0us, total: 187.13ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.66ms, accelerator: 0us, total: 90.66ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 204963822.51sec, total: 204963822.51sec
train.py:448:<module>, cpu: 90.66ms, accelerator: 0us, total: 90.66ms
train.py:442:<module>, cpu: 4.06ms, accelerator: 47.69ms, total: 51.81ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.14ms, total: 43.47ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.14ms, total: 43.45ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.05ms, total: 43.29ms
  train.py:359:image_losses, cpu: 548us, accelerator: 6.94ms, total: 7.51ms
    train.py:322:loss_fn, cpu: 536us, accelerator: 6.94ms, total: 7.49ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.98ms, total: 5.17ms
      train.py:342:hfe, cpu: 212us, accelerator: 1.42ms, total: 1.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_45000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 101915712.86sec, total: 101915712.86sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 101915712.83sec, total: 101915712.84sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.16ms, accelerator: 0us, total: 187.16ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.66ms, accelerator: 0us, total: 90.66ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 203831425.70sec, total: 203831425.70sec
train.py:448:<module>, cpu: 90.66ms, accelerator: 0us, total: 90.66ms
train.py:442:<module>, cpu: 4.06ms, accelerator: 47.70ms, total: 51.83ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.15ms, total: 43.49ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.15ms, total: 43.47ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.06ms, total: 43.31ms
  train.py:359:image_losses, cpu: 550us, accelerator: 6.94ms, total: 7.51ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 6.94ms, total: 7.50ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.98ms, total: 5.17ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.42ms, total: 1.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_45250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 101355736.42sec, total: 101355736.42sec (50.00%)
top 2 operation type: ReluGrad, cpu: 981us, accelerator: 101355736.39sec, total: 101355736.39sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.15ms, accelerator: 0us, total: 187.15ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.68ms, accelerator: 0us, total: 90.68ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 202711472.81sec, total: 202711472.81sec
train.py:448:<module>, cpu: 90.69ms, accelerator: 0us, total: 90.69ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.72ms, total: 51.85ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.16ms, total: 43.51ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.16ms, total: 43.49ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.08ms, total: 43.33ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.95ms, total: 7.51ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.95ms, total: 7.50ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.99ms, total: 5.18ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.42ms, total: 1.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_45500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 100801879.93sec, total: 100801879.93sec (50.00%)
top 2 operation type: ReluGrad, cpu: 980us, accelerator: 100801879.91sec, total: 100801879.91sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.15ms, accelerator: 0us, total: 187.15ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.70ms, accelerator: 0us, total: 90.70ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 201603759.84sec, total: 201603759.85sec
train.py:448:<module>, cpu: 90.70ms, accelerator: 0us, total: 90.70ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.74ms, total: 51.85ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.18ms, total: 43.52ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.18ms, total: 43.49ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.09ms, total: 43.33ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.95ms, total: 7.51ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.95ms, total: 7.50ms
      train.py:343:hfe, cpu: 190us, accelerator: 5.00ms, total: 5.19ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.42ms, total: 1.64ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_45750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 100254043.63sec, total: 100254043.63sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 100254043.60sec, total: 100254043.60sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.15ms, accelerator: 0us, total: 187.15ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.70ms, accelerator: 0us, total: 90.70ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 200508087.23sec, total: 200508087.24sec
train.py:448:<module>, cpu: 90.70ms, accelerator: 0us, total: 90.70ms
train.py:442:<module>, cpu: 4.06ms, accelerator: 47.75ms, total: 51.87ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.19ms, total: 43.53ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.19ms, total: 43.51ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.11ms, total: 43.34ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.95ms, total: 7.51ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.95ms, total: 7.50ms
      train.py:343:hfe, cpu: 190us, accelerator: 5.00ms, total: 5.19ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.42ms, total: 1.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_46000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 99712129.88sec, total: 99712129.88sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 99712129.85sec, total: 99712129.86sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.17ms, accelerator: 0us, total: 187.17ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.72ms, accelerator: 0us, total: 90.72ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 199424259.74sec, total: 199424259.74sec
train.py:448:<module>, cpu: 90.72ms, accelerator: 0us, total: 90.72ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.76ms, total: 51.89ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.20ms, total: 43.55ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.20ms, total: 43.52ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.12ms, total: 43.36ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.95ms, total: 7.52ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.95ms, total: 7.51ms
      train.py:343:hfe, cpu: 190us, accelerator: 5.00ms, total: 5.20ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.42ms, total: 1.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_46250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 99176043.16sec, total: 99176043.16sec (50.00%)
top 2 operation type: ReluGrad, cpu: 978us, accelerator: 99176043.14sec, total: 99176043.14sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.11ms, accelerator: 0us, total: 187.11ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.71ms, accelerator: 0us, total: 90.71ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 198352086.30sec, total: 198352086.30sec
train.py:448:<module>, cpu: 90.71ms, accelerator: 0us, total: 90.71ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.78ms, total: 51.91ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.22ms, total: 43.56ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.22ms, total: 43.54ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.14ms, total: 43.38ms
  train.py:359:image_losses, cpu: 551us, accelerator: 6.95ms, total: 7.52ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 6.95ms, total: 7.51ms
      train.py:343:hfe, cpu: 190us, accelerator: 5.01ms, total: 5.20ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.42ms, total: 1.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_46500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 98645689.99sec, total: 98645689.99sec (50.00%)
top 2 operation type: ReluGrad, cpu: 979us, accelerator: 98645689.96sec, total: 98645689.96sec (50.00%)
top 3 operation type: ImageSummary, cpu: 187.10ms, accelerator: 0us, total: 187.10ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.72ms, accelerator: 0us, total: 90.72ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 197291379.95sec, total: 197291379.96sec
train.py:448:<module>, cpu: 90.72ms, accelerator: 0us, total: 90.72ms
train.py:442:<module>, cpu: 4.07ms, accelerator: 47.78ms, total: 51.91ms
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 40.11ms, total: 43.46ms
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 40.11ms, total: 43.44ms
      train.py:349:msssim, cpu: 3.20ms, accelerator: 40.03ms, total: 43.27ms
  train.py:359:image_losses, cpu: 551us, accelerator: 7.06ms, total: 7.63ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.06ms, total: 7.61ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.98ms, total: 5.18ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.48ms, total: 1.70ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_46750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 98120978.87sec, total: 98120978.87sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 98120978.87sec, total: 98120978.87sec (33.33%)
top 3 operation type: ReluGrad, cpu: 982us, accelerator: 98120978.85sec, total: 98120978.85sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.74ms, accelerator: 0us, total: 90.74ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 196241957.72sec, total: 196241957.72sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 98120978.89sec, total: 98120978.90sec
train.py:448:<module>, cpu: 90.74ms, accelerator: 0us, total: 90.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.50
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_47000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 97601820.25sec, total: 97601820.25sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 97601820.25sec, total: 97601820.25sec (33.33%)
top 3 operation type: ReluGrad, cpu: 980us, accelerator: 97601820.23sec, total: 97601820.23sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.75ms, accelerator: 0us, total: 90.75ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 195203640.48sec, total: 195203640.49sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 97601820.28sec, total: 97601820.28sec
train.py:448:<module>, cpu: 90.76ms, accelerator: 0us, total: 90.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_47250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 97088126.46sec, total: 97088126.46sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 97088126.46sec, total: 97088126.46sec (33.33%)
top 3 operation type: ReluGrad, cpu: 982us, accelerator: 97088126.44sec, total: 97088126.44sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.75ms, accelerator: 0us, total: 90.75ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 194176252.90sec, total: 194176252.91sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 97088126.49sec, total: 97088126.49sec
train.py:448:<module>, cpu: 90.75ms, accelerator: 0us, total: 90.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_47500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 96579811.66sec, total: 96579811.67sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 96579811.66sec, total: 96579811.66sec (33.33%)
top 3 operation type: ReluGrad, cpu: 980us, accelerator: 96579811.64sec, total: 96579811.64sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.75ms, accelerator: 0us, total: 90.75ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 193159623.30sec, total: 193159623.31sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 96579811.69sec, total: 96579811.69sec
train.py:448:<module>, cpu: 90.75ms, accelerator: 0us, total: 90.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_47750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 96076791.81sec, total: 96076791.81sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 96076791.81sec, total: 96076791.81sec (33.33%)
top 3 operation type: ReluGrad, cpu: 980us, accelerator: 96076791.79sec, total: 96076791.79sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.74ms, accelerator: 0us, total: 90.74ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 192153583.60sec, total: 192153583.61sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 96076791.83sec, total: 96076791.84sec
train.py:448:<module>, cpu: 90.75ms, accelerator: 0us, total: 90.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_48000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 95578984.60sec, total: 95578984.60sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 95578984.59sec, total: 95578984.60sec (33.33%)
top 3 operation type: ReluGrad, cpu: 981us, accelerator: 95578984.58sec, total: 95578984.58sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.76ms, accelerator: 0us, total: 90.76ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 191157969.18sec, total: 191157969.18sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 95578984.62sec, total: 95578984.63sec
train.py:448:<module>, cpu: 90.76ms, accelerator: 0us, total: 90.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_48250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 95086309.42sec, total: 95086309.42sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 95086309.42sec, total: 95086309.42sec (33.33%)
top 3 operation type: ReluGrad, cpu: 983us, accelerator: 95086309.40sec, total: 95086309.40sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.77ms, accelerator: 0us, total: 90.77ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 190172618.82sec, total: 190172618.83sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 95086309.45sec, total: 95086309.45sec
train.py:448:<module>, cpu: 90.77ms, accelerator: 0us, total: 90.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_48500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 94598687.32sec, total: 94598687.32sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 94598687.32sec, total: 94598687.32sec (33.33%)
top 3 operation type: ReluGrad, cpu: 980us, accelerator: 94598687.30sec, total: 94598687.30sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.77ms, accelerator: 0us, total: 90.77ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 189197374.62sec, total: 189197374.63sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 94598687.35sec, total: 94598687.35sec
train.py:448:<module>, cpu: 90.77ms, accelerator: 0us, total: 90.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_48750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 94116040.96sec, total: 94116040.96sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 94116040.95sec, total: 94116040.95sec (33.33%)
top 3 operation type: ReluGrad, cpu: 980us, accelerator: 94116040.93sec, total: 94116040.94sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.77ms, accelerator: 0us, total: 90.77ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 188232081.89sec, total: 188232081.90sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 94116040.98sec, total: 94116040.99sec
train.py:448:<module>, cpu: 90.77ms, accelerator: 0us, total: 90.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_49000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 93638294.56sec, total: 93638294.56sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 93638294.55sec, total: 93638294.55sec (33.33%)
top 3 operation type: ReluGrad, cpu: 980us, accelerator: 93638294.53sec, total: 93638294.54sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.78ms, accelerator: 0us, total: 90.78ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 187276589.09sec, total: 187276589.10sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 93638294.58sec, total: 93638294.59sec
train.py:448:<module>, cpu: 90.78ms, accelerator: 0us, total: 90.78ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_49250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 93165373.88sec, total: 93165373.88sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 93165373.87sec, total: 93165373.87sec (33.33%)
top 3 operation type: ReluGrad, cpu: 978us, accelerator: 93165373.85sec, total: 93165373.86sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.76ms, accelerator: 0us, total: 90.76ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 186330747.73sec, total: 186330747.74sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 93165373.90sec, total: 93165373.91sec
train.py:448:<module>, cpu: 90.76ms, accelerator: 0us, total: 90.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_49500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 92697206.17sec, total: 92697206.17sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 92697206.16sec, total: 92697206.17sec (33.33%)
top 3 operation type: ReluGrad, cpu: 981us, accelerator: 92697206.15sec, total: 92697206.15sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.77ms, accelerator: 0us, total: 90.77ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 185394412.32sec, total: 185394412.32sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 92697206.19sec, total: 92697206.20sec
train.py:448:<module>, cpu: 90.77ms, accelerator: 0us, total: 90.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_49750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 92233720.14sec, total: 92233720.14sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 92233720.13sec, total: 92233720.13sec (33.33%)
top 3 operation type: ReluGrad, cpu: 981us, accelerator: 92233720.12sec, total: 92233720.12sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.78ms, accelerator: 0us, total: 90.78ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 184467440.26sec, total: 184467440.26sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 92233720.16sec, total: 92233720.17sec
train.py:448:<module>, cpu: 90.78ms, accelerator: 0us, total: 90.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_50000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 91774845.91sec, total: 91774845.91sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 91774845.90sec, total: 91774845.91sec (33.33%)
top 3 operation type: ReluGrad, cpu: 982us, accelerator: 91774845.89sec, total: 91774845.89sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.79ms, accelerator: 0us, total: 90.79ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 183549691.80sec, total: 183549691.80sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 91774845.93sec, total: 91774845.94sec
train.py:448:<module>, cpu: 90.79ms, accelerator: 0us, total: 90.79ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_50250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 91320514.99sec, total: 91320514.99sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 91320514.98sec, total: 91320514.99sec (33.33%)
top 3 operation type: ReluGrad, cpu: 980us, accelerator: 91320514.97sec, total: 91320514.97sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.81ms, accelerator: 0us, total: 90.81ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 182641029.96sec, total: 182641029.96sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 91320515.01sec, total: 91320515.02sec
train.py:448:<module>, cpu: 90.81ms, accelerator: 0us, total: 90.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_50500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 90870660.24sec, total: 90870660.24sec (33.33%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 90870660.23sec, total: 90870660.23sec (33.33%)
top 3 operation type: ReluGrad, cpu: 982us, accelerator: 90870660.21sec, total: 90870660.21sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 90.83ms, accelerator: 0us, total: 90.83ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 181741320.45sec, total: 181741320.46sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 90870660.26sec, total: 90870660.26sec
train.py:448:<module>, cpu: 90.83ms, accelerator: 0us, total: 90.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_50750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 180850431.63sec, total: 180850431.63sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 90425215.82sec, total: 90425215.82sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 90425215.81sec, total: 90425215.81sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.85ms, accelerator: 0us, total: 90.85ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 271275647.43sec, total: 271275647.44sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 90425215.85sec, total: 90425215.85sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 90425215.83sec, total: 90425215.84sec
  train.py:360:image_losses, cpu: 3.30ms, accelerator: 90425215.83sec, total: 90425215.83sec
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 90425215.83sec, total: 90425215.83sec
      train.py:349:msssim, cpu: 3.20ms, accelerator: 90425215.83sec, total: 90425215.83sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.14ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.13ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.81ms, total: 5.01ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.73ms, total: 1.95ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.03ms, total: 1.17ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_51000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 179968234.40sec, total: 179968234.41sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 89984117.20sec, total: 89984117.21sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 89984117.20sec, total: 89984117.20sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.87ms, accelerator: 0us, total: 90.87ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 269952351.59sec, total: 269952351.60sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 89984117.23sec, total: 89984117.24sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 89984117.22sec, total: 89984117.22sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 89984117.21sec, total: 89984117.22sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 89984117.21sec, total: 89984117.22sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 89984117.21sec, total: 89984117.22sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.57ms, total: 8.14ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.57ms, total: 8.13ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.82ms, total: 5.01ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.73ms, total: 1.95ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.02ms, total: 1.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_51250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 179094602.20sec, total: 179094602.20sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 89547301.10sec, total: 89547301.10sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 89547301.09sec, total: 89547301.10sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.89ms, accelerator: 0us, total: 90.89ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 268641903.28sec, total: 268641903.29sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 89547301.13sec, total: 89547301.13sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 89547301.12sec, total: 89547301.12sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 89547301.11sec, total: 89547301.11sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 89547301.11sec, total: 89547301.11sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 89547301.11sec, total: 89547301.11sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.56ms, total: 8.12ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.56ms, total: 8.11ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.81ms, total: 5.00ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.72ms, total: 1.94ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.02ms, total: 1.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_51500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 178229410.88sec, total: 178229410.89sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 89114705.44sec, total: 89114705.44sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 89114705.44sec, total: 89114705.44sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.90ms, accelerator: 0us, total: 90.90ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 267344116.31sec, total: 267344116.32sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 89114705.47sec, total: 89114705.48sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 89114705.46sec, total: 89114705.46sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 89114705.45sec, total: 89114705.46sec
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 89114705.45sec, total: 89114705.46sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 89114705.45sec, total: 89114705.46sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.54ms, total: 8.11ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.54ms, total: 8.10ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.80ms, total: 4.99ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.72ms, total: 1.94ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.02ms, total: 1.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_51750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 177372538.72sec, total: 177372538.72sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 88686269.36sec, total: 88686269.36sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 88686269.35sec, total: 88686269.35sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.94ms, accelerator: 0us, total: 90.94ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 266058808.06sec, total: 266058808.07sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 88686269.39sec, total: 88686269.39sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 88686269.38sec, total: 88686269.38sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 88686269.37sec, total: 88686269.37sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 88686269.37sec, total: 88686269.37sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 88686269.37sec, total: 88686269.37sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.54ms, total: 8.11ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.54ms, total: 8.09ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.80ms, total: 5.00ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.72ms, total: 1.94ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.02ms, total: 1.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_52000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 176523866.28sec, total: 176523866.28sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 88261933.14sec, total: 88261933.14sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 88261933.14sec, total: 88261933.14sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.96ms, accelerator: 0us, total: 90.96ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 264785799.41sec, total: 264785799.42sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 88261933.17sec, total: 88261933.18sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 88261933.16sec, total: 88261933.16sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 88261933.15sec, total: 88261933.15sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 88261933.15sec, total: 88261933.15sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 88261933.15sec, total: 88261933.15sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.54ms, total: 8.10ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.54ms, total: 8.09ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.81ms, total: 5.00ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.72ms, total: 1.94ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.01ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_52250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 175683276.44sec, total: 175683276.44sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 87841638.22sec, total: 87841638.22sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 87841638.22sec, total: 87841638.22sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.97ms, accelerator: 0us, total: 90.97ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 263524914.65sec, total: 263524914.66sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 87841638.25sec, total: 87841638.26sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 87841638.24sec, total: 87841638.24sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 87841638.23sec, total: 87841638.24sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 87841638.23sec, total: 87841638.24sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 87841638.23sec, total: 87841638.24sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.54ms, total: 8.11ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.54ms, total: 8.09ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.82ms, total: 5.01ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.72ms, total: 1.93ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.01ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_52500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 174850654.28sec, total: 174850654.28sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 87425327.14sec, total: 87425327.14sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 87425327.13sec, total: 87425327.14sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.96ms, accelerator: 0us, total: 90.96ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 262275981.41sec, total: 262275981.41sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 87425327.17sec, total: 87425327.18sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 87425327.16sec, total: 87425327.16sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 87425327.15sec, total: 87425327.15sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 87425327.15sec, total: 87425327.15sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 87425327.15sec, total: 87425327.15sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.53ms, total: 8.09ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.53ms, total: 8.08ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.81ms, total: 5.00ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.71ms, total: 1.93ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.01ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_52750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 174025887.04sec, total: 174025887.04sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 87012943.52sec, total: 87012943.52sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 87012943.52sec, total: 87012943.52sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.97ms, accelerator: 0us, total: 90.97ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 261038830.55sec, total: 261038830.56sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 87012943.55sec, total: 87012943.56sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 87012943.54sec, total: 87012943.54sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 87012943.53sec, total: 87012943.54sec
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 87012943.53sec, total: 87012943.54sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 87012943.53sec, total: 87012943.54sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.53ms, total: 8.09ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.53ms, total: 8.08ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.81ms, total: 5.01ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.71ms, total: 1.93ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.00ms, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_53000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 173208864.10sec, total: 173208864.10sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 86604432.05sec, total: 86604432.05sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 86604432.04sec, total: 86604432.05sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.99ms, accelerator: 0us, total: 90.99ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 259813296.13sec, total: 259813296.14sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 86604432.08sec, total: 86604432.08sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 86604432.07sec, total: 86604432.07sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 86604432.06sec, total: 86604432.06sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 86604432.06sec, total: 86604432.06sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 86604432.06sec, total: 86604432.06sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.51ms, total: 8.08ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.51ms, total: 8.07ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.80ms, total: 5.00ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.71ms, total: 1.93ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.00ms, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_53250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 172399476.88sec, total: 172399476.88sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 86199738.44sec, total: 86199738.44sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 86199738.44sec, total: 86199738.44sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.99ms, accelerator: 0us, total: 90.99ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 258599215.31sec, total: 258599215.32sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 86199738.47sec, total: 86199738.48sec
train.py:442:<module>, cpu: 4.07ms, accelerator: 86199738.46sec, total: 86199738.46sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 86199738.45sec, total: 86199738.46sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 86199738.45sec, total: 86199738.46sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 86199738.45sec, total: 86199738.46sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.50ms, total: 8.06ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.50ms, total: 8.05ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.79ms, total: 4.98ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.70ms, total: 1.92ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.00ms, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_53500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.56ms, accelerator: 171597618.85sec, total: 171597618.85sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 85798809.43sec, total: 85798809.43sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 85798809.42sec, total: 85798809.42sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.01ms, accelerator: 0us, total: 91.01ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 257396428.26sec, total: 257396428.27sec
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 85798809.46sec, total: 85798809.46sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 85798809.44sec, total: 85798809.45sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 85798809.44sec, total: 85798809.44sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 85798809.44sec, total: 85798809.44sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 85798809.44sec, total: 85798809.44sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.47ms, total: 8.03ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.47ms, total: 8.02ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.77ms, total: 4.96ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.70ms, total: 1.91ms
      train.py:344:hfe, cpu: 137us, accelerator: 998us, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_53750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 170803185.43sec, total: 170803185.43sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 85401592.72sec, total: 85401592.72sec (20.00%)
top 3 operation type: Mul, cpu: 2.07ms, accelerator: 85401592.71sec, total: 85401592.71sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.00ms, accelerator: 0us, total: 91.00ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 256204778.13sec, total: 256204778.14sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 85401592.75sec, total: 85401592.75sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 85401592.73sec, total: 85401592.74sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 85401592.73sec, total: 85401592.73sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 85401592.73sec, total: 85401592.73sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 85401592.73sec, total: 85401592.73sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.45ms, total: 8.02ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.45ms, total: 8.00ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.76ms, total: 4.95ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 138us, accelerator: 999us, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_54000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 170016073.98sec, total: 170016073.98sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 85008036.99sec, total: 85008036.99sec (20.00%)
top 3 operation type: Mul, cpu: 2.07ms, accelerator: 85008036.98sec, total: 85008036.99sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.99ms, accelerator: 0us, total: 90.99ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 255024110.95sec, total: 255024110.96sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 85008037.02sec, total: 85008037.02sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 85008037.01sec, total: 85008037.01sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 85008037.00sec, total: 85008037.00sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 85008037.00sec, total: 85008037.00sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 85008037.00sec, total: 85008037.00sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.44ms, total: 8.00ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.44ms, total: 7.99ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.75ms, total: 4.94ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 137us, accelerator: 995us, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_54250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 169236183.73sec, total: 169236183.73sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 84618091.87sec, total: 84618091.87sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 84618091.86sec, total: 84618091.86sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.98ms, accelerator: 0us, total: 90.98ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 253854275.58sec, total: 253854275.59sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 84618091.89sec, total: 84618091.90sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 84618091.88sec, total: 84618091.89sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 84618091.88sec, total: 84618091.88sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 84618091.88sec, total: 84618091.88sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 84618091.88sec, total: 84618091.88sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.43ms, total: 7.99ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.43ms, total: 7.97ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.74ms, total: 4.93ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.69ms, total: 1.90ms
      train.py:344:hfe, cpu: 137us, accelerator: 996us, total: 1.14ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_54500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 168463415.77sec, total: 168463415.77sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 84231707.89sec, total: 84231707.89sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 84231707.88sec, total: 84231707.88sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.98ms, accelerator: 0us, total: 90.98ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 252695123.64sec, total: 252695123.64sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 84231707.91sec, total: 84231707.92sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 84231707.90sec, total: 84231707.91sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 84231707.90sec, total: 84231707.90sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 84231707.90sec, total: 84231707.90sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 84231707.90sec, total: 84231707.90sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.41ms, total: 7.97ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.41ms, total: 7.96ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.73ms, total: 4.92ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 137us, accelerator: 995us, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_54750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 167697672.97sec, total: 167697672.97sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 83848836.49sec, total: 83848836.49sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 83848836.48sec, total: 83848836.48sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.97ms, accelerator: 0us, total: 90.97ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 251546509.44sec, total: 251546509.45sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 83848836.51sec, total: 83848836.52sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 83848836.50sec, total: 83848836.51sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 83848836.50sec, total: 83848836.50sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 83848836.50sec, total: 83848836.50sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 83848836.50sec, total: 83848836.50sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.40ms, total: 7.96ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.40ms, total: 7.95ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.71ms, total: 4.91ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.01ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_55000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 166938859.97sec, total: 166938859.97sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 83469429.99sec, total: 83469429.99sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 83469429.98sec, total: 83469429.98sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.99ms, accelerator: 0us, total: 90.99ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 250408289.94sec, total: 250408289.95sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 83469430.01sec, total: 83469430.02sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 83469430.00sec, total: 83469430.01sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 83469430.00sec, total: 83469430.00sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 83469430.00sec, total: 83469430.00sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 83469430.00sec, total: 83469430.00sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.38ms, total: 7.95ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.38ms, total: 7.93ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.70ms, total: 4.90ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.01ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_55250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 166186883.12sec, total: 166186883.12sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 83093441.56sec, total: 83093441.56sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 83093441.56sec, total: 83093441.56sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.98ms, accelerator: 0us, total: 90.98ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 249280324.67sec, total: 249280324.68sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 83093441.59sec, total: 83093441.60sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 83093441.58sec, total: 83093441.59sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 83093441.57sec, total: 83093441.58sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 83093441.57sec, total: 83093441.58sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 83093441.57sec, total: 83093441.58sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.37ms, total: 7.93ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.37ms, total: 7.92ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.70ms, total: 4.89ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.01ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_55500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 165441650.46sec, total: 165441650.46sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 82720825.23sec, total: 82720825.23sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 82720825.23sec, total: 82720825.23sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.97ms, accelerator: 0us, total: 90.97ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 248162475.68sec, total: 248162475.69sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 82720825.26sec, total: 82720825.27sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 82720825.25sec, total: 82720825.26sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 82720825.24sec, total: 82720825.25sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 82720825.24sec, total: 82720825.25sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 82720825.24sec, total: 82720825.25sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.36ms, total: 7.92ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.36ms, total: 7.91ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.68ms, total: 4.88ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.00ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_55750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 164703071.67sec, total: 164703071.67sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 82351535.83sec, total: 82351535.84sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 82351535.83sec, total: 82351535.83sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.99ms, accelerator: 0us, total: 90.99ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 247054607.49sec, total: 247054607.49sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 82351535.86sec, total: 82351535.87sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 82351535.85sec, total: 82351535.86sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 82351535.85sec, total: 82351535.85sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 82351535.85sec, total: 82351535.85sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 82351535.85sec, total: 82351535.85sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.34ms, total: 7.91ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.34ms, total: 7.90ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.68ms, total: 4.87ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.01ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_56000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 163971058.01sec, total: 163971058.02sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 81985529.01sec, total: 81985529.01sec (20.00%)
top 3 operation type: Mul, cpu: 2.07ms, accelerator: 81985529.00sec, total: 81985529.01sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.98ms, accelerator: 0us, total: 90.98ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 245956587.01sec, total: 245956587.01sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 81985529.04sec, total: 81985529.04sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 81985529.03sec, total: 81985529.03sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 81985529.02sec, total: 81985529.02sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 81985529.02sec, total: 81985529.02sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 81985529.02sec, total: 81985529.02sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.33ms, total: 7.89ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.33ms, total: 7.88ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.67ms, total: 4.86ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.00ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_56250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 163245522.36sec, total: 163245522.36sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 81622761.18sec, total: 81622761.18sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 81622761.18sec, total: 81622761.18sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.00ms, accelerator: 0us, total: 91.00ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 244868283.53sec, total: 244868283.53sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 81622761.21sec, total: 81622761.21sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 81622761.20sec, total: 81622761.20sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 81622761.19sec, total: 81622761.20sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 81622761.19sec, total: 81622761.20sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 81622761.19sec, total: 81622761.20sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.32ms, total: 7.88ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.32ms, total: 7.87ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.66ms, total: 4.85ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.00ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1990.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_56500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 162526379.09sec, total: 162526379.09sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 81263189.55sec, total: 81263189.55sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 81263189.54sec, total: 81263189.54sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.00ms, accelerator: 0us, total: 91.00ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 243789568.62sec, total: 243789568.63sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 81263189.57sec, total: 81263189.58sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 81263189.57sec, total: 81263189.57sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 81263189.56sec, total: 81263189.56sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 81263189.56sec, total: 81263189.56sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 81263189.56sec, total: 81263189.56sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.31ms, total: 7.87ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.31ms, total: 7.86ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.65ms, total: 4.84ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.66ms, total: 1.87ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.00ms, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_56750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 161813544.09sec, total: 161813544.09sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 80906772.05sec, total: 80906772.05sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 80906772.04sec, total: 80906772.05sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.03ms, accelerator: 0us, total: 91.03ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 242720316.13sec, total: 242720316.13sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 80906772.08sec, total: 80906772.08sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 80906772.07sec, total: 80906772.07sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 80906772.06sec, total: 80906772.06sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 80906772.06sec, total: 80906772.06sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 80906772.06sec, total: 80906772.06sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.29ms, total: 7.86ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.29ms, total: 7.85ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.64ms, total: 4.83ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.65ms, total: 1.87ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.00ms, total: 1.14ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_57000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 161106934.73sec, total: 161106934.73sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 80553467.37sec, total: 80553467.37sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 80553467.36sec, total: 80553467.36sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.06ms, accelerator: 0us, total: 91.06ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 241660402.08sec, total: 241660402.09sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 80553467.39sec, total: 80553467.40sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 80553467.39sec, total: 80553467.39sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 80553467.38sec, total: 80553467.38sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 80553467.38sec, total: 80553467.38sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 80553467.38sec, total: 80553467.38sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.28ms, total: 7.85ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.28ms, total: 7.84ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.63ms, total: 4.83ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.65ms, total: 1.87ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.00ms, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_57250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 160406469.80sec, total: 160406469.80sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 80203234.90sec, total: 80203234.90sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 80203234.90sec, total: 80203234.90sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.07ms, accelerator: 0us, total: 91.07ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 240609704.68sec, total: 240609704.69sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 80203234.93sec, total: 80203234.93sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 80203234.92sec, total: 80203234.92sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 80203234.91sec, total: 80203234.91sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 80203234.91sec, total: 80203234.91sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 80203234.91sec, total: 80203234.91sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.27ms, total: 7.83ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.27ms, total: 7.82ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.62ms, total: 4.81ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.65ms, total: 1.86ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.00ms, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_57500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 159712069.49sec, total: 159712069.50sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 79856034.75sec, total: 79856034.75sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 79856034.74sec, total: 79856034.75sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.08ms, accelerator: 0us, total: 91.08ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 239568104.23sec, total: 239568104.24sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 79856034.78sec, total: 79856034.78sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 79856034.77sec, total: 79856034.77sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 79856034.76sec, total: 79856034.76sec
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 79856034.76sec, total: 79856034.76sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 79856034.76sec, total: 79856034.76sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.26ms, total: 7.82ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.26ms, total: 7.81ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.61ms, total: 4.80ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.64ms, total: 1.86ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.00ms, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_57750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 159023655.40sec, total: 159023655.40sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 79511827.70sec, total: 79511827.70sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 79511827.70sec, total: 79511827.70sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.09ms, accelerator: 0us, total: 91.09ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 238535483.09sec, total: 238535483.10sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 79511827.73sec, total: 79511827.73sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 79511827.72sec, total: 79511827.73sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 79511827.71sec, total: 79511827.72sec
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 79511827.71sec, total: 79511827.72sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 79511827.71sec, total: 79511827.72sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.24ms, total: 7.81ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.24ms, total: 7.79ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.60ms, total: 4.80ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.64ms, total: 1.86ms
      train.py:344:hfe, cpu: 138us, accelerator: 999us, total: 1.14ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_58000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 158341150.44sec, total: 158341150.44sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 79170575.22sec, total: 79170575.22sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 79170575.22sec, total: 79170575.22sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.10ms, accelerator: 0us, total: 91.10ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 237511725.65sec, total: 237511725.66sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 79170575.25sec, total: 79170575.26sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 79170575.24sec, total: 79170575.25sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 79170575.23sec, total: 79170575.24sec
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 79170575.23sec, total: 79170575.24sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 79170575.23sec, total: 79170575.24sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.23ms, total: 7.80ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.23ms, total: 7.78ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.59ms, total: 4.79ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.64ms, total: 1.85ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.00ms, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_58250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 157664478.86sec, total: 157664478.86sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 78832239.43sec, total: 78832239.43sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 78832239.43sec, total: 78832239.43sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.10ms, accelerator: 0us, total: 91.10ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 236496718.28sec, total: 236496718.28sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 78832239.46sec, total: 78832239.46sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 78832239.45sec, total: 78832239.46sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 78832239.44sec, total: 78832239.45sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 78832239.44sec, total: 78832239.45sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 78832239.44sec, total: 78832239.45sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.22ms, total: 7.79ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.22ms, total: 7.77ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.59ms, total: 4.78ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.63ms, total: 1.85ms
      train.py:344:hfe, cpu: 138us, accelerator: 998us, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_58500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 156993566.18sec, total: 156993566.19sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.29ms, accelerator: 78496783.09sec, total: 78496783.09sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 78496783.09sec, total: 78496783.09sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.11ms, accelerator: 0us, total: 91.11ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 235490349.27sec, total: 235490349.27sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 78496783.12sec, total: 78496783.13sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 78496783.11sec, total: 78496783.12sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 78496783.11sec, total: 78496783.11sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 78496783.11sec, total: 78496783.11sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 78496783.11sec, total: 78496783.11sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.21ms, total: 7.78ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.21ms, total: 7.76ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.58ms, total: 4.77ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.63ms, total: 1.85ms
      train.py:344:hfe, cpu: 138us, accelerator: 999us, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_58750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 156328339.21sec, total: 156328339.21sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 78164169.61sec, total: 78164169.61sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 78164169.60sec, total: 78164169.60sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.13ms, accelerator: 0us, total: 91.13ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 234492508.80sec, total: 234492508.81sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 78164169.63sec, total: 78164169.64sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 78164169.63sec, total: 78164169.63sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 78164169.62sec, total: 78164169.62sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 78164169.62sec, total: 78164169.62sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 78164169.62sec, total: 78164169.62sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.23ms, total: 7.79ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.23ms, total: 7.78ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.57ms, total: 4.76ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 998us, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_59000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 155668725.96sec, total: 155668725.96sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 77834362.98sec, total: 77834362.98sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 77834362.98sec, total: 77834362.98sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.16ms, accelerator: 0us, total: 91.16ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 233503088.93sec, total: 233503088.94sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 77834363.01sec, total: 77834363.01sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 77834363.00sec, total: 77834363.01sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 77834363.00sec, total: 77834363.00sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 77834363.00sec, total: 77834363.00sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 77834363.00sec, total: 77834363.00sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.31ms, total: 7.88ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.31ms, total: 7.86ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.55ms, total: 4.74ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.71ms, total: 1.93ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_59250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 155014655.69sec, total: 155014655.69sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 77507327.84sec, total: 77507327.85sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 77507327.84sec, total: 77507327.84sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.16ms, accelerator: 0us, total: 91.16ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 232521983.52sec, total: 232521983.52sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 77507327.87sec, total: 77507327.88sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 77507327.86sec, total: 77507327.87sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 77507327.86sec, total: 77507327.86sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 77507327.86sec, total: 77507327.86sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 77507327.86sec, total: 77507327.86sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.30ms, total: 7.86ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.30ms, total: 7.85ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.54ms, total: 4.73ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.71ms, total: 1.92ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_59500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 154366058.80sec, total: 154366058.80sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 77183029.40sec, total: 77183029.40sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 77183029.40sec, total: 77183029.40sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.18ms, accelerator: 0us, total: 91.18ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 231549088.19sec, total: 231549088.20sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 77183029.43sec, total: 77183029.43sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 77183029.42sec, total: 77183029.43sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 77183029.41sec, total: 77183029.42sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 77183029.41sec, total: 77183029.42sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 77183029.41sec, total: 77183029.42sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.29ms, total: 7.85ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.29ms, total: 7.84ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.53ms, total: 4.73ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.70ms, total: 1.92ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_59750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 153722866.89sec, total: 153722866.89sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 76861433.45sec, total: 76861433.45sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 76861433.44sec, total: 76861433.44sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.19ms, accelerator: 0us, total: 91.19ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 230584300.32sec, total: 230584300.33sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 76861433.47sec, total: 76861433.48sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 76861433.47sec, total: 76861433.47sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 76861433.46sec, total: 76861433.46sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 76861433.46sec, total: 76861433.46sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 76861433.46sec, total: 76861433.46sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.27ms, total: 7.84ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.27ms, total: 7.83ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.52ms, total: 4.72ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.70ms, total: 1.92ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_60000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 153085012.67sec, total: 153085012.67sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 76542506.34sec, total: 76542506.34sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 76542506.33sec, total: 76542506.33sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.19ms, accelerator: 0us, total: 91.19ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 229627518.99sec, total: 229627519.00sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 76542506.36sec, total: 76542506.37sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 76542506.36sec, total: 76542506.36sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 76542506.35sec, total: 76542506.35sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 76542506.35sec, total: 76542506.35sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 76542506.35sec, total: 76542506.35sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.26ms, total: 7.83ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.26ms, total: 7.82ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.52ms, total: 4.71ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.70ms, total: 1.91ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_60250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 152452429.97sec, total: 152452429.97sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 76226214.99sec, total: 76226214.99sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 76226214.98sec, total: 76226214.99sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.19ms, accelerator: 0us, total: 91.19ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 228678644.95sec, total: 228678644.95sec
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 76226215.01sec, total: 76226215.02sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 76226215.01sec, total: 76226215.01sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 76226215.00sec, total: 76226215.00sec
    train.py:322:loss_fn, cpu: 3.28ms, accelerator: 76226215.00sec, total: 76226215.00sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 76226215.00sec, total: 76226215.00sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.25ms, total: 7.82ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.25ms, total: 7.80ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.51ms, total: 4.70ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_60500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 151825053.72sec, total: 151825053.72sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 75912526.86sec, total: 75912526.86sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 75912526.86sec, total: 75912526.86sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.21ms, accelerator: 0us, total: 91.21ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 227737580.57sec, total: 227737580.57sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 75912526.89sec, total: 75912526.89sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 75912526.88sec, total: 75912526.89sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 75912526.87sec, total: 75912526.88sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 75912526.87sec, total: 75912526.88sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 75912526.87sec, total: 75912526.88sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.24ms, total: 7.80ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.24ms, total: 7.79ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.50ms, total: 4.69ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_60750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 151202819.89sec, total: 151202819.89sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 75601409.95sec, total: 75601409.95sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 75601409.94sec, total: 75601409.95sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.21ms, accelerator: 0us, total: 91.21ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 226804229.83sec, total: 226804229.83sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 75601409.97sec, total: 75601409.98sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 75601409.97sec, total: 75601409.97sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 75601409.96sec, total: 75601409.96sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 75601409.96sec, total: 75601409.96sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 75601409.96sec, total: 75601409.96sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.28ms, total: 7.84ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.28ms, total: 7.83ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.53ms, total: 4.72ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.70ms, total: 1.92ms
      train.py:344:hfe, cpu: 139us, accelerator: 1.05ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_61000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 150585665.52sec, total: 150585665.53sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 75292832.76sec, total: 75292832.76sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 75292832.76sec, total: 75292832.76sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.23ms, accelerator: 0us, total: 91.23ms
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 225878498.28sec, total: 225878498.28sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 75292832.79sec, total: 75292832.79sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 75292832.78sec, total: 75292832.79sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 75292832.78sec, total: 75292832.78sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 75292832.78sec, total: 75292832.78sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 75292832.78sec, total: 75292832.78sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.27ms, total: 7.83ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.27ms, total: 7.82ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.52ms, total: 4.71ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.70ms, total: 1.91ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.20ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_61250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 149973528.67sec, total: 149973528.67sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 74986764.34sec, total: 74986764.34sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 74986764.33sec, total: 74986764.34sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.24ms, accelerator: 0us, total: 91.24ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 224960293.00sec, total: 224960293.00sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 74986764.36sec, total: 74986764.37sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 74986764.36sec, total: 74986764.36sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 74986764.35sec, total: 74986764.35sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 74986764.35sec, total: 74986764.35sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 74986764.35sec, total: 74986764.35sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.25ms, total: 7.82ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.25ms, total: 7.81ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.51ms, total: 4.70ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_61500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 149366348.39sec, total: 149366348.40sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 74683174.20sec, total: 74683174.20sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 74683174.20sec, total: 74683174.20sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.24ms, accelerator: 0us, total: 91.24ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 224049522.58sec, total: 224049522.59sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 74683174.22sec, total: 74683174.23sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 74683174.22sec, total: 74683174.22sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 74683174.21sec, total: 74683174.22sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 74683174.21sec, total: 74683174.22sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 74683174.21sec, total: 74683174.22sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.26ms, total: 7.82ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.26ms, total: 7.81ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.52ms, total: 4.71ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_61750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 148764064.73sec, total: 148764064.73sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 74382032.37sec, total: 74382032.37sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 74382032.36sec, total: 74382032.37sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.26ms, accelerator: 0us, total: 91.26ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 223146097.09sec, total: 223146097.09sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 74382032.39sec, total: 74382032.40sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 74382032.39sec, total: 74382032.39sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 74382032.38sec, total: 74382032.38sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 74382032.38sec, total: 74382032.38sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 74382032.38sec, total: 74382032.38sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.25ms, total: 7.81ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.25ms, total: 7.80ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.51ms, total: 4.70ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.69ms, total: 1.90ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_62000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 148166618.69sec, total: 148166618.69sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 74083309.35sec, total: 74083309.35sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 74083309.34sec, total: 74083309.35sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.23ms, accelerator: 0us, total: 91.23ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 222249928.02sec, total: 222249928.03sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 74083309.37sec, total: 74083309.38sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 74083309.37sec, total: 74083309.37sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 74083309.36sec, total: 74083309.36sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 74083309.36sec, total: 74083309.36sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 74083309.36sec, total: 74083309.36sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.31ms, total: 7.88ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.31ms, total: 7.86ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.50ms, total: 4.70ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.72ms, total: 1.94ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.09ms, total: 1.23ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_62250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 147573952.21sec, total: 147573952.22sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 73786976.11sec, total: 73786976.11sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 73786976.11sec, total: 73786976.11sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.24ms, accelerator: 0us, total: 91.24ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 221360928.31sec, total: 221360928.32sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 73786976.13sec, total: 73786976.14sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 73786976.13sec, total: 73786976.13sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 73786976.12sec, total: 73786976.13sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 73786976.12sec, total: 73786976.13sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 73786976.12sec, total: 73786976.13sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.30ms, total: 7.86ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.30ms, total: 7.85ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.49ms, total: 4.69ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.72ms, total: 1.94ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.08ms, total: 1.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_62500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 146986008.18sec, total: 146986008.18sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 73493004.09sec, total: 73493004.09sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 73493004.09sec, total: 73493004.09sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.25ms, accelerator: 0us, total: 91.25ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 220479012.26sec, total: 220479012.27sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 73493004.12sec, total: 73493004.12sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 73493004.11sec, total: 73493004.12sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 73493004.11sec, total: 73493004.11sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 73493004.11sec, total: 73493004.11sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 73493004.11sec, total: 73493004.11sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.29ms, total: 7.85ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.29ms, total: 7.84ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.49ms, total: 4.68ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.72ms, total: 1.94ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.08ms, total: 1.23ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_62750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 146402730.37sec, total: 146402730.37sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 73201365.19sec, total: 73201365.19sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 73201365.18sec, total: 73201365.19sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.26ms, accelerator: 0us, total: 91.26ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 219604095.55sec, total: 219604095.55sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 73201365.21sec, total: 73201365.22sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 73201365.21sec, total: 73201365.21sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 73201365.20sec, total: 73201365.20sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 73201365.20sec, total: 73201365.20sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 73201365.20sec, total: 73201365.20sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.27ms, total: 7.84ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.27ms, total: 7.83ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.48ms, total: 4.67ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.71ms, total: 1.93ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.08ms, total: 1.22ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_63000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 145824063.45sec, total: 145824063.45sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 72912031.73sec, total: 72912031.73sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 72912031.73sec, total: 72912031.73sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.26ms, accelerator: 0us, total: 91.26ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 218736095.17sec, total: 218736095.17sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 72912031.75sec, total: 72912031.76sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 72912031.75sec, total: 72912031.75sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 72912031.74sec, total: 72912031.74sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 72912031.74sec, total: 72912031.74sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 72912031.74sec, total: 72912031.74sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.27ms, total: 7.84ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.27ms, total: 7.83ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.48ms, total: 4.68ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.71ms, total: 1.93ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.08ms, total: 1.22ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_63250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 145249952.97sec, total: 145249952.97sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 72624976.48sec, total: 72624976.49sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 72624976.48sec, total: 72624976.48sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.27ms, accelerator: 0us, total: 91.27ms
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 217874929.44sec, total: 217874929.45sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 72624976.51sec, total: 72624976.52sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 72624976.51sec, total: 72624976.51sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 72624976.50sec, total: 72624976.50sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 72624976.50sec, total: 72624976.50sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 72624976.50sec, total: 72624976.50sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.27ms, total: 7.83ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.27ms, total: 7.82ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.48ms, total: 4.67ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.71ms, total: 1.93ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.08ms, total: 1.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_63500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 144680345.31sec, total: 144680345.31sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 72340172.65sec, total: 72340172.66sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 72340172.65sec, total: 72340172.66sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.27ms, accelerator: 0us, total: 91.27ms
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 217020517.95sec, total: 217020517.96sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 72340172.68sec, total: 72340172.69sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 72340172.68sec, total: 72340172.68sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 72340172.67sec, total: 72340172.67sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 72340172.67sec, total: 72340172.67sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 72340172.67sec, total: 72340172.67sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.25ms, total: 7.82ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.25ms, total: 7.80ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.47ms, total: 4.66ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.71ms, total: 1.92ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.08ms, total: 1.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_63750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 144115187.71sec, total: 144115187.71sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 72057593.86sec, total: 72057593.86sec (20.00%)
top 3 operation type: Mul, cpu: 2.05ms, accelerator: 72057593.85sec, total: 72057593.86sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.27ms, accelerator: 0us, total: 91.27ms
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 216172781.55sec, total: 216172781.56sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 72057593.88sec, total: 72057593.89sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 72057593.88sec, total: 72057593.88sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 72057593.87sec, total: 72057593.87sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 72057593.87sec, total: 72057593.87sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 72057593.87sec, total: 72057593.87sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.24ms, total: 7.80ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.24ms, total: 7.79ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.46ms, total: 4.65ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.70ms, total: 1.92ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.08ms, total: 1.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_64000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 143554428.22sec, total: 143554428.23sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 71777214.11sec, total: 71777214.11sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 71777214.11sec, total: 71777214.11sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.25ms, accelerator: 0us, total: 91.25ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 215331642.33sec, total: 215331642.33sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 71777214.14sec, total: 71777214.14sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 71777214.14sec, total: 71777214.14sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 71777214.13sec, total: 71777214.13sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 71777214.13sec, total: 71777214.13sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 71777214.13sec, total: 71777214.13sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.23ms, total: 7.80ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.23ms, total: 7.78ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.46ms, total: 4.65ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.70ms, total: 1.92ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.08ms, total: 1.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_64250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 142998015.71sec, total: 142998015.71sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 71499007.86sec, total: 71499007.86sec (20.00%)
top 3 operation type: Mul, cpu: 2.05ms, accelerator: 71499007.86sec, total: 71499007.86sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.25ms, accelerator: 0us, total: 91.25ms
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 214497023.56sec, total: 214497023.56sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 71499007.88sec, total: 71499007.89sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 71499007.88sec, total: 71499007.88sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 71499007.87sec, total: 71499007.87sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 71499007.87sec, total: 71499007.87sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 71499007.87sec, total: 71499007.87sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.22ms, total: 7.79ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.22ms, total: 7.77ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.45ms, total: 4.64ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.70ms, total: 1.91ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.07ms, total: 1.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_64500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.57ms, accelerator: 142445899.82sec, total: 142445899.82sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 71222949.91sec, total: 71222949.91sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 71222949.91sec, total: 71222949.91sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.24ms, accelerator: 0us, total: 91.24ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 213668849.72sec, total: 213668849.73sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 71222949.94sec, total: 71222949.94sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 71222949.93sec, total: 71222949.94sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 71222949.93sec, total: 71222949.93sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 71222949.93sec, total: 71222949.93sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 71222949.93sec, total: 71222949.93sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.21ms, total: 7.77ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.21ms, total: 7.76ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.44ms, total: 4.63ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.07ms, total: 1.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_64750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 141898030.98sec, total: 141898030.98sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 70949015.49sec, total: 70949015.49sec (20.00%)
top 3 operation type: Mul, cpu: 2.05ms, accelerator: 70949015.49sec, total: 70949015.49sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.23ms, accelerator: 0us, total: 91.23ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 212847046.45sec, total: 212847046.46sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 70949015.51sec, total: 70949015.52sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 70949015.51sec, total: 70949015.52sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 70949015.50sec, total: 70949015.51sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 70949015.50sec, total: 70949015.51sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 70949015.50sec, total: 70949015.51sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.20ms, total: 7.77ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.20ms, total: 7.75ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.43ms, total: 4.63ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.70ms, total: 1.91ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.07ms, total: 1.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_65000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 141354360.36sec, total: 141354360.36sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 70677180.18sec, total: 70677180.18sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 70677180.18sec, total: 70677180.18sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.23ms, accelerator: 0us, total: 91.23ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 212031540.53sec, total: 212031540.53sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 70677180.21sec, total: 70677180.21sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 70677180.20sec, total: 70677180.21sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 70677180.20sec, total: 70677180.20sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 70677180.20sec, total: 70677180.20sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 70677180.20sec, total: 70677180.20sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.20ms, total: 7.76ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.20ms, total: 7.75ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.44ms, total: 4.63ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.07ms, total: 1.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_65250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 140814839.90sec, total: 140814839.90sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 70407419.95sec, total: 70407419.95sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 70407419.95sec, total: 70407419.95sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.25ms, accelerator: 0us, total: 91.25ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 211222259.84sec, total: 211222259.85sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 70407419.98sec, total: 70407419.98sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 70407419.97sec, total: 70407419.98sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 70407419.97sec, total: 70407419.97sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 70407419.97sec, total: 70407419.97sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 70407419.97sec, total: 70407419.97sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.19ms, total: 7.75ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.19ms, total: 7.74ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.43ms, total: 4.62ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.07ms, total: 1.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_65500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 140279422.26sec, total: 140279422.26sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 70139711.13sec, total: 70139711.13sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 70139711.13sec, total: 70139711.13sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.25ms, accelerator: 0us, total: 91.25ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 210419133.38sec, total: 210419133.38sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 70139711.15sec, total: 70139711.16sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 70139711.15sec, total: 70139711.16sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 70139711.14sec, total: 70139711.15sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 70139711.14sec, total: 70139711.15sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 70139711.14sec, total: 70139711.15sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.18ms, total: 7.74ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.18ms, total: 7.73ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.42ms, total: 4.62ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.69ms, total: 1.90ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.07ms, total: 1.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_65750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 139748060.81sec, total: 139748060.81sec (40.00%)
top 2 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 69874030.41sec, total: 69874030.41sec (20.00%)
top 3 operation type: Mul, cpu: 2.06ms, accelerator: 69874030.40sec, total: 69874030.41sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.26ms, accelerator: 0us, total: 91.26ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 209622091.21sec, total: 209622091.21sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 69874030.43sec, total: 69874030.44sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 69874030.43sec, total: 69874030.43sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 69874030.42sec, total: 69874030.42sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 69874030.42sec, total: 69874030.42sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 69874030.42sec, total: 69874030.42sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.17ms, total: 7.73ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.17ms, total: 7.72ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.42ms, total: 4.61ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.07ms, total: 1.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_66000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 139220709.64sec, total: 139220709.64sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 69610354.82sec, total: 69610354.82sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 69610354.82sec, total: 69610354.82sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.25ms, accelerator: 0us, total: 91.25ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 208831064.45sec, total: 208831064.45sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 69610354.84sec, total: 69610354.85sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 69610354.84sec, total: 69610354.85sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 69610354.83sec, total: 69610354.84sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 69610354.83sec, total: 69610354.84sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 69610354.83sec, total: 69610354.84sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.17ms, total: 7.74ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.17ms, total: 7.72ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.42ms, total: 4.62ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.06ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_66250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 138697323.51sec, total: 138697323.51sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 69348661.76sec, total: 69348661.76sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 69348661.76sec, total: 69348661.76sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.26ms, accelerator: 0us, total: 91.26ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 208045985.26sec, total: 208045985.26sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 69348661.78sec, total: 69348661.79sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 69348661.78sec, total: 69348661.78sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 69348661.77sec, total: 69348661.77sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 69348661.77sec, total: 69348661.77sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 69348661.77sec, total: 69348661.77sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.17ms, total: 7.74ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.17ms, total: 7.72ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.43ms, total: 4.62ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.06ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_66500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 138177857.88sec, total: 138177857.88sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 69088928.94sec, total: 69088928.94sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 69088928.94sec, total: 69088928.94sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.26ms, accelerator: 0us, total: 91.26ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 207266786.81sec, total: 207266786.82sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 69088928.97sec, total: 69088928.97sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 69088928.96sec, total: 69088928.97sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 69088928.96sec, total: 69088928.96sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 69088928.96sec, total: 69088928.96sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 69088928.96sec, total: 69088928.96sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.17ms, total: 7.74ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.17ms, total: 7.73ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.43ms, total: 4.63ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.06ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_66750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 137662268.86sec, total: 137662268.86sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 68831134.43sec, total: 68831134.43sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 68831134.43sec, total: 68831134.43sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.26ms, accelerator: 0us, total: 91.26ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 206493403.28sec, total: 206493403.28sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 68831134.45sec, total: 68831134.46sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 68831134.45sec, total: 68831134.46sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 68831134.45sec, total: 68831134.45sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 68831134.45sec, total: 68831134.45sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 68831134.45sec, total: 68831134.45sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.16ms, total: 7.73ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.16ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.43ms, total: 4.62ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.06ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_67000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 137150513.21sec, total: 137150513.21sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 68575256.61sec, total: 68575256.61sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 68575256.61sec, total: 68575256.61sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.24ms, accelerator: 0us, total: 91.24ms
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 205725769.81sec, total: 205725769.81sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 68575256.63sec, total: 68575256.64sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 68575256.63sec, total: 68575256.63sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 68575256.62sec, total: 68575256.63sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 68575256.62sec, total: 68575256.63sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 68575256.62sec, total: 68575256.63sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.41ms, total: 4.61ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.89ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.05ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_67250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 136642548.35sec, total: 136642548.35sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 68321274.17sec, total: 68321274.18sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 68321274.17sec, total: 68321274.18sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.23ms, accelerator: 0us, total: 91.23ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 204963822.51sec, total: 204963822.52sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 68321274.20sec, total: 68321274.20sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 68321274.20sec, total: 68321274.20sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 68321274.19sec, total: 68321274.19sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 68321274.19sec, total: 68321274.19sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 68321274.19sec, total: 68321274.19sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.14ms, total: 7.70ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.14ms, total: 7.69ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.41ms, total: 4.60ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.05ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_67500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 136138332.30sec, total: 136138332.30sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 68069166.15sec, total: 68069166.15sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 68069166.15sec, total: 68069166.15sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.24ms, accelerator: 0us, total: 91.24ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 204207498.44sec, total: 204207498.45sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 68069166.18sec, total: 68069166.18sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 68069166.18sec, total: 68069166.18sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 68069166.17sec, total: 68069166.17sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 68069166.17sec, total: 68069166.17sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 68069166.17sec, total: 68069166.17sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.12ms, total: 7.69ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.12ms, total: 7.68ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.40ms, total: 4.60ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_67750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 135637823.73sec, total: 135637823.73sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 67818911.86sec, total: 67818911.87sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 67818911.86sec, total: 67818911.87sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.24ms, accelerator: 0us, total: 91.24ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 203456735.58sec, total: 203456735.59sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 67818911.89sec, total: 67818911.89sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 67818911.89sec, total: 67818911.89sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 67818911.88sec, total: 67818911.88sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 67818911.88sec, total: 67818911.88sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 67818911.88sec, total: 67818911.88sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.11ms, total: 7.68ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.11ms, total: 7.67ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.39ms, total: 4.59ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_68000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 135140981.88sec, total: 135140981.88sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 67570490.94sec, total: 67570490.94sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 67570490.94sec, total: 67570490.94sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.23ms, accelerator: 0us, total: 91.23ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 202711472.81sec, total: 202711472.82sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 67570490.97sec, total: 67570490.97sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 67570490.97sec, total: 67570490.97sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 67570490.96sec, total: 67570490.96sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 67570490.96sec, total: 67570490.96sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 67570490.96sec, total: 67570490.96sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.12ms, total: 7.68ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.12ms, total: 7.67ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.40ms, total: 4.59ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_68250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 134647766.62sec, total: 134647766.62sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 67323883.31sec, total: 67323883.31sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 67323883.31sec, total: 67323883.31sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.23ms, accelerator: 0us, total: 91.23ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 201971649.92sec, total: 201971649.93sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 67323883.34sec, total: 67323883.34sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 67323883.33sec, total: 67323883.34sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 67323883.33sec, total: 67323883.33sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 67323883.33sec, total: 67323883.33sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 67323883.33sec, total: 67323883.33sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.12ms, total: 7.68ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.12ms, total: 7.67ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.41ms, total: 4.60ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.67ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.04ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_68500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 134158138.38sec, total: 134158138.38sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 67079069.19sec, total: 67079069.19sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 67079069.19sec, total: 67079069.19sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.25ms, accelerator: 0us, total: 91.25ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 201237207.56sec, total: 201237207.56sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 67079069.21sec, total: 67079069.22sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 67079069.21sec, total: 67079069.22sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 67079069.21sec, total: 67079069.21sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 67079069.21sec, total: 67079069.21sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 67079069.21sec, total: 67079069.21sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.11ms, total: 7.67ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.11ms, total: 7.66ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.40ms, total: 4.59ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.04ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_68750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 133672058.17sec, total: 133672058.17sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 66836029.08sec, total: 66836029.09sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 66836029.08sec, total: 66836029.08sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.25ms, accelerator: 0us, total: 91.25ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 200508087.24sec, total: 200508087.25sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 66836029.11sec, total: 66836029.11sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 66836029.11sec, total: 66836029.11sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 66836029.10sec, total: 66836029.10sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 66836029.10sec, total: 66836029.10sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 66836029.10sec, total: 66836029.10sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.11ms, total: 7.67ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.11ms, total: 7.66ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.41ms, total: 4.60ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.04ms, total: 1.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_69000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 133189487.56sec, total: 133189487.56sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 66594743.78sec, total: 66594743.78sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 66594743.78sec, total: 66594743.78sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.24ms, accelerator: 0us, total: 91.24ms
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 199784231.33sec, total: 199784231.34sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 66594743.81sec, total: 66594743.81sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 66594743.80sec, total: 66594743.81sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 66594743.80sec, total: 66594743.80sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 66594743.80sec, total: 66594743.80sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 66594743.80sec, total: 66594743.80sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.10ms, total: 7.67ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.10ms, total: 7.65ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.40ms, total: 4.59ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.04ms, total: 1.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_69250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 132710388.68sec, total: 132710388.68sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 66355194.34sec, total: 66355194.34sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 66355194.34sec, total: 66355194.34sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.25ms, accelerator: 0us, total: 91.25ms
train.py:441:<module> (gradient), cpu: 5.34ms, accelerator: 199065583.02sec, total: 199065583.02sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 66355194.37sec, total: 66355194.37sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 66355194.37sec, total: 66355194.37sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 66355194.36sec, total: 66355194.36sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 66355194.36sec, total: 66355194.36sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 66355194.36sec, total: 66355194.36sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.09ms, total: 7.66ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.09ms, total: 7.64ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.39ms, total: 4.59ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.04ms, total: 1.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_69500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 132234724.21sec, total: 132234724.21sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 66117362.10sec, total: 66117362.11sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 66117362.10sec, total: 66117362.11sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.26ms, accelerator: 0us, total: 91.26ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 198352086.30sec, total: 198352086.31sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 66117362.13sec, total: 66117362.13sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 66117362.13sec, total: 66117362.13sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 66117362.12sec, total: 66117362.12sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 66117362.12sec, total: 66117362.12sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 66117362.12sec, total: 66117362.12sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.16ms, total: 7.73ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.16ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.38ms, total: 4.57ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.70ms, total: 1.92ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.09ms, total: 1.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_69750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 131762457.33sec, total: 131762457.34sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 65881228.67sec, total: 65881228.67sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 65881228.67sec, total: 65881228.67sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.26ms, accelerator: 0us, total: 91.26ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 197643685.99sec, total: 197643686.00sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 65881228.69sec, total: 65881228.70sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 65881228.69sec, total: 65881228.70sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 65881228.69sec, total: 65881228.69sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 65881228.69sec, total: 65881228.69sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 65881228.68sec, total: 65881228.69sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.15ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.37ms, total: 4.56ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.09ms, total: 1.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_70000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 131293551.79sec, total: 131293551.79sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 65646775.90sec, total: 65646775.90sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 65646775.90sec, total: 65646775.90sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.27ms, accelerator: 0us, total: 91.27ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 196940327.68sec, total: 196940327.69sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 65646775.92sec, total: 65646775.93sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 65646775.92sec, total: 65646775.93sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 65646775.91sec, total: 65646775.92sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 65646775.91sec, total: 65646775.92sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 65646775.91sec, total: 65646775.92sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.15ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.38ms, total: 4.57ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.08ms, total: 1.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_70250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 130827971.82sec, total: 130827971.82sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 65413985.91sec, total: 65413985.91sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 65413985.91sec, total: 65413985.91sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.27ms, accelerator: 0us, total: 91.27ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 196241957.73sec, total: 196241957.73sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 65413985.94sec, total: 65413985.94sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 65413985.94sec, total: 65413985.94sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 65413985.93sec, total: 65413985.93sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 65413985.93sec, total: 65413985.93sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 65413985.93sec, total: 65413985.93sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.15ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.15ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.38ms, total: 4.58ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.08ms, total: 1.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_70500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 130365682.17sec, total: 130365682.17sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 65182841.09sec, total: 65182841.09sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 65182841.09sec, total: 65182841.09sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.28ms, accelerator: 0us, total: 91.28ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 195548523.25sec, total: 195548523.25sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 65182841.11sec, total: 65182841.12sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 65182841.11sec, total: 65182841.11sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 65182841.10sec, total: 65182841.11sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 65182841.10sec, total: 65182841.11sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 65182841.10sec, total: 65182841.11sec
  train.py:359:image_losses, cpu: 558us, accelerator: 7.15ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 545us, accelerator: 7.15ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.39ms, total: 4.58ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 139us, accelerator: 1.07ms, total: 1.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_70750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 129906648.08sec, total: 129906648.08sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 64953324.04sec, total: 64953324.04sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 64953324.04sec, total: 64953324.04sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.27ms, accelerator: 0us, total: 91.27ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 194859972.11sec, total: 194859972.11sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 64953324.06sec, total: 64953324.07sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 64953324.06sec, total: 64953324.07sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 64953324.06sec, total: 64953324.06sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 64953324.06sec, total: 64953324.06sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 64953324.06sec, total: 64953324.06sec
  train.py:359:image_losses, cpu: 558us, accelerator: 7.15ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 545us, accelerator: 7.15ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.39ms, total: 4.59ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.69ms, total: 1.91ms
      train.py:344:hfe, cpu: 139us, accelerator: 1.07ms, total: 1.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_71000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 129450835.28sec, total: 129450835.28sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 64725417.64sec, total: 64725417.64sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 64725417.64sec, total: 64725417.64sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.27ms, accelerator: 0us, total: 91.27ms
train.py:441:<module> (gradient), cpu: 5.35ms, accelerator: 194176252.91sec, total: 194176252.91sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 64725417.66sec, total: 64725417.67sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 64725417.66sec, total: 64725417.67sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 64725417.66sec, total: 64725417.66sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 64725417.66sec, total: 64725417.66sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 64725417.66sec, total: 64725417.66sec
  train.py:359:image_losses, cpu: 558us, accelerator: 7.16ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 545us, accelerator: 7.16ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.40ms, total: 4.59ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.69ms, total: 1.90ms
      train.py:344:hfe, cpu: 139us, accelerator: 1.07ms, total: 1.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_71250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 128998209.98sec, total: 128998209.98sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 64499104.99sec, total: 64499104.99sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 64499104.99sec, total: 64499104.99sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.28ms, accelerator: 0us, total: 91.28ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 193497314.96sec, total: 193497314.97sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 64499105.02sec, total: 64499105.02sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 64499105.02sec, total: 64499105.02sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 64499105.01sec, total: 64499105.01sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 64499105.01sec, total: 64499105.01sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 64499105.01sec, total: 64499105.01sec
  train.py:359:image_losses, cpu: 558us, accelerator: 7.15ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 545us, accelerator: 7.15ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.41ms, total: 4.60ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.69ms, total: 1.90ms
      train.py:344:hfe, cpu: 139us, accelerator: 1.06ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_71500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 128548738.86sec, total: 128548738.87sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 64274369.43sec, total: 64274369.44sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 64274369.43sec, total: 64274369.43sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.28ms, accelerator: 0us, total: 91.28ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 192823108.29sec, total: 192823108.29sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 64274369.46sec, total: 64274369.46sec
train.py:442:<module>, cpu: 4.10ms, accelerator: 64274369.46sec, total: 64274369.46sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 64274369.45sec, total: 64274369.45sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 64274369.45sec, total: 64274369.45sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 64274369.45sec, total: 64274369.45sec
  train.py:359:image_losses, cpu: 558us, accelerator: 7.16ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 545us, accelerator: 7.16ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.41ms, total: 4.60ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 139us, accelerator: 1.06ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_71750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 128102389.08sec, total: 128102389.08sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 64051194.54sec, total: 64051194.54sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 64051194.54sec, total: 64051194.54sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.27ms, accelerator: 0us, total: 91.27ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 192153583.61sec, total: 192153583.61sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 64051194.56sec, total: 64051194.57sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 64051194.56sec, total: 64051194.57sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 64051194.56sec, total: 64051194.56sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 64051194.56sec, total: 64051194.56sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 64051194.56sec, total: 64051194.56sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.16ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.16ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.42ms, total: 4.61ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.06ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_72000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 127659128.21sec, total: 127659128.22sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 63829564.11sec, total: 63829564.11sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 63829564.11sec, total: 63829564.11sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.28ms, accelerator: 0us, total: 91.28ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 191488692.31sec, total: 191488692.32sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 63829564.13sec, total: 63829564.14sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 63829564.13sec, total: 63829564.14sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 63829564.13sec, total: 63829564.13sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 63829564.13sec, total: 63829564.13sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 63829564.13sec, total: 63829564.13sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.16ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.16ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.42ms, total: 4.62ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_72250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 127218924.32sec, total: 127218924.33sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 63609462.16sec, total: 63609462.17sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 63609462.16sec, total: 63609462.16sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.27ms, accelerator: 0us, total: 91.27ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 190828386.48sec, total: 190828386.48sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 63609462.19sec, total: 63609462.19sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 63609462.19sec, total: 63609462.19sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 63609462.18sec, total: 63609462.18sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 63609462.18sec, total: 63609462.18sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 63609462.18sec, total: 63609462.18sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.16ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.16ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.43ms, total: 4.62ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_72500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 126781745.89sec, total: 126781745.89sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 63390872.95sec, total: 63390872.95sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 63390872.95sec, total: 63390872.95sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.23ms, accelerator: 0us, total: 91.23ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 190172618.83sec, total: 190172618.83sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 63390872.97sec, total: 63390872.98sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 63390872.97sec, total: 63390872.98sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 63390872.96sec, total: 63390872.97sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 63390872.96sec, total: 63390872.97sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 63390872.96sec, total: 63390872.97sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.16ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.16ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.43ms, total: 4.63ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.05ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_72750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 126347561.83sec, total: 126347561.83sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 63173780.92sec, total: 63173780.92sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 63173780.92sec, total: 63173780.92sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.20ms, accelerator: 0us, total: 91.20ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 189521342.74sec, total: 189521342.74sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 63173780.94sec, total: 63173780.95sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 63173780.94sec, total: 63173780.94sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 63173780.93sec, total: 63173780.94sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 63173780.93sec, total: 63173780.94sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 63173780.93sec, total: 63173780.94sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.16ms, total: 7.73ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.16ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.44ms, total: 4.63ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.90ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.04ms, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_73000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 125916341.48sec, total: 125916341.48sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 62958170.74sec, total: 62958170.74sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 62958170.74sec, total: 62958170.74sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.18ms, accelerator: 0us, total: 91.18ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 188874512.21sec, total: 188874512.22sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 62958170.77sec, total: 62958170.77sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 62958170.77sec, total: 62958170.77sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 62958170.76sec, total: 62958170.76sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 62958170.76sec, total: 62958170.76sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 62958170.76sec, total: 62958170.76sec
  train.py:359:image_losses, cpu: 558us, accelerator: 7.17ms, total: 7.73ms
    train.py:322:loss_fn, cpu: 545us, accelerator: 7.17ms, total: 7.72ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.45ms, total: 4.64ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.89ms
      train.py:344:hfe, cpu: 139us, accelerator: 1.04ms, total: 1.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_73250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 125488054.61sec, total: 125488054.61sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 62744027.30sec, total: 62744027.31sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 62744027.30sec, total: 62744027.30sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.17ms, accelerator: 0us, total: 91.17ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 188232081.90sec, total: 188232081.91sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 62744027.33sec, total: 62744027.33sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 62744027.33sec, total: 62744027.33sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 62744027.32sec, total: 62744027.32sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 62744027.32sec, total: 62744027.32sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 62744027.32sec, total: 62744027.32sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.16ms, total: 7.73ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.16ms, total: 7.72ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.45ms, total: 4.64ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.68ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.04ms, total: 1.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_73500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 125062671.37sec, total: 125062671.37sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 62531335.69sec, total: 62531335.69sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 62531335.69sec, total: 62531335.69sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.16ms, accelerator: 0us, total: 91.16ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 187594007.05sec, total: 187594007.05sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 62531335.71sec, total: 62531335.72sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 62531335.71sec, total: 62531335.72sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 62531335.70sec, total: 62531335.71sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 62531335.70sec, total: 62531335.71sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 62531335.70sec, total: 62531335.71sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.16ms, total: 7.73ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.16ms, total: 7.72ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.46ms, total: 4.65ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.03ms, total: 1.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_73750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 124640162.34sec, total: 124640162.35sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 62320081.17sec, total: 62320081.18sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 62320081.17sec, total: 62320081.17sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.14ms, accelerator: 0us, total: 91.14ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 186960243.51sec, total: 186960243.51sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 62320081.20sec, total: 62320081.20sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 62320081.20sec, total: 62320081.20sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 62320081.19sec, total: 62320081.19sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 62320081.19sec, total: 62320081.19sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 62320081.19sec, total: 62320081.19sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.17ms, total: 7.73ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.17ms, total: 7.72ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.46ms, total: 4.66ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.03ms, total: 1.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_74000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 124220498.50sec, total: 124220498.50sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 62110249.25sec, total: 62110249.25sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 62110249.25sec, total: 62110249.25sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.10ms, accelerator: 0us, total: 91.10ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 186330747.74sec, total: 186330747.75sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 62110249.28sec, total: 62110249.28sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 62110249.28sec, total: 62110249.28sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 62110249.27sec, total: 62110249.27sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 62110249.27sec, total: 62110249.27sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 62110249.27sec, total: 62110249.27sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.45ms, total: 4.64ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.03ms, total: 1.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_74250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 123803651.19sec, total: 123803651.19sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 61901825.60sec, total: 61901825.60sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 61901825.59sec, total: 61901825.60sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.08ms, accelerator: 0us, total: 91.08ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 185705476.77sec, total: 185705476.78sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 61901825.62sec, total: 61901825.63sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 61901825.62sec, total: 61901825.62sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 61901825.61sec, total: 61901825.62sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 61901825.61sec, total: 61901825.62sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 61901825.61sec, total: 61901825.62sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.45ms, total: 4.65ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.02ms, total: 1.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_74500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 123389592.15sec, total: 123389592.16sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 61694796.08sec, total: 61694796.08sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 61694796.08sec, total: 61694796.08sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.05ms, accelerator: 0us, total: 91.05ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 185084388.22sec, total: 185084388.23sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 61694796.10sec, total: 61694796.11sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 61694796.10sec, total: 61694796.11sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 61694796.10sec, total: 61694796.10sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 61694796.10sec, total: 61694796.10sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 61694796.10sec, total: 61694796.10sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.44ms, total: 4.64ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.67ms, total: 1.89ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.03ms, total: 1.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_74750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 122978293.51sec, total: 122978293.51sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 61489146.76sec, total: 61489146.76sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 61489146.76sec, total: 61489146.76sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.04ms, accelerator: 0us, total: 91.04ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 184467440.26sec, total: 184467440.27sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 61489146.78sec, total: 61489146.79sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 61489146.78sec, total: 61489146.79sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 61489146.78sec, total: 61489146.78sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 61489146.78sec, total: 61489146.78sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 61489146.78sec, total: 61489146.78sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.45ms, total: 4.64ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.03ms, total: 1.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_75000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 122569727.75sec, total: 122569727.76sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 61284863.88sec, total: 61284863.88sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 61284863.88sec, total: 61284863.88sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.03ms, accelerator: 0us, total: 91.03ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 183854591.62sec, total: 183854591.63sec
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 61284863.90sec, total: 61284863.91sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 61284863.90sec, total: 61284863.91sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 61284863.90sec, total: 61284863.90sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 61284863.90sec, total: 61284863.90sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 61284863.90sec, total: 61284863.90sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.15ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.45ms, total: 4.65ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.03ms, total: 1.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_75250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 122163867.73sec, total: 122163867.73sec (40.00%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 61081933.87sec, total: 61081933.87sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 61081933.87sec, total: 61081933.87sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.03ms, accelerator: 0us, total: 91.03ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 183245801.59sec, total: 183245801.59sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 61081933.89sec, total: 61081933.90sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 61081933.89sec, total: 61081933.90sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 61081933.88sec, total: 61081933.89sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 61081933.88sec, total: 61081933.89sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 61081933.88sec, total: 61081933.89sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.15ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.46ms, total: 4.65ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.02ms, total: 1.17ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_75500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 121760686.65sec, total: 121760686.65sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 60880343.33sec, total: 60880343.33sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 60880343.32sec, total: 60880343.33sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.01ms, accelerator: 0us, total: 91.01ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 182641029.96sec, total: 182641029.97sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 60880343.35sec, total: 60880343.36sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 60880343.35sec, total: 60880343.35sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 60880343.34sec, total: 60880343.35sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 60880343.34sec, total: 60880343.35sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 60880343.34sec, total: 60880343.35sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.15ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.46ms, total: 4.66ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.02ms, total: 1.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_75750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 121360158.07sec, total: 121360158.07sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 60680079.04sec, total: 60680079.04sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 60680079.04sec, total: 60680079.04sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.99ms, accelerator: 0us, total: 90.99ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 182040237.10sec, total: 182040237.11sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 60680079.06sec, total: 60680079.07sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 60680079.06sec, total: 60680079.07sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 60680079.06sec, total: 60680079.06sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 60680079.06sec, total: 60680079.06sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 60680079.06sec, total: 60680079.06sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.15ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.47ms, total: 4.66ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.02ms, total: 1.16ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_76000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 120962255.91sec, total: 120962255.92sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 60481127.96sec, total: 60481127.96sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 60481127.96sec, total: 60481127.96sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.97ms, accelerator: 0us, total: 90.97ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 181443383.87sec, total: 181443383.87sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 60481127.98sec, total: 60481127.99sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 60481127.98sec, total: 60481127.99sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 60481127.98sec, total: 60481127.98sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 60481127.98sec, total: 60481127.98sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 60481127.98sec, total: 60481127.98sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.15ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.47ms, total: 4.67ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.02ms, total: 1.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_76250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 120566954.43sec, total: 120566954.43sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 60283477.22sec, total: 60283477.22sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 60283477.21sec, total: 60283477.21sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.95ms, accelerator: 0us, total: 90.95ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 180850431.63sec, total: 180850431.64sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 60283477.24sec, total: 60283477.24sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 60283477.24sec, total: 60283477.24sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 60283477.23sec, total: 60283477.24sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 60283477.23sec, total: 60283477.23sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 60283477.23sec, total: 60283477.23sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.15ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.48ms, total: 4.67ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.01ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_76500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 120174228.19sec, total: 120174228.19sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 60087114.10sec, total: 60087114.10sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 60087114.10sec, total: 60087114.10sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.95ms, accelerator: 0us, total: 90.95ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 180261342.28sec, total: 180261342.28sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 60087114.12sec, total: 60087114.13sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 60087114.12sec, total: 60087114.13sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 60087114.11sec, total: 60087114.12sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 60087114.11sec, total: 60087114.12sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 60087114.11sec, total: 60087114.12sec
  train.py:359:image_losses, cpu: 557us, accelerator: 7.15ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 544us, accelerator: 7.15ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.49ms, total: 4.68ms
      train.py:342:hfe, cpu: 215us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.01ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_76750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 119784052.12sec, total: 119784052.13sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 59892026.06sec, total: 59892026.07sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 59892026.06sec, total: 59892026.06sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.94ms, accelerator: 0us, total: 90.94ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 179676078.18sec, total: 179676078.18sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 59892026.09sec, total: 59892026.09sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 59892026.09sec, total: 59892026.09sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 59892026.08sec, total: 59892026.08sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 59892026.08sec, total: 59892026.08sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 59892026.08sec, total: 59892026.08sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.15ms, total: 7.72ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.15ms, total: 7.71ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.49ms, total: 4.68ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.66ms, total: 1.88ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.01ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_77000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 119396401.47sec, total: 119396401.47sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 59698200.74sec, total: 59698200.74sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 59698200.74sec, total: 59698200.74sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.93ms, accelerator: 0us, total: 90.93ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 179094602.20sec, total: 179094602.20sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 59698200.76sec, total: 59698200.77sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 59698200.76sec, total: 59698200.77sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 59698200.75sec, total: 59698200.76sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 59698200.75sec, total: 59698200.76sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 59698200.75sec, total: 59698200.76sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.13ms, total: 7.70ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.13ms, total: 7.69ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.48ms, total: 4.67ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.65ms, total: 1.87ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.00ms, total: 1.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_77250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 119011251.79sec, total: 119011251.79sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 59505625.90sec, total: 59505625.90sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 59505625.89sec, total: 59505625.90sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.92ms, accelerator: 0us, total: 90.92ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 178516877.67sec, total: 178516877.68sec
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 59505625.92sec, total: 59505625.93sec
train.py:442:<module>, cpu: 4.08ms, accelerator: 59505625.92sec, total: 59505625.93sec
  train.py:360:image_losses, cpu: 3.31ms, accelerator: 59505625.91sec, total: 59505625.92sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 59505625.91sec, total: 59505625.92sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 59505625.91sec, total: 59505625.92sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.14ms, total: 7.70ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.14ms, total: 7.69ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.49ms, total: 4.68ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.65ms, total: 1.87ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.00ms, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_77500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 118628578.95sec, total: 118628578.95sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 59314289.48sec, total: 59314289.48sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 59314289.48sec, total: 59314289.48sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.91ms, accelerator: 0us, total: 90.91ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 177942868.42sec, total: 177942868.43sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 59314289.50sec, total: 59314289.51sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 59314289.50sec, total: 59314289.51sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 59314289.50sec, total: 59314289.50sec
    train.py:322:loss_fn, cpu: 3.29ms, accelerator: 59314289.50sec, total: 59314289.50sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 59314289.50sec, total: 59314289.50sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.14ms, total: 7.69ms
      train.py:343:hfe, cpu: 191us, accelerator: 4.49ms, total: 4.68ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.65ms, total: 1.87ms
      train.py:344:hfe, cpu: 138us, accelerator: 998us, total: 1.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_77750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 118248359.15sec, total: 118248359.15sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 59124179.58sec, total: 59124179.58sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 59124179.57sec, total: 59124179.58sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.91ms, accelerator: 0us, total: 90.91ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 177372538.71sec, total: 177372538.72sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 59124179.60sec, total: 59124179.61sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 59124179.60sec, total: 59124179.61sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 59124179.59sec, total: 59124179.60sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 59124179.59sec, total: 59124179.60sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 59124179.59sec, total: 59124179.60sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.14ms, total: 7.69ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.50ms, total: 4.69ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.65ms, total: 1.87ms
      train.py:344:hfe, cpu: 138us, accelerator: 996us, total: 1.14ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_78000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 117870568.86sec, total: 117870568.86sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 58935284.43sec, total: 58935284.44sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 58935284.43sec, total: 58935284.43sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.91ms, accelerator: 0us, total: 90.91ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 176805853.29sec, total: 176805853.29sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 58935284.46sec, total: 58935284.46sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 58935284.46sec, total: 58935284.46sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 58935284.45sec, total: 58935284.45sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 58935284.45sec, total: 58935284.45sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 58935284.45sec, total: 58935284.45sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.50ms, total: 4.69ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.65ms, total: 1.87ms
      train.py:344:hfe, cpu: 138us, accelerator: 993us, total: 1.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_78250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 117495184.89sec, total: 117495184.89sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 58747592.45sec, total: 58747592.45sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 58747592.44sec, total: 58747592.45sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.91ms, accelerator: 0us, total: 90.91ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 176242777.32sec, total: 176242777.33sec
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 58747592.47sec, total: 58747592.47sec
train.py:442:<module>, cpu: 4.09ms, accelerator: 58747592.47sec, total: 58747592.47sec
  train.py:360:image_losses, cpu: 3.32ms, accelerator: 58747592.46sec, total: 58747592.47sec
    train.py:322:loss_fn, cpu: 3.30ms, accelerator: 58747592.46sec, total: 58747592.47sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 58747592.46sec, total: 58747592.47sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.50ms, total: 4.70ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.65ms, total: 1.87ms
      train.py:344:hfe, cpu: 138us, accelerator: 991us, total: 1.13ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1990.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_78500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 117122184.30sec, total: 117122184.30sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 58561092.15sec, total: 58561092.15sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 58561092.15sec, total: 58561092.15sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.66ms, accelerator: 0us, total: 91.66ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 175683276.44sec, total: 175683276.45sec
train.py:442:<module>, cpu: 4.66ms, accelerator: 58561092.18sec, total: 58561092.18sec
  train.py:360:image_losses, cpu: 3.40ms, accelerator: 58561092.17sec, total: 58561092.17sec
    train.py:322:loss_fn, cpu: 3.38ms, accelerator: 58561092.17sec, total: 58561092.17sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 58561092.17sec, total: 58561092.17sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.51ms, total: 4.70ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.65ms, total: 1.86ms
      train.py:344:hfe, cpu: 138us, accelerator: 988us, total: 1.13ms
  train.py:357:image_losses, cpu: 524us, accelerator: 568us, total: 1.09ms
    train.py:322:loss_fn, cpu: 507us, accelerator: 568us, total: 1.08ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 58561092.18sec, total: 58561092.18sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_78750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 116751544.48sec, total: 116751544.48sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 58375772.24sec, total: 58375772.24sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 58375772.24sec, total: 58375772.24sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.65ms, accelerator: 0us, total: 91.65ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 175127316.71sec, total: 175127316.71sec
train.py:442:<module>, cpu: 4.65ms, accelerator: 58375772.27sec, total: 58375772.27sec
  train.py:360:image_losses, cpu: 3.40ms, accelerator: 58375772.26sec, total: 58375772.26sec
    train.py:322:loss_fn, cpu: 3.38ms, accelerator: 58375772.26sec, total: 58375772.26sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 58375772.26sec, total: 58375772.26sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.51ms, total: 4.71ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.65ms, total: 1.86ms
      train.py:344:hfe, cpu: 138us, accelerator: 984us, total: 1.13ms
  train.py:357:image_losses, cpu: 523us, accelerator: 567us, total: 1.09ms
    train.py:322:loss_fn, cpu: 506us, accelerator: 567us, total: 1.07ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 58375772.26sec, total: 58375772.27sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_79000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 116383243.07sec, total: 116383243.07sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 58191621.54sec, total: 58191621.54sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 58191621.54sec, total: 58191621.54sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.65ms, accelerator: 0us, total: 91.65ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 174574864.60sec, total: 174574864.61sec
train.py:442:<module>, cpu: 4.65ms, accelerator: 58191621.56sec, total: 58191621.57sec
  train.py:360:image_losses, cpu: 3.40ms, accelerator: 58191621.56sec, total: 58191621.56sec
    train.py:322:loss_fn, cpu: 3.38ms, accelerator: 58191621.56sec, total: 58191621.56sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 58191621.56sec, total: 58191621.56sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.52ms, total: 4.71ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.65ms, total: 1.86ms
      train.py:344:hfe, cpu: 138us, accelerator: 982us, total: 1.12ms
  train.py:357:image_losses, cpu: 522us, accelerator: 565us, total: 1.09ms
    train.py:322:loss_fn, cpu: 505us, accelerator: 565us, total: 1.07ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 58191621.56sec, total: 58191621.57sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_79250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 116017258.03sec, total: 116017258.03sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 58008629.02sec, total: 58008629.02sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 58008629.02sec, total: 58008629.02sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.63ms, accelerator: 0us, total: 91.63ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 174025887.04sec, total: 174025887.05sec
train.py:442:<module>, cpu: 4.65ms, accelerator: 58008629.04sec, total: 58008629.05sec
  train.py:360:image_losses, cpu: 3.40ms, accelerator: 58008629.04sec, total: 58008629.04sec
    train.py:322:loss_fn, cpu: 3.38ms, accelerator: 58008629.04sec, total: 58008629.04sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 58008629.04sec, total: 58008629.04sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.15ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.52ms, total: 4.72ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.64ms, total: 1.86ms
      train.py:344:hfe, cpu: 138us, accelerator: 979us, total: 1.12ms
  train.py:357:image_losses, cpu: 521us, accelerator: 565us, total: 1.09ms
    train.py:322:loss_fn, cpu: 504us, accelerator: 565us, total: 1.07ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 58008629.04sec, total: 58008629.05sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_79500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 115653567.57sec, total: 115653567.57sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 57826783.79sec, total: 57826783.79sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 57826783.79sec, total: 57826783.79sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.62ms, accelerator: 0us, total: 91.62ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 173480351.35sec, total: 173480351.35sec
train.py:442:<module>, cpu: 4.64ms, accelerator: 57826783.81sec, total: 57826783.82sec
  train.py:360:image_losses, cpu: 3.40ms, accelerator: 57826783.80sec, total: 57826783.81sec
    train.py:322:loss_fn, cpu: 3.38ms, accelerator: 57826783.80sec, total: 57826783.81sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 57826783.80sec, total: 57826783.81sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.14ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.14ms, total: 7.70ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.53ms, total: 4.72ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.64ms, total: 1.86ms
      train.py:344:hfe, cpu: 138us, accelerator: 976us, total: 1.12ms
  train.py:357:image_losses, cpu: 520us, accelerator: 565us, total: 1.09ms
    train.py:322:loss_fn, cpu: 503us, accelerator: 565us, total: 1.07ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 57826783.81sec, total: 57826783.82sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_79750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 115292150.17sec, total: 115292150.17sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 57646075.09sec, total: 57646075.09sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 57646075.09sec, total: 57646075.09sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.59ms, accelerator: 0us, total: 91.59ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 172938225.25sec, total: 172938225.25sec
train.py:442:<module>, cpu: 4.64ms, accelerator: 57646075.11sec, total: 57646075.12sec
  train.py:360:image_losses, cpu: 3.40ms, accelerator: 57646075.10sec, total: 57646075.11sec
    train.py:322:loss_fn, cpu: 3.38ms, accelerator: 57646075.10sec, total: 57646075.11sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 57646075.10sec, total: 57646075.11sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.15ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.53ms, total: 4.73ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.64ms, total: 1.86ms
      train.py:344:hfe, cpu: 138us, accelerator: 973us, total: 1.11ms
  train.py:357:image_losses, cpu: 518us, accelerator: 564us, total: 1.08ms
    train.py:322:loss_fn, cpu: 501us, accelerator: 564us, total: 1.07ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 57646075.11sec, total: 57646075.12sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_80000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 114932984.59sec, total: 114932984.59sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 57466492.30sec, total: 57466492.30sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 57466492.30sec, total: 57466492.30sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.56ms, accelerator: 0us, total: 91.56ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 172399476.88sec, total: 172399476.89sec
train.py:442:<module>, cpu: 4.64ms, accelerator: 57466492.32sec, total: 57466492.33sec
  train.py:360:image_losses, cpu: 3.40ms, accelerator: 57466492.32sec, total: 57466492.32sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 57466492.32sec, total: 57466492.32sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 57466492.32sec, total: 57466492.32sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.15ms, total: 7.71ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.15ms, total: 7.70ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.54ms, total: 4.73ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.64ms, total: 1.86ms
      train.py:344:hfe, cpu: 138us, accelerator: 970us, total: 1.11ms
  train.py:357:image_losses, cpu: 517us, accelerator: 564us, total: 1.08ms
    train.py:322:loss_fn, cpu: 500us, accelerator: 564us, total: 1.06ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 57466492.32sec, total: 57466492.33sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_80250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 114576049.86sec, total: 114576049.86sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 57288024.93sec, total: 57288024.93sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 57288024.93sec, total: 57288024.93sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.55ms, accelerator: 0us, total: 91.55ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 171864074.78sec, total: 171864074.79sec
train.py:442:<module>, cpu: 4.64ms, accelerator: 57288024.96sec, total: 57288024.96sec
  train.py:360:image_losses, cpu: 3.40ms, accelerator: 57288024.95sec, total: 57288024.95sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 57288024.95sec, total: 57288024.95sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 57288024.95sec, total: 57288024.95sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.21ms, total: 7.77ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.21ms, total: 7.76ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.52ms, total: 4.72ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.68ms, total: 1.89ms
      train.py:344:hfe, cpu: 139us, accelerator: 1.01ms, total: 1.15ms
  train.py:357:image_losses, cpu: 516us, accelerator: 562us, total: 1.08ms
    train.py:322:loss_fn, cpu: 499us, accelerator: 562us, total: 1.06ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 57288024.96sec, total: 57288024.96sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_80500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 114221325.25sec, total: 114221325.25sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 57110662.63sec, total: 57110662.63sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 57110662.62sec, total: 57110662.63sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.51ms, accelerator: 0us, total: 91.51ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 171331987.86sec, total: 171331987.87sec
train.py:442:<module>, cpu: 4.63ms, accelerator: 57110662.65sec, total: 57110662.66sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 57110662.64sec, total: 57110662.65sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 57110662.64sec, total: 57110662.65sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 57110662.64sec, total: 57110662.65sec
  train.py:359:image_losses, cpu: 556us, accelerator: 7.27ms, total: 7.83ms
    train.py:322:loss_fn, cpu: 543us, accelerator: 7.27ms, total: 7.82ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.51ms, total: 4.70ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.71ms, total: 1.93ms
      train.py:344:hfe, cpu: 139us, accelerator: 1.05ms, total: 1.19ms
  train.py:357:image_losses, cpu: 515us, accelerator: 561us, total: 1.08ms
    train.py:322:loss_fn, cpu: 498us, accelerator: 561us, total: 1.06ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 57110662.65sec, total: 57110662.65sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_80750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 113868790.29sec, total: 113868790.29sec (40.00%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 56934395.15sec, total: 56934395.15sec (20.00%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 56934395.15sec, total: 56934395.15sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.49ms, accelerator: 0us, total: 91.49ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 170803185.43sec, total: 170803185.43sec
train.py:442:<module>, cpu: 4.63ms, accelerator: 56934395.17sec, total: 56934395.18sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 56934395.17sec, total: 56934395.17sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 56934395.17sec, total: 56934395.17sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 56934395.17sec, total: 56934395.17sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.33ms, total: 7.89ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.33ms, total: 7.88ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.50ms, total: 4.69ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.74ms, total: 1.96ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.09ms, total: 1.23ms
  train.py:357:image_losses, cpu: 514us, accelerator: 560us, total: 1.07ms
    train.py:322:loss_fn, cpu: 497us, accelerator: 560us, total: 1.06ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 56934395.17sec, total: 56934395.18sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_81000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 113518424.78sec, total: 113518424.78sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 56759212.39sec, total: 56759212.40sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 56759212.39sec, total: 56759212.39sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.47ms, accelerator: 0us, total: 91.47ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 170277637.17sec, total: 170277637.17sec
train.py:442:<module>, cpu: 4.63ms, accelerator: 56759212.42sec, total: 56759212.42sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 56759212.41sec, total: 56759212.41sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 56759212.41sec, total: 56759212.41sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 56759212.41sec, total: 56759212.41sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.33ms, total: 7.90ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.33ms, total: 7.89ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.49ms, total: 4.68ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.75ms, total: 1.97ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.09ms, total: 1.23ms
  train.py:357:image_losses, cpu: 512us, accelerator: 560us, total: 1.07ms
    train.py:322:loss_fn, cpu: 495us, accelerator: 560us, total: 1.06ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 56759212.42sec, total: 56759212.42sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_81250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 113170208.76sec, total: 113170208.76sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 56585104.38sec, total: 56585104.38sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 56585104.38sec, total: 56585104.38sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.45ms, accelerator: 0us, total: 91.45ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 169755313.13sec, total: 169755313.13sec
train.py:442:<module>, cpu: 4.63ms, accelerator: 56585104.41sec, total: 56585104.41sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 56585104.40sec, total: 56585104.40sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 56585104.40sec, total: 56585104.40sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 56585104.40sec, total: 56585104.40sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.40ms, total: 7.96ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.40ms, total: 7.95ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.48ms, total: 4.67ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.79ms, total: 2.01ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.13ms, total: 1.27ms
  train.py:357:image_losses, cpu: 511us, accelerator: 559us, total: 1.07ms
    train.py:322:loss_fn, cpu: 494us, accelerator: 559us, total: 1.05ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 56585104.40sec, total: 56585104.41sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_81500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 112824122.49sec, total: 112824122.49sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 56412061.25sec, total: 56412061.25sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 56412061.25sec, total: 56412061.25sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.43ms, accelerator: 0us, total: 91.43ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 169236183.73sec, total: 169236183.73sec
train.py:442:<module>, cpu: 4.63ms, accelerator: 56412061.27sec, total: 56412061.28sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 56412061.27sec, total: 56412061.27sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 56412061.27sec, total: 56412061.27sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 56412061.26sec, total: 56412061.27sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.39ms, total: 7.96ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.39ms, total: 7.95ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.48ms, total: 4.67ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.79ms, total: 2.01ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.13ms, total: 1.27ms
  train.py:357:image_losses, cpu: 510us, accelerator: 558us, total: 1.07ms
    train.py:322:loss_fn, cpu: 493us, accelerator: 558us, total: 1.05ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 56412061.27sec, total: 56412061.28sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_81750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 112480146.51sec, total: 112480146.51sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 56240073.26sec, total: 56240073.26sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 56240073.25sec, total: 56240073.26sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.42ms, accelerator: 0us, total: 91.42ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 168720219.75sec, total: 168720219.76sec
train.py:442:<module>, cpu: 4.62ms, accelerator: 56240073.28sec, total: 56240073.29sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 56240073.27sec, total: 56240073.28sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 56240073.27sec, total: 56240073.28sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 56240073.27sec, total: 56240073.28sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.46ms, total: 8.02ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.46ms, total: 8.01ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.47ms, total: 4.66ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.82ms, total: 2.04ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.17ms, total: 1.31ms
  train.py:357:image_losses, cpu: 509us, accelerator: 556us, total: 1.07ms
    train.py:322:loss_fn, cpu: 492us, accelerator: 556us, total: 1.05ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 56240073.28sec, total: 56240073.29sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_82000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 112138261.56sec, total: 112138261.57sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 56069130.79sec, total: 56069130.79sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 56069130.78sec, total: 56069130.78sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.40ms, accelerator: 0us, total: 91.40ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 168207392.34sec, total: 168207392.34sec
train.py:442:<module>, cpu: 4.62ms, accelerator: 56069130.81sec, total: 56069130.81sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 56069130.80sec, total: 56069130.81sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 56069130.80sec, total: 56069130.81sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 56069130.80sec, total: 56069130.80sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.43ms, total: 8.00ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.43ms, total: 7.99ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.46ms, total: 4.65ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.81ms, total: 2.03ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.16ms, total: 1.30ms
  train.py:357:image_losses, cpu: 508us, accelerator: 557us, total: 1.07ms
    train.py:322:loss_fn, cpu: 491us, accelerator: 557us, total: 1.05ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 56069130.81sec, total: 56069130.81sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_82250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 111798448.65sec, total: 111798448.65sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 55899224.33sec, total: 55899224.33sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 55899224.33sec, total: 55899224.33sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.40ms, accelerator: 0us, total: 91.40ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 167697672.97sec, total: 167697672.97sec
train.py:442:<module>, cpu: 4.62ms, accelerator: 55899224.35sec, total: 55899224.36sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 55899224.34sec, total: 55899224.35sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 55899224.34sec, total: 55899224.35sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 55899224.34sec, total: 55899224.35sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.49ms, total: 8.06ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.49ms, total: 8.04ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.44ms, total: 4.64ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.85ms, total: 2.07ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.20ms, total: 1.34ms
  train.py:357:image_losses, cpu: 507us, accelerator: 556us, total: 1.06ms
    train.py:322:loss_fn, cpu: 490us, accelerator: 556us, total: 1.05ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 55899224.35sec, total: 55899224.36sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_82500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 111460688.99sec, total: 111460688.99sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 55730344.50sec, total: 55730344.50sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 55730344.49sec, total: 55730344.50sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.38ms, accelerator: 0us, total: 91.38ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 167191033.47sec, total: 167191033.48sec
train.py:442:<module>, cpu: 4.62ms, accelerator: 55730344.52sec, total: 55730344.53sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 55730344.51sec, total: 55730344.52sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 55730344.51sec, total: 55730344.52sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 55730344.51sec, total: 55730344.52sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.55ms, total: 8.12ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.55ms, total: 8.10ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.43ms, total: 4.62ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.10ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.24ms, total: 1.38ms
  train.py:357:image_losses, cpu: 506us, accelerator: 554us, total: 1.06ms
    train.py:322:loss_fn, cpu: 489us, accelerator: 554us, total: 1.05ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 55730344.52sec, total: 55730344.53sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_82750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 111124964.02sec, total: 111124964.02sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 55562482.01sec, total: 55562482.02sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 55562482.01sec, total: 55562482.01sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.35ms, accelerator: 0us, total: 91.35ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 166687446.02sec, total: 166687446.03sec
train.py:442:<module>, cpu: 4.62ms, accelerator: 55562482.04sec, total: 55562482.04sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 55562482.03sec, total: 55562482.03sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 55562482.03sec, total: 55562482.03sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 55562482.03sec, total: 55562482.03sec
  train.py:359:image_losses, cpu: 555us, accelerator: 7.61ms, total: 8.17ms
    train.py:322:loss_fn, cpu: 542us, accelerator: 7.61ms, total: 8.16ms
      train.py:343:hfe, cpu: 190us, accelerator: 4.42ms, total: 4.61ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.91ms, total: 2.13ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.28ms, total: 1.42ms
  train.py:357:image_losses, cpu: 505us, accelerator: 554us, total: 1.06ms
    train.py:322:loss_fn, cpu: 488us, accelerator: 554us, total: 1.04ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 55562482.04sec, total: 55562482.04sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_83000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 110791255.42sec, total: 110791255.42sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 55395627.71sec, total: 55395627.72sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 55395627.71sec, total: 55395627.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.33ms, accelerator: 0us, total: 91.33ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 166186883.12sec, total: 166186883.13sec
train.py:442:<module>, cpu: 4.61ms, accelerator: 55395627.74sec, total: 55395627.74sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 55395627.73sec, total: 55395627.73sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 55395627.73sec, total: 55395627.73sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 55395627.73sec, total: 55395627.73sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.61ms, total: 8.17ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.61ms, total: 8.16ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.42ms, total: 4.61ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.91ms, total: 2.13ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.28ms, total: 1.42ms
  train.py:357:image_losses, cpu: 503us, accelerator: 552us, total: 1.06ms
    train.py:322:loss_fn, cpu: 486us, accelerator: 552us, total: 1.04ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 55395627.74sec, total: 55395627.74sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_83250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 110459545.07sec, total: 110459545.07sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 55229772.54sec, total: 55229772.54sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 55229772.54sec, total: 55229772.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.32ms, accelerator: 0us, total: 91.32ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 165689317.60sec, total: 165689317.61sec
train.py:442:<module>, cpu: 4.61ms, accelerator: 55229772.56sec, total: 55229772.57sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 55229772.56sec, total: 55229772.56sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 55229772.56sec, total: 55229772.56sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 55229772.56sec, total: 55229772.56sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.61ms, total: 8.17ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.61ms, total: 8.16ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.43ms, total: 4.62ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.91ms, total: 2.13ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.27ms, total: 1.41ms
  train.py:357:image_losses, cpu: 502us, accelerator: 552us, total: 1.06ms
    train.py:322:loss_fn, cpu: 485us, accelerator: 552us, total: 1.04ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 55229772.56sec, total: 55229772.57sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_83500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 110129815.09sec, total: 110129815.09sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 55064907.55sec, total: 55064907.55sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 55064907.54sec, total: 55064907.55sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.29ms, accelerator: 0us, total: 91.29ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 165194722.62sec, total: 165194722.63sec
train.py:442:<module>, cpu: 4.61ms, accelerator: 55064907.57sec, total: 55064907.58sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 55064907.56sec, total: 55064907.57sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 55064907.56sec, total: 55064907.57sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 55064907.56sec, total: 55064907.57sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.61ms, total: 8.17ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.61ms, total: 8.16ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.43ms, total: 4.62ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.91ms, total: 2.13ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.27ms, total: 1.41ms
  train.py:357:image_losses, cpu: 501us, accelerator: 552us, total: 1.05ms
    train.py:322:loss_fn, cpu: 484us, accelerator: 552us, total: 1.04ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 55064907.57sec, total: 55064907.58sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_83750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 109802047.78sec, total: 109802047.78sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 54901023.89sec, total: 54901023.90sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 54901023.89sec, total: 54901023.89sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.29ms, accelerator: 0us, total: 91.29ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 164703071.66sec, total: 164703071.67sec
train.py:442:<module>, cpu: 4.61ms, accelerator: 54901023.92sec, total: 54901023.92sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 54901023.91sec, total: 54901023.91sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 54901023.91sec, total: 54901023.91sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 54901023.91sec, total: 54901023.91sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.61ms, total: 8.17ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.61ms, total: 8.16ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.43ms, total: 4.63ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.91ms, total: 2.12ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.27ms, total: 1.41ms
  train.py:357:image_losses, cpu: 500us, accelerator: 551us, total: 1.05ms
    train.py:322:loss_fn, cpu: 483us, accelerator: 551us, total: 1.04ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 54901023.92sec, total: 54901023.92sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_84000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 109476225.68sec, total: 109476225.68sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 54738112.84sec, total: 54738112.85sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 54738112.84sec, total: 54738112.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.28ms, accelerator: 0us, total: 91.28ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 164214338.51sec, total: 164214338.52sec
train.py:442:<module>, cpu: 4.61ms, accelerator: 54738112.87sec, total: 54738112.87sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 54738112.86sec, total: 54738112.86sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 54738112.86sec, total: 54738112.86sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 54738112.86sec, total: 54738112.86sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.60ms, total: 8.17ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.60ms, total: 8.16ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.44ms, total: 4.63ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.12ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.26ms, total: 1.40ms
  train.py:357:image_losses, cpu: 499us, accelerator: 550us, total: 1.05ms
    train.py:322:loss_fn, cpu: 482us, accelerator: 550us, total: 1.03ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 54738112.87sec, total: 54738112.87sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_84250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 109152331.52sec, total: 109152331.52sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 54576165.76sec, total: 54576165.77sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 54576165.76sec, total: 54576165.76sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.27ms, accelerator: 0us, total: 91.27ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 163728497.28sec, total: 163728497.28sec
train.py:442:<module>, cpu: 4.61ms, accelerator: 54576165.79sec, total: 54576165.79sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 54576165.78sec, total: 54576165.78sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 54576165.78sec, total: 54576165.78sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 54576165.78sec, total: 54576165.78sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.60ms, total: 8.17ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.60ms, total: 8.16ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.44ms, total: 4.64ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.12ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.26ms, total: 1.40ms
  train.py:357:image_losses, cpu: 498us, accelerator: 550us, total: 1.05ms
    train.py:322:loss_fn, cpu: 481us, accelerator: 550us, total: 1.03ms
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 54576165.79sec, total: 54576165.79sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_84500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 108830348.24sec, total: 108830348.25sec (33.33%)
top 2 operation type: Mul, cpu: 2.05ms, accelerator: 54415174.13sec, total: 54415174.13sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 54415174.12sec, total: 54415174.12sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.24ms, accelerator: 0us, total: 91.24ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 163245522.36sec, total: 163245522.36sec
train.py:442:<module>, cpu: 4.60ms, accelerator: 54415174.15sec, total: 54415174.15sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 54415174.14sec, total: 54415174.15sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 54415174.14sec, total: 54415174.15sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 54415174.14sec, total: 54415174.15sec
  train.py:359:image_losses, cpu: 554us, accelerator: 7.60ms, total: 8.17ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.60ms, total: 8.15ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.45ms, total: 4.64ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.12ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.25ms, total: 1.40ms
  train.py:357:image_losses, cpu: 497us, accelerator: 549us, total: 1.05ms
    train.py:322:loss_fn, cpu: 480us, accelerator: 549us, total: 1.03ms
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 54415174.15sec, total: 54415174.15sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_84750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 108510258.98sec, total: 108510258.99sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 54255129.50sec, total: 54255129.50sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 54255129.49sec, total: 54255129.49sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.21ms, accelerator: 0us, total: 91.21ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 162765388.47sec, total: 162765388.47sec
train.py:442:<module>, cpu: 4.60ms, accelerator: 54255129.52sec, total: 54255129.53sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 54255129.51sec, total: 54255129.52sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 54255129.51sec, total: 54255129.52sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 54255129.51sec, total: 54255129.52sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.60ms, total: 8.17ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.60ms, total: 8.15ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.45ms, total: 4.65ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.12ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.25ms, total: 1.39ms
  train.py:357:image_losses, cpu: 496us, accelerator: 548us, total: 1.05ms
    train.py:322:loss_fn, cpu: 479us, accelerator: 548us, total: 1.03ms
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 54255129.52sec, total: 54255129.52sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_85000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 108192047.08sec, total: 108192047.08sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 54096023.54sec, total: 54096023.55sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 54096023.54sec, total: 54096023.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.19ms, accelerator: 0us, total: 91.19ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 162288070.61sec, total: 162288070.62sec
train.py:442:<module>, cpu: 4.60ms, accelerator: 54096023.57sec, total: 54096023.57sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 54096023.56sec, total: 54096023.56sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 54096023.56sec, total: 54096023.56sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 54096023.56sec, total: 54096023.56sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.60ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.60ms, total: 8.15ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.45ms, total: 4.64ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.12ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.25ms, total: 1.39ms
  train.py:357:image_losses, cpu: 495us, accelerator: 549us, total: 1.04ms
    train.py:322:loss_fn, cpu: 478us, accelerator: 549us, total: 1.03ms
train.py:436:<module> (gradient), cpu: 5.21ms, accelerator: 54096023.57sec, total: 54096023.57sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_85250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 107875696.07sec, total: 107875696.07sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 53937848.04sec, total: 53937848.04sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 53937848.03sec, total: 53937848.04sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.18ms, accelerator: 0us, total: 91.18ms
train.py:441:<module> (gradient), cpu: 5.36ms, accelerator: 161813544.09sec, total: 161813544.10sec
train.py:442:<module>, cpu: 4.60ms, accelerator: 53937848.06sec, total: 53937848.07sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 53937848.05sec, total: 53937848.06sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 53937848.05sec, total: 53937848.06sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 53937848.05sec, total: 53937848.06sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.60ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.60ms, total: 8.15ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.45ms, total: 4.64ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.12ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.25ms, total: 1.39ms
  train.py:357:image_losses, cpu: 494us, accelerator: 549us, total: 1.04ms
    train.py:322:loss_fn, cpu: 477us, accelerator: 549us, total: 1.03ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 53937848.06sec, total: 53937848.07sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_85500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 107561189.66sec, total: 107561189.67sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 53780594.84sec, total: 53780594.84sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 53780594.83sec, total: 53780594.83sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.16ms, accelerator: 0us, total: 91.16ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 161341784.49sec, total: 161341784.49sec
train.py:442:<module>, cpu: 4.60ms, accelerator: 53780594.86sec, total: 53780594.87sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 53780594.85sec, total: 53780594.86sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 53780594.85sec, total: 53780594.86sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 53780594.85sec, total: 53780594.86sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.60ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.60ms, total: 8.15ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.46ms, total: 4.65ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.12ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.24ms, total: 1.38ms
  train.py:357:image_losses, cpu: 493us, accelerator: 548us, total: 1.04ms
    train.py:322:loss_fn, cpu: 476us, accelerator: 548us, total: 1.02ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 53780594.86sec, total: 53780594.86sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_85750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 107248511.79sec, total: 107248511.79sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 53624255.90sec, total: 53624255.90sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 53624255.89sec, total: 53624255.90sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.14ms, accelerator: 0us, total: 91.14ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 160872767.67sec, total: 160872767.68sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 53624255.92sec, total: 53624255.93sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 53624255.91sec, total: 53624255.92sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 53624255.91sec, total: 53624255.92sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 53624255.91sec, total: 53624255.92sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.60ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.60ms, total: 8.15ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.46ms, total: 4.65ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.12ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.24ms, total: 1.38ms
  train.py:357:image_losses, cpu: 492us, accelerator: 546us, total: 1.04ms
    train.py:322:loss_fn, cpu: 475us, accelerator: 546us, total: 1.02ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 53624255.92sec, total: 53624255.93sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_86000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 106937646.54sec, total: 106937646.54sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 53468823.27sec, total: 53468823.27sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 53468823.27sec, total: 53468823.27sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.11ms, accelerator: 0us, total: 91.11ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 160406469.80sec, total: 160406469.80sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 53468823.30sec, total: 53468823.30sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 53468823.29sec, total: 53468823.29sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 53468823.29sec, total: 53468823.29sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 53468823.29sec, total: 53468823.29sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.59ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.59ms, total: 8.15ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.46ms, total: 4.66ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.12ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.24ms, total: 1.38ms
  train.py:357:image_losses, cpu: 491us, accelerator: 546us, total: 1.04ms
    train.py:322:loss_fn, cpu: 474us, accelerator: 546us, total: 1.02ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 53468823.29sec, total: 53468823.30sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_86250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 106628578.19sec, total: 106628578.19sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 53314289.10sec, total: 53314289.10sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 53314289.10sec, total: 53314289.10sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.09ms, accelerator: 0us, total: 91.09ms
train.py:441:<module> (gradient), cpu: 5.37ms, accelerator: 159942867.28sec, total: 159942867.29sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 53314289.13sec, total: 53314289.13sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 53314289.12sec, total: 53314289.12sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 53314289.12sec, total: 53314289.12sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 53314289.12sec, total: 53314289.12sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.60ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.60ms, total: 8.15ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.47ms, total: 4.66ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.11ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.23ms, total: 1.37ms
  train.py:357:image_losses, cpu: 490us, accelerator: 546us, total: 1.04ms
    train.py:322:loss_fn, cpu: 473us, accelerator: 546us, total: 1.02ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 53314289.12sec, total: 53314289.13sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_86500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 106321291.22sec, total: 106321291.23sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 53160645.62sec, total: 53160645.62sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 53160645.61sec, total: 53160645.61sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.07ms, accelerator: 0us, total: 91.07ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 159481936.83sec, total: 159481936.83sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 53160645.64sec, total: 53160645.65sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 53160645.63sec, total: 53160645.64sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 53160645.63sec, total: 53160645.64sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 53160645.63sec, total: 53160645.64sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.60ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.60ms, total: 8.15ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.47ms, total: 4.67ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.11ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.23ms, total: 1.37ms
  train.py:357:image_losses, cpu: 489us, accelerator: 545us, total: 1.03ms
    train.py:322:loss_fn, cpu: 472us, accelerator: 545us, total: 1.02ms
train.py:436:<module> (gradient), cpu: 5.22ms, accelerator: 53160645.64sec, total: 53160645.64sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_86750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 106015770.27sec, total: 106015770.27sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 53007885.14sec, total: 53007885.14sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 53007885.14sec, total: 53007885.14sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.05ms, accelerator: 0us, total: 91.05ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 159023655.40sec, total: 159023655.41sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 53007885.16sec, total: 53007885.17sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 53007885.16sec, total: 53007885.16sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 53007885.16sec, total: 53007885.16sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 53007885.16sec, total: 53007885.16sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.59ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.59ms, total: 8.14ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.48ms, total: 4.67ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.11ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.23ms, total: 1.37ms
  train.py:357:image_losses, cpu: 488us, accelerator: 545us, total: 1.03ms
    train.py:322:loss_fn, cpu: 471us, accelerator: 545us, total: 1.02ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 53007885.16sec, total: 53007885.17sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_87000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 105712000.16sec, total: 105712000.16sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 52856000.08sec, total: 52856000.08sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 52856000.08sec, total: 52856000.08sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.03ms, accelerator: 0us, total: 91.03ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 158568000.23sec, total: 158568000.23sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 52856000.11sec, total: 52856000.11sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 52856000.10sec, total: 52856000.10sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 52856000.10sec, total: 52856000.10sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 52856000.10sec, total: 52856000.10sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.59ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.59ms, total: 8.15ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.48ms, total: 4.67ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.11ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.22ms, total: 1.36ms
  train.py:357:image_losses, cpu: 487us, accelerator: 545us, total: 1.03ms
    train.py:322:loss_fn, cpu: 470us, accelerator: 545us, total: 1.02ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 52856000.11sec, total: 52856000.11sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_87250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 105409965.87sec, total: 105409965.87sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 52704982.94sec, total: 52704982.94sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 52704982.94sec, total: 52704982.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 91.02ms, accelerator: 0us, total: 91.02ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 158114948.80sec, total: 158114948.80sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 52704982.96sec, total: 52704982.97sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 52704982.96sec, total: 52704982.96sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 52704982.96sec, total: 52704982.96sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 52704982.96sec, total: 52704982.96sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.59ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.59ms, total: 8.14ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.49ms, total: 4.68ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.10ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.22ms, total: 1.36ms
  train.py:357:image_losses, cpu: 486us, accelerator: 543us, total: 1.03ms
    train.py:322:loss_fn, cpu: 469us, accelerator: 543us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 52704982.96sec, total: 52704982.97sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_87500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.60ms, accelerator: 105109652.58sec, total: 105109652.58sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 52554826.29sec, total: 52554826.30sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 52554826.29sec, total: 52554826.29sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.99ms, accelerator: 0us, total: 90.99ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 157664478.86sec, total: 157664478.86sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 52554826.32sec, total: 52554826.32sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 52554826.31sec, total: 52554826.31sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 52554826.31sec, total: 52554826.31sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 52554826.31sec, total: 52554826.31sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.59ms, total: 8.15ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.59ms, total: 8.14ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.49ms, total: 4.68ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.10ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.22ms, total: 1.36ms
  train.py:357:image_losses, cpu: 485us, accelerator: 543us, total: 1.03ms
    train.py:322:loss_fn, cpu: 468us, accelerator: 543us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 52554826.32sec, total: 52554826.32sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_87750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 104811045.61sec, total: 104811045.61sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 52405522.81sec, total: 52405522.81sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 52405522.81sec, total: 52405522.81sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.96ms, accelerator: 0us, total: 90.96ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 157216568.41sec, total: 157216568.41sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 52405522.83sec, total: 52405522.84sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 52405522.83sec, total: 52405522.83sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 52405522.83sec, total: 52405522.83sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 52405522.83sec, total: 52405522.83sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.59ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.59ms, total: 8.14ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.50ms, total: 4.69ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.10ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.21ms, total: 1.35ms
  train.py:357:image_losses, cpu: 484us, accelerator: 543us, total: 1.03ms
    train.py:322:loss_fn, cpu: 467us, accelerator: 543us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 52405522.83sec, total: 52405522.84sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_88000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 104514130.47sec, total: 104514130.47sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 52257065.24sec, total: 52257065.24sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 52257065.23sec, total: 52257065.24sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.94ms, accelerator: 0us, total: 90.94ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 156771195.69sec, total: 156771195.70sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 52257065.26sec, total: 52257065.27sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 52257065.25sec, total: 52257065.26sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 52257065.25sec, total: 52257065.26sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 52257065.25sec, total: 52257065.26sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.59ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.59ms, total: 8.14ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.50ms, total: 4.70ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.10ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.21ms, total: 1.35ms
  train.py:357:image_losses, cpu: 483us, accelerator: 543us, total: 1.03ms
    train.py:322:loss_fn, cpu: 466us, accelerator: 543us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 52257065.26sec, total: 52257065.27sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_88250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 104218892.81sec, total: 104218892.81sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 52109446.41sec, total: 52109446.41sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 52109446.41sec, total: 52109446.41sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.92ms, accelerator: 0us, total: 90.92ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 156328339.21sec, total: 156328339.21sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 52109446.43sec, total: 52109446.44sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 52109446.43sec, total: 52109446.43sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 52109446.43sec, total: 52109446.43sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 52109446.43sec, total: 52109446.43sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.59ms, total: 8.15ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.59ms, total: 8.14ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.50ms, total: 4.70ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.10ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.21ms, total: 1.35ms
  train.py:357:image_losses, cpu: 482us, accelerator: 542us, total: 1.02ms
    train.py:322:loss_fn, cpu: 465us, accelerator: 542us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 52109446.43sec, total: 52109446.44sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_88500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 103925318.46sec, total: 103925318.47sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 51962659.24sec, total: 51962659.24sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 51962659.23sec, total: 51962659.23sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.90ms, accelerator: 0us, total: 90.90ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 155887977.69sec, total: 155887977.69sec
train.py:442:<module>, cpu: 4.58ms, accelerator: 51962659.26sec, total: 51962659.27sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 51962659.25sec, total: 51962659.26sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 51962659.25sec, total: 51962659.26sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 51962659.25sec, total: 51962659.26sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.59ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.59ms, total: 8.15ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.51ms, total: 4.70ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.10ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.20ms, total: 1.34ms
  train.py:357:image_losses, cpu: 481us, accelerator: 542us, total: 1.02ms
    train.py:322:loss_fn, cpu: 464us, accelerator: 542us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 51962659.26sec, total: 51962659.26sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_88750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 103633393.41sec, total: 103633393.41sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 51816696.71sec, total: 51816696.71sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 51816696.71sec, total: 51816696.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.88ms, accelerator: 0us, total: 90.88ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 155450090.11sec, total: 155450090.12sec
train.py:442:<module>, cpu: 4.58ms, accelerator: 51816696.74sec, total: 51816696.74sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 51816696.73sec, total: 51816696.73sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 51816696.73sec, total: 51816696.73sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 51816696.73sec, total: 51816696.73sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.59ms, total: 8.15ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.59ms, total: 8.14ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.51ms, total: 4.71ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.09ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.20ms, total: 1.34ms
  train.py:357:image_losses, cpu: 480us, accelerator: 542us, total: 1.02ms
    train.py:322:loss_fn, cpu: 463us, accelerator: 542us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.23ms, accelerator: 51816696.73sec, total: 51816696.74sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_89000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 103343103.79sec, total: 103343103.80sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 51671551.90sec, total: 51671551.90sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 51671551.90sec, total: 51671551.90sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.86ms, accelerator: 0us, total: 90.86ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 155014655.69sec, total: 155014655.69sec
train.py:442:<module>, cpu: 4.59ms, accelerator: 51671551.93sec, total: 51671551.93sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 51671551.92sec, total: 51671551.92sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 51671551.92sec, total: 51671551.92sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 51671551.92sec, total: 51671551.92sec
  train.py:359:image_losses, cpu: 553us, accelerator: 7.59ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 541us, accelerator: 7.59ms, total: 8.14ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.52ms, total: 4.71ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.09ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.20ms, total: 1.34ms
  train.py:357:image_losses, cpu: 479us, accelerator: 540us, total: 1.02ms
    train.py:322:loss_fn, cpu: 462us, accelerator: 540us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 51671551.92sec, total: 51671551.93sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_89250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 103054435.91sec, total: 103054435.91sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 51527217.96sec, total: 51527217.96sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 51527217.95sec, total: 51527217.96sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.84ms, accelerator: 0us, total: 90.84ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 154581653.85sec, total: 154581653.86sec
train.py:442:<module>, cpu: 4.58ms, accelerator: 51527217.98sec, total: 51527217.99sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 51527217.97sec, total: 51527217.98sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 51527217.97sec, total: 51527217.98sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 51527217.97sec, total: 51527217.98sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.59ms, total: 8.16ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.59ms, total: 8.14ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.52ms, total: 4.72ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.87ms, total: 2.09ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.19ms, total: 1.33ms
  train.py:357:image_losses, cpu: 478us, accelerator: 540us, total: 1.02ms
    train.py:322:loss_fn, cpu: 461us, accelerator: 540us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 51527217.98sec, total: 51527217.99sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_89500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 102767376.20sec, total: 102767376.20sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 51383688.10sec, total: 51383688.11sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 51383688.10sec, total: 51383688.10sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.83ms, accelerator: 0us, total: 90.83ms
train.py:441:<module> (gradient), cpu: 5.38ms, accelerator: 154151064.29sec, total: 154151064.29sec
train.py:442:<module>, cpu: 4.58ms, accelerator: 51383688.13sec, total: 51383688.13sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 51383688.12sec, total: 51383688.12sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 51383688.12sec, total: 51383688.12sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 51383688.12sec, total: 51383688.12sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.59ms, total: 8.15ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.59ms, total: 8.14ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.53ms, total: 4.72ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.09ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.19ms, total: 1.33ms
  train.py:357:image_losses, cpu: 477us, accelerator: 540us, total: 1.02ms
    train.py:322:loss_fn, cpu: 460us, accelerator: 540us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 51383688.13sec, total: 51383688.13sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2005.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_89750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 102481911.26sec, total: 102481911.26sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 51240955.64sec, total: 51240955.64sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 51240955.63sec, total: 51240955.63sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.80ms, accelerator: 0us, total: 90.80ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 153722866.89sec, total: 153722866.89sec
train.py:442:<module>, cpu: 4.58ms, accelerator: 51240955.66sec, total: 51240955.67sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 51240955.65sec, total: 51240955.66sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 51240955.65sec, total: 51240955.66sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 51240955.65sec, total: 51240955.66sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.51ms, total: 4.71ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.87ms, total: 2.09ms
      train.py:344:hfe, cpu: 138us, accelerator: 1.19ms, total: 1.33ms
  train.py:357:image_losses, cpu: 476us, accelerator: 539us, total: 1.02ms
    train.py:322:loss_fn, cpu: 459us, accelerator: 539us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 51240955.66sec, total: 51240955.66sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_90000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 102198027.85sec, total: 102198027.85sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 51099013.93sec, total: 51099013.93sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 51099013.93sec, total: 51099013.93sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.77ms, accelerator: 0us, total: 90.77ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 153297041.77sec, total: 153297041.78sec
train.py:442:<module>, cpu: 4.58ms, accelerator: 51099013.96sec, total: 51099013.96sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 51099013.95sec, total: 51099013.95sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 51099013.95sec, total: 51099013.95sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 51099013.95sec, total: 51099013.95sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.52ms, total: 4.71ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.87ms, total: 2.08ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.18ms, total: 1.32ms
  train.py:357:image_losses, cpu: 475us, accelerator: 539us, total: 1.02ms
    train.py:322:loss_fn, cpu: 458us, accelerator: 539us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 51099013.95sec, total: 51099013.96sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_90250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 101915712.86sec, total: 101915712.86sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 50957856.43sec, total: 50957856.44sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 50957856.43sec, total: 50957856.43sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.76ms, accelerator: 0us, total: 90.76ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 152873569.28sec, total: 152873569.29sec
train.py:442:<module>, cpu: 4.58ms, accelerator: 50957856.46sec, total: 50957856.46sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 50957856.45sec, total: 50957856.45sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 50957856.45sec, total: 50957856.45sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 50957856.45sec, total: 50957856.45sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.52ms, total: 4.71ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.87ms, total: 2.08ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.18ms, total: 1.32ms
  train.py:357:image_losses, cpu: 474us, accelerator: 539us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 50957856.46sec, total: 50957856.46sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_90500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 101634953.32sec, total: 101634953.32sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 50817476.66sec, total: 50817476.67sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 50817476.66sec, total: 50817476.66sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.73ms, accelerator: 0us, total: 90.73ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 152452429.97sec, total: 152452429.98sec
train.py:442:<module>, cpu: 4.58ms, accelerator: 50817476.69sec, total: 50817476.69sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 50817476.68sec, total: 50817476.68sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 50817476.68sec, total: 50817476.68sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 50817476.68sec, total: 50817476.68sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.53ms, total: 4.72ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.86ms, total: 2.08ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.18ms, total: 1.32ms
  train.py:357:image_losses, cpu: 473us, accelerator: 539us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 50817476.69sec, total: 50817476.69sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_90750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 101355736.41sec, total: 101355736.42sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 50677868.21sec, total: 50677868.21sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 50677868.21sec, total: 50677868.21sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.72ms, accelerator: 0us, total: 90.72ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 152033604.61sec, total: 152033604.62sec
train.py:442:<module>, cpu: 4.57ms, accelerator: 50677868.24sec, total: 50677868.24sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 50677868.23sec, total: 50677868.23sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 50677868.23sec, total: 50677868.23sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 50677868.23sec, total: 50677868.23sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.53ms, total: 4.72ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.86ms, total: 2.08ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.18ms, total: 1.32ms
  train.py:357:image_losses, cpu: 472us, accelerator: 538us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 50677868.23sec, total: 50677868.24sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_91000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 101078049.47sec, total: 101078049.47sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 50539024.74sec, total: 50539024.74sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 50539024.73sec, total: 50539024.74sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.70ms, accelerator: 0us, total: 90.70ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 151617074.19sec, total: 151617074.20sec
train.py:442:<module>, cpu: 4.57ms, accelerator: 50539024.76sec, total: 50539024.77sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 50539024.75sec, total: 50539024.76sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 50539024.75sec, total: 50539024.76sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 50539024.75sec, total: 50539024.76sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.54ms, total: 4.73ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.86ms, total: 2.08ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.17ms, total: 1.31ms
  train.py:357:image_losses, cpu: 471us, accelerator: 538us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 50539024.76sec, total: 50539024.76sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_91250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 100801879.93sec, total: 100801879.93sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 50400939.97sec, total: 50400939.97sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 50400939.97sec, total: 50400939.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.68ms, accelerator: 0us, total: 90.68ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 151202819.89sec, total: 151202819.90sec
train.py:442:<module>, cpu: 4.57ms, accelerator: 50400940.00sec, total: 50400940.00sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 50400939.99sec, total: 50400939.99sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 50400939.99sec, total: 50400939.99sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 50400939.99sec, total: 50400939.99sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.54ms, total: 4.73ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.86ms, total: 2.08ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.17ms, total: 1.31ms
  train.py:357:image_losses, cpu: 470us, accelerator: 537us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 50400939.99sec, total: 50400940.00sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_91500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 100527215.41sec, total: 100527215.41sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 50263607.71sec, total: 50263607.71sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 50263607.71sec, total: 50263607.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.65ms, accelerator: 0us, total: 90.65ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 150790823.11sec, total: 150790823.11sec
train.py:442:<module>, cpu: 4.57ms, accelerator: 50263607.73sec, total: 50263607.74sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 50263607.73sec, total: 50263607.73sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 50263607.73sec, total: 50263607.73sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 50263607.73sec, total: 50263607.73sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.54ms, total: 4.74ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.86ms, total: 2.08ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.17ms, total: 1.31ms
  train.py:357:image_losses, cpu: 469us, accelerator: 537us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 50263607.73sec, total: 50263607.74sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_91750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 100254043.63sec, total: 100254043.63sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 50127021.82sec, total: 50127021.82sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 50127021.81sec, total: 50127021.82sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.65ms, accelerator: 0us, total: 90.65ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 150381065.43sec, total: 150381065.44sec
train.py:442:<module>, cpu: 4.57ms, accelerator: 50127021.84sec, total: 50127021.85sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 50127021.84sec, total: 50127021.84sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 50127021.84sec, total: 50127021.84sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 50127021.83sec, total: 50127021.84sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.55ms, total: 4.74ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.86ms, total: 2.07ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.17ms, total: 1.30ms
  train.py:357:image_losses, cpu: 469us, accelerator: 536us, total: 1.01ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 50127021.84sec, total: 50127021.85sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_92000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 99982352.45sec, total: 99982352.45sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 49991176.23sec, total: 49991176.23sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 49991176.23sec, total: 49991176.23sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.62ms, accelerator: 0us, total: 90.62ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 149973528.67sec, total: 149973528.68sec
train.py:442:<module>, cpu: 4.57ms, accelerator: 49991176.26sec, total: 49991176.26sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 49991176.25sec, total: 49991176.25sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 49991176.25sec, total: 49991176.25sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 49991176.25sec, total: 49991176.25sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.55ms, total: 4.75ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.85ms, total: 2.07ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.16ms, total: 1.30ms
  train.py:357:image_losses, cpu: 468us, accelerator: 536us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 49991176.25sec, total: 49991176.26sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_92250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 99712129.88sec, total: 99712129.88sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 49856064.94sec, total: 49856064.95sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 49856064.94sec, total: 49856064.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.60ms, accelerator: 0us, total: 90.60ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 149568194.81sec, total: 149568194.82sec
train.py:442:<module>, cpu: 4.57ms, accelerator: 49856064.97sec, total: 49856064.97sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 49856064.96sec, total: 49856064.96sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 49856064.96sec, total: 49856064.96sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 49856064.96sec, total: 49856064.96sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.55ms, total: 4.75ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.85ms, total: 2.07ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.16ms, total: 1.30ms
  train.py:357:image_losses, cpu: 467us, accelerator: 536us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 49856064.97sec, total: 49856064.97sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_92500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 99443364.03sec, total: 99443364.03sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 49721682.02sec, total: 49721682.02sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 49721682.02sec, total: 49721682.02sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.59ms, accelerator: 0us, total: 90.59ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 149165046.04sec, total: 149165046.04sec
train.py:442:<module>, cpu: 4.57ms, accelerator: 49721682.04sec, total: 49721682.05sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 49721682.04sec, total: 49721682.04sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 49721682.04sec, total: 49721682.04sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 49721682.04sec, total: 49721682.04sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.12ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.11ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.56ms, total: 4.75ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.85ms, total: 2.07ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.16ms, total: 1.29ms
  train.py:357:image_losses, cpu: 466us, accelerator: 536us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 49721682.04sec, total: 49721682.05sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_92750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 99176043.16sec, total: 99176043.16sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 49588021.58sec, total: 49588021.59sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 49588021.58sec, total: 49588021.58sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.58ms, accelerator: 0us, total: 90.58ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 148764064.73sec, total: 148764064.74sec
train.py:442:<module>, cpu: 4.56ms, accelerator: 49588021.61sec, total: 49588021.61sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 49588021.60sec, total: 49588021.60sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 49588021.60sec, total: 49588021.60sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 49588021.60sec, total: 49588021.60sec
  train.py:359:image_losses, cpu: 552us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 540us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 189us, accelerator: 4.56ms, total: 4.76ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.85ms, total: 2.07ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.15ms, total: 1.29ms
  train.py:357:image_losses, cpu: 465us, accelerator: 535us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 49588021.61sec, total: 49588021.61sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_93000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 98910155.64sec, total: 98910155.64sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 49455077.83sec, total: 49455077.83sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 49455077.82sec, total: 49455077.82sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.56ms, accelerator: 0us, total: 90.56ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 148365233.46sec, total: 148365233.46sec
train.py:442:<module>, cpu: 4.56ms, accelerator: 49455077.85sec, total: 49455077.86sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 49455077.84sec, total: 49455077.85sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 49455077.84sec, total: 49455077.85sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 49455077.84sec, total: 49455077.85sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.57ms, total: 8.11ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.57ms, total: 4.76ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.85ms, total: 2.06ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.15ms, total: 1.29ms
  train.py:357:image_losses, cpu: 464us, accelerator: 534us, total: 1.00ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 49455077.85sec, total: 49455077.85sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_93250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 98645689.99sec, total: 98645689.99sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 49322845.00sec, total: 49322845.00sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 49322844.99sec, total: 49322845.00sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.54ms, accelerator: 0us, total: 90.54ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 147968534.97sec, total: 147968534.98sec
train.py:442:<module>, cpu: 4.56ms, accelerator: 49322845.02sec, total: 49322845.03sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 49322845.01sec, total: 49322845.02sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 49322845.01sec, total: 49322845.02sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 49322845.01sec, total: 49322845.02sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.57ms, total: 8.13ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.57ms, total: 8.12ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.57ms, total: 4.76ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.85ms, total: 2.07ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.15ms, total: 1.29ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 49322845.02sec, total: 49322845.03sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_93500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 98382634.81sec, total: 98382634.81sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 49191317.41sec, total: 49191317.41sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 49191317.41sec, total: 49191317.41sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.52ms, accelerator: 0us, total: 90.52ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 147573952.21sec, total: 147573952.22sec
train.py:442:<module>, cpu: 4.56ms, accelerator: 49191317.44sec, total: 49191317.44sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 49191317.43sec, total: 49191317.43sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 49191317.43sec, total: 49191317.43sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 49191317.43sec, total: 49191317.43sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.62ms, total: 8.18ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.62ms, total: 8.17ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.56ms, total: 4.75ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.10ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.18ms, total: 1.32ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 49191317.43sec, total: 49191317.44sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_93750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 98120978.87sec, total: 98120978.87sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 49060489.44sec, total: 49060489.44sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 49060489.44sec, total: 49060489.44sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.50ms, accelerator: 0us, total: 90.50ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 147181468.30sec, total: 147181468.30sec
train.py:442:<module>, cpu: 4.56ms, accelerator: 49060489.46sec, total: 49060489.47sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 49060489.46sec, total: 49060489.46sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 49060489.46sec, total: 49060489.46sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 49060489.46sec, total: 49060489.46sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.62ms, total: 8.18ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.62ms, total: 8.17ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.57ms, total: 4.76ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.09ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.18ms, total: 1.32ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 49060489.46sec, total: 49060489.47sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_94000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 97860711.02sec, total: 97860711.02sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 48930355.52sec, total: 48930355.52sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 48930355.51sec, total: 48930355.51sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.50ms, accelerator: 0us, total: 90.50ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 146791066.52sec, total: 146791066.53sec
train.py:442:<module>, cpu: 4.56ms, accelerator: 48930355.54sec, total: 48930355.55sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 48930355.53sec, total: 48930355.54sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 48930355.53sec, total: 48930355.54sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 48930355.53sec, total: 48930355.54sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.67ms, total: 8.23ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.67ms, total: 8.22ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.55ms, total: 4.75ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.91ms, total: 2.12ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.21ms, total: 1.35ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 48930355.54sec, total: 48930355.54sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_94250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 97601820.25sec, total: 97601820.25sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 48800910.13sec, total: 48800910.13sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 48800910.13sec, total: 48800910.13sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.47ms, accelerator: 0us, total: 90.47ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 146402730.37sec, total: 146402730.38sec
train.py:442:<module>, cpu: 4.55ms, accelerator: 48800910.16sec, total: 48800910.16sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 48800910.15sec, total: 48800910.15sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 48800910.15sec, total: 48800910.15sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 48800910.15sec, total: 48800910.15sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.65ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.65ms, total: 8.20ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.54ms, total: 4.73ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.12ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.21ms, total: 1.35ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 48800910.15sec, total: 48800910.16sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_94500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 97344295.66sec, total: 97344295.66sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 48672147.84sec, total: 48672147.84sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 48672147.83sec, total: 48672147.83sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.44ms, accelerator: 0us, total: 90.44ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 146016443.48sec, total: 146016443.49sec
train.py:442:<module>, cpu: 4.55ms, accelerator: 48672147.86sec, total: 48672147.86sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 48672147.85sec, total: 48672147.85sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 48672147.85sec, total: 48672147.85sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 48672147.85sec, total: 48672147.85sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.65ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.65ms, total: 8.20ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.54ms, total: 4.74ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.11ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.21ms, total: 1.34ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 48672147.86sec, total: 48672147.86sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_94750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 97088126.46sec, total: 97088126.46sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 48544063.24sec, total: 48544063.24sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 48544063.23sec, total: 48544063.23sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.41ms, accelerator: 0us, total: 90.41ms
train.py:441:<module> (gradient), cpu: 5.41ms, accelerator: 145632189.68sec, total: 145632189.69sec
train.py:442:<module>, cpu: 4.55ms, accelerator: 48544063.26sec, total: 48544063.27sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 48544063.25sec, total: 48544063.26sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 48544063.25sec, total: 48544063.26sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 48544063.25sec, total: 48544063.26sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.65ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.65ms, total: 8.20ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.55ms, total: 4.74ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.90ms, total: 2.11ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.20ms, total: 1.34ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 48544063.26sec, total: 48544063.26sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_95000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 96833301.98sec, total: 96833301.98sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 48416651.00sec, total: 48416651.00sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 48416650.99sec, total: 48416650.99sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.38ms, accelerator: 0us, total: 90.38ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 145249952.97sec, total: 145249952.97sec
train.py:442:<module>, cpu: 4.55ms, accelerator: 48416651.02sec, total: 48416651.03sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 48416651.01sec, total: 48416651.02sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 48416651.01sec, total: 48416651.02sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 48416651.01sec, total: 48416651.02sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.64ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.64ms, total: 8.20ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.55ms, total: 4.75ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.11ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.20ms, total: 1.34ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 48416651.02sec, total: 48416651.02sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_95250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 96579811.66sec, total: 96579811.66sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 48289905.84sec, total: 48289905.84sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 48289905.83sec, total: 48289905.83sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.37ms, accelerator: 0us, total: 90.37ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 144869717.49sec, total: 144869717.49sec
train.py:442:<module>, cpu: 4.55ms, accelerator: 48289905.86sec, total: 48289905.87sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 48289905.85sec, total: 48289905.86sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 48289905.85sec, total: 48289905.86sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 48289905.85sec, total: 48289905.86sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.65ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.65ms, total: 8.20ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.56ms, total: 4.75ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.11ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.20ms, total: 1.34ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 48289905.86sec, total: 48289905.86sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_95500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 96327645.05sec, total: 96327645.05sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 48163822.53sec, total: 48163822.53sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 48163822.53sec, total: 48163822.53sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.38ms, accelerator: 0us, total: 90.38ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 144491467.57sec, total: 144491467.58sec
train.py:442:<module>, cpu: 4.55ms, accelerator: 48163822.56sec, total: 48163822.56sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 48163822.55sec, total: 48163822.55sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 48163822.55sec, total: 48163822.55sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 48163822.55sec, total: 48163822.55sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.65ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.65ms, total: 8.19ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.56ms, total: 4.75ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.11ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.19ms, total: 1.33ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 48163822.55sec, total: 48163822.56sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_95750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 96076791.81sec, total: 96076791.81sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 48038395.91sec, total: 48038395.91sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 48038395.91sec, total: 48038395.91sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.37ms, accelerator: 0us, total: 90.37ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 144115187.71sec, total: 144115187.71sec
train.py:442:<module>, cpu: 4.55ms, accelerator: 48038395.94sec, total: 48038395.94sec
  train.py:360:image_losses, cpu: 3.39ms, accelerator: 48038395.93sec, total: 48038395.93sec
    train.py:322:loss_fn, cpu: 3.37ms, accelerator: 48038395.93sec, total: 48038395.93sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 48038395.93sec, total: 48038395.93sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.64ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.64ms, total: 8.20ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.56ms, total: 4.76ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.11ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.19ms, total: 1.33ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 48038395.93sec, total: 48038395.94sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_96000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 95827241.70sec, total: 95827241.70sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 47913620.86sec, total: 47913620.86sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 47913620.85sec, total: 47913620.85sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.36ms, accelerator: 0us, total: 90.36ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 143740862.55sec, total: 143740862.55sec
train.py:442:<module>, cpu: 4.54ms, accelerator: 47913620.88sec, total: 47913620.89sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 47913620.87sec, total: 47913620.88sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 47913620.87sec, total: 47913620.88sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 47913620.87sec, total: 47913620.88sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.64ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.64ms, total: 8.20ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.57ms, total: 4.76ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.11ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.19ms, total: 1.33ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 47913620.88sec, total: 47913620.88sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_96250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 95578984.60sec, total: 95578984.60sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 47789492.30sec, total: 47789492.31sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 47789492.30sec, total: 47789492.30sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.34ms, accelerator: 0us, total: 90.34ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 143368476.89sec, total: 143368476.90sec
train.py:442:<module>, cpu: 4.54ms, accelerator: 47789492.33sec, total: 47789492.33sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 47789492.32sec, total: 47789492.32sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 47789492.32sec, total: 47789492.32sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 47789492.32sec, total: 47789492.32sec
  train.py:359:image_losses, cpu: 551us, accelerator: 7.64ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 539us, accelerator: 7.64ms, total: 8.20ms
      train.py:343:hfe, cpu: 188us, accelerator: 4.57ms, total: 4.76ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.10ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.19ms, total: 1.33ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 47789492.33sec, total: 47789492.33sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_96500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 95332010.48sec, total: 95332010.48sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 47666005.24sec, total: 47666005.25sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 47666005.24sec, total: 47666005.24sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.32ms, accelerator: 0us, total: 90.32ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 142998015.71sec, total: 142998015.72sec
train.py:442:<module>, cpu: 4.54ms, accelerator: 47666005.27sec, total: 47666005.27sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 47666005.26sec, total: 47666005.26sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 47666005.26sec, total: 47666005.26sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 47666005.26sec, total: 47666005.26sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.64ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.64ms, total: 8.20ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.58ms, total: 4.77ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.10ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.18ms, total: 1.32ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 47666005.27sec, total: 47666005.27sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_96750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 95086309.42sec, total: 95086309.42sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 47543154.72sec, total: 47543154.72sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.31ms, accelerator: 47543154.71sec, total: 47543154.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.31ms, accelerator: 0us, total: 90.31ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 142629464.12sec, total: 142629464.13sec
train.py:442:<module>, cpu: 4.54ms, accelerator: 47543154.74sec, total: 47543154.75sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 47543154.73sec, total: 47543154.74sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 47543154.73sec, total: 47543154.74sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 47543154.73sec, total: 47543154.74sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.64ms, total: 8.21ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.64ms, total: 8.19ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.58ms, total: 4.77ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.10ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.18ms, total: 1.32ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 47543154.74sec, total: 47543154.74sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_97000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 94841871.61sec, total: 94841871.61sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 47420935.81sec, total: 47420935.81sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 47420935.80sec, total: 47420935.81sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.29ms, accelerator: 0us, total: 90.29ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 142262807.40sec, total: 142262807.41sec
train.py:442:<module>, cpu: 4.54ms, accelerator: 47420935.83sec, total: 47420935.84sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 47420935.83sec, total: 47420935.83sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 47420935.83sec, total: 47420935.83sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 47420935.83sec, total: 47420935.83sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.64ms, total: 8.20ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.64ms, total: 8.19ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.58ms, total: 4.78ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.89ms, total: 2.10ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.18ms, total: 1.32ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 47420935.83sec, total: 47420935.84sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_97250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 94598687.32sec, total: 94598687.32sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 47299343.67sec, total: 47299343.67sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 47299343.66sec, total: 47299343.66sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.28ms, accelerator: 0us, total: 90.28ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 141898030.97sec, total: 141898030.98sec
train.py:442:<module>, cpu: 4.54ms, accelerator: 47299343.69sec, total: 47299343.70sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 47299343.68sec, total: 47299343.69sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 47299343.68sec, total: 47299343.69sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 47299343.68sec, total: 47299343.69sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.64ms, total: 8.20ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.64ms, total: 8.19ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.59ms, total: 4.78ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.10ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.17ms, total: 1.31ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 47299343.69sec, total: 47299343.69sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_97500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 94356746.94sec, total: 94356746.95sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 47178373.48sec, total: 47178373.48sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 47178373.47sec, total: 47178373.47sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.26ms, accelerator: 0us, total: 90.26ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 141535120.41sec, total: 141535120.41sec
train.py:442:<module>, cpu: 4.54ms, accelerator: 47178373.50sec, total: 47178373.51sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 47178373.49sec, total: 47178373.50sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 47178373.49sec, total: 47178373.50sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 47178373.49sec, total: 47178373.50sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.64ms, total: 8.20ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.64ms, total: 8.19ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.59ms, total: 4.78ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.10ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.17ms, total: 1.31ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 47178373.50sec, total: 47178373.50sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_97750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 94116040.96sec, total: 94116040.96sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 47058020.48sec, total: 47058020.49sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 47058020.48sec, total: 47058020.48sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.24ms, accelerator: 0us, total: 90.24ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 141174061.43sec, total: 141174061.43sec
train.py:442:<module>, cpu: 4.54ms, accelerator: 47058020.51sec, total: 47058020.51sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 47058020.50sec, total: 47058020.50sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 47058020.50sec, total: 47058020.50sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 47058020.50sec, total: 47058020.50sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.64ms, total: 8.20ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.64ms, total: 8.19ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.59ms, total: 4.79ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.10ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.17ms, total: 1.31ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 47058020.51sec, total: 47058020.51sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_98000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 93876559.94sec, total: 93876559.94sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 46938279.97sec, total: 46938279.98sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 46938279.97sec, total: 46938279.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.22ms, accelerator: 0us, total: 90.22ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 140814839.90sec, total: 140814839.90sec
train.py:442:<module>, cpu: 4.53ms, accelerator: 46938280.00sec, total: 46938280.00sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 46938279.99sec, total: 46938279.99sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 46938279.99sec, total: 46938279.99sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 46938279.99sec, total: 46938279.99sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.64ms, total: 8.20ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.64ms, total: 8.19ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.60ms, total: 4.79ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.10ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.17ms, total: 1.30ms
train.py:436:<module> (gradient), cpu: 5.25ms, accelerator: 46938280.00sec, total: 46938280.00sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_98250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 93638294.56sec, total: 93638294.56sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 46819147.28sec, total: 46819147.29sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 46819147.28sec, total: 46819147.28sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.20ms, accelerator: 0us, total: 90.20ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 140457441.83sec, total: 140457441.83sec
train.py:442:<module>, cpu: 4.53ms, accelerator: 46819147.31sec, total: 46819147.31sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 46819147.30sec, total: 46819147.30sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 46819147.30sec, total: 46819147.30sec
      train.py:349:msssim, cpu: 3.22ms, accelerator: 46819147.30sec, total: 46819147.30sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.64ms, total: 8.20ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.64ms, total: 8.19ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.60ms, total: 4.79ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.88ms, total: 2.09ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.16ms, total: 1.30ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 46819147.31sec, total: 46819147.31sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_98500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 93401235.58sec, total: 93401235.58sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 46700617.80sec, total: 46700617.80sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 46700617.79sec, total: 46700617.79sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.19ms, accelerator: 0us, total: 90.19ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 140101853.37sec, total: 140101853.37sec
train.py:442:<module>, cpu: 4.53ms, accelerator: 46700617.82sec, total: 46700617.83sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 46700617.81sec, total: 46700617.82sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 46700617.81sec, total: 46700617.82sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 46700617.81sec, total: 46700617.82sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.64ms, total: 8.20ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.64ms, total: 8.19ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.61ms, total: 4.80ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.87ms, total: 2.09ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.16ms, total: 1.30ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 46700617.82sec, total: 46700617.82sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_98750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 93165373.88sec, total: 93165373.88sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 46582686.94sec, total: 46582686.95sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 46582686.94sec, total: 46582686.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.16ms, accelerator: 0us, total: 90.16ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 139748060.81sec, total: 139748060.81sec
train.py:442:<module>, cpu: 4.53ms, accelerator: 46582686.97sec, total: 46582686.97sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 46582686.96sec, total: 46582686.96sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 46582686.96sec, total: 46582686.96sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 46582686.96sec, total: 46582686.96sec
  train.py:359:image_losses, cpu: 549us, accelerator: 7.62ms, total: 8.18ms
    train.py:322:loss_fn, cpu: 537us, accelerator: 7.62ms, total: 8.17ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.59ms, total: 4.79ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.87ms, total: 2.09ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.16ms, total: 1.30ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 46582686.97sec, total: 46582686.97sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_99000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 92930700.39sec, total: 92930700.39sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 46465350.20sec, total: 46465350.20sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 46465350.20sec, total: 46465350.20sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.14ms, accelerator: 0us, total: 90.14ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 139396050.58sec, total: 139396050.59sec
train.py:442:<module>, cpu: 4.53ms, accelerator: 46465350.23sec, total: 46465350.23sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 46465350.22sec, total: 46465350.22sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 46465350.22sec, total: 46465350.22sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 46465350.22sec, total: 46465350.22sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.62ms, total: 8.18ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.62ms, total: 8.17ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.60ms, total: 4.79ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.87ms, total: 2.09ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.15ms, total: 1.29ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 46465350.22sec, total: 46465350.23sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_99250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 92697206.17sec, total: 92697206.17sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 46348603.09sec, total: 46348603.09sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 46348603.09sec, total: 46348603.09sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.12ms, accelerator: 0us, total: 90.12ms
train.py:441:<module> (gradient), cpu: 5.39ms, accelerator: 139045809.25sec, total: 139045809.25sec
train.py:442:<module>, cpu: 4.53ms, accelerator: 46348603.12sec, total: 46348603.12sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 46348603.11sec, total: 46348603.11sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 46348603.11sec, total: 46348603.11sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 46348603.11sec, total: 46348603.11sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.62ms, total: 8.18ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.62ms, total: 8.17ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.60ms, total: 4.79ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.87ms, total: 2.08ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.15ms, total: 1.29ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 46348603.11sec, total: 46348603.12sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_99500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 92464882.34sec, total: 92464882.35sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 46232441.18sec, total: 46232441.18sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 46232441.17sec, total: 46232441.17sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.10ms, accelerator: 0us, total: 90.10ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 138697323.51sec, total: 138697323.51sec
train.py:442:<module>, cpu: 4.52ms, accelerator: 46232441.20sec, total: 46232441.21sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 46232441.19sec, total: 46232441.20sec
    train.py:322:loss_fn, cpu: 3.35ms, accelerator: 46232441.19sec, total: 46232441.20sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 46232441.19sec, total: 46232441.20sec
  train.py:359:image_losses, cpu: 550us, accelerator: 7.62ms, total: 8.18ms
    train.py:322:loss_fn, cpu: 538us, accelerator: 7.62ms, total: 8.17ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.61ms, total: 4.80ms
      train.py:342:hfe, cpu: 214us, accelerator: 1.87ms, total: 2.08ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.15ms, total: 1.29ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 46232441.20sec, total: 46232441.20sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 1992.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9-22_oceans/timelines/t.json_99750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2D, cpu: 1.59ms, accelerator: 92233720.14sec, total: 92233720.14sec (33.33%)
top 2 operation type: Mul, cpu: 2.06ms, accelerator: 46116860.08sec, total: 46116860.08sec (16.67%)
top 3 operation type: BiasAddGrad, cpu: 1.30ms, accelerator: 46116860.07sec, total: 46116860.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 90.10ms, accelerator: 0us, total: 90.10ms
train.py:441:<module> (gradient), cpu: 5.40ms, accelerator: 138350580.20sec, total: 138350580.21sec
train.py:442:<module>, cpu: 4.52ms, accelerator: 46116860.10sec, total: 46116860.10sec
  train.py:360:image_losses, cpu: 3.38ms, accelerator: 46116860.09sec, total: 46116860.09sec
    train.py:322:loss_fn, cpu: 3.36ms, accelerator: 46116860.09sec, total: 46116860.09sec
      train.py:349:msssim, cpu: 3.21ms, accelerator: 46116860.09sec, total: 46116860.09sec
  train.py:359:image_losses, cpu: 549us, accelerator: 7.62ms, total: 8.18ms
    train.py:322:loss_fn, cpu: 537us, accelerator: 7.62ms, total: 8.17ms
      train.py:343:hfe, cpu: 187us, accelerator: 4.61ms, total: 4.80ms
      train.py:342:hfe, cpu: 213us, accelerator: 1.86ms, total: 2.08ms
      train.py:344:hfe, cpu: 137us, accelerator: 1.15ms, total: 1.29ms
train.py:436:<module> (gradient), cpu: 5.24ms, accelerator: 46116860.10sec, total: 46116860.10sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
