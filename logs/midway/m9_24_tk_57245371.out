/software/openmpi-3.1.2-el7-x86_64/bin/mpirun
/software/Anaconda3-5.3.0-el7-x86_64/bin/python
/software/cuda-9.0-el7-x86_64/bin/nvcc
Parsing Inputs...
Parsing Inputs...
Parsing Inputs...
Parsing Inputs...
midway2-gpu05:32118:32185 [0] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:32118:32185 [0] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu05:32118:32185 [0] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu05:32118:32185 [0] INFO Using internal Network IB
midway2-gpu05:32118:32185 [0] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu05:32118:32185 [0] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:32118:32185 [0] INFO NET/Socket : 1 interfaces found
NCCL version 2.2.13+cuda9.0
midway2-gpu05:32120:32183 [2] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:32120:32183 [2] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu05:32119:32184 [1] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:32119:32184 [1] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu05:32121:32186 [3] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:32121:32186 [3] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu05:32120:32183 [2] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu05:32120:32183 [2] INFO Using internal Network IB
midway2-gpu05:32120:32183 [2] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu05:32121:32186 [3] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu05:32121:32186 [3] INFO Using internal Network IB
midway2-gpu05:32121:32186 [3] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu05:32119:32184 [1] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu05:32119:32184 [1] INFO Using internal Network IB
midway2-gpu05:32119:32184 [1] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu05:32118:32185 [0] INFO comm 0x7f6d34880f00 rank 0 nranks 4
midway2-gpu05:32118:32185 [0] INFO CUDA Dev 0, IB Ports : mlx5_0/1(SOC) 
midway2-gpu05:32121:32186 [3] INFO comm 0x7f4c84871aa0 rank 3 nranks 4
midway2-gpu05:32121:32186 [3] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:32121:32186 [3] INFO NET/Socket : 1 interfaces found
midway2-gpu05:32121:32186 [3] INFO CUDA Dev 3, IB Ports : mlx5_0/1(PHB) 
midway2-gpu05:32119:32184 [1] INFO comm 0x7f27f4871b50 rank 1 nranks 4
midway2-gpu05:32119:32184 [1] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:32120:32183 [2] INFO comm 0x7f9044871c20 rank 2 nranks 4
midway2-gpu05:32119:32184 [1] INFO NET/Socket : 1 interfaces found
midway2-gpu05:32120:32183 [2] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:32120:32183 [2] INFO NET/Socket : 1 interfaces found
midway2-gpu05:32119:32184 [1] INFO CUDA Dev 1, IB Ports : mlx5_0/1(SOC) 
midway2-gpu05:32120:32183 [2] INFO CUDA Dev 2, IB Ports : mlx5_0/1(PHB) 
midway2-gpu05:32118:32185 [0] INFO Using 128 threads
midway2-gpu05:32118:32185 [0] INFO Min Comp Cap 3
midway2-gpu05:32118:32185 [0] INFO NCCL_SINGLE_RING_THRESHOLD=131072
midway2-gpu05:32118:32185 [0] INFO Ring 00 :    0   1   2   3
midway2-gpu05:32118:32185 [0] INFO Ring 01 :    0   1   2   3
midway2-gpu05:32121:32186 [3] INFO 3[32121] -> 0[32118] via direct shared memory
midway2-gpu05:32119:32184 [1] INFO 1[32119] -> 2[32120] via direct shared memory
midway2-gpu05:32118:32185 [0] INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC
midway2-gpu05:32120:32183 [2] INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC
midway2-gpu05:32118:32185 [0] INFO Ring 01 : 0[0] -> 1[1] via P2P/IPC
midway2-gpu05:32121:32186 [3] INFO 3[32121] -> 0[32118] via direct shared memory
midway2-gpu05:32120:32183 [2] INFO Ring 01 : 2[2] -> 3[3] via P2P/IPC
midway2-gpu05:32119:32184 [1] INFO 1[32119] -> 2[32120] via direct shared memory
midway2-gpu05:32118:32185 [0] INFO Launch mode Parallel
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_0.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 9.16sec, accelerator: 0us, total: 9.16sec (92.72%)
top 2 operation type: ImageSummary, cpu: 197.33ms, accelerator: 0us, total: 197.33ms (2.00%)
top 3 operation type: HistogramSummary, cpu: 137.14ms, accelerator: 0us, total: 137.14ms (1.39%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 110.84ms, accelerator: 0us, total: 110.84ms
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:511:<module>, cpu: 9.17sec, accelerator: 12.62ms, total: 9.18sec
  __init__.py:194:compute_gradients, cpu: 9.17sec, accelerator: 309us, total: 9.17sec
    __init__.py:83:allreduce, cpu: 9.16sec, accelerator: 0us, total: 9.16sec
    __init__.py:86:allreduce, cpu: 6.89ms, accelerator: 309us, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 1.69ms, accelerator: 12.31ms, total: 14.00ms
train.py:447:<module>, cpu: 110.85ms, accelerator: 0us, total: 110.85ms
train.py:515:<module>, cpu: 86.90ms, accelerator: 0us, total: 86.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.77
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.54sec, accelerator: 0us, total: 8.54sec (92.79%)
top 2 operation type: ImageSummary, cpu: 200.75ms, accelerator: 0us, total: 200.75ms (2.18%)
top 3 operation type: HistogramSummary, cpu: 112.53ms, accelerator: 0us, total: 112.53ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 92.88ms, accelerator: 0us, total: 92.88ms
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:511:<module>, cpu: 8.55sec, accelerator: 25.07ms, total: 8.57sec
  __init__.py:194:compute_gradients, cpu: 8.54sec, accelerator: 6.49ms, total: 8.55sec
    __init__.py:83:allreduce, cpu: 8.54sec, accelerator: 0us, total: 8.54sec
    __init__.py:86:allreduce, cpu: 5.51ms, accelerator: 6.49ms, total: 12.01ms
  __init__.py:185:compute_gradients, cpu: 4.51ms, accelerator: 18.58ms, total: 23.11ms
train.py:447:<module>, cpu: 92.88ms, accelerator: 0us, total: 92.88ms
train.py:515:<module>, cpu: 81.09ms, accelerator: 0us, total: 81.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.74sec, accelerator: 0us, total: 8.74sec (92.93%)
top 2 operation type: ImageSummary, cpu: 227.90ms, accelerator: 0us, total: 227.90ms (2.42%)
top 3 operation type: HistogramSummary, cpu: 112.75ms, accelerator: 0us, total: 112.75ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 96.84ms, accelerator: 0us, total: 96.84ms
top 3 graph node: original, cpu: 81.74ms, accelerator: 0us, total: 81.74ms
train.py:511:<module>, cpu: 8.75sec, accelerator: 27.27ms, total: 8.78sec
  __init__.py:194:compute_gradients, cpu: 8.74sec, accelerator: 13.09ms, total: 8.76sec
    __init__.py:83:allreduce, cpu: 8.74sec, accelerator: 0us, total: 8.74sec
    __init__.py:86:allreduce, cpu: 4.37ms, accelerator: 13.09ms, total: 17.48ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 14.18ms, total: 17.97ms
train.py:448:<module>, cpu: 96.85ms, accelerator: 0us, total: 96.85ms
train.py:515:<module>, cpu: 85.95ms, accelerator: 0us, total: 85.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2135.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.79sec, accelerator: 0us, total: 8.79sec (93.64%)
top 2 operation type: ImageSummary, cpu: 224.96ms, accelerator: 0us, total: 224.96ms (2.40%)
top 3 operation type: HistogramSummary, cpu: 112.64ms, accelerator: 0us, total: 112.64ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 88.46ms, accelerator: 0us, total: 88.46ms
top 3 graph node: original, cpu: 81.53ms, accelerator: 0us, total: 81.53ms
train.py:511:<module>, cpu: 8.80sec, accelerator: 20.96ms, total: 8.83sec
  __init__.py:194:compute_gradients, cpu: 8.80sec, accelerator: 10.07ms, total: 8.81sec
    __init__.py:83:allreduce, cpu: 8.79sec, accelerator: 0us, total: 8.79sec
    __init__.py:86:allreduce, cpu: 6.27ms, accelerator: 10.07ms, total: 16.37ms
  __init__.py:185:compute_gradients, cpu: 3.39ms, accelerator: 10.88ms, total: 14.30ms
train.py:448:<module>, cpu: 88.47ms, accelerator: 0us, total: 88.47ms
train.py:515:<module>, cpu: 86.76ms, accelerator: 0us, total: 86.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2122.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_1000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.92sec, accelerator: 0us, total: 8.92sec (93.79%)
top 2 operation type: ImageSummary, cpu: 249.59ms, accelerator: 0us, total: 249.59ms (2.62%)
top 3 operation type: HistogramSummary, cpu: 103.06ms, accelerator: 0us, total: 103.06ms (1.08%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 101.87ms, accelerator: 0us, total: 101.87ms
top 3 graph node: original, cpu: 78.12ms, accelerator: 0us, total: 78.12ms
train.py:511:<module>, cpu: 8.94sec, accelerator: 16.91ms, total: 8.95sec
  __init__.py:194:compute_gradients, cpu: 8.93sec, accelerator: 8.12ms, total: 8.94sec
    __init__.py:83:allreduce, cpu: 8.92sec, accelerator: 0us, total: 8.92sec
    __init__.py:86:allreduce, cpu: 8.50ms, accelerator: 8.12ms, total: 16.64ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 8.80ms, total: 12.63ms
train.py:448:<module>, cpu: 101.87ms, accelerator: 0us, total: 101.87ms
train.py:515:<module>, cpu: 79.85ms, accelerator: 0us, total: 79.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_1250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.95sec, accelerator: 0us, total: 8.95sec (93.52%)
top 2 operation type: ImageSummary, cpu: 297.23ms, accelerator: 0us, total: 297.23ms (3.10%)
top 3 operation type: HistogramSummary, cpu: 113.76ms, accelerator: 0us, total: 113.76ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 114.02ms, accelerator: 0us, total: 114.02ms
top 3 graph node: original, cpu: 99.20ms, accelerator: 0us, total: 99.20ms
train.py:511:<module>, cpu: 8.97sec, accelerator: 14.21ms, total: 8.98sec
  __init__.py:194:compute_gradients, cpu: 8.96sec, accelerator: 6.81ms, total: 8.97sec
    __init__.py:83:allreduce, cpu: 8.95sec, accelerator: 0us, total: 8.95sec
    __init__.py:86:allreduce, cpu: 8.69ms, accelerator: 6.81ms, total: 15.53ms
  __init__.py:185:compute_gradients, cpu: 3.82ms, accelerator: 7.40ms, total: 11.25ms
train.py:448:<module>, cpu: 114.03ms, accelerator: 0us, total: 114.03ms
train.py:447:<module>, cpu: 99.20ms, accelerator: 0us, total: 99.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2135.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_1500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.84sec, accelerator: 0us, total: 8.84sec (92.97%)
top 2 operation type: ImageSummary, cpu: 343.54ms, accelerator: 0us, total: 343.54ms (3.61%)
top 3 operation type: HistogramSummary, cpu: 130.02ms, accelerator: 0us, total: 130.02ms (1.37%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 125.61ms, accelerator: 0us, total: 125.61ms
top 3 graph node: original, cpu: 121.14ms, accelerator: 0us, total: 121.14ms
train.py:511:<module>, cpu: 8.85sec, accelerator: 16.64ms, total: 8.87sec
  __init__.py:194:compute_gradients, cpu: 8.85sec, accelerator: 10.23ms, total: 8.86sec
    __init__.py:83:allreduce, cpu: 8.84sec, accelerator: 0us, total: 8.84sec
    __init__.py:86:allreduce, cpu: 8.30ms, accelerator: 10.23ms, total: 18.55ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 6.41ms, total: 10.06ms
train.py:448:<module>, cpu: 125.61ms, accelerator: 0us, total: 125.61ms
train.py:447:<module>, cpu: 121.15ms, accelerator: 0us, total: 121.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_1750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.64sec, accelerator: 0us, total: 8.64sec (93.05%)
top 2 operation type: ImageSummary, cpu: 344.07ms, accelerator: 0us, total: 344.07ms (3.71%)
top 3 operation type: HistogramSummary, cpu: 121.88ms, accelerator: 0us, total: 121.88ms (1.31%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 127.88ms, accelerator: 0us, total: 127.88ms
top 3 graph node: original, cpu: 113.88ms, accelerator: 0us, total: 113.88ms
train.py:511:<module>, cpu: 8.65sec, accelerator: 14.67ms, total: 8.66sec
  __init__.py:194:compute_gradients, cpu: 8.64sec, accelerator: 8.99ms, total: 8.65sec
    __init__.py:83:allreduce, cpu: 8.64sec, accelerator: 0us, total: 8.64sec
    __init__.py:86:allreduce, cpu: 7.77ms, accelerator: 8.99ms, total: 16.78ms
  __init__.py:185:compute_gradients, cpu: 3.41ms, accelerator: 5.68ms, total: 9.13ms
train.py:448:<module>, cpu: 127.89ms, accelerator: 0us, total: 127.89ms
train.py:447:<module>, cpu: 113.88ms, accelerator: 0us, total: 113.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_2000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.48sec, accelerator: 0us, total: 8.48sec (93.11%)
top 2 operation type: ImageSummary, cpu: 341.34ms, accelerator: 0us, total: 341.34ms (3.75%)
top 3 operation type: HistogramSummary, cpu: 120.91ms, accelerator: 0us, total: 120.91ms (1.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 125.71ms, accelerator: 0us, total: 125.71ms
top 3 graph node: original, cpu: 109.91ms, accelerator: 0us, total: 109.91ms
train.py:511:<module>, cpu: 8.49sec, accelerator: 13.13ms, total: 8.50sec
  __init__.py:194:compute_gradients, cpu: 8.49sec, accelerator: 8.02ms, total: 8.50sec
    __init__.py:83:allreduce, cpu: 8.48sec, accelerator: 0us, total: 8.48sec
    __init__.py:86:allreduce, cpu: 7.06ms, accelerator: 8.02ms, total: 15.11ms
  __init__.py:185:compute_gradients, cpu: 3.23ms, accelerator: 5.11ms, total: 8.38ms
train.py:448:<module>, cpu: 125.71ms, accelerator: 0us, total: 125.71ms
train.py:447:<module>, cpu: 109.91ms, accelerator: 0us, total: 109.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_2250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.41sec, accelerator: 0us, total: 8.41sec (93.14%)
top 2 operation type: ImageSummary, cpu: 343.31ms, accelerator: 0us, total: 343.31ms (3.80%)
top 3 operation type: HistogramSummary, cpu: 116.68ms, accelerator: 0us, total: 116.68ms (1.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 131.05ms, accelerator: 0us, total: 131.05ms
top 3 graph node: difference, cpu: 107.01ms, accelerator: 0us, total: 107.01ms
train.py:511:<module>, cpu: 8.42sec, accelerator: 13.41ms, total: 8.43sec
  __init__.py:194:compute_gradients, cpu: 8.41sec, accelerator: 8.73ms, total: 8.42sec
    __init__.py:83:allreduce, cpu: 8.41sec, accelerator: 0us, total: 8.41sec
    __init__.py:86:allreduce, cpu: 6.55ms, accelerator: 8.73ms, total: 15.31ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 4.67ms, total: 8.43ms
train.py:448:<module>, cpu: 131.06ms, accelerator: 0us, total: 131.06ms
train.py:449:<module>, cpu: 107.07ms, accelerator: 19us, total: 107.09ms
  summary.py:146:image, cpu: 107.02ms, accelerator: 0us, total: 107.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_2500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.42sec, accelerator: 0us, total: 8.42sec (93.36%)
top 2 operation type: ImageSummary, cpu: 336.52ms, accelerator: 0us, total: 336.52ms (3.73%)
top 3 operation type: HistogramSummary, cpu: 111.51ms, accelerator: 0us, total: 111.51ms (1.24%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 130.96ms, accelerator: 0us, total: 130.96ms
top 3 graph node: difference, cpu: 104.78ms, accelerator: 0us, total: 104.78ms
train.py:511:<module>, cpu: 8.43sec, accelerator: 12.26ms, total: 8.44sec
  __init__.py:194:compute_gradients, cpu: 8.42sec, accelerator: 7.97ms, total: 8.43sec
    __init__.py:83:allreduce, cpu: 8.42sec, accelerator: 0us, total: 8.42sec
    __init__.py:86:allreduce, cpu: 6.78ms, accelerator: 7.97ms, total: 14.76ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 4.29ms, total: 7.93ms
train.py:448:<module>, cpu: 130.96ms, accelerator: 0us, total: 130.96ms
train.py:449:<module>, cpu: 104.84ms, accelerator: 17us, total: 104.86ms
  summary.py:146:image, cpu: 104.79ms, accelerator: 0us, total: 104.79ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_2750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.36sec, accelerator: 0us, total: 8.36sec (93.44%)
top 2 operation type: ImageSummary, cpu: 331.20ms, accelerator: 0us, total: 331.20ms (3.70%)
top 3 operation type: HistogramSummary, cpu: 112.44ms, accelerator: 0us, total: 112.44ms (1.26%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 128.20ms, accelerator: 0us, total: 128.20ms
top 3 graph node: difference, cpu: 103.33ms, accelerator: 0us, total: 103.33ms
train.py:511:<module>, cpu: 8.37sec, accelerator: 11.28ms, total: 8.38sec
  __init__.py:194:compute_gradients, cpu: 8.36sec, accelerator: 7.32ms, total: 8.37sec
    __init__.py:83:allreduce, cpu: 8.36sec, accelerator: 0us, total: 8.36sec
    __init__.py:86:allreduce, cpu: 6.41ms, accelerator: 7.32ms, total: 13.75ms
  __init__.py:185:compute_gradients, cpu: 3.45ms, accelerator: 3.96ms, total: 7.45ms
train.py:448:<module>, cpu: 128.21ms, accelerator: 0us, total: 128.21ms
train.py:449:<module>, cpu: 103.38ms, accelerator: 17us, total: 103.40ms
  summary.py:146:image, cpu: 103.33ms, accelerator: 0us, total: 103.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_3000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.35sec, accelerator: 0us, total: 8.35sec (93.54%)
top 2 operation type: ImageSummary, cpu: 329.00ms, accelerator: 0us, total: 329.00ms (3.69%)
top 3 operation type: HistogramSummary, cpu: 109.71ms, accelerator: 0us, total: 109.71ms (1.23%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 127.88ms, accelerator: 0us, total: 127.88ms
top 3 graph node: difference, cpu: 104.16ms, accelerator: 0us, total: 104.16ms
train.py:511:<module>, cpu: 8.36sec, accelerator: 10.48ms, total: 8.37sec
  __init__.py:194:compute_gradients, cpu: 8.36sec, accelerator: 6.79ms, total: 8.36sec
    __init__.py:83:allreduce, cpu: 8.35sec, accelerator: 0us, total: 8.35sec
    __init__.py:86:allreduce, cpu: 6.12ms, accelerator: 6.79ms, total: 12.93ms
  __init__.py:185:compute_gradients, cpu: 3.33ms, accelerator: 3.69ms, total: 7.06ms
train.py:448:<module>, cpu: 127.88ms, accelerator: 0us, total: 127.88ms
train.py:449:<module>, cpu: 104.21ms, accelerator: 17us, total: 104.22ms
  summary.py:146:image, cpu: 104.16ms, accelerator: 0us, total: 104.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_3250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.27sec, accelerator: 0us, total: 8.27sec (93.53%)
top 2 operation type: ImageSummary, cpu: 329.53ms, accelerator: 0us, total: 329.53ms (3.72%)
top 3 operation type: HistogramSummary, cpu: 108.86ms, accelerator: 0us, total: 108.86ms (1.23%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 128.85ms, accelerator: 0us, total: 128.85ms
top 3 graph node: difference, cpu: 104.91ms, accelerator: 0us, total: 104.91ms
train.py:511:<module>, cpu: 8.28sec, accelerator: 9.81ms, total: 8.29sec
  __init__.py:194:compute_gradients, cpu: 8.28sec, accelerator: 6.33ms, total: 8.29sec
    __init__.py:83:allreduce, cpu: 8.27sec, accelerator: 0us, total: 8.27sec
    __init__.py:86:allreduce, cpu: 5.87ms, accelerator: 6.33ms, total: 12.22ms
  __init__.py:185:compute_gradients, cpu: 3.31ms, accelerator: 3.47ms, total: 6.83ms
train.py:448:<module>, cpu: 128.86ms, accelerator: 0us, total: 128.86ms
train.py:449:<module>, cpu: 104.96ms, accelerator: 17us, total: 104.98ms
  summary.py:146:image, cpu: 104.92ms, accelerator: 0us, total: 104.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_3500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.25sec, accelerator: 0us, total: 8.25sec (93.52%)
top 2 operation type: ImageSummary, cpu: 334.13ms, accelerator: 0us, total: 334.13ms (3.79%)
top 3 operation type: HistogramSummary, cpu: 105.26ms, accelerator: 0us, total: 105.26ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 129.42ms, accelerator: 0us, total: 129.42ms
top 3 graph node: difference, cpu: 105.31ms, accelerator: 0us, total: 105.31ms
train.py:511:<module>, cpu: 8.26sec, accelerator: 12.09ms, total: 8.28sec
  __init__.py:194:compute_gradients, cpu: 8.26sec, accelerator: 5.93ms, total: 8.27sec
    __init__.py:83:allreduce, cpu: 8.25sec, accelerator: 0us, total: 8.25sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 5.93ms, total: 11.60ms
  __init__.py:185:compute_gradients, cpu: 3.20ms, accelerator: 6.16ms, total: 9.41ms
train.py:448:<module>, cpu: 129.42ms, accelerator: 0us, total: 129.42ms
train.py:449:<module>, cpu: 105.36ms, accelerator: 16us, total: 105.37ms
  summary.py:146:image, cpu: 105.31ms, accelerator: 0us, total: 105.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_3750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec (93.58%)
top 2 operation type: ImageSummary, cpu: 336.20ms, accelerator: 0us, total: 336.20ms (3.80%)
top 3 operation type: HistogramSummary, cpu: 102.66ms, accelerator: 0us, total: 102.66ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 130.00ms, accelerator: 0us, total: 130.00ms
top 3 graph node: difference, cpu: 105.15ms, accelerator: 0us, total: 105.15ms
train.py:511:<module>, cpu: 8.29sec, accelerator: 12.10ms, total: 8.30sec
  __init__.py:194:compute_gradients, cpu: 8.29sec, accelerator: 5.57ms, total: 8.29sec
    __init__.py:83:allreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec
    __init__.py:86:allreduce, cpu: 5.85ms, accelerator: 5.57ms, total: 11.45ms
  __init__.py:185:compute_gradients, cpu: 3.12ms, accelerator: 6.53ms, total: 9.69ms
train.py:448:<module>, cpu: 130.01ms, accelerator: 0us, total: 130.01ms
train.py:449:<module>, cpu: 105.19ms, accelerator: 15us, total: 105.21ms
  summary.py:146:image, cpu: 105.15ms, accelerator: 0us, total: 105.15ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_4000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.30sec, accelerator: 0us, total: 8.30sec (93.59%)
top 2 operation type: ImageSummary, cpu: 333.58ms, accelerator: 0us, total: 333.58ms (3.76%)
top 3 operation type: HistogramSummary, cpu: 104.46ms, accelerator: 0us, total: 104.46ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 129.84ms, accelerator: 0us, total: 129.84ms
top 3 graph node: difference, cpu: 103.93ms, accelerator: 0us, total: 103.93ms
train.py:511:<module>, cpu: 8.31sec, accelerator: 11.43ms, total: 8.32sec
  __init__.py:194:compute_gradients, cpu: 8.31sec, accelerator: 5.26ms, total: 8.31sec
    __init__.py:83:allreduce, cpu: 8.30sec, accelerator: 0us, total: 8.30sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 5.26ms, total: 10.87ms
  __init__.py:185:compute_gradients, cpu: 3.16ms, accelerator: 6.17ms, total: 9.37ms
train.py:448:<module>, cpu: 129.84ms, accelerator: 0us, total: 129.84ms
train.py:449:<module>, cpu: 103.97ms, accelerator: 15us, total: 103.99ms
  summary.py:146:image, cpu: 103.93ms, accelerator: 0us, total: 103.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_4250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.40sec, accelerator: 0us, total: 8.40sec (93.63%)
top 2 operation type: ImageSummary, cpu: 340.00ms, accelerator: 0us, total: 340.00ms (3.79%)
top 3 operation type: HistogramSummary, cpu: 103.47ms, accelerator: 0us, total: 103.47ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 132.37ms, accelerator: 0us, total: 132.37ms
top 3 graph node: difference, cpu: 105.65ms, accelerator: 0us, total: 105.65ms
train.py:511:<module>, cpu: 8.41sec, accelerator: 10.84ms, total: 8.42sec
  __init__.py:194:compute_gradients, cpu: 8.41sec, accelerator: 4.98ms, total: 8.41sec
    __init__.py:83:allreduce, cpu: 8.40sec, accelerator: 0us, total: 8.40sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 4.98ms, total: 10.42ms
  __init__.py:185:compute_gradients, cpu: 3.08ms, accelerator: 5.86ms, total: 8.99ms
train.py:448:<module>, cpu: 132.38ms, accelerator: 0us, total: 132.38ms
train.py:449:<module>, cpu: 105.69ms, accelerator: 14us, total: 105.70ms
  summary.py:146:image, cpu: 105.65ms, accelerator: 0us, total: 105.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_4500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.42sec, accelerator: 0us, total: 8.42sec (93.65%)
top 2 operation type: ImageSummary, cpu: 342.49ms, accelerator: 0us, total: 342.49ms (3.81%)
top 3 operation type: HistogramSummary, cpu: 103.01ms, accelerator: 0us, total: 103.01ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 134.34ms, accelerator: 0us, total: 134.34ms
top 3 graph node: difference, cpu: 107.74ms, accelerator: 0us, total: 107.74ms
train.py:511:<module>, cpu: 8.43sec, accelerator: 10.33ms, total: 8.44sec
  __init__.py:194:compute_gradients, cpu: 8.43sec, accelerator: 4.74ms, total: 8.43sec
    __init__.py:83:allreduce, cpu: 8.42sec, accelerator: 0us, total: 8.42sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 4.74ms, total: 10.01ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.59ms, total: 9.22ms
train.py:448:<module>, cpu: 134.34ms, accelerator: 0us, total: 134.34ms
train.py:449:<module>, cpu: 107.79ms, accelerator: 14us, total: 107.80ms
  summary.py:146:image, cpu: 107.74ms, accelerator: 0us, total: 107.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_4750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.51sec, accelerator: 0us, total: 8.51sec (93.73%)
top 2 operation type: ImageSummary, cpu: 341.76ms, accelerator: 0us, total: 341.76ms (3.77%)
top 3 operation type: HistogramSummary, cpu: 102.71ms, accelerator: 0us, total: 102.71ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 133.04ms, accelerator: 0us, total: 133.04ms
top 3 graph node: difference, cpu: 108.01ms, accelerator: 0us, total: 108.01ms
train.py:511:<module>, cpu: 8.52sec, accelerator: 9.89ms, total: 8.53sec
  __init__.py:194:compute_gradients, cpu: 8.51sec, accelerator: 4.56ms, total: 8.52sec
    __init__.py:83:allreduce, cpu: 8.51sec, accelerator: 0us, total: 8.51sec
    __init__.py:86:allreduce, cpu: 5.13ms, accelerator: 4.56ms, total: 9.72ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 5.33ms, total: 9.12ms
train.py:448:<module>, cpu: 133.04ms, accelerator: 0us, total: 133.04ms
train.py:449:<module>, cpu: 108.06ms, accelerator: 13us, total: 108.07ms
  summary.py:146:image, cpu: 108.01ms, accelerator: 0us, total: 108.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_5000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.45sec, accelerator: 0us, total: 8.45sec (93.69%)
top 2 operation type: ImageSummary, cpu: 340.89ms, accelerator: 0us, total: 340.89ms (3.78%)
top 3 operation type: HistogramSummary, cpu: 106.75ms, accelerator: 0us, total: 106.75ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 132.88ms, accelerator: 0us, total: 132.88ms
top 3 graph node: difference, cpu: 105.68ms, accelerator: 0us, total: 105.68ms
train.py:511:<module>, cpu: 8.46sec, accelerator: 9.46ms, total: 8.47sec
  __init__.py:194:compute_gradients, cpu: 8.45sec, accelerator: 4.36ms, total: 8.46sec
    __init__.py:83:allreduce, cpu: 8.45sec, accelerator: 0us, total: 8.45sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 4.36ms, total: 9.38ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 5.10ms, total: 8.79ms
train.py:448:<module>, cpu: 132.88ms, accelerator: 0us, total: 132.88ms
train.py:449:<module>, cpu: 105.73ms, accelerator: 13us, total: 105.74ms
  summary.py:146:image, cpu: 105.69ms, accelerator: 0us, total: 105.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_5250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.50sec, accelerator: 0us, total: 8.50sec (93.77%)
top 2 operation type: ImageSummary, cpu: 339.40ms, accelerator: 0us, total: 339.40ms (3.75%)
top 3 operation type: HistogramSummary, cpu: 106.94ms, accelerator: 0us, total: 106.94ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 132.51ms, accelerator: 0us, total: 132.51ms
top 3 graph node: difference, cpu: 106.60ms, accelerator: 0us, total: 106.60ms
train.py:511:<module>, cpu: 8.51sec, accelerator: 9.06ms, total: 8.51sec
  __init__.py:194:compute_gradients, cpu: 8.50sec, accelerator: 4.17ms, total: 8.51sec
    __init__.py:83:allreduce, cpu: 8.50sec, accelerator: 0us, total: 8.50sec
    __init__.py:86:allreduce, cpu: 5.08ms, accelerator: 4.17ms, total: 9.27ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.89ms, total: 8.49ms
train.py:448:<module>, cpu: 132.52ms, accelerator: 0us, total: 132.52ms
train.py:449:<module>, cpu: 106.65ms, accelerator: 12us, total: 106.66ms
  summary.py:146:image, cpu: 106.60ms, accelerator: 0us, total: 106.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_5500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.48sec, accelerator: 0us, total: 8.48sec (93.69%)
top 2 operation type: ImageSummary, cpu: 345.25ms, accelerator: 0us, total: 345.25ms (3.81%)
top 3 operation type: HistogramSummary, cpu: 106.57ms, accelerator: 0us, total: 106.57ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 134.91ms, accelerator: 0us, total: 134.91ms
top 3 graph node: difference, cpu: 108.80ms, accelerator: 0us, total: 108.80ms
train.py:511:<module>, cpu: 8.49sec, accelerator: 9.94ms, total: 8.50sec
  __init__.py:194:compute_gradients, cpu: 8.49sec, accelerator: 4.43ms, total: 8.49sec
    __init__.py:83:allreduce, cpu: 8.48sec, accelerator: 0us, total: 8.48sec
    __init__.py:86:allreduce, cpu: 4.97ms, accelerator: 4.43ms, total: 9.42ms
  __init__.py:185:compute_gradients, cpu: 3.48ms, accelerator: 5.51ms, total: 9.04ms
train.py:448:<module>, cpu: 134.92ms, accelerator: 0us, total: 134.92ms
train.py:449:<module>, cpu: 108.84ms, accelerator: 35us, total: 108.88ms
  summary.py:146:image, cpu: 108.80ms, accelerator: 0us, total: 108.80ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_5750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.50sec, accelerator: 0us, total: 8.50sec (93.74%)
top 2 operation type: ImageSummary, cpu: 343.28ms, accelerator: 0us, total: 343.28ms (3.79%)
top 3 operation type: HistogramSummary, cpu: 105.61ms, accelerator: 0us, total: 105.61ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 135.62ms, accelerator: 0us, total: 135.62ms
top 3 graph node: difference, cpu: 107.45ms, accelerator: 0us, total: 107.45ms
train.py:511:<module>, cpu: 8.51sec, accelerator: 10.49ms, total: 8.52sec
  __init__.py:194:compute_gradients, cpu: 8.51sec, accelerator: 4.60ms, total: 8.51sec
    __init__.py:83:allreduce, cpu: 8.50sec, accelerator: 0us, total: 8.50sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 4.60ms, total: 9.48ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 5.89ms, total: 9.40ms
train.py:448:<module>, cpu: 135.62ms, accelerator: 0us, total: 135.62ms
train.py:449:<module>, cpu: 107.49ms, accelerator: 34us, total: 107.53ms
  summary.py:146:image, cpu: 107.45ms, accelerator: 0us, total: 107.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_6000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.41sec, accelerator: 0us, total: 8.41sec (93.72%)
top 2 operation type: ImageSummary, cpu: 343.64ms, accelerator: 0us, total: 343.64ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 104.83ms, accelerator: 0us, total: 104.83ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 135.82ms, accelerator: 0us, total: 135.82ms
top 3 graph node: difference, cpu: 106.19ms, accelerator: 0us, total: 106.19ms
train.py:511:<module>, cpu: 8.42sec, accelerator: 10.11ms, total: 8.43sec
  __init__.py:194:compute_gradients, cpu: 8.42sec, accelerator: 4.43ms, total: 8.42sec
    __init__.py:83:allreduce, cpu: 8.41sec, accelerator: 0us, total: 8.41sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 4.43ms, total: 9.40ms
  __init__.py:185:compute_gradients, cpu: 3.39ms, accelerator: 5.68ms, total: 9.11ms
train.py:448:<module>, cpu: 135.82ms, accelerator: 0us, total: 135.82ms
train.py:449:<module>, cpu: 106.24ms, accelerator: 33us, total: 106.27ms
  summary.py:146:image, cpu: 106.20ms, accelerator: 0us, total: 106.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_6250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.37sec, accelerator: 0us, total: 8.37sec (93.71%)
top 2 operation type: ImageSummary, cpu: 344.43ms, accelerator: 0us, total: 344.43ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 104.23ms, accelerator: 0us, total: 104.23ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.27ms, accelerator: 0us, total: 137.27ms
top 3 graph node: difference, cpu: 105.43ms, accelerator: 0us, total: 105.43ms
train.py:511:<module>, cpu: 8.38sec, accelerator: 9.77ms, total: 8.39sec
  __init__.py:194:compute_gradients, cpu: 8.37sec, accelerator: 4.29ms, total: 8.38sec
    __init__.py:83:allreduce, cpu: 8.37sec, accelerator: 0us, total: 8.37sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 4.29ms, total: 9.15ms
  __init__.py:185:compute_gradients, cpu: 3.34ms, accelerator: 5.48ms, total: 8.86ms
train.py:448:<module>, cpu: 137.28ms, accelerator: 0us, total: 137.28ms
train.py:449:<module>, cpu: 105.47ms, accelerator: 32us, total: 105.50ms
  summary.py:146:image, cpu: 105.43ms, accelerator: 0us, total: 105.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_6500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.33sec, accelerator: 0us, total: 8.33sec (93.72%)
top 2 operation type: ImageSummary, cpu: 343.36ms, accelerator: 0us, total: 343.36ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 103.82ms, accelerator: 0us, total: 103.82ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.72ms, accelerator: 0us, total: 137.72ms
top 3 graph node: difference, cpu: 105.22ms, accelerator: 0us, total: 105.22ms
train.py:511:<module>, cpu: 8.34sec, accelerator: 9.44ms, total: 8.35sec
  __init__.py:194:compute_gradients, cpu: 8.33sec, accelerator: 4.15ms, total: 8.34sec
    __init__.py:83:allreduce, cpu: 8.33sec, accelerator: 0us, total: 8.33sec
    __init__.py:86:allreduce, cpu: 4.77ms, accelerator: 4.15ms, total: 8.95ms
  __init__.py:185:compute_gradients, cpu: 3.35ms, accelerator: 5.29ms, total: 8.68ms
train.py:448:<module>, cpu: 137.73ms, accelerator: 0us, total: 137.73ms
train.py:449:<module>, cpu: 105.26ms, accelerator: 31us, total: 105.30ms
  summary.py:146:image, cpu: 105.22ms, accelerator: 0us, total: 105.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_6750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec (93.69%)
top 2 operation type: ImageSummary, cpu: 344.42ms, accelerator: 0us, total: 344.42ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 102.54ms, accelerator: 0us, total: 102.54ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.48ms, accelerator: 0us, total: 138.48ms
top 3 graph node: difference, cpu: 105.42ms, accelerator: 0us, total: 105.42ms
train.py:511:<module>, cpu: 8.29sec, accelerator: 10.29ms, total: 8.30sec
  __init__.py:194:compute_gradients, cpu: 8.28sec, accelerator: 5.16ms, total: 8.29sec
    __init__.py:83:allreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec
    __init__.py:86:allreduce, cpu: 4.67ms, accelerator: 5.16ms, total: 9.85ms
  __init__.py:185:compute_gradients, cpu: 3.29ms, accelerator: 5.14ms, total: 8.47ms
train.py:448:<module>, cpu: 138.49ms, accelerator: 0us, total: 138.49ms
train.py:449:<module>, cpu: 105.46ms, accelerator: 30us, total: 105.49ms
  summary.py:146:image, cpu: 105.42ms, accelerator: 0us, total: 105.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2130.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_7000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.23sec, accelerator: 0us, total: 8.23sec (93.67%)
top 2 operation type: ImageSummary, cpu: 345.19ms, accelerator: 0us, total: 345.19ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 101.94ms, accelerator: 0us, total: 101.94ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.52ms, accelerator: 0us, total: 139.52ms
top 3 graph node: difference, cpu: 105.78ms, accelerator: 0us, total: 105.78ms
train.py:511:<module>, cpu: 8.24sec, accelerator: 9.97ms, total: 8.25sec
  __init__.py:194:compute_gradients, cpu: 8.24sec, accelerator: 4.99ms, total: 8.24sec
    __init__.py:83:allreduce, cpu: 8.23sec, accelerator: 0us, total: 8.23sec
    __init__.py:86:allreduce, cpu: 4.58ms, accelerator: 4.99ms, total: 9.59ms
  __init__.py:185:compute_gradients, cpu: 3.24ms, accelerator: 4.98ms, total: 8.26ms
train.py:448:<module>, cpu: 139.52ms, accelerator: 0us, total: 139.52ms
train.py:449:<module>, cpu: 105.82ms, accelerator: 29us, total: 105.85ms
  summary.py:146:image, cpu: 105.78ms, accelerator: 0us, total: 105.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_7250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.24sec, accelerator: 0us, total: 8.24sec (93.72%)
top 2 operation type: ImageSummary, cpu: 342.95ms, accelerator: 0us, total: 342.95ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 100.78ms, accelerator: 0us, total: 100.78ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.62ms, accelerator: 0us, total: 138.62ms
top 3 graph node: difference, cpu: 104.88ms, accelerator: 0us, total: 104.88ms
train.py:511:<module>, cpu: 8.25sec, accelerator: 9.69ms, total: 8.26sec
  __init__.py:194:compute_gradients, cpu: 8.24sec, accelerator: 4.86ms, total: 8.25sec
    __init__.py:83:allreduce, cpu: 8.24sec, accelerator: 0us, total: 8.24sec
    __init__.py:86:allreduce, cpu: 4.61ms, accelerator: 4.86ms, total: 9.50ms
  __init__.py:185:compute_gradients, cpu: 3.20ms, accelerator: 4.83ms, total: 8.07ms
train.py:448:<module>, cpu: 138.62ms, accelerator: 0us, total: 138.62ms
train.py:449:<module>, cpu: 104.93ms, accelerator: 28us, total: 104.95ms
  summary.py:146:image, cpu: 104.89ms, accelerator: 0us, total: 104.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_7500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec (93.71%)
top 2 operation type: ImageSummary, cpu: 345.14ms, accelerator: 0us, total: 345.14ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 99.95ms, accelerator: 0us, total: 99.95ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.09ms, accelerator: 0us, total: 138.09ms
top 3 graph node: difference, cpu: 106.04ms, accelerator: 0us, total: 106.04ms
train.py:511:<module>, cpu: 8.22sec, accelerator: 9.41ms, total: 8.23sec
  __init__.py:194:compute_gradients, cpu: 8.22sec, accelerator: 4.71ms, total: 8.23sec
    __init__.py:83:allreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec
    __init__.py:86:allreduce, cpu: 4.52ms, accelerator: 4.71ms, total: 9.27ms
  __init__.py:185:compute_gradients, cpu: 3.18ms, accelerator: 4.70ms, total: 7.91ms
train.py:448:<module>, cpu: 138.09ms, accelerator: 0us, total: 138.09ms
train.py:449:<module>, cpu: 106.08ms, accelerator: 27us, total: 106.11ms
  summary.py:146:image, cpu: 106.04ms, accelerator: 0us, total: 106.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_7750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec (93.73%)
top 2 operation type: ImageSummary, cpu: 344.13ms, accelerator: 0us, total: 344.13ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 99.16ms, accelerator: 0us, total: 99.16ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.78ms, accelerator: 0us, total: 138.78ms
top 3 graph node: difference, cpu: 105.42ms, accelerator: 0us, total: 105.42ms
train.py:511:<module>, cpu: 8.22sec, accelerator: 9.20ms, total: 8.23sec
  __init__.py:194:compute_gradients, cpu: 8.22sec, accelerator: 4.58ms, total: 8.23sec
    __init__.py:83:allreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec
    __init__.py:86:allreduce, cpu: 5.10ms, accelerator: 4.58ms, total: 9.71ms
  __init__.py:185:compute_gradients, cpu: 3.13ms, accelerator: 4.63ms, total: 7.80ms
train.py:448:<module>, cpu: 138.79ms, accelerator: 0us, total: 138.79ms
train.py:449:<module>, cpu: 105.46ms, accelerator: 27us, total: 105.49ms
  summary.py:146:image, cpu: 105.42ms, accelerator: 0us, total: 105.42ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_8000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.19sec, accelerator: 0us, total: 8.19sec (93.71%)
top 2 operation type: ImageSummary, cpu: 344.83ms, accelerator: 0us, total: 344.83ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 99.04ms, accelerator: 0us, total: 99.04ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.41ms, accelerator: 0us, total: 139.41ms
top 3 graph node: difference, cpu: 106.11ms, accelerator: 0us, total: 106.11ms
train.py:511:<module>, cpu: 8.20sec, accelerator: 8.95ms, total: 8.21sec
  __init__.py:194:compute_gradients, cpu: 8.19sec, accelerator: 4.45ms, total: 8.20sec
    __init__.py:83:allreduce, cpu: 8.19sec, accelerator: 0us, total: 8.19sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 4.45ms, total: 9.75ms
  __init__.py:185:compute_gradients, cpu: 3.10ms, accelerator: 4.50ms, total: 7.64ms
train.py:448:<module>, cpu: 139.41ms, accelerator: 0us, total: 139.41ms
train.py:449:<module>, cpu: 106.16ms, accelerator: 26us, total: 106.18ms
  summary.py:146:image, cpu: 106.12ms, accelerator: 0us, total: 106.12ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_8250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec (93.71%)
top 2 operation type: ImageSummary, cpu: 346.06ms, accelerator: 0us, total: 346.06ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 97.78ms, accelerator: 0us, total: 97.78ms (1.11%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.83ms, accelerator: 0us, total: 139.83ms
top 3 graph node: difference, cpu: 105.94ms, accelerator: 0us, total: 105.94ms
train.py:511:<module>, cpu: 8.23sec, accelerator: 8.92ms, total: 8.24sec
  __init__.py:194:compute_gradients, cpu: 8.23sec, accelerator: 4.32ms, total: 8.23sec
    __init__.py:83:allreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 4.32ms, total: 9.52ms
  __init__.py:185:compute_gradients, cpu: 3.06ms, accelerator: 4.60ms, total: 7.70ms
train.py:448:<module>, cpu: 139.84ms, accelerator: 0us, total: 139.84ms
train.py:449:<module>, cpu: 105.98ms, accelerator: 101us, total: 106.08ms
  summary.py:146:image, cpu: 105.94ms, accelerator: 0us, total: 105.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_8500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.19sec, accelerator: 0us, total: 8.19sec (93.73%)
top 2 operation type: ImageSummary, cpu: 343.79ms, accelerator: 0us, total: 343.79ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 97.05ms, accelerator: 0us, total: 97.05ms (1.11%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.53ms, accelerator: 0us, total: 139.53ms
top 3 graph node: difference, cpu: 105.19ms, accelerator: 0us, total: 105.19ms
train.py:511:<module>, cpu: 8.20sec, accelerator: 8.71ms, total: 8.21sec
  __init__.py:194:compute_gradients, cpu: 8.19sec, accelerator: 4.21ms, total: 8.20sec
    __init__.py:83:allreduce, cpu: 8.19sec, accelerator: 0us, total: 8.19sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 4.21ms, total: 9.41ms
  __init__.py:185:compute_gradients, cpu: 3.20ms, accelerator: 4.50ms, total: 7.75ms
train.py:448:<module>, cpu: 139.54ms, accelerator: 0us, total: 139.54ms
train.py:449:<module>, cpu: 105.23ms, accelerator: 99us, total: 105.33ms
  summary.py:146:image, cpu: 105.19ms, accelerator: 0us, total: 105.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_8750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec (93.75%)
top 2 operation type: ImageSummary, cpu: 343.00ms, accelerator: 0us, total: 343.00ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 98.28ms, accelerator: 0us, total: 98.28ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.54ms, accelerator: 0us, total: 139.54ms
top 3 graph node: difference, cpu: 104.61ms, accelerator: 0us, total: 104.61ms
train.py:511:<module>, cpu: 8.22sec, accelerator: 8.74ms, total: 8.22sec
  __init__.py:194:compute_gradients, cpu: 8.21sec, accelerator: 4.34ms, total: 8.22sec
    __init__.py:83:allreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec
    __init__.py:86:allreduce, cpu: 5.10ms, accelerator: 4.34ms, total: 9.46ms
  __init__.py:185:compute_gradients, cpu: 3.16ms, accelerator: 4.40ms, total: 7.60ms
train.py:448:<module>, cpu: 139.55ms, accelerator: 0us, total: 139.55ms
train.py:449:<module>, cpu: 104.65ms, accelerator: 97us, total: 104.75ms
  summary.py:146:image, cpu: 104.61ms, accelerator: 0us, total: 104.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_9000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.16sec, accelerator: 0us, total: 8.16sec (93.75%)
top 2 operation type: ImageSummary, cpu: 340.64ms, accelerator: 0us, total: 340.64ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 97.61ms, accelerator: 0us, total: 97.61ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.97ms, accelerator: 0us, total: 138.97ms
top 3 graph node: difference, cpu: 103.68ms, accelerator: 0us, total: 103.68ms
train.py:511:<module>, cpu: 8.17sec, accelerator: 9.10ms, total: 8.18sec
  __init__.py:194:compute_gradients, cpu: 8.16sec, accelerator: 4.65ms, total: 8.17sec
    __init__.py:83:allreduce, cpu: 8.16sec, accelerator: 0us, total: 8.16sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 4.65ms, total: 9.68ms
  __init__.py:185:compute_gradients, cpu: 3.12ms, accelerator: 4.45ms, total: 7.61ms
train.py:448:<module>, cpu: 138.98ms, accelerator: 0us, total: 138.98ms
train.py:449:<module>, cpu: 103.72ms, accelerator: 94us, total: 103.81ms
  summary.py:146:image, cpu: 103.68ms, accelerator: 0us, total: 103.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_9250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec (93.74%)
top 2 operation type: ImageSummary, cpu: 339.67ms, accelerator: 0us, total: 339.67ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 98.46ms, accelerator: 0us, total: 98.46ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.15ms, accelerator: 0us, total: 139.15ms
top 3 graph node: difference, cpu: 102.64ms, accelerator: 0us, total: 102.64ms
train.py:511:<module>, cpu: 8.13sec, accelerator: 8.89ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.13sec, accelerator: 4.54ms, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 4.54ms, total: 9.51ms
  __init__.py:185:compute_gradients, cpu: 3.21ms, accelerator: 4.35ms, total: 7.60ms
train.py:448:<module>, cpu: 139.16ms, accelerator: 0us, total: 139.16ms
train.py:449:<module>, cpu: 102.69ms, accelerator: 92us, total: 102.78ms
  summary.py:146:image, cpu: 102.65ms, accelerator: 0us, total: 102.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_9500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.74%)
top 2 operation type: ImageSummary, cpu: 339.42ms, accelerator: 0us, total: 339.42ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 97.95ms, accelerator: 0us, total: 97.95ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.01ms, accelerator: 0us, total: 139.01ms
top 3 graph node: difference, cpu: 102.35ms, accelerator: 0us, total: 102.35ms
train.py:511:<module>, cpu: 8.12sec, accelerator: 9.09ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 4.85ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 4.85ms, total: 9.75ms
  __init__.py:185:compute_gradients, cpu: 3.18ms, accelerator: 4.24ms, total: 7.47ms
train.py:448:<module>, cpu: 139.02ms, accelerator: 0us, total: 139.02ms
train.py:449:<module>, cpu: 102.39ms, accelerator: 90us, total: 102.48ms
  summary.py:146:image, cpu: 102.36ms, accelerator: 0us, total: 102.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_9750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (93.74%)
top 2 operation type: ImageSummary, cpu: 341.05ms, accelerator: 0us, total: 341.05ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 98.10ms, accelerator: 0us, total: 98.10ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.44ms, accelerator: 0us, total: 139.44ms
top 3 graph node: difference, cpu: 102.46ms, accelerator: 0us, total: 102.46ms
train.py:511:<module>, cpu: 8.13sec, accelerator: 8.89ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 4.74ms, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 4.80ms, accelerator: 4.74ms, total: 9.56ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 4.16ms, total: 7.62ms
train.py:448:<module>, cpu: 139.44ms, accelerator: 0us, total: 139.44ms
train.py:449:<module>, cpu: 102.50ms, accelerator: 88us, total: 102.59ms
  summary.py:146:image, cpu: 102.47ms, accelerator: 0us, total: 102.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_10000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.75%)
top 2 operation type: ImageSummary, cpu: 338.94ms, accelerator: 0us, total: 338.94ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 97.72ms, accelerator: 0us, total: 97.72ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.45ms, accelerator: 0us, total: 138.45ms
top 3 graph node: difference, cpu: 102.01ms, accelerator: 0us, total: 102.01ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 8.69ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 4.63ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.74ms, accelerator: 4.63ms, total: 9.39ms
  __init__.py:185:compute_gradients, cpu: 3.41ms, accelerator: 4.06ms, total: 7.52ms
train.py:448:<module>, cpu: 138.46ms, accelerator: 0us, total: 138.46ms
train.py:449:<module>, cpu: 102.05ms, accelerator: 86us, total: 102.13ms
  summary.py:146:image, cpu: 102.01ms, accelerator: 0us, total: 102.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_10250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.76%)
top 2 operation type: ImageSummary, cpu: 339.77ms, accelerator: 0us, total: 339.77ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 97.34ms, accelerator: 0us, total: 97.34ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.29ms, accelerator: 0us, total: 138.29ms
top 3 graph node: difference, cpu: 102.11ms, accelerator: 0us, total: 102.11ms
train.py:511:<module>, cpu: 8.12sec, accelerator: 8.52ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 4.54ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 4.68ms, accelerator: 4.54ms, total: 9.25ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 3.98ms, total: 7.46ms
train.py:448:<module>, cpu: 138.29ms, accelerator: 0us, total: 138.29ms
train.py:449:<module>, cpu: 102.15ms, accelerator: 84us, total: 102.24ms
  summary.py:146:image, cpu: 102.12ms, accelerator: 0us, total: 102.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_10500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.73%)
top 2 operation type: ImageSummary, cpu: 340.39ms, accelerator: 0us, total: 340.39ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 97.11ms, accelerator: 0us, total: 97.11ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.54ms, accelerator: 0us, total: 138.54ms
top 3 graph node: difference, cpu: 102.56ms, accelerator: 0us, total: 102.56ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 8.49ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 4.57ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.64ms, accelerator: 4.57ms, total: 9.22ms
  __init__.py:185:compute_gradients, cpu: 3.40ms, accelerator: 3.93ms, total: 7.37ms
train.py:448:<module>, cpu: 138.55ms, accelerator: 0us, total: 138.55ms
train.py:449:<module>, cpu: 102.60ms, accelerator: 101us, total: 102.70ms
  summary.py:146:image, cpu: 102.56ms, accelerator: 0us, total: 102.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_10750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.76%)
top 2 operation type: ImageSummary, cpu: 339.44ms, accelerator: 0us, total: 339.44ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 96.32ms, accelerator: 0us, total: 96.32ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.95ms, accelerator: 0us, total: 137.95ms
top 3 graph node: difference, cpu: 102.85ms, accelerator: 0us, total: 102.85ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 8.32ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 4.46ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.57ms, accelerator: 4.46ms, total: 9.05ms
  __init__.py:185:compute_gradients, cpu: 3.38ms, accelerator: 3.85ms, total: 7.27ms
train.py:448:<module>, cpu: 137.96ms, accelerator: 0us, total: 137.96ms
train.py:449:<module>, cpu: 102.89ms, accelerator: 99us, total: 102.99ms
  summary.py:146:image, cpu: 102.86ms, accelerator: 0us, total: 102.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_11000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.74%)
top 2 operation type: ImageSummary, cpu: 341.15ms, accelerator: 0us, total: 341.15ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 97.19ms, accelerator: 0us, total: 97.19ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.16ms, accelerator: 0us, total: 139.16ms
top 3 graph node: difference, cpu: 102.51ms, accelerator: 0us, total: 102.51ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 8.15ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 4.37ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.56ms, accelerator: 4.37ms, total: 8.95ms
  __init__.py:185:compute_gradients, cpu: 3.37ms, accelerator: 3.78ms, total: 7.19ms
train.py:448:<module>, cpu: 139.16ms, accelerator: 0us, total: 139.16ms
train.py:449:<module>, cpu: 102.55ms, accelerator: 97us, total: 102.65ms
  summary.py:146:image, cpu: 102.52ms, accelerator: 0us, total: 102.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_11250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.76%)
top 2 operation type: ImageSummary, cpu: 339.91ms, accelerator: 0us, total: 339.91ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 96.91ms, accelerator: 0us, total: 96.91ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.93ms, accelerator: 0us, total: 138.93ms
top 3 graph node: difference, cpu: 102.20ms, accelerator: 0us, total: 102.20ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 8.00ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 4.29ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 4.29ms, total: 9.64ms
  __init__.py:185:compute_gradients, cpu: 3.34ms, accelerator: 3.71ms, total: 7.09ms
train.py:448:<module>, cpu: 138.93ms, accelerator: 0us, total: 138.93ms
train.py:449:<module>, cpu: 102.24ms, accelerator: 95us, total: 102.34ms
  summary.py:146:image, cpu: 102.21ms, accelerator: 0us, total: 102.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_11500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.75%)
top 2 operation type: ImageSummary, cpu: 340.14ms, accelerator: 0us, total: 340.14ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 97.21ms, accelerator: 0us, total: 97.21ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.53ms, accelerator: 0us, total: 138.53ms
top 3 graph node: difference, cpu: 101.69ms, accelerator: 0us, total: 101.69ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 8.44ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 4.80ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 4.80ms, total: 10.07ms
  __init__.py:185:compute_gradients, cpu: 3.31ms, accelerator: 3.65ms, total: 6.99ms
train.py:448:<module>, cpu: 138.53ms, accelerator: 0us, total: 138.53ms
train.py:449:<module>, cpu: 101.73ms, accelerator: 93us, total: 101.83ms
  summary.py:146:image, cpu: 101.70ms, accelerator: 0us, total: 101.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_11750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.72%)
top 2 operation type: ImageSummary, cpu: 342.20ms, accelerator: 0us, total: 342.20ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 97.68ms, accelerator: 0us, total: 97.68ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.79ms, accelerator: 0us, total: 139.79ms
top 3 graph node: difference, cpu: 103.00ms, accelerator: 0us, total: 103.00ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 8.39ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 4.70ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.24ms, accelerator: 4.70ms, total: 9.96ms
  __init__.py:185:compute_gradients, cpu: 3.31ms, accelerator: 3.69ms, total: 7.04ms
train.py:448:<module>, cpu: 139.79ms, accelerator: 0us, total: 139.79ms
train.py:449:<module>, cpu: 103.04ms, accelerator: 92us, total: 103.13ms
  summary.py:146:image, cpu: 103.00ms, accelerator: 0us, total: 103.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_12000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.70%)
top 2 operation type: ImageSummary, cpu: 343.87ms, accelerator: 0us, total: 343.87ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 97.39ms, accelerator: 0us, total: 97.39ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.09ms, accelerator: 0us, total: 140.09ms
top 3 graph node: difference, cpu: 103.76ms, accelerator: 0us, total: 103.76ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 8.24ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 4.61ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.30ms, accelerator: 4.61ms, total: 9.94ms
  __init__.py:185:compute_gradients, cpu: 3.33ms, accelerator: 3.63ms, total: 6.99ms
train.py:448:<module>, cpu: 140.10ms, accelerator: 0us, total: 140.10ms
train.py:449:<module>, cpu: 103.80ms, accelerator: 90us, total: 103.89ms
  summary.py:146:image, cpu: 103.77ms, accelerator: 0us, total: 103.77ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_12250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.73%)
top 2 operation type: ImageSummary, cpu: 343.99ms, accelerator: 0us, total: 343.99ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 97.24ms, accelerator: 0us, total: 97.24ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.64ms, accelerator: 0us, total: 140.64ms
top 3 graph node: difference, cpu: 103.62ms, accelerator: 0us, total: 103.62ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 8.11ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 4.52ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 4.52ms, total: 9.90ms
  __init__.py:185:compute_gradients, cpu: 3.31ms, accelerator: 3.58ms, total: 6.92ms
train.py:448:<module>, cpu: 140.64ms, accelerator: 0us, total: 140.64ms
train.py:449:<module>, cpu: 103.66ms, accelerator: 88us, total: 103.75ms
  summary.py:146:image, cpu: 103.62ms, accelerator: 0us, total: 103.62ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_12500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.75%)
top 2 operation type: ImageSummary, cpu: 343.48ms, accelerator: 0us, total: 343.48ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 97.20ms, accelerator: 0us, total: 97.20ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.50ms, accelerator: 0us, total: 140.50ms
top 3 graph node: difference, cpu: 103.89ms, accelerator: 0us, total: 103.89ms
train.py:511:<module>, cpu: 8.12sec, accelerator: 7.96ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 4.44ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 4.44ms, total: 9.76ms
  __init__.py:185:compute_gradients, cpu: 3.41ms, accelerator: 3.52ms, total: 6.96ms
train.py:448:<module>, cpu: 140.50ms, accelerator: 0us, total: 140.50ms
train.py:449:<module>, cpu: 103.93ms, accelerator: 87us, total: 104.01ms
  summary.py:146:image, cpu: 103.89ms, accelerator: 0us, total: 103.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_12750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.75%)
top 2 operation type: ImageSummary, cpu: 343.00ms, accelerator: 0us, total: 343.00ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 97.25ms, accelerator: 0us, total: 97.25ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.26ms, accelerator: 0us, total: 141.26ms
top 3 graph node: difference, cpu: 103.34ms, accelerator: 0us, total: 103.34ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 7.81ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 4.36ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 4.36ms, total: 9.63ms
  __init__.py:185:compute_gradients, cpu: 3.38ms, accelerator: 3.46ms, total: 6.87ms
train.py:448:<module>, cpu: 141.26ms, accelerator: 0us, total: 141.26ms
train.py:449:<module>, cpu: 103.38ms, accelerator: 85us, total: 103.47ms
  summary.py:146:image, cpu: 103.35ms, accelerator: 0us, total: 103.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2130.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_13000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.74%)
top 2 operation type: ImageSummary, cpu: 341.44ms, accelerator: 0us, total: 341.44ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 98.68ms, accelerator: 0us, total: 98.68ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.40ms, accelerator: 0us, total: 140.40ms
top 3 graph node: difference, cpu: 102.57ms, accelerator: 0us, total: 102.57ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 7.68ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 4.28ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 4.28ms, total: 9.47ms
  __init__.py:185:compute_gradients, cpu: 3.36ms, accelerator: 3.40ms, total: 6.80ms
train.py:448:<module>, cpu: 140.40ms, accelerator: 0us, total: 140.40ms
train.py:449:<module>, cpu: 102.61ms, accelerator: 84us, total: 102.69ms
  summary.py:146:image, cpu: 102.57ms, accelerator: 0us, total: 102.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_13250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.75%)
top 2 operation type: ImageSummary, cpu: 340.15ms, accelerator: 0us, total: 340.15ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 98.73ms, accelerator: 0us, total: 98.73ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.16ms, accelerator: 0us, total: 140.16ms
top 3 graph node: difference, cpu: 102.41ms, accelerator: 0us, total: 102.41ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 7.79ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 4.44ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.10ms, accelerator: 4.44ms, total: 9.57ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 3.35ms, total: 7.00ms
train.py:448:<module>, cpu: 140.17ms, accelerator: 0us, total: 140.17ms
train.py:449:<module>, cpu: 102.45ms, accelerator: 82us, total: 102.53ms
  summary.py:146:image, cpu: 102.41ms, accelerator: 0us, total: 102.41ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_13500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.76%)
top 2 operation type: ImageSummary, cpu: 341.14ms, accelerator: 0us, total: 341.14ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 98.31ms, accelerator: 0us, total: 98.31ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.96ms, accelerator: 0us, total: 140.96ms
top 3 graph node: difference, cpu: 102.93ms, accelerator: 0us, total: 102.93ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 7.73ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 4.37ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.08ms, accelerator: 4.37ms, total: 9.47ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 3.36ms, total: 6.99ms
train.py:448:<module>, cpu: 140.96ms, accelerator: 0us, total: 140.96ms
train.py:449:<module>, cpu: 102.97ms, accelerator: 81us, total: 103.05ms
  summary.py:146:image, cpu: 102.94ms, accelerator: 0us, total: 102.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_13750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.75%)
top 2 operation type: ImageSummary, cpu: 341.23ms, accelerator: 0us, total: 341.23ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 98.56ms, accelerator: 0us, total: 98.56ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.42ms, accelerator: 0us, total: 141.42ms
top 3 graph node: difference, cpu: 102.40ms, accelerator: 0us, total: 102.40ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 7.59ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 4.29ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.02ms, accelerator: 4.29ms, total: 9.34ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 3.30ms, total: 6.90ms
train.py:448:<module>, cpu: 141.42ms, accelerator: 0us, total: 141.42ms
train.py:449:<module>, cpu: 102.44ms, accelerator: 80us, total: 102.52ms
  summary.py:146:image, cpu: 102.40ms, accelerator: 0us, total: 102.40ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_14000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.75%)
top 2 operation type: ImageSummary, cpu: 341.20ms, accelerator: 0us, total: 341.20ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 97.86ms, accelerator: 0us, total: 97.86ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.11ms, accelerator: 0us, total: 141.11ms
top 3 graph node: difference, cpu: 102.75ms, accelerator: 0us, total: 102.75ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 7.62ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 4.22ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 4.22ms, total: 9.40ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 3.40ms, total: 6.96ms
train.py:448:<module>, cpu: 141.12ms, accelerator: 0us, total: 141.12ms
train.py:449:<module>, cpu: 102.79ms, accelerator: 78us, total: 102.87ms
  summary.py:146:image, cpu: 102.76ms, accelerator: 0us, total: 102.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_14250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.74%)
top 2 operation type: ImageSummary, cpu: 341.53ms, accelerator: 0us, total: 341.53ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 98.00ms, accelerator: 0us, total: 98.00ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.31ms, accelerator: 0us, total: 141.31ms
top 3 graph node: difference, cpu: 102.35ms, accelerator: 0us, total: 102.35ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 7.55ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 4.15ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.30ms, accelerator: 4.15ms, total: 9.48ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 3.40ms, total: 6.92ms
train.py:448:<module>, cpu: 141.31ms, accelerator: 0us, total: 141.31ms
train.py:449:<module>, cpu: 102.39ms, accelerator: 77us, total: 102.47ms
  summary.py:146:image, cpu: 102.35ms, accelerator: 0us, total: 102.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_14500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.75%)
top 2 operation type: ImageSummary, cpu: 341.35ms, accelerator: 0us, total: 341.35ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 97.65ms, accelerator: 0us, total: 97.65ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.33ms, accelerator: 0us, total: 141.33ms
top 3 graph node: difference, cpu: 101.93ms, accelerator: 0us, total: 101.93ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 7.43ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 4.09ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 4.09ms, total: 9.55ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 3.35ms, total: 6.85ms
train.py:448:<module>, cpu: 141.34ms, accelerator: 0us, total: 141.34ms
train.py:449:<module>, cpu: 101.97ms, accelerator: 76us, total: 102.05ms
  summary.py:146:image, cpu: 101.93ms, accelerator: 0us, total: 101.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_14750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.73%)
top 2 operation type: ImageSummary, cpu: 340.78ms, accelerator: 0us, total: 340.78ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 98.79ms, accelerator: 0us, total: 98.79ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.65ms, accelerator: 0us, total: 141.65ms
top 3 graph node: difference, cpu: 101.52ms, accelerator: 0us, total: 101.52ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 8.28ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 4.54ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 4.54ms, total: 9.94ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 3.74ms, total: 7.22ms
train.py:448:<module>, cpu: 141.66ms, accelerator: 0us, total: 141.66ms
train.py:449:<module>, cpu: 101.56ms, accelerator: 76us, total: 101.64ms
  summary.py:146:image, cpu: 101.53ms, accelerator: 0us, total: 101.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_15000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.76%)
top 2 operation type: ImageSummary, cpu: 339.18ms, accelerator: 0us, total: 339.18ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 98.46ms, accelerator: 0us, total: 98.46ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.72ms, accelerator: 0us, total: 140.72ms
top 3 graph node: difference, cpu: 100.92ms, accelerator: 0us, total: 100.92ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 8.16ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 4.47ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 4.47ms, total: 9.81ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 3.69ms, total: 7.38ms
train.py:448:<module>, cpu: 140.73ms, accelerator: 0us, total: 140.73ms
train.py:449:<module>, cpu: 100.96ms, accelerator: 74us, total: 101.04ms
  summary.py:146:image, cpu: 100.92ms, accelerator: 0us, total: 100.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_15250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.79%)
top 2 operation type: ImageSummary, cpu: 337.91ms, accelerator: 0us, total: 337.91ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 97.87ms, accelerator: 0us, total: 97.87ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.30ms, accelerator: 0us, total: 140.30ms
top 3 graph node: difference, cpu: 100.81ms, accelerator: 0us, total: 100.81ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 8.04ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 4.40ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.26ms, accelerator: 4.40ms, total: 9.69ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 3.64ms, total: 7.32ms
train.py:448:<module>, cpu: 140.31ms, accelerator: 0us, total: 140.31ms
train.py:449:<module>, cpu: 100.85ms, accelerator: 73us, total: 100.92ms
  summary.py:146:image, cpu: 100.81ms, accelerator: 0us, total: 100.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_15500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (93.81%)
top 2 operation type: ImageSummary, cpu: 338.35ms, accelerator: 0us, total: 338.35ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 99.49ms, accelerator: 0us, total: 99.49ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.23ms, accelerator: 0us, total: 140.23ms
top 3 graph node: difference, cpu: 100.88ms, accelerator: 0us, total: 100.88ms
train.py:511:<module>, cpu: 8.13sec, accelerator: 7.93ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 4.33ms, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 4.33ms, total: 9.59ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 3.59ms, total: 7.23ms
train.py:448:<module>, cpu: 140.24ms, accelerator: 0us, total: 140.24ms
train.py:449:<module>, cpu: 100.92ms, accelerator: 72us, total: 101.00ms
  summary.py:146:image, cpu: 100.89ms, accelerator: 0us, total: 100.89ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_15750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.81%)
top 2 operation type: ImageSummary, cpu: 338.18ms, accelerator: 0us, total: 338.18ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 98.80ms, accelerator: 0us, total: 98.80ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.44ms, accelerator: 0us, total: 140.44ms
top 3 graph node: difference, cpu: 100.95ms, accelerator: 0us, total: 100.95ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 7.82ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 4.28ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 4.28ms, total: 9.50ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 3.54ms, total: 7.17ms
train.py:448:<module>, cpu: 140.45ms, accelerator: 0us, total: 140.45ms
train.py:449:<module>, cpu: 100.99ms, accelerator: 71us, total: 101.06ms
  summary.py:146:image, cpu: 100.96ms, accelerator: 0us, total: 100.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_16000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.80%)
top 2 operation type: ImageSummary, cpu: 338.96ms, accelerator: 0us, total: 338.96ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 98.84ms, accelerator: 0us, total: 98.84ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.13ms, accelerator: 0us, total: 140.13ms
top 3 graph node: difference, cpu: 101.38ms, accelerator: 0us, total: 101.38ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 7.71ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 4.21ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 4.21ms, total: 9.38ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 3.50ms, total: 7.13ms
train.py:448:<module>, cpu: 140.13ms, accelerator: 0us, total: 140.13ms
train.py:449:<module>, cpu: 101.42ms, accelerator: 70us, total: 101.49ms
  summary.py:146:image, cpu: 101.39ms, accelerator: 0us, total: 101.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_16250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.77%)
top 2 operation type: ImageSummary, cpu: 340.50ms, accelerator: 0us, total: 340.50ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 98.39ms, accelerator: 0us, total: 98.39ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.67ms, accelerator: 0us, total: 140.67ms
top 3 graph node: difference, cpu: 101.76ms, accelerator: 0us, total: 101.76ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 7.75ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 4.28ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.10ms, accelerator: 4.28ms, total: 9.41ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 3.47ms, total: 7.07ms
train.py:448:<module>, cpu: 140.67ms, accelerator: 0us, total: 140.67ms
train.py:449:<module>, cpu: 101.80ms, accelerator: 69us, total: 101.87ms
  summary.py:146:image, cpu: 101.77ms, accelerator: 0us, total: 101.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_16500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.81%)
top 2 operation type: ImageSummary, cpu: 339.47ms, accelerator: 0us, total: 339.47ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 98.14ms, accelerator: 0us, total: 98.14ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.14ms, accelerator: 0us, total: 140.14ms
top 3 graph node: difference, cpu: 101.30ms, accelerator: 0us, total: 101.30ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 7.66ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 4.23ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 4.23ms, total: 9.41ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 3.43ms, total: 7.01ms
train.py:448:<module>, cpu: 140.15ms, accelerator: 0us, total: 140.15ms
train.py:449:<module>, cpu: 101.33ms, accelerator: 68us, total: 101.40ms
  summary.py:146:image, cpu: 101.30ms, accelerator: 0us, total: 101.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_16750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.78%)
top 2 operation type: ImageSummary, cpu: 339.30ms, accelerator: 0us, total: 339.30ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 99.80ms, accelerator: 0us, total: 99.80ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.40ms, accelerator: 0us, total: 140.40ms
top 3 graph node: difference, cpu: 100.90ms, accelerator: 0us, total: 100.90ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 7.94ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 4.49ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.10ms, accelerator: 4.49ms, total: 9.62ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 3.46ms, total: 7.02ms
train.py:448:<module>, cpu: 140.40ms, accelerator: 0us, total: 140.40ms
train.py:449:<module>, cpu: 100.94ms, accelerator: 67us, total: 101.01ms
  summary.py:146:image, cpu: 100.91ms, accelerator: 0us, total: 100.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_17000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.78%)
top 2 operation type: ImageSummary, cpu: 338.47ms, accelerator: 0us, total: 338.47ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 99.55ms, accelerator: 0us, total: 99.55ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.89ms, accelerator: 0us, total: 139.89ms
top 3 graph node: difference, cpu: 101.02ms, accelerator: 0us, total: 101.02ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 7.88ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 4.43ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 4.43ms, total: 9.65ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 3.46ms, total: 7.00ms
train.py:448:<module>, cpu: 139.90ms, accelerator: 0us, total: 139.90ms
train.py:449:<module>, cpu: 101.06ms, accelerator: 66us, total: 101.12ms
  summary.py:146:image, cpu: 101.02ms, accelerator: 0us, total: 101.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_17250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.81%)
top 2 operation type: ImageSummary, cpu: 337.61ms, accelerator: 0us, total: 337.61ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 99.12ms, accelerator: 0us, total: 99.12ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.40ms, accelerator: 0us, total: 139.40ms
top 3 graph node: difference, cpu: 101.11ms, accelerator: 0us, total: 101.11ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 7.87ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 4.41ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 4.41ms, total: 9.58ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 3.46ms, total: 6.99ms
train.py:448:<module>, cpu: 139.41ms, accelerator: 0us, total: 139.41ms
train.py:449:<module>, cpu: 101.15ms, accelerator: 65us, total: 101.22ms
  summary.py:146:image, cpu: 101.12ms, accelerator: 0us, total: 101.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_17500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.78%)
top 2 operation type: ImageSummary, cpu: 340.88ms, accelerator: 0us, total: 340.88ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 98.50ms, accelerator: 0us, total: 98.50ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.68ms, accelerator: 0us, total: 140.68ms
top 3 graph node: difference, cpu: 102.12ms, accelerator: 0us, total: 102.12ms
train.py:511:<module>, cpu: 8.12sec, accelerator: 8.04ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 4.35ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 5.10ms, accelerator: 4.35ms, total: 9.47ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 3.69ms, total: 7.23ms
train.py:448:<module>, cpu: 140.68ms, accelerator: 0us, total: 140.68ms
train.py:449:<module>, cpu: 102.17ms, accelerator: 65us, total: 102.23ms
  summary.py:146:image, cpu: 102.13ms, accelerator: 0us, total: 102.13ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_17750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.79%)
top 2 operation type: ImageSummary, cpu: 340.16ms, accelerator: 0us, total: 340.16ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 98.26ms, accelerator: 0us, total: 98.26ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.75ms, accelerator: 0us, total: 140.75ms
top 3 graph node: difference, cpu: 101.76ms, accelerator: 0us, total: 101.76ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 7.94ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 4.29ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 4.29ms, total: 9.66ms
  __init__.py:185:compute_gradients, cpu: 3.48ms, accelerator: 3.65ms, total: 7.17ms
train.py:448:<module>, cpu: 140.75ms, accelerator: 0us, total: 140.75ms
train.py:449:<module>, cpu: 101.80ms, accelerator: 64us, total: 101.86ms
  summary.py:146:image, cpu: 101.76ms, accelerator: 0us, total: 101.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_18000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.78%)
top 2 operation type: ImageSummary, cpu: 339.88ms, accelerator: 0us, total: 339.88ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 98.30ms, accelerator: 0us, total: 98.30ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.75ms, accelerator: 0us, total: 140.75ms
top 3 graph node: difference, cpu: 101.37ms, accelerator: 0us, total: 101.37ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 7.99ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 4.24ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.30ms, accelerator: 4.24ms, total: 9.56ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 3.75ms, total: 7.25ms
train.py:448:<module>, cpu: 140.75ms, accelerator: 0us, total: 140.75ms
train.py:449:<module>, cpu: 101.41ms, accelerator: 63us, total: 101.48ms
  summary.py:146:image, cpu: 101.38ms, accelerator: 0us, total: 101.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_18250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.79%)
top 2 operation type: ImageSummary, cpu: 339.12ms, accelerator: 0us, total: 339.12ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 98.10ms, accelerator: 0us, total: 98.10ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.48ms, accelerator: 0us, total: 140.48ms
top 3 graph node: difference, cpu: 100.97ms, accelerator: 0us, total: 100.97ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 7.89ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 4.19ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.28ms, accelerator: 4.19ms, total: 9.49ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 3.70ms, total: 7.29ms
train.py:448:<module>, cpu: 140.48ms, accelerator: 0us, total: 140.48ms
train.py:449:<module>, cpu: 101.01ms, accelerator: 62us, total: 101.07ms
  summary.py:146:image, cpu: 100.97ms, accelerator: 0us, total: 100.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_18500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.80%)
top 2 operation type: ImageSummary, cpu: 339.53ms, accelerator: 0us, total: 339.53ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 98.23ms, accelerator: 0us, total: 98.23ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.88ms, accelerator: 0us, total: 140.88ms
top 3 graph node: difference, cpu: 101.37ms, accelerator: 0us, total: 101.37ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 7.81ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 4.14ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 4.14ms, total: 9.40ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 3.67ms, total: 7.24ms
train.py:448:<module>, cpu: 140.89ms, accelerator: 0us, total: 140.89ms
train.py:449:<module>, cpu: 101.41ms, accelerator: 61us, total: 101.47ms
  summary.py:146:image, cpu: 101.37ms, accelerator: 0us, total: 101.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_18750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.81%)
top 2 operation type: ImageSummary, cpu: 338.66ms, accelerator: 0us, total: 338.66ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 98.06ms, accelerator: 0us, total: 98.06ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.74ms, accelerator: 0us, total: 140.74ms
top 3 graph node: difference, cpu: 100.93ms, accelerator: 0us, total: 100.93ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 7.73ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 4.09ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 4.09ms, total: 9.32ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 3.64ms, total: 7.18ms
train.py:448:<module>, cpu: 140.74ms, accelerator: 0us, total: 140.74ms
train.py:449:<module>, cpu: 100.97ms, accelerator: 61us, total: 101.03ms
  summary.py:146:image, cpu: 100.93ms, accelerator: 0us, total: 100.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_19000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.83%)
top 2 operation type: ImageSummary, cpu: 337.71ms, accelerator: 0us, total: 337.71ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 97.61ms, accelerator: 0us, total: 97.61ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.34ms, accelerator: 0us, total: 140.34ms
top 3 graph node: difference, cpu: 100.51ms, accelerator: 0us, total: 100.51ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 7.64ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 4.04ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 4.04ms, total: 9.23ms
  __init__.py:185:compute_gradients, cpu: 3.48ms, accelerator: 3.60ms, total: 7.12ms
train.py:448:<module>, cpu: 140.34ms, accelerator: 0us, total: 140.34ms
train.py:449:<module>, cpu: 100.55ms, accelerator: 60us, total: 100.61ms
  summary.py:146:image, cpu: 100.51ms, accelerator: 0us, total: 100.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_19250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.84%)
top 2 operation type: ImageSummary, cpu: 336.81ms, accelerator: 0us, total: 336.81ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 99.49ms, accelerator: 0us, total: 99.49ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.44ms, accelerator: 0us, total: 140.44ms
top 3 graph node: difference, cpu: 100.10ms, accelerator: 0us, total: 100.10ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 7.55ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 3.99ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.12ms, accelerator: 3.99ms, total: 9.14ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 3.56ms, total: 7.07ms
train.py:448:<module>, cpu: 140.45ms, accelerator: 0us, total: 140.45ms
train.py:449:<module>, cpu: 100.14ms, accelerator: 59us, total: 100.20ms
  summary.py:146:image, cpu: 100.11ms, accelerator: 0us, total: 100.11ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_19500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.87%)
top 2 operation type: ImageSummary, cpu: 335.72ms, accelerator: 0us, total: 335.72ms (3.89%)
top 3 operation type: HistogramSummary, cpu: 99.04ms, accelerator: 0us, total: 99.04ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.13ms, accelerator: 0us, total: 140.13ms
top 3 graph node: difference, cpu: 99.45ms, accelerator: 0us, total: 99.45ms
train.py:511:<module>, cpu: 8.12sec, accelerator: 7.62ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 3.95ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 5.08ms, accelerator: 3.95ms, total: 9.05ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 3.68ms, total: 7.16ms
train.py:448:<module>, cpu: 140.13ms, accelerator: 0us, total: 140.13ms
train.py:449:<module>, cpu: 99.49ms, accelerator: 59us, total: 99.55ms
  summary.py:146:image, cpu: 99.45ms, accelerator: 0us, total: 99.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_19750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.88%)
top 2 operation type: ImageSummary, cpu: 334.82ms, accelerator: 0us, total: 334.82ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 98.93ms, accelerator: 0us, total: 98.93ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.79ms, accelerator: 0us, total: 139.79ms
top 3 graph node: difference, cpu: 99.27ms, accelerator: 0us, total: 99.27ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 7.53ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 3.90ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.04ms, accelerator: 3.90ms, total: 8.96ms
  __init__.py:185:compute_gradients, cpu: 3.42ms, accelerator: 3.64ms, total: 7.10ms
train.py:448:<module>, cpu: 139.80ms, accelerator: 0us, total: 139.80ms
train.py:449:<module>, cpu: 99.31ms, accelerator: 58us, total: 99.36ms
  summary.py:146:image, cpu: 99.27ms, accelerator: 0us, total: 99.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_20000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.89%)
top 2 operation type: ImageSummary, cpu: 334.26ms, accelerator: 0us, total: 334.26ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 98.85ms, accelerator: 0us, total: 98.85ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.64ms, accelerator: 0us, total: 139.64ms
top 3 graph node: difference, cpu: 98.91ms, accelerator: 0us, total: 98.91ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 7.61ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 3.85ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 3.85ms, total: 8.88ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 3.75ms, total: 7.23ms
train.py:448:<module>, cpu: 139.65ms, accelerator: 0us, total: 139.65ms
train.py:449:<module>, cpu: 98.95ms, accelerator: 57us, total: 99.01ms
  summary.py:146:image, cpu: 98.92ms, accelerator: 0us, total: 98.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_20250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.89%)
top 2 operation type: ImageSummary, cpu: 334.31ms, accelerator: 0us, total: 334.31ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 98.71ms, accelerator: 0us, total: 98.71ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.77ms, accelerator: 0us, total: 139.77ms
top 3 graph node: difference, cpu: 98.57ms, accelerator: 0us, total: 98.57ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 7.54ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 3.82ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 3.82ms, total: 8.81ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 3.71ms, total: 7.29ms
train.py:448:<module>, cpu: 139.78ms, accelerator: 0us, total: 139.78ms
train.py:449:<module>, cpu: 98.61ms, accelerator: 57us, total: 98.67ms
  summary.py:146:image, cpu: 98.57ms, accelerator: 0us, total: 98.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_20500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.89%)
top 2 operation type: ImageSummary, cpu: 334.39ms, accelerator: 0us, total: 334.39ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 98.85ms, accelerator: 0us, total: 98.85ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.74ms, accelerator: 0us, total: 139.74ms
top 3 graph node: difference, cpu: 98.40ms, accelerator: 0us, total: 98.40ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 7.47ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 3.79ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 3.79ms, total: 8.76ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 3.68ms, total: 7.23ms
train.py:448:<module>, cpu: 139.75ms, accelerator: 0us, total: 139.75ms
train.py:449:<module>, cpu: 98.44ms, accelerator: 56us, total: 98.50ms
  summary.py:146:image, cpu: 98.41ms, accelerator: 0us, total: 98.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2116.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_20750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.91%)
top 2 operation type: ImageSummary, cpu: 333.83ms, accelerator: 0us, total: 333.83ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 98.31ms, accelerator: 0us, total: 98.31ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.69ms, accelerator: 0us, total: 139.69ms
top 3 graph node: difference, cpu: 98.36ms, accelerator: 0us, total: 98.36ms
train.py:511:<module>, cpu: 8.12sec, accelerator: 7.39ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 3.74ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 3.74ms, total: 8.68ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 3.64ms, total: 7.18ms
train.py:448:<module>, cpu: 139.70ms, accelerator: 0us, total: 139.70ms
train.py:449:<module>, cpu: 98.40ms, accelerator: 56us, total: 98.45ms
  summary.py:146:image, cpu: 98.36ms, accelerator: 0us, total: 98.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_21000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.91%)
top 2 operation type: ImageSummary, cpu: 333.76ms, accelerator: 0us, total: 333.76ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 97.97ms, accelerator: 0us, total: 97.97ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.54ms, accelerator: 0us, total: 139.54ms
top 3 graph node: difference, cpu: 98.22ms, accelerator: 0us, total: 98.22ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 7.37ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 3.72ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 3.72ms, total: 8.62ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 3.64ms, total: 7.18ms
train.py:448:<module>, cpu: 139.54ms, accelerator: 0us, total: 139.54ms
train.py:449:<module>, cpu: 98.26ms, accelerator: 55us, total: 98.32ms
  summary.py:146:image, cpu: 98.23ms, accelerator: 0us, total: 98.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_21250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.92%)
top 2 operation type: ImageSummary, cpu: 333.08ms, accelerator: 0us, total: 333.08ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 97.86ms, accelerator: 0us, total: 97.86ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.27ms, accelerator: 0us, total: 139.27ms
top 3 graph node: difference, cpu: 97.91ms, accelerator: 0us, total: 97.91ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 7.29ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 3.68ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 3.68ms, total: 8.63ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 3.61ms, total: 7.12ms
train.py:448:<module>, cpu: 139.28ms, accelerator: 0us, total: 139.28ms
train.py:449:<module>, cpu: 97.95ms, accelerator: 54us, total: 98.00ms
  summary.py:146:image, cpu: 97.92ms, accelerator: 0us, total: 97.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_21500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.92%)
top 2 operation type: ImageSummary, cpu: 333.11ms, accelerator: 0us, total: 333.11ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 97.55ms, accelerator: 0us, total: 97.55ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.07ms, accelerator: 0us, total: 139.07ms
top 3 graph node: difference, cpu: 98.02ms, accelerator: 0us, total: 98.02ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 7.21ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 3.64ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 3.64ms, total: 8.56ms
  __init__.py:185:compute_gradients, cpu: 3.45ms, accelerator: 3.57ms, total: 7.06ms
train.py:448:<module>, cpu: 139.07ms, accelerator: 0us, total: 139.07ms
train.py:449:<module>, cpu: 98.06ms, accelerator: 54us, total: 98.11ms
  summary.py:146:image, cpu: 98.03ms, accelerator: 0us, total: 98.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_21750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.93%)
top 2 operation type: ImageSummary, cpu: 332.97ms, accelerator: 0us, total: 332.97ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 97.54ms, accelerator: 0us, total: 97.54ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.91ms, accelerator: 0us, total: 138.91ms
top 3 graph node: difference, cpu: 97.78ms, accelerator: 0us, total: 97.78ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 7.16ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 3.62ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.02ms, accelerator: 3.62ms, total: 8.67ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 3.53ms, total: 7.01ms
train.py:448:<module>, cpu: 138.91ms, accelerator: 0us, total: 138.91ms
train.py:449:<module>, cpu: 97.82ms, accelerator: 53us, total: 97.88ms
  summary.py:146:image, cpu: 97.79ms, accelerator: 0us, total: 97.79ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_22000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (93.94%)
top 2 operation type: ImageSummary, cpu: 332.45ms, accelerator: 0us, total: 332.45ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 98.67ms, accelerator: 0us, total: 98.67ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.12ms, accelerator: 0us, total: 139.12ms
top 3 graph node: difference, cpu: 97.46ms, accelerator: 0us, total: 97.46ms
train.py:511:<module>, cpu: 8.12sec, accelerator: 7.09ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 3.58ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 3.58ms, total: 8.60ms
  __init__.py:185:compute_gradients, cpu: 3.45ms, accelerator: 3.51ms, total: 7.00ms
train.py:448:<module>, cpu: 139.12ms, accelerator: 0us, total: 139.12ms
train.py:449:<module>, cpu: 97.50ms, accelerator: 53us, total: 97.55ms
  summary.py:146:image, cpu: 97.46ms, accelerator: 0us, total: 97.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_22250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (93.96%)
top 2 operation type: ImageSummary, cpu: 332.03ms, accelerator: 0us, total: 332.03ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 98.27ms, accelerator: 0us, total: 98.27ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.30ms, accelerator: 0us, total: 139.30ms
top 3 graph node: difference, cpu: 97.26ms, accelerator: 0us, total: 97.26ms
train.py:511:<module>, cpu: 8.13sec, accelerator: 7.03ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 3.55ms, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 3.55ms, total: 8.53ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 3.47ms, total: 6.95ms
train.py:448:<module>, cpu: 139.30ms, accelerator: 0us, total: 139.30ms
train.py:449:<module>, cpu: 97.30ms, accelerator: 52us, total: 97.35ms
  summary.py:146:image, cpu: 97.26ms, accelerator: 0us, total: 97.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_22500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.96%)
top 2 operation type: ImageSummary, cpu: 331.54ms, accelerator: 0us, total: 331.54ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 98.47ms, accelerator: 0us, total: 98.47ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.36ms, accelerator: 0us, total: 139.36ms
top 3 graph node: difference, cpu: 97.00ms, accelerator: 0us, total: 97.00ms
train.py:511:<module>, cpu: 8.12sec, accelerator: 6.95ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 3.52ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 3.52ms, total: 8.48ms
  __init__.py:185:compute_gradients, cpu: 3.42ms, accelerator: 3.44ms, total: 6.90ms
train.py:448:<module>, cpu: 139.37ms, accelerator: 0us, total: 139.37ms
train.py:449:<module>, cpu: 97.04ms, accelerator: 52us, total: 97.09ms
  summary.py:146:image, cpu: 97.01ms, accelerator: 0us, total: 97.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_22750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.97%)
top 2 operation type: ImageSummary, cpu: 331.16ms, accelerator: 0us, total: 331.16ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 98.11ms, accelerator: 0us, total: 98.11ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.05ms, accelerator: 0us, total: 139.05ms
top 3 graph node: difference, cpu: 97.30ms, accelerator: 0us, total: 97.30ms
train.py:511:<module>, cpu: 8.12sec, accelerator: 6.88ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 3.48ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 5.09ms, accelerator: 3.48ms, total: 8.59ms
  __init__.py:185:compute_gradients, cpu: 3.40ms, accelerator: 3.40ms, total: 6.85ms
train.py:448:<module>, cpu: 139.06ms, accelerator: 0us, total: 139.06ms
train.py:449:<module>, cpu: 97.34ms, accelerator: 51us, total: 97.39ms
  summary.py:146:image, cpu: 97.30ms, accelerator: 0us, total: 97.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_23000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.97%)
top 2 operation type: ImageSummary, cpu: 330.67ms, accelerator: 0us, total: 330.67ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 98.34ms, accelerator: 0us, total: 98.34ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.97ms, accelerator: 0us, total: 138.97ms
top 3 graph node: difference, cpu: 96.86ms, accelerator: 0us, total: 96.86ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 6.82ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 3.45ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 5.06ms, accelerator: 3.45ms, total: 8.52ms
  __init__.py:185:compute_gradients, cpu: 3.42ms, accelerator: 3.37ms, total: 6.83ms
train.py:448:<module>, cpu: 138.98ms, accelerator: 0us, total: 138.98ms
train.py:449:<module>, cpu: 96.90ms, accelerator: 51us, total: 96.95ms
  summary.py:146:image, cpu: 96.87ms, accelerator: 0us, total: 96.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_23250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.97%)
top 2 operation type: ImageSummary, cpu: 330.17ms, accelerator: 0us, total: 330.17ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 98.66ms, accelerator: 0us, total: 98.66ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.92ms, accelerator: 0us, total: 138.92ms
top 3 graph node: difference, cpu: 96.57ms, accelerator: 0us, total: 96.57ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 6.76ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 3.42ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.10ms, accelerator: 3.42ms, total: 8.54ms
  __init__.py:185:compute_gradients, cpu: 3.40ms, accelerator: 3.35ms, total: 6.79ms
train.py:448:<module>, cpu: 138.93ms, accelerator: 0us, total: 138.93ms
train.py:449:<module>, cpu: 96.61ms, accelerator: 50us, total: 96.66ms
  summary.py:146:image, cpu: 96.58ms, accelerator: 0us, total: 96.58ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_23500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.97%)
top 2 operation type: ImageSummary, cpu: 330.27ms, accelerator: 0us, total: 330.27ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 98.34ms, accelerator: 0us, total: 98.34ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.25ms, accelerator: 0us, total: 139.25ms
top 3 graph node: difference, cpu: 96.65ms, accelerator: 0us, total: 96.65ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 6.69ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 3.38ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.11ms, accelerator: 3.38ms, total: 8.51ms
  __init__.py:185:compute_gradients, cpu: 3.38ms, accelerator: 3.31ms, total: 6.74ms
train.py:448:<module>, cpu: 139.26ms, accelerator: 0us, total: 139.26ms
train.py:449:<module>, cpu: 96.69ms, accelerator: 50us, total: 96.74ms
  summary.py:146:image, cpu: 96.66ms, accelerator: 0us, total: 96.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_23750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.97%)
top 2 operation type: ImageSummary, cpu: 330.29ms, accelerator: 0us, total: 330.29ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 98.31ms, accelerator: 0us, total: 98.31ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.50ms, accelerator: 0us, total: 139.50ms
top 3 graph node: difference, cpu: 96.33ms, accelerator: 0us, total: 96.33ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 6.65ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 3.35ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 3.35ms, total: 8.69ms
  __init__.py:185:compute_gradients, cpu: 3.43ms, accelerator: 3.30ms, total: 6.76ms
train.py:448:<module>, cpu: 139.51ms, accelerator: 0us, total: 139.51ms
train.py:449:<module>, cpu: 96.37ms, accelerator: 49us, total: 96.42ms
  summary.py:146:image, cpu: 96.33ms, accelerator: 0us, total: 96.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_24000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.96%)
top 2 operation type: ImageSummary, cpu: 329.93ms, accelerator: 0us, total: 329.93ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 99.25ms, accelerator: 0us, total: 99.25ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.46ms, accelerator: 0us, total: 139.46ms
top 3 graph node: difference, cpu: 96.42ms, accelerator: 0us, total: 96.42ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 6.58ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 3.31ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 3.31ms, total: 8.64ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 3.27ms, total: 6.82ms
train.py:448:<module>, cpu: 139.47ms, accelerator: 0us, total: 139.47ms
train.py:449:<module>, cpu: 96.46ms, accelerator: 49us, total: 96.51ms
  summary.py:146:image, cpu: 96.43ms, accelerator: 0us, total: 96.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_24250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.98%)
top 2 operation type: ImageSummary, cpu: 328.97ms, accelerator: 0us, total: 328.97ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 99.08ms, accelerator: 0us, total: 99.08ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.35ms, accelerator: 0us, total: 139.35ms
top 3 graph node: difference, cpu: 96.02ms, accelerator: 0us, total: 96.02ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 6.52ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 3.29ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 3.29ms, total: 8.60ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 3.24ms, total: 6.78ms
train.py:448:<module>, cpu: 139.36ms, accelerator: 0us, total: 139.36ms
train.py:449:<module>, cpu: 96.06ms, accelerator: 49us, total: 96.11ms
  summary.py:146:image, cpu: 96.03ms, accelerator: 0us, total: 96.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_24500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.97%)
top 2 operation type: ImageSummary, cpu: 329.49ms, accelerator: 0us, total: 329.49ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 99.14ms, accelerator: 0us, total: 99.14ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.20ms, accelerator: 0us, total: 139.20ms
top 3 graph node: difference, cpu: 96.27ms, accelerator: 0us, total: 96.27ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 6.48ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 3.26ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.28ms, accelerator: 3.26ms, total: 8.56ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 3.23ms, total: 6.75ms
train.py:448:<module>, cpu: 139.20ms, accelerator: 0us, total: 139.20ms
train.py:449:<module>, cpu: 96.31ms, accelerator: 48us, total: 96.35ms
  summary.py:146:image, cpu: 96.27ms, accelerator: 0us, total: 96.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_24750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.96%)
top 2 operation type: ImageSummary, cpu: 329.96ms, accelerator: 0us, total: 329.96ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 98.73ms, accelerator: 0us, total: 98.73ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.54ms, accelerator: 0us, total: 139.54ms
top 3 graph node: difference, cpu: 96.44ms, accelerator: 0us, total: 96.44ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 6.43ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 3.23ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 3.23ms, total: 8.50ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 3.20ms, total: 6.71ms
train.py:448:<module>, cpu: 139.55ms, accelerator: 0us, total: 139.55ms
train.py:449:<module>, cpu: 96.48ms, accelerator: 48us, total: 96.53ms
  summary.py:146:image, cpu: 96.45ms, accelerator: 0us, total: 96.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_25000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.95%)
top 2 operation type: ImageSummary, cpu: 330.03ms, accelerator: 0us, total: 330.03ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 98.52ms, accelerator: 0us, total: 98.52ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.72ms, accelerator: 0us, total: 139.72ms
top 3 graph node: difference, cpu: 96.48ms, accelerator: 0us, total: 96.48ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 6.37ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 3.20ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 3.20ms, total: 8.45ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 3.17ms, total: 6.83ms
train.py:448:<module>, cpu: 139.72ms, accelerator: 0us, total: 139.72ms
train.py:449:<module>, cpu: 96.52ms, accelerator: 47us, total: 96.56ms
  summary.py:146:image, cpu: 96.48ms, accelerator: 0us, total: 96.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_25250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.19ms, accelerator: 0us, total: 329.19ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 98.37ms, accelerator: 0us, total: 98.37ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.41ms, accelerator: 0us, total: 139.41ms
top 3 graph node: difference, cpu: 96.13ms, accelerator: 0us, total: 96.13ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 6.36ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 3.21ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 3.21ms, total: 8.43ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 3.14ms, total: 6.78ms
train.py:448:<module>, cpu: 139.41ms, accelerator: 0us, total: 139.41ms
train.py:449:<module>, cpu: 96.17ms, accelerator: 47us, total: 96.22ms
  summary.py:146:image, cpu: 96.14ms, accelerator: 0us, total: 96.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_25500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.34ms, accelerator: 0us, total: 329.34ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 98.41ms, accelerator: 0us, total: 98.41ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.35ms, accelerator: 0us, total: 139.35ms
top 3 graph node: difference, cpu: 96.58ms, accelerator: 0us, total: 96.58ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 6.30ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 3.19ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 3.19ms, total: 8.37ms
  __init__.py:185:compute_gradients, cpu: 3.84ms, accelerator: 3.11ms, total: 7.00ms
train.py:448:<module>, cpu: 139.35ms, accelerator: 0us, total: 139.35ms
train.py:449:<module>, cpu: 96.62ms, accelerator: 47us, total: 96.67ms
  summary.py:146:image, cpu: 96.59ms, accelerator: 0us, total: 96.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_25750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.23ms, accelerator: 0us, total: 329.23ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 98.08ms, accelerator: 0us, total: 98.08ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.21ms, accelerator: 0us, total: 139.21ms
top 3 graph node: difference, cpu: 96.50ms, accelerator: 0us, total: 96.50ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 6.25ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 3.16ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 3.16ms, total: 8.36ms
  __init__.py:185:compute_gradients, cpu: 3.85ms, accelerator: 3.09ms, total: 6.99ms
train.py:448:<module>, cpu: 139.21ms, accelerator: 0us, total: 139.21ms
train.py:449:<module>, cpu: 96.53ms, accelerator: 46us, total: 96.58ms
  summary.py:146:image, cpu: 96.50ms, accelerator: 0us, total: 96.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_26000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 329.53ms, accelerator: 0us, total: 329.53ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 97.97ms, accelerator: 0us, total: 97.97ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.86ms, accelerator: 0us, total: 138.86ms
top 3 graph node: difference, cpu: 96.86ms, accelerator: 0us, total: 96.86ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 6.20ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 3.14ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 3.14ms, total: 8.30ms
  __init__.py:185:compute_gradients, cpu: 3.85ms, accelerator: 3.07ms, total: 6.95ms
train.py:448:<module>, cpu: 138.87ms, accelerator: 0us, total: 138.87ms
train.py:449:<module>, cpu: 96.90ms, accelerator: 46us, total: 96.95ms
  summary.py:146:image, cpu: 96.87ms, accelerator: 0us, total: 96.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2133.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_26250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.96%)
top 2 operation type: ImageSummary, cpu: 329.24ms, accelerator: 0us, total: 329.24ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 98.02ms, accelerator: 0us, total: 98.02ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.02ms, accelerator: 0us, total: 139.02ms
top 3 graph node: difference, cpu: 96.62ms, accelerator: 0us, total: 96.62ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 6.16ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 3.11ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.13ms, accelerator: 3.11ms, total: 8.26ms
  __init__.py:185:compute_gradients, cpu: 3.82ms, accelerator: 3.05ms, total: 6.91ms
train.py:448:<module>, cpu: 139.03ms, accelerator: 0us, total: 139.03ms
train.py:449:<module>, cpu: 96.66ms, accelerator: 45us, total: 96.70ms
  summary.py:146:image, cpu: 96.62ms, accelerator: 0us, total: 96.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_26500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.95%)
top 2 operation type: ImageSummary, cpu: 328.72ms, accelerator: 0us, total: 328.72ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 98.91ms, accelerator: 0us, total: 98.91ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.00ms, accelerator: 0us, total: 139.00ms
top 3 graph node: difference, cpu: 96.44ms, accelerator: 0us, total: 96.44ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 6.33ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 3.08ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.11ms, accelerator: 3.08ms, total: 8.21ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 3.25ms, total: 7.09ms
train.py:448:<module>, cpu: 139.01ms, accelerator: 0us, total: 139.01ms
train.py:449:<module>, cpu: 96.48ms, accelerator: 45us, total: 96.53ms
  summary.py:146:image, cpu: 96.45ms, accelerator: 0us, total: 96.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2123.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_26750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.30ms, accelerator: 0us, total: 329.30ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 98.66ms, accelerator: 0us, total: 98.66ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.32ms, accelerator: 0us, total: 139.32ms
top 3 graph node: difference, cpu: 96.34ms, accelerator: 0us, total: 96.34ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 6.29ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 3.06ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.07ms, accelerator: 3.06ms, total: 8.16ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 3.22ms, total: 7.05ms
train.py:448:<module>, cpu: 139.32ms, accelerator: 0us, total: 139.32ms
train.py:449:<module>, cpu: 96.38ms, accelerator: 44us, total: 96.42ms
  summary.py:146:image, cpu: 96.34ms, accelerator: 0us, total: 96.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_27000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.94%)
top 2 operation type: ImageSummary, cpu: 330.17ms, accelerator: 0us, total: 330.17ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 98.28ms, accelerator: 0us, total: 98.28ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.38ms, accelerator: 0us, total: 139.38ms
top 3 graph node: difference, cpu: 96.66ms, accelerator: 0us, total: 96.66ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 6.24ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 3.04ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 3.04ms, total: 8.26ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 3.19ms, total: 7.01ms
train.py:448:<module>, cpu: 139.38ms, accelerator: 0us, total: 139.38ms
train.py:449:<module>, cpu: 96.70ms, accelerator: 44us, total: 96.74ms
  summary.py:146:image, cpu: 96.66ms, accelerator: 0us, total: 96.66ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_27250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.91%)
top 2 operation type: ImageSummary, cpu: 332.39ms, accelerator: 0us, total: 332.39ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 98.50ms, accelerator: 0us, total: 98.50ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.93ms, accelerator: 0us, total: 139.93ms
top 3 graph node: difference, cpu: 97.15ms, accelerator: 0us, total: 97.15ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 6.19ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 3.02ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 3.02ms, total: 8.20ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 3.17ms, total: 7.01ms
train.py:448:<module>, cpu: 139.94ms, accelerator: 0us, total: 139.94ms
train.py:449:<module>, cpu: 97.19ms, accelerator: 44us, total: 97.24ms
  summary.py:146:image, cpu: 97.16ms, accelerator: 0us, total: 97.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_27500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.90%)
top 2 operation type: ImageSummary, cpu: 333.49ms, accelerator: 0us, total: 333.49ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 98.38ms, accelerator: 0us, total: 98.38ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.34ms, accelerator: 0us, total: 140.34ms
top 3 graph node: difference, cpu: 97.54ms, accelerator: 0us, total: 97.54ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 6.14ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.99ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.13ms, accelerator: 2.99ms, total: 8.15ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 3.15ms, total: 6.96ms
train.py:448:<module>, cpu: 140.34ms, accelerator: 0us, total: 140.34ms
train.py:449:<module>, cpu: 97.58ms, accelerator: 43us, total: 97.63ms
  summary.py:146:image, cpu: 97.55ms, accelerator: 0us, total: 97.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_27750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.91%)
top 2 operation type: ImageSummary, cpu: 333.16ms, accelerator: 0us, total: 333.16ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 98.28ms, accelerator: 0us, total: 98.28ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.97ms, accelerator: 0us, total: 139.97ms
top 3 graph node: difference, cpu: 97.57ms, accelerator: 0us, total: 97.57ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 6.11ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 2.97ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.11ms, accelerator: 2.97ms, total: 8.10ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 3.14ms, total: 6.93ms
train.py:448:<module>, cpu: 139.98ms, accelerator: 0us, total: 139.98ms
train.py:449:<module>, cpu: 97.61ms, accelerator: 43us, total: 97.65ms
  summary.py:146:image, cpu: 97.58ms, accelerator: 0us, total: 97.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_28000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.91%)
top 2 operation type: ImageSummary, cpu: 333.06ms, accelerator: 0us, total: 333.06ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 97.93ms, accelerator: 0us, total: 97.93ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.84ms, accelerator: 0us, total: 139.84ms
top 3 graph node: difference, cpu: 97.65ms, accelerator: 0us, total: 97.65ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 6.12ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.94ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.08ms, accelerator: 2.94ms, total: 8.05ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 3.17ms, total: 6.96ms
train.py:448:<module>, cpu: 139.85ms, accelerator: 0us, total: 139.85ms
train.py:449:<module>, cpu: 97.68ms, accelerator: 65us, total: 97.75ms
  summary.py:146:image, cpu: 97.65ms, accelerator: 0us, total: 97.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_28250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.90%)
top 2 operation type: ImageSummary, cpu: 332.89ms, accelerator: 0us, total: 332.89ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 97.95ms, accelerator: 0us, total: 97.95ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.60ms, accelerator: 0us, total: 139.60ms
top 3 graph node: difference, cpu: 97.75ms, accelerator: 0us, total: 97.75ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 6.09ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.92ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 2.92ms, total: 8.00ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 3.17ms, total: 6.96ms
train.py:448:<module>, cpu: 139.61ms, accelerator: 0us, total: 139.61ms
train.py:449:<module>, cpu: 97.79ms, accelerator: 65us, total: 97.86ms
  summary.py:146:image, cpu: 97.76ms, accelerator: 0us, total: 97.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_28500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.92%)
top 2 operation type: ImageSummary, cpu: 332.27ms, accelerator: 0us, total: 332.27ms (3.89%)
top 3 operation type: HistogramSummary, cpu: 98.12ms, accelerator: 0us, total: 98.12ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.39ms, accelerator: 0us, total: 139.39ms
top 3 graph node: difference, cpu: 97.52ms, accelerator: 0us, total: 97.52ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 6.04ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.89ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.03ms, accelerator: 2.89ms, total: 7.95ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 3.15ms, total: 6.93ms
train.py:448:<module>, cpu: 139.39ms, accelerator: 0us, total: 139.39ms
train.py:449:<module>, cpu: 97.56ms, accelerator: 64us, total: 97.63ms
  summary.py:146:image, cpu: 97.53ms, accelerator: 0us, total: 97.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_28750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.91%)
top 2 operation type: ImageSummary, cpu: 332.35ms, accelerator: 0us, total: 332.35ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 97.84ms, accelerator: 0us, total: 97.84ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.19ms, accelerator: 0us, total: 139.19ms
top 3 graph node: difference, cpu: 97.67ms, accelerator: 0us, total: 97.67ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 6.00ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.87ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 2.87ms, total: 7.91ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 3.13ms, total: 6.90ms
train.py:448:<module>, cpu: 139.20ms, accelerator: 0us, total: 139.20ms
train.py:449:<module>, cpu: 97.71ms, accelerator: 64us, total: 97.77ms
  summary.py:146:image, cpu: 97.67ms, accelerator: 0us, total: 97.67ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_29000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec (93.91%)
top 2 operation type: ImageSummary, cpu: 332.12ms, accelerator: 0us, total: 332.12ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 97.77ms, accelerator: 0us, total: 97.77ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.93ms, accelerator: 0us, total: 138.93ms
top 3 graph node: difference, cpu: 97.69ms, accelerator: 0us, total: 97.69ms
train.py:511:<module>, cpu: 8.01sec, accelerator: 5.96ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 2.85ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 2.85ms, total: 7.87ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 3.11ms, total: 6.86ms
train.py:448:<module>, cpu: 138.94ms, accelerator: 0us, total: 138.94ms
train.py:449:<module>, cpu: 97.72ms, accelerator: 63us, total: 97.79ms
  summary.py:146:image, cpu: 97.69ms, accelerator: 0us, total: 97.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_29250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.92%)
top 2 operation type: ImageSummary, cpu: 332.52ms, accelerator: 0us, total: 332.52ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 97.89ms, accelerator: 0us, total: 97.89ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.08ms, accelerator: 0us, total: 139.08ms
top 3 graph node: difference, cpu: 97.46ms, accelerator: 0us, total: 97.46ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 5.92ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.83ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 2.83ms, total: 7.85ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 3.09ms, total: 6.82ms
train.py:448:<module>, cpu: 139.09ms, accelerator: 0us, total: 139.09ms
train.py:449:<module>, cpu: 97.50ms, accelerator: 63us, total: 97.56ms
  summary.py:146:image, cpu: 97.46ms, accelerator: 0us, total: 97.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_29500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.93%)
top 2 operation type: ImageSummary, cpu: 332.26ms, accelerator: 0us, total: 332.26ms (3.89%)
top 3 operation type: HistogramSummary, cpu: 98.47ms, accelerator: 0us, total: 98.47ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.84ms, accelerator: 0us, total: 138.84ms
top 3 graph node: difference, cpu: 97.21ms, accelerator: 0us, total: 97.21ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.87ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.81ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 2.81ms, total: 7.98ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 3.06ms, total: 6.79ms
train.py:448:<module>, cpu: 138.84ms, accelerator: 0us, total: 138.84ms
train.py:449:<module>, cpu: 97.25ms, accelerator: 62us, total: 97.31ms
  summary.py:146:image, cpu: 97.22ms, accelerator: 0us, total: 97.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_29750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.92%)
top 2 operation type: ImageSummary, cpu: 332.12ms, accelerator: 0us, total: 332.12ms (3.89%)
top 3 operation type: HistogramSummary, cpu: 98.61ms, accelerator: 0us, total: 98.61ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.52ms, accelerator: 0us, total: 138.52ms
top 3 graph node: difference, cpu: 97.42ms, accelerator: 0us, total: 97.42ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.83ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.79ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.12ms, accelerator: 2.79ms, total: 7.93ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 3.04ms, total: 6.75ms
train.py:448:<module>, cpu: 138.52ms, accelerator: 0us, total: 138.52ms
train.py:449:<module>, cpu: 97.46ms, accelerator: 62us, total: 97.52ms
  summary.py:146:image, cpu: 97.42ms, accelerator: 0us, total: 97.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_30000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.93%)
top 2 operation type: ImageSummary, cpu: 331.59ms, accelerator: 0us, total: 331.59ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 98.93ms, accelerator: 0us, total: 98.93ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.32ms, accelerator: 0us, total: 138.32ms
top 3 graph node: difference, cpu: 97.40ms, accelerator: 0us, total: 97.40ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.79ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.76ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.10ms, accelerator: 2.76ms, total: 7.89ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 3.02ms, total: 6.72ms
train.py:448:<module>, cpu: 138.32ms, accelerator: 0us, total: 138.32ms
train.py:449:<module>, cpu: 97.44ms, accelerator: 61us, total: 97.50ms
  summary.py:146:image, cpu: 97.40ms, accelerator: 0us, total: 97.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_30250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.95%)
top 2 operation type: ImageSummary, cpu: 331.37ms, accelerator: 0us, total: 331.37ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 98.89ms, accelerator: 0us, total: 98.89ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.33ms, accelerator: 0us, total: 138.33ms
top 3 graph node: difference, cpu: 97.19ms, accelerator: 0us, total: 97.19ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.75ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.75ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.09ms, accelerator: 2.75ms, total: 7.86ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 3.00ms, total: 6.69ms
train.py:448:<module>, cpu: 138.33ms, accelerator: 0us, total: 138.33ms
train.py:449:<module>, cpu: 97.23ms, accelerator: 61us, total: 97.29ms
  summary.py:146:image, cpu: 97.20ms, accelerator: 0us, total: 97.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2117.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_30500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.94%)
top 2 operation type: ImageSummary, cpu: 331.54ms, accelerator: 0us, total: 331.54ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 99.05ms, accelerator: 0us, total: 99.05ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.50ms, accelerator: 0us, total: 138.50ms
top 3 graph node: difference, cpu: 97.44ms, accelerator: 0us, total: 97.44ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.71ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.72ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.06ms, accelerator: 2.72ms, total: 7.81ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.98ms, total: 6.65ms
train.py:448:<module>, cpu: 138.51ms, accelerator: 0us, total: 138.51ms
train.py:449:<module>, cpu: 97.48ms, accelerator: 60us, total: 97.54ms
  summary.py:146:image, cpu: 97.45ms, accelerator: 0us, total: 97.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_30750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.94%)
top 2 operation type: ImageSummary, cpu: 331.15ms, accelerator: 0us, total: 331.15ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 98.96ms, accelerator: 0us, total: 98.96ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.26ms, accelerator: 0us, total: 138.26ms
top 3 graph node: difference, cpu: 97.38ms, accelerator: 0us, total: 97.38ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.68ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.71ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 2.71ms, total: 7.78ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 2.97ms, total: 6.62ms
train.py:448:<module>, cpu: 138.26ms, accelerator: 0us, total: 138.26ms
train.py:449:<module>, cpu: 97.42ms, accelerator: 60us, total: 97.48ms
  summary.py:146:image, cpu: 97.39ms, accelerator: 0us, total: 97.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2121.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_31000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.94%)
top 2 operation type: ImageSummary, cpu: 330.87ms, accelerator: 0us, total: 330.87ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 98.86ms, accelerator: 0us, total: 98.86ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.15ms, accelerator: 0us, total: 138.15ms
top 3 graph node: difference, cpu: 97.49ms, accelerator: 0us, total: 97.49ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 5.64ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.69ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.02ms, accelerator: 2.69ms, total: 7.74ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 2.95ms, total: 6.59ms
train.py:448:<module>, cpu: 138.15ms, accelerator: 0us, total: 138.15ms
train.py:449:<module>, cpu: 97.53ms, accelerator: 59us, total: 97.59ms
  summary.py:146:image, cpu: 97.50ms, accelerator: 0us, total: 97.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_31250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec (93.94%)
top 2 operation type: ImageSummary, cpu: 330.73ms, accelerator: 0us, total: 330.73ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 98.69ms, accelerator: 0us, total: 98.69ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.32ms, accelerator: 0us, total: 138.32ms
top 3 graph node: difference, cpu: 97.30ms, accelerator: 0us, total: 97.30ms
train.py:511:<module>, cpu: 8.01sec, accelerator: 5.60ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 2.67ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec
    __init__.py:86:allreduce, cpu: 5.02ms, accelerator: 2.67ms, total: 7.71ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 2.93ms, total: 6.55ms
train.py:448:<module>, cpu: 138.32ms, accelerator: 0us, total: 138.32ms
train.py:449:<module>, cpu: 97.34ms, accelerator: 59us, total: 97.40ms
  summary.py:146:image, cpu: 97.31ms, accelerator: 0us, total: 97.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_31500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec (93.94%)
top 2 operation type: ImageSummary, cpu: 330.39ms, accelerator: 0us, total: 330.39ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 99.12ms, accelerator: 0us, total: 99.12ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.07ms, accelerator: 0us, total: 138.07ms
top 3 graph node: difference, cpu: 97.40ms, accelerator: 0us, total: 97.40ms
train.py:511:<module>, cpu: 8.01sec, accelerator: 5.57ms, total: 8.01sec
  __init__.py:194:compute_gradients, cpu: 8.00sec, accelerator: 2.65ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 2.65ms, total: 7.69ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 2.91ms, total: 6.54ms
train.py:448:<module>, cpu: 138.07ms, accelerator: 0us, total: 138.07ms
train.py:449:<module>, cpu: 97.44ms, accelerator: 59us, total: 97.50ms
  summary.py:146:image, cpu: 97.40ms, accelerator: 0us, total: 97.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_31750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.95%)
top 2 operation type: ImageSummary, cpu: 330.03ms, accelerator: 0us, total: 330.03ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 99.23ms, accelerator: 0us, total: 99.23ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.06ms, accelerator: 0us, total: 138.06ms
top 3 graph node: difference, cpu: 97.39ms, accelerator: 0us, total: 97.39ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.53ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.63ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 2.63ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 2.89ms, total: 6.51ms
train.py:448:<module>, cpu: 138.07ms, accelerator: 0us, total: 138.07ms
train.py:449:<module>, cpu: 97.43ms, accelerator: 58us, total: 97.48ms
  summary.py:146:image, cpu: 97.39ms, accelerator: 0us, total: 97.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_32000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.96%)
top 2 operation type: ImageSummary, cpu: 329.44ms, accelerator: 0us, total: 329.44ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 99.28ms, accelerator: 0us, total: 99.28ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.00ms, accelerator: 0us, total: 138.00ms
top 3 graph node: difference, cpu: 97.20ms, accelerator: 0us, total: 97.20ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 5.49ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.62ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.62ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 2.87ms, total: 6.47ms
train.py:448:<module>, cpu: 138.00ms, accelerator: 0us, total: 138.00ms
train.py:449:<module>, cpu: 97.24ms, accelerator: 58us, total: 97.30ms
  summary.py:146:image, cpu: 97.20ms, accelerator: 0us, total: 97.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_32250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.95%)
top 2 operation type: ImageSummary, cpu: 330.60ms, accelerator: 0us, total: 330.60ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 99.55ms, accelerator: 0us, total: 99.55ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.55ms, accelerator: 0us, total: 138.55ms
top 3 graph node: difference, cpu: 97.56ms, accelerator: 0us, total: 97.56ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.45ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.60ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.60ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 2.85ms, total: 6.50ms
train.py:448:<module>, cpu: 138.55ms, accelerator: 0us, total: 138.55ms
train.py:449:<module>, cpu: 97.59ms, accelerator: 57us, total: 97.65ms
  summary.py:146:image, cpu: 97.56ms, accelerator: 0us, total: 97.56ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_32500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.94%)
top 2 operation type: ImageSummary, cpu: 330.59ms, accelerator: 0us, total: 330.59ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 99.57ms, accelerator: 0us, total: 99.57ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.28ms, accelerator: 0us, total: 138.28ms
top 3 graph node: difference, cpu: 97.79ms, accelerator: 0us, total: 97.79ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.42ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.58ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.58ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 2.84ms, total: 6.47ms
train.py:448:<module>, cpu: 138.28ms, accelerator: 0us, total: 138.28ms
train.py:449:<module>, cpu: 97.83ms, accelerator: 57us, total: 97.89ms
  summary.py:146:image, cpu: 97.80ms, accelerator: 0us, total: 97.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_32750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.96%)
top 2 operation type: ImageSummary, cpu: 330.24ms, accelerator: 0us, total: 330.24ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 99.49ms, accelerator: 0us, total: 99.49ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
top 3 graph node: difference, cpu: 97.61ms, accelerator: 0us, total: 97.61ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.40ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.57ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.57ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 2.83ms, total: 6.46ms
train.py:448:<module>, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
train.py:449:<module>, cpu: 97.65ms, accelerator: 57us, total: 97.71ms
  summary.py:146:image, cpu: 97.62ms, accelerator: 0us, total: 97.62ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_33000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.96%)
top 2 operation type: ImageSummary, cpu: 330.14ms, accelerator: 0us, total: 330.14ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 99.77ms, accelerator: 0us, total: 99.77ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.01ms, accelerator: 0us, total: 138.01ms
top 3 graph node: difference, cpu: 97.77ms, accelerator: 0us, total: 97.77ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.37ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.55ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.55ms, total: 7.46ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 2.82ms, total: 6.44ms
train.py:448:<module>, cpu: 138.02ms, accelerator: 0us, total: 138.02ms
train.py:449:<module>, cpu: 97.81ms, accelerator: 56us, total: 97.86ms
  summary.py:146:image, cpu: 97.77ms, accelerator: 0us, total: 97.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_33250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.96%)
top 2 operation type: ImageSummary, cpu: 330.11ms, accelerator: 0us, total: 330.11ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 99.47ms, accelerator: 0us, total: 99.47ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.99ms, accelerator: 0us, total: 137.99ms
top 3 graph node: difference, cpu: 97.87ms, accelerator: 0us, total: 97.87ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.42ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.53ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.53ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 2.89ms, total: 6.49ms
train.py:448:<module>, cpu: 137.99ms, accelerator: 0us, total: 137.99ms
train.py:449:<module>, cpu: 97.91ms, accelerator: 56us, total: 97.96ms
  summary.py:146:image, cpu: 97.87ms, accelerator: 0us, total: 97.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_33500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.96%)
top 2 operation type: ImageSummary, cpu: 329.52ms, accelerator: 0us, total: 329.52ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 99.43ms, accelerator: 0us, total: 99.43ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.75ms, accelerator: 0us, total: 137.75ms
top 3 graph node: difference, cpu: 97.76ms, accelerator: 0us, total: 97.76ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 5.48ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.51ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.51ms, total: 7.39ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 2.97ms, total: 6.55ms
train.py:448:<module>, cpu: 137.76ms, accelerator: 0us, total: 137.76ms
train.py:449:<module>, cpu: 97.80ms, accelerator: 55us, total: 97.85ms
  summary.py:146:image, cpu: 97.76ms, accelerator: 0us, total: 97.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_33750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.96%)
top 2 operation type: ImageSummary, cpu: 329.60ms, accelerator: 0us, total: 329.60ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 99.64ms, accelerator: 0us, total: 99.64ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.71ms, accelerator: 0us, total: 137.71ms
top 3 graph node: difference, cpu: 97.83ms, accelerator: 0us, total: 97.83ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.45ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.50ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.50ms, total: 7.36ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.95ms, total: 6.62ms
train.py:448:<module>, cpu: 137.71ms, accelerator: 0us, total: 137.71ms
train.py:449:<module>, cpu: 97.87ms, accelerator: 55us, total: 97.92ms
  summary.py:146:image, cpu: 97.84ms, accelerator: 0us, total: 97.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_34000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.98%)
top 2 operation type: ImageSummary, cpu: 329.24ms, accelerator: 0us, total: 329.24ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 99.48ms, accelerator: 0us, total: 99.48ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.49ms, accelerator: 0us, total: 137.49ms
top 3 graph node: difference, cpu: 97.85ms, accelerator: 0us, total: 97.85ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.40ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.48ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.48ms, total: 7.32ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.92ms, total: 6.58ms
train.py:448:<module>, cpu: 137.49ms, accelerator: 0us, total: 137.49ms
train.py:449:<module>, cpu: 97.89ms, accelerator: 65us, total: 97.95ms
  summary.py:146:image, cpu: 97.86ms, accelerator: 0us, total: 97.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_34250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.98%)
top 2 operation type: ImageSummary, cpu: 328.90ms, accelerator: 0us, total: 328.90ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 99.56ms, accelerator: 0us, total: 99.56ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.33ms, accelerator: 0us, total: 137.33ms
top 3 graph node: difference, cpu: 97.88ms, accelerator: 0us, total: 97.88ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.37ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.46ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.79ms, accelerator: 2.46ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 2.91ms, total: 6.55ms
train.py:448:<module>, cpu: 137.34ms, accelerator: 0us, total: 137.34ms
train.py:449:<module>, cpu: 97.92ms, accelerator: 68us, total: 97.98ms
  summary.py:146:image, cpu: 97.88ms, accelerator: 0us, total: 97.88ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_34500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.97%)
top 2 operation type: ImageSummary, cpu: 328.68ms, accelerator: 0us, total: 328.68ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 99.75ms, accelerator: 0us, total: 99.75ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.40ms, accelerator: 0us, total: 137.40ms
top 3 graph node: difference, cpu: 97.80ms, accelerator: 0us, total: 97.80ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.47ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.45ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 4.76ms, accelerator: 2.45ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 3.02ms, total: 6.65ms
train.py:448:<module>, cpu: 137.41ms, accelerator: 0us, total: 137.41ms
train.py:449:<module>, cpu: 97.84ms, accelerator: 68us, total: 97.91ms
  summary.py:146:image, cpu: 97.81ms, accelerator: 0us, total: 97.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_34750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.85ms, accelerator: 0us, total: 328.85ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 99.73ms, accelerator: 0us, total: 99.73ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.55ms, accelerator: 0us, total: 137.55ms
top 3 graph node: difference, cpu: 97.59ms, accelerator: 0us, total: 97.59ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.43ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.44ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 4.75ms, accelerator: 2.44ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 3.00ms, total: 6.63ms
train.py:448:<module>, cpu: 137.56ms, accelerator: 0us, total: 137.56ms
train.py:449:<module>, cpu: 97.63ms, accelerator: 67us, total: 97.70ms
  summary.py:146:image, cpu: 97.60ms, accelerator: 0us, total: 97.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_35000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.97%)
top 2 operation type: ImageSummary, cpu: 328.88ms, accelerator: 0us, total: 328.88ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 100.07ms, accelerator: 0us, total: 100.07ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.55ms, accelerator: 0us, total: 137.55ms
top 3 graph node: difference, cpu: 97.62ms, accelerator: 0us, total: 97.62ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.40ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.41ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 4.73ms, accelerator: 2.41ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 2.98ms, total: 6.60ms
train.py:448:<module>, cpu: 137.56ms, accelerator: 0us, total: 137.56ms
train.py:449:<module>, cpu: 97.66ms, accelerator: 67us, total: 97.72ms
  summary.py:146:image, cpu: 97.62ms, accelerator: 0us, total: 97.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_35250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.40ms, accelerator: 0us, total: 329.40ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 100.58ms, accelerator: 0us, total: 100.58ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.49ms, accelerator: 0us, total: 137.49ms
top 3 graph node: difference, cpu: 97.69ms, accelerator: 0us, total: 97.69ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.37ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.40ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 4.71ms, accelerator: 2.40ms, total: 7.14ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 2.97ms, total: 6.61ms
train.py:448:<module>, cpu: 137.49ms, accelerator: 0us, total: 137.49ms
train.py:449:<module>, cpu: 97.73ms, accelerator: 67us, total: 97.80ms
  summary.py:146:image, cpu: 97.70ms, accelerator: 0us, total: 97.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_35500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.04ms, accelerator: 0us, total: 329.04ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 100.51ms, accelerator: 0us, total: 100.51ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.29ms, accelerator: 0us, total: 137.29ms
top 3 graph node: difference, cpu: 97.69ms, accelerator: 0us, total: 97.69ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 5.34ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.39ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 4.71ms, accelerator: 2.39ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 2.95ms, total: 6.59ms
train.py:448:<module>, cpu: 137.29ms, accelerator: 0us, total: 137.29ms
train.py:449:<module>, cpu: 97.72ms, accelerator: 66us, total: 97.79ms
  summary.py:146:image, cpu: 97.69ms, accelerator: 0us, total: 97.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_35750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.90ms, accelerator: 0us, total: 328.90ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 100.38ms, accelerator: 0us, total: 100.38ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.21ms, accelerator: 0us, total: 137.21ms
top 3 graph node: difference, cpu: 97.80ms, accelerator: 0us, total: 97.80ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.30ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.37ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 4.70ms, accelerator: 2.37ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 2.93ms, total: 6.56ms
train.py:448:<module>, cpu: 137.22ms, accelerator: 0us, total: 137.22ms
train.py:449:<module>, cpu: 97.84ms, accelerator: 66us, total: 97.91ms
  summary.py:146:image, cpu: 97.81ms, accelerator: 0us, total: 97.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_36000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.12ms, accelerator: 0us, total: 329.12ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 100.44ms, accelerator: 0us, total: 100.44ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.37ms, accelerator: 0us, total: 137.37ms
top 3 graph node: difference, cpu: 97.93ms, accelerator: 0us, total: 97.93ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 5.27ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 2.36ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 4.68ms, accelerator: 2.36ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.92ms, total: 6.61ms
train.py:448:<module>, cpu: 137.37ms, accelerator: 0us, total: 137.37ms
train.py:449:<module>, cpu: 97.97ms, accelerator: 65us, total: 98.03ms
  summary.py:146:image, cpu: 97.94ms, accelerator: 0us, total: 97.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_36250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.19ms, accelerator: 0us, total: 329.19ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 100.39ms, accelerator: 0us, total: 100.39ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.53ms, accelerator: 0us, total: 137.53ms
top 3 graph node: difference, cpu: 97.90ms, accelerator: 0us, total: 97.90ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 5.24ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 2.34ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 4.67ms, accelerator: 2.34ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.90ms, total: 6.63ms
train.py:448:<module>, cpu: 137.54ms, accelerator: 0us, total: 137.54ms
train.py:449:<module>, cpu: 97.94ms, accelerator: 65us, total: 98.00ms
  summary.py:146:image, cpu: 97.91ms, accelerator: 0us, total: 97.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_36500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.98%)
top 2 operation type: ImageSummary, cpu: 328.75ms, accelerator: 0us, total: 328.75ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 100.20ms, accelerator: 0us, total: 100.20ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.44ms, accelerator: 0us, total: 137.44ms
top 3 graph node: difference, cpu: 97.70ms, accelerator: 0us, total: 97.70ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.21ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.33ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 4.68ms, accelerator: 2.33ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.88ms, total: 6.60ms
train.py:448:<module>, cpu: 137.45ms, accelerator: 0us, total: 137.45ms
train.py:449:<module>, cpu: 97.74ms, accelerator: 65us, total: 97.80ms
  summary.py:146:image, cpu: 97.70ms, accelerator: 0us, total: 97.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_36750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (94.00%)
top 2 operation type: ImageSummary, cpu: 329.07ms, accelerator: 0us, total: 329.07ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 100.14ms, accelerator: 0us, total: 100.14ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.47ms, accelerator: 0us, total: 137.47ms
top 3 graph node: difference, cpu: 97.72ms, accelerator: 0us, total: 97.72ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.18ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.31ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.70ms, accelerator: 2.31ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.87ms, total: 6.57ms
train.py:448:<module>, cpu: 137.47ms, accelerator: 0us, total: 137.47ms
train.py:449:<module>, cpu: 97.76ms, accelerator: 64us, total: 97.82ms
  summary.py:146:image, cpu: 97.73ms, accelerator: 0us, total: 97.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_37000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.99%)
top 2 operation type: ImageSummary, cpu: 329.55ms, accelerator: 0us, total: 329.55ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 100.11ms, accelerator: 0us, total: 100.11ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.60ms, accelerator: 0us, total: 137.60ms
top 3 graph node: difference, cpu: 97.89ms, accelerator: 0us, total: 97.89ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.17ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.31ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.68ms, accelerator: 2.31ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.87ms, total: 6.56ms
train.py:448:<module>, cpu: 137.60ms, accelerator: 0us, total: 137.60ms
train.py:449:<module>, cpu: 97.93ms, accelerator: 64us, total: 97.99ms
  summary.py:146:image, cpu: 97.90ms, accelerator: 0us, total: 97.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_37250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (94.00%)
top 2 operation type: ImageSummary, cpu: 329.40ms, accelerator: 0us, total: 329.40ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 100.06ms, accelerator: 0us, total: 100.06ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.67ms, accelerator: 0us, total: 137.67ms
top 3 graph node: difference, cpu: 97.71ms, accelerator: 0us, total: 97.71ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.21ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.34ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.71ms, accelerator: 2.34ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.87ms, total: 6.58ms
train.py:448:<module>, cpu: 137.68ms, accelerator: 0us, total: 137.68ms
train.py:449:<module>, cpu: 97.75ms, accelerator: 91us, total: 97.84ms
  summary.py:146:image, cpu: 97.72ms, accelerator: 0us, total: 97.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_37500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (94.00%)
top 2 operation type: ImageSummary, cpu: 329.16ms, accelerator: 0us, total: 329.16ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 99.83ms, accelerator: 0us, total: 99.83ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.53ms, accelerator: 0us, total: 137.53ms
top 3 graph node: difference, cpu: 97.52ms, accelerator: 0us, total: 97.52ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.18ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.33ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.72ms, accelerator: 2.33ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.85ms, total: 6.55ms
train.py:448:<module>, cpu: 137.54ms, accelerator: 0us, total: 137.54ms
train.py:449:<module>, cpu: 97.56ms, accelerator: 90us, total: 97.65ms
  summary.py:146:image, cpu: 97.53ms, accelerator: 0us, total: 97.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2129.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_37750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (94.01%)
top 2 operation type: ImageSummary, cpu: 328.59ms, accelerator: 0us, total: 328.59ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 99.88ms, accelerator: 0us, total: 99.88ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.50ms, accelerator: 0us, total: 137.50ms
top 3 graph node: difference, cpu: 97.28ms, accelerator: 0us, total: 97.28ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.15ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.31ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.73ms, accelerator: 2.31ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.84ms, total: 6.52ms
train.py:448:<module>, cpu: 137.50ms, accelerator: 0us, total: 137.50ms
train.py:449:<module>, cpu: 97.31ms, accelerator: 90us, total: 97.40ms
  summary.py:146:image, cpu: 97.28ms, accelerator: 0us, total: 97.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_38000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (94.02%)
top 2 operation type: ImageSummary, cpu: 328.19ms, accelerator: 0us, total: 328.19ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 99.58ms, accelerator: 0us, total: 99.58ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.33ms, accelerator: 0us, total: 137.33ms
top 3 graph node: difference, cpu: 97.24ms, accelerator: 0us, total: 97.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.12ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.30ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.79ms, accelerator: 2.30ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.82ms, total: 6.50ms
train.py:448:<module>, cpu: 137.33ms, accelerator: 0us, total: 137.33ms
train.py:449:<module>, cpu: 97.28ms, accelerator: 89us, total: 97.37ms
  summary.py:146:image, cpu: 97.24ms, accelerator: 0us, total: 97.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_38250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (94.03%)
top 2 operation type: ImageSummary, cpu: 327.89ms, accelerator: 0us, total: 327.89ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 99.52ms, accelerator: 0us, total: 99.52ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.37ms, accelerator: 0us, total: 137.37ms
top 3 graph node: difference, cpu: 97.09ms, accelerator: 0us, total: 97.09ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.10ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.29ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.78ms, accelerator: 2.29ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.81ms, total: 6.47ms
train.py:448:<module>, cpu: 137.38ms, accelerator: 0us, total: 137.38ms
train.py:449:<module>, cpu: 97.13ms, accelerator: 94us, total: 97.23ms
  summary.py:146:image, cpu: 97.10ms, accelerator: 0us, total: 97.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_38500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (94.03%)
top 2 operation type: ImageSummary, cpu: 327.80ms, accelerator: 0us, total: 327.80ms (3.81%)
top 3 operation type: HistogramSummary, cpu: 99.51ms, accelerator: 0us, total: 99.51ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.48ms, accelerator: 0us, total: 137.48ms
top 3 graph node: difference, cpu: 96.98ms, accelerator: 0us, total: 96.98ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.07ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.28ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.28ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.79ms, total: 6.46ms
train.py:448:<module>, cpu: 137.49ms, accelerator: 0us, total: 137.49ms
train.py:449:<module>, cpu: 97.02ms, accelerator: 93us, total: 97.11ms
  summary.py:146:image, cpu: 96.98ms, accelerator: 0us, total: 96.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_38750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.99%)
top 2 operation type: ImageSummary, cpu: 328.86ms, accelerator: 0us, total: 328.86ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 99.81ms, accelerator: 0us, total: 99.81ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.78ms, accelerator: 0us, total: 137.78ms
top 3 graph node: difference, cpu: 97.29ms, accelerator: 0us, total: 97.29ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.20ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.36ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.36ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.84ms, total: 6.51ms
train.py:448:<module>, cpu: 137.78ms, accelerator: 0us, total: 137.78ms
train.py:449:<module>, cpu: 97.33ms, accelerator: 93us, total: 97.42ms
  summary.py:146:image, cpu: 97.30ms, accelerator: 0us, total: 97.30ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_39000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.98%)
top 2 operation type: ImageSummary, cpu: 328.74ms, accelerator: 0us, total: 328.74ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 100.33ms, accelerator: 0us, total: 100.33ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.01ms, accelerator: 0us, total: 138.01ms
top 3 graph node: difference, cpu: 97.13ms, accelerator: 0us, total: 97.13ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.34ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.42ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.42ms, total: 7.36ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.92ms, total: 6.65ms
train.py:448:<module>, cpu: 138.01ms, accelerator: 0us, total: 138.01ms
train.py:449:<module>, cpu: 97.17ms, accelerator: 92us, total: 97.26ms
  summary.py:146:image, cpu: 97.14ms, accelerator: 0us, total: 97.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_39250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.98%)
top 2 operation type: ImageSummary, cpu: 328.88ms, accelerator: 0us, total: 328.88ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 100.51ms, accelerator: 0us, total: 100.51ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.97ms, accelerator: 0us, total: 137.97ms
top 3 graph node: difference, cpu: 97.36ms, accelerator: 0us, total: 97.36ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.32ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.42ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.42ms, total: 7.34ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.90ms, total: 6.74ms
train.py:448:<module>, cpu: 137.98ms, accelerator: 0us, total: 137.98ms
train.py:449:<module>, cpu: 97.40ms, accelerator: 92us, total: 97.49ms
  summary.py:146:image, cpu: 97.37ms, accelerator: 0us, total: 97.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_39500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.97%)
top 2 operation type: ImageSummary, cpu: 329.29ms, accelerator: 0us, total: 329.29ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 100.56ms, accelerator: 0us, total: 100.56ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
top 3 graph node: difference, cpu: 97.26ms, accelerator: 0us, total: 97.26ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.29ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.40ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.40ms, total: 7.31ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.89ms, total: 6.71ms
train.py:448:<module>, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
train.py:449:<module>, cpu: 97.29ms, accelerator: 91us, total: 97.39ms
  summary.py:146:image, cpu: 97.26ms, accelerator: 0us, total: 97.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_39750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.99%)
top 2 operation type: ImageSummary, cpu: 328.70ms, accelerator: 0us, total: 328.70ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 100.56ms, accelerator: 0us, total: 100.56ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.96ms, accelerator: 0us, total: 137.96ms
top 3 graph node: difference, cpu: 97.05ms, accelerator: 0us, total: 97.05ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.26ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.39ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.39ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.87ms, total: 6.68ms
train.py:448:<module>, cpu: 137.96ms, accelerator: 0us, total: 137.96ms
train.py:449:<module>, cpu: 97.09ms, accelerator: 91us, total: 97.18ms
  summary.py:146:image, cpu: 97.06ms, accelerator: 0us, total: 97.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_40000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.98%)
top 2 operation type: ImageSummary, cpu: 328.78ms, accelerator: 0us, total: 328.78ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 100.65ms, accelerator: 0us, total: 100.65ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
top 3 graph node: difference, cpu: 97.11ms, accelerator: 0us, total: 97.11ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.23ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.37ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.37ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.86ms, total: 6.66ms
train.py:448:<module>, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
train.py:449:<module>, cpu: 97.14ms, accelerator: 90us, total: 97.23ms
  summary.py:146:image, cpu: 97.11ms, accelerator: 0us, total: 97.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_40250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.99%)
top 2 operation type: ImageSummary, cpu: 329.08ms, accelerator: 0us, total: 329.08ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 100.50ms, accelerator: 0us, total: 100.50ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.01ms, accelerator: 0us, total: 138.01ms
top 3 graph node: difference, cpu: 97.18ms, accelerator: 0us, total: 97.18ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.21ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.36ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.36ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.85ms, total: 6.64ms
train.py:448:<module>, cpu: 138.02ms, accelerator: 0us, total: 138.02ms
train.py:449:<module>, cpu: 97.22ms, accelerator: 90us, total: 97.31ms
  summary.py:146:image, cpu: 97.18ms, accelerator: 0us, total: 97.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_40500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (94.00%)
top 2 operation type: ImageSummary, cpu: 328.62ms, accelerator: 0us, total: 328.62ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 100.51ms, accelerator: 0us, total: 100.51ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.83ms, accelerator: 0us, total: 137.83ms
top 3 graph node: difference, cpu: 97.14ms, accelerator: 0us, total: 97.14ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.20ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.35ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.35ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.85ms, total: 6.63ms
train.py:448:<module>, cpu: 137.84ms, accelerator: 0us, total: 137.84ms
train.py:449:<module>, cpu: 97.18ms, accelerator: 89us, total: 97.27ms
  summary.py:146:image, cpu: 97.14ms, accelerator: 0us, total: 97.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_40750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.98%)
top 2 operation type: ImageSummary, cpu: 328.35ms, accelerator: 0us, total: 328.35ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 101.20ms, accelerator: 0us, total: 101.20ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.76ms, accelerator: 0us, total: 137.76ms
top 3 graph node: difference, cpu: 96.94ms, accelerator: 0us, total: 96.94ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.18ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.33ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.33ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.84ms, total: 6.67ms
train.py:448:<module>, cpu: 137.77ms, accelerator: 0us, total: 137.77ms
train.py:449:<module>, cpu: 96.97ms, accelerator: 92us, total: 97.07ms
  summary.py:146:image, cpu: 96.94ms, accelerator: 0us, total: 96.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_41000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (94.00%)
top 2 operation type: ImageSummary, cpu: 327.95ms, accelerator: 0us, total: 327.95ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.05ms, accelerator: 0us, total: 101.05ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.47ms, accelerator: 0us, total: 137.47ms
top 3 graph node: difference, cpu: 97.01ms, accelerator: 0us, total: 97.01ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.32ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.32ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.83ms, total: 6.65ms
train.py:448:<module>, cpu: 137.48ms, accelerator: 0us, total: 137.48ms
train.py:449:<module>, cpu: 97.05ms, accelerator: 91us, total: 97.14ms
  summary.py:146:image, cpu: 97.01ms, accelerator: 0us, total: 97.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_41250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (94.00%)
top 2 operation type: ImageSummary, cpu: 327.80ms, accelerator: 0us, total: 327.80ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.31ms, accelerator: 0us, total: 101.31ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.35ms, accelerator: 0us, total: 137.35ms
top 3 graph node: difference, cpu: 96.86ms, accelerator: 0us, total: 96.86ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.13ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.31ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.31ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.82ms, total: 6.67ms
train.py:448:<module>, cpu: 137.35ms, accelerator: 0us, total: 137.35ms
train.py:449:<module>, cpu: 96.89ms, accelerator: 91us, total: 96.99ms
  summary.py:146:image, cpu: 96.86ms, accelerator: 0us, total: 96.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_41500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (94.00%)
top 2 operation type: ImageSummary, cpu: 327.69ms, accelerator: 0us, total: 327.69ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.22ms, accelerator: 0us, total: 101.22ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.44ms, accelerator: 0us, total: 137.44ms
top 3 graph node: difference, cpu: 96.89ms, accelerator: 0us, total: 96.89ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.11ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.30ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.30ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.81ms, total: 6.64ms
train.py:448:<module>, cpu: 137.44ms, accelerator: 0us, total: 137.44ms
train.py:449:<module>, cpu: 96.93ms, accelerator: 90us, total: 97.02ms
  summary.py:146:image, cpu: 96.90ms, accelerator: 0us, total: 96.90ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_41750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.97%)
top 2 operation type: ImageSummary, cpu: 329.18ms, accelerator: 0us, total: 329.18ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 101.31ms, accelerator: 0us, total: 101.31ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.86ms, accelerator: 0us, total: 137.86ms
top 3 graph node: difference, cpu: 97.41ms, accelerator: 0us, total: 97.41ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.17ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.28ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.28ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.89ms, total: 6.71ms
train.py:448:<module>, cpu: 137.87ms, accelerator: 0us, total: 137.87ms
train.py:449:<module>, cpu: 97.44ms, accelerator: 90us, total: 97.53ms
  summary.py:146:image, cpu: 97.41ms, accelerator: 0us, total: 97.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_42000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.96%)
top 2 operation type: ImageSummary, cpu: 329.16ms, accelerator: 0us, total: 329.16ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 101.36ms, accelerator: 0us, total: 101.36ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.89ms, accelerator: 0us, total: 137.89ms
top 3 graph node: difference, cpu: 97.34ms, accelerator: 0us, total: 97.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.15ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.27ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 2.27ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.85ms, accelerator: 2.88ms, total: 6.77ms
train.py:448:<module>, cpu: 137.89ms, accelerator: 0us, total: 137.89ms
train.py:449:<module>, cpu: 97.38ms, accelerator: 89us, total: 97.47ms
  summary.py:146:image, cpu: 97.35ms, accelerator: 0us, total: 97.35ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_42250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.97%)
top 2 operation type: ImageSummary, cpu: 328.92ms, accelerator: 0us, total: 328.92ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 101.28ms, accelerator: 0us, total: 101.28ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.92ms, accelerator: 0us, total: 137.92ms
top 3 graph node: difference, cpu: 97.23ms, accelerator: 0us, total: 97.23ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.19ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.27ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.27ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.84ms, accelerator: 2.92ms, total: 6.80ms
train.py:448:<module>, cpu: 137.93ms, accelerator: 0us, total: 137.93ms
train.py:449:<module>, cpu: 97.27ms, accelerator: 89us, total: 97.36ms
  summary.py:146:image, cpu: 97.24ms, accelerator: 0us, total: 97.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_42500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.99%)
top 2 operation type: ImageSummary, cpu: 328.46ms, accelerator: 0us, total: 328.46ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.32ms, accelerator: 0us, total: 101.32ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.72ms, accelerator: 0us, total: 137.72ms
top 3 graph node: difference, cpu: 97.20ms, accelerator: 0us, total: 97.20ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.22ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.30ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.30ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.83ms, accelerator: 2.91ms, total: 6.78ms
train.py:448:<module>, cpu: 137.72ms, accelerator: 0us, total: 137.72ms
train.py:449:<module>, cpu: 97.24ms, accelerator: 88us, total: 97.33ms
  summary.py:146:image, cpu: 97.20ms, accelerator: 0us, total: 97.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_42750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.99%)
top 2 operation type: ImageSummary, cpu: 328.48ms, accelerator: 0us, total: 328.48ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.21ms, accelerator: 0us, total: 101.21ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.66ms, accelerator: 0us, total: 137.66ms
top 3 graph node: difference, cpu: 97.32ms, accelerator: 0us, total: 97.32ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.26ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.30ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.30ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.82ms, accelerator: 2.97ms, total: 6.84ms
train.py:448:<module>, cpu: 137.67ms, accelerator: 0us, total: 137.67ms
train.py:449:<module>, cpu: 97.36ms, accelerator: 89us, total: 97.45ms
  summary.py:146:image, cpu: 97.32ms, accelerator: 0us, total: 97.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_43000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.98%)
top 2 operation type: ImageSummary, cpu: 329.24ms, accelerator: 0us, total: 329.24ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.44ms, accelerator: 0us, total: 101.44ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.90ms, accelerator: 0us, total: 137.90ms
top 3 graph node: difference, cpu: 97.47ms, accelerator: 0us, total: 97.47ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.24ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.29ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.29ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.96ms, total: 6.81ms
train.py:448:<module>, cpu: 137.90ms, accelerator: 0us, total: 137.90ms
train.py:449:<module>, cpu: 97.51ms, accelerator: 89us, total: 97.60ms
  summary.py:146:image, cpu: 97.48ms, accelerator: 0us, total: 97.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_43250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.98%)
top 2 operation type: ImageSummary, cpu: 328.98ms, accelerator: 0us, total: 328.98ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.61ms, accelerator: 0us, total: 101.61ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.66ms, accelerator: 0us, total: 137.66ms
top 3 graph node: difference, cpu: 97.68ms, accelerator: 0us, total: 97.68ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.21ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.27ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.27ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.94ms, total: 6.78ms
train.py:448:<module>, cpu: 137.67ms, accelerator: 0us, total: 137.67ms
train.py:449:<module>, cpu: 97.72ms, accelerator: 88us, total: 97.81ms
  summary.py:146:image, cpu: 97.69ms, accelerator: 0us, total: 97.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_43500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.99%)
top 2 operation type: ImageSummary, cpu: 328.62ms, accelerator: 0us, total: 328.62ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.50ms, accelerator: 0us, total: 101.50ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.50ms, accelerator: 0us, total: 137.50ms
top 3 graph node: difference, cpu: 97.62ms, accelerator: 0us, total: 97.62ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.19ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.26ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.26ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.93ms, total: 6.76ms
train.py:448:<module>, cpu: 137.51ms, accelerator: 0us, total: 137.51ms
train.py:449:<module>, cpu: 97.66ms, accelerator: 88us, total: 97.75ms
  summary.py:146:image, cpu: 97.63ms, accelerator: 0us, total: 97.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_43750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.98%)
top 2 operation type: ImageSummary, cpu: 328.92ms, accelerator: 0us, total: 328.92ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.50ms, accelerator: 0us, total: 101.50ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.54ms, accelerator: 0us, total: 137.54ms
top 3 graph node: difference, cpu: 97.64ms, accelerator: 0us, total: 97.64ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.29ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.25ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.25ms, total: 7.14ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 3.04ms, total: 6.86ms
train.py:448:<module>, cpu: 137.55ms, accelerator: 0us, total: 137.55ms
train.py:449:<module>, cpu: 97.67ms, accelerator: 87us, total: 97.76ms
  summary.py:146:image, cpu: 97.64ms, accelerator: 0us, total: 97.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_44000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.98%)
top 2 operation type: ImageSummary, cpu: 329.53ms, accelerator: 0us, total: 329.53ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 101.47ms, accelerator: 0us, total: 101.47ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.74ms, accelerator: 0us, total: 137.74ms
top 3 graph node: difference, cpu: 97.84ms, accelerator: 0us, total: 97.84ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.27ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.24ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.24ms, total: 7.13ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 3.02ms, total: 6.84ms
train.py:448:<module>, cpu: 137.74ms, accelerator: 0us, total: 137.74ms
train.py:449:<module>, cpu: 97.88ms, accelerator: 87us, total: 97.96ms
  summary.py:146:image, cpu: 97.84ms, accelerator: 0us, total: 97.84ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_44250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.99%)
top 2 operation type: ImageSummary, cpu: 329.46ms, accelerator: 0us, total: 329.46ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.69ms, accelerator: 0us, total: 101.69ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.74ms, accelerator: 0us, total: 137.74ms
top 3 graph node: difference, cpu: 97.66ms, accelerator: 0us, total: 97.66ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 5.24ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 2.23ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.23ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 3.01ms, total: 6.81ms
train.py:448:<module>, cpu: 137.74ms, accelerator: 0us, total: 137.74ms
train.py:449:<module>, cpu: 97.69ms, accelerator: 86us, total: 97.78ms
  summary.py:146:image, cpu: 97.66ms, accelerator: 0us, total: 97.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_44500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.98%)
top 2 operation type: ImageSummary, cpu: 329.83ms, accelerator: 0us, total: 329.83ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 101.87ms, accelerator: 0us, total: 101.87ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.76ms, accelerator: 0us, total: 137.76ms
top 3 graph node: difference, cpu: 97.71ms, accelerator: 0us, total: 97.71ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 5.25ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 2.22ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 2.22ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 3.03ms, total: 6.81ms
train.py:448:<module>, cpu: 137.77ms, accelerator: 0us, total: 137.77ms
train.py:449:<module>, cpu: 97.75ms, accelerator: 86us, total: 97.83ms
  summary.py:146:image, cpu: 97.72ms, accelerator: 0us, total: 97.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_44750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.97%)
top 2 operation type: ImageSummary, cpu: 330.48ms, accelerator: 0us, total: 330.48ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 101.63ms, accelerator: 0us, total: 101.63ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.00ms, accelerator: 0us, total: 138.00ms
top 3 graph node: difference, cpu: 97.94ms, accelerator: 0us, total: 97.94ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.22ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.21ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.21ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 3.02ms, total: 6.79ms
train.py:448:<module>, cpu: 138.01ms, accelerator: 0us, total: 138.01ms
train.py:449:<module>, cpu: 97.98ms, accelerator: 85us, total: 98.07ms
  summary.py:146:image, cpu: 97.95ms, accelerator: 0us, total: 97.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_45000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.96%)
top 2 operation type: ImageSummary, cpu: 330.51ms, accelerator: 0us, total: 330.51ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.87ms, accelerator: 0us, total: 102.87ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.94ms, accelerator: 0us, total: 137.94ms
top 3 graph node: difference, cpu: 97.98ms, accelerator: 0us, total: 97.98ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 5.20ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.20ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 2.20ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 3.00ms, total: 6.79ms
train.py:448:<module>, cpu: 137.94ms, accelerator: 0us, total: 137.94ms
train.py:449:<module>, cpu: 98.02ms, accelerator: 85us, total: 98.11ms
  summary.py:146:image, cpu: 97.99ms, accelerator: 0us, total: 97.99ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_45250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.97%)
top 2 operation type: ImageSummary, cpu: 330.15ms, accelerator: 0us, total: 330.15ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 102.74ms, accelerator: 0us, total: 102.74ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.81ms, accelerator: 0us, total: 137.81ms
top 3 graph node: difference, cpu: 97.88ms, accelerator: 0us, total: 97.88ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.17ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.19ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 2.19ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.98ms, total: 6.76ms
train.py:448:<module>, cpu: 137.82ms, accelerator: 0us, total: 137.82ms
train.py:449:<module>, cpu: 97.92ms, accelerator: 85us, total: 98.01ms
  summary.py:146:image, cpu: 97.89ms, accelerator: 0us, total: 97.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_45500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.96%)
top 2 operation type: ImageSummary, cpu: 330.42ms, accelerator: 0us, total: 330.42ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.72ms, accelerator: 0us, total: 102.72ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.00ms, accelerator: 0us, total: 138.00ms
top 3 graph node: difference, cpu: 97.82ms, accelerator: 0us, total: 97.82ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.17ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.19ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 2.19ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.98ms, total: 6.76ms
train.py:448:<module>, cpu: 138.01ms, accelerator: 0us, total: 138.01ms
train.py:449:<module>, cpu: 97.86ms, accelerator: 84us, total: 97.94ms
  summary.py:146:image, cpu: 97.82ms, accelerator: 0us, total: 97.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_45750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.97%)
top 2 operation type: ImageSummary, cpu: 330.38ms, accelerator: 0us, total: 330.38ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.50ms, accelerator: 0us, total: 102.50ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.98ms, accelerator: 0us, total: 137.98ms
top 3 graph node: difference, cpu: 97.89ms, accelerator: 0us, total: 97.89ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.15ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.18ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 2.18ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.97ms, total: 6.75ms
train.py:448:<module>, cpu: 137.99ms, accelerator: 0us, total: 137.99ms
train.py:449:<module>, cpu: 97.92ms, accelerator: 84us, total: 98.01ms
  summary.py:146:image, cpu: 97.89ms, accelerator: 0us, total: 97.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_46000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.96%)
top 2 operation type: ImageSummary, cpu: 330.58ms, accelerator: 0us, total: 330.58ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 103.09ms, accelerator: 0us, total: 103.09ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.97ms, accelerator: 0us, total: 137.97ms
top 3 graph node: difference, cpu: 97.78ms, accelerator: 0us, total: 97.78ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.12ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.17ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 2.17ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.95ms, total: 6.72ms
train.py:448:<module>, cpu: 137.97ms, accelerator: 0us, total: 137.97ms
train.py:449:<module>, cpu: 97.81ms, accelerator: 83us, total: 97.90ms
  summary.py:146:image, cpu: 97.78ms, accelerator: 0us, total: 97.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_46250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.95%)
top 2 operation type: ImageSummary, cpu: 331.27ms, accelerator: 0us, total: 331.27ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 103.06ms, accelerator: 0us, total: 103.06ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.15ms, accelerator: 0us, total: 138.15ms
top 3 graph node: difference, cpu: 97.96ms, accelerator: 0us, total: 97.96ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.26ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.30ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.30ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.96ms, total: 6.72ms
train.py:448:<module>, cpu: 138.16ms, accelerator: 0us, total: 138.16ms
train.py:449:<module>, cpu: 98.00ms, accelerator: 83us, total: 98.08ms
  summary.py:146:image, cpu: 97.96ms, accelerator: 0us, total: 97.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_46500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (93.96%)
top 2 operation type: ImageSummary, cpu: 331.29ms, accelerator: 0us, total: 331.29ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.88ms, accelerator: 0us, total: 102.88ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.34ms, accelerator: 0us, total: 138.34ms
top 3 graph node: difference, cpu: 97.79ms, accelerator: 0us, total: 97.79ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 5.24ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.29ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.29ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.95ms, total: 6.71ms
train.py:448:<module>, cpu: 138.34ms, accelerator: 0us, total: 138.34ms
train.py:449:<module>, cpu: 97.83ms, accelerator: 83us, total: 97.91ms
  summary.py:146:image, cpu: 97.80ms, accelerator: 0us, total: 97.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_46750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.94%)
top 2 operation type: ImageSummary, cpu: 331.95ms, accelerator: 0us, total: 331.95ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 103.11ms, accelerator: 0us, total: 103.11ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.46ms, accelerator: 0us, total: 138.46ms
top 3 graph node: difference, cpu: 97.99ms, accelerator: 0us, total: 97.99ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.22ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.28ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.28ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.94ms, total: 6.68ms
train.py:448:<module>, cpu: 138.47ms, accelerator: 0us, total: 138.47ms
train.py:449:<module>, cpu: 98.03ms, accelerator: 82us, total: 98.11ms
  summary.py:146:image, cpu: 97.99ms, accelerator: 0us, total: 97.99ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_47000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.94%)
top 2 operation type: ImageSummary, cpu: 331.71ms, accelerator: 0us, total: 331.71ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 103.12ms, accelerator: 0us, total: 103.12ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.52ms, accelerator: 0us, total: 138.52ms
top 3 graph node: difference, cpu: 97.89ms, accelerator: 0us, total: 97.89ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.22ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.27ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.27ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.96ms, total: 6.70ms
train.py:448:<module>, cpu: 138.52ms, accelerator: 0us, total: 138.52ms
train.py:449:<module>, cpu: 97.93ms, accelerator: 82us, total: 98.01ms
  summary.py:146:image, cpu: 97.90ms, accelerator: 0us, total: 97.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_47250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.95%)
top 2 operation type: ImageSummary, cpu: 331.17ms, accelerator: 0us, total: 331.17ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 103.03ms, accelerator: 0us, total: 103.03ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.44ms, accelerator: 0us, total: 138.44ms
top 3 graph node: difference, cpu: 97.66ms, accelerator: 0us, total: 97.66ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.21ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.26ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.26ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.96ms, total: 6.68ms
train.py:448:<module>, cpu: 138.45ms, accelerator: 0us, total: 138.45ms
train.py:449:<module>, cpu: 97.70ms, accelerator: 81us, total: 97.78ms
  summary.py:146:image, cpu: 97.66ms, accelerator: 0us, total: 97.66ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_47500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.95%)
top 2 operation type: ImageSummary, cpu: 331.08ms, accelerator: 0us, total: 331.08ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 103.10ms, accelerator: 0us, total: 103.10ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.53ms, accelerator: 0us, total: 138.53ms
top 3 graph node: difference, cpu: 97.57ms, accelerator: 0us, total: 97.57ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.19ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.25ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.25ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.94ms, total: 6.67ms
train.py:448:<module>, cpu: 138.53ms, accelerator: 0us, total: 138.53ms
train.py:449:<module>, cpu: 97.61ms, accelerator: 81us, total: 97.69ms
  summary.py:146:image, cpu: 97.58ms, accelerator: 0us, total: 97.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_47750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.96%)
top 2 operation type: ImageSummary, cpu: 330.94ms, accelerator: 0us, total: 330.94ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 103.24ms, accelerator: 0us, total: 103.24ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.53ms, accelerator: 0us, total: 138.53ms
top 3 graph node: difference, cpu: 97.43ms, accelerator: 0us, total: 97.43ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.17ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.24ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.24ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.93ms, total: 6.65ms
train.py:448:<module>, cpu: 138.54ms, accelerator: 0us, total: 138.54ms
train.py:449:<module>, cpu: 97.47ms, accelerator: 81us, total: 97.55ms
  summary.py:146:image, cpu: 97.43ms, accelerator: 0us, total: 97.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_48000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.95%)
top 2 operation type: ImageSummary, cpu: 330.88ms, accelerator: 0us, total: 330.88ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 103.21ms, accelerator: 0us, total: 103.21ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.63ms, accelerator: 0us, total: 138.63ms
top 3 graph node: difference, cpu: 97.43ms, accelerator: 0us, total: 97.43ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.17ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.23ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.23ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.94ms, total: 6.64ms
train.py:448:<module>, cpu: 138.64ms, accelerator: 0us, total: 138.64ms
train.py:449:<module>, cpu: 97.46ms, accelerator: 80us, total: 97.54ms
  summary.py:146:image, cpu: 97.43ms, accelerator: 0us, total: 97.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_48250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.94%)
top 2 operation type: ImageSummary, cpu: 330.72ms, accelerator: 0us, total: 330.72ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 103.34ms, accelerator: 0us, total: 103.34ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.60ms, accelerator: 0us, total: 138.60ms
top 3 graph node: difference, cpu: 97.28ms, accelerator: 0us, total: 97.28ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.24ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.27ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.27ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.97ms, total: 6.67ms
train.py:448:<module>, cpu: 138.60ms, accelerator: 0us, total: 138.60ms
train.py:449:<module>, cpu: 97.31ms, accelerator: 80us, total: 97.39ms
  summary.py:146:image, cpu: 97.28ms, accelerator: 0us, total: 97.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_48500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.95%)
top 2 operation type: ImageSummary, cpu: 330.85ms, accelerator: 0us, total: 330.85ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 103.25ms, accelerator: 0us, total: 103.25ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.62ms, accelerator: 0us, total: 138.62ms
top 3 graph node: difference, cpu: 97.39ms, accelerator: 0us, total: 97.39ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.22ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.26ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.26ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.96ms, total: 6.67ms
train.py:448:<module>, cpu: 138.62ms, accelerator: 0us, total: 138.62ms
train.py:449:<module>, cpu: 97.42ms, accelerator: 79us, total: 97.50ms
  summary.py:146:image, cpu: 97.39ms, accelerator: 0us, total: 97.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_48750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (93.95%)
top 2 operation type: ImageSummary, cpu: 330.98ms, accelerator: 0us, total: 330.98ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 103.12ms, accelerator: 0us, total: 103.12ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.72ms, accelerator: 0us, total: 138.72ms
top 3 graph node: difference, cpu: 97.44ms, accelerator: 0us, total: 97.44ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 5.19ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.25ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.25ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.95ms, total: 6.64ms
train.py:448:<module>, cpu: 138.72ms, accelerator: 0us, total: 138.72ms
train.py:449:<module>, cpu: 97.47ms, accelerator: 79us, total: 97.55ms
  summary.py:146:image, cpu: 97.44ms, accelerator: 0us, total: 97.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_49000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.95%)
top 2 operation type: ImageSummary, cpu: 330.81ms, accelerator: 0us, total: 330.81ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 102.96ms, accelerator: 0us, total: 102.96ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.72ms, accelerator: 0us, total: 138.72ms
top 3 graph node: difference, cpu: 97.35ms, accelerator: 0us, total: 97.35ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.18ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.24ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.24ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.94ms, total: 6.63ms
train.py:448:<module>, cpu: 138.73ms, accelerator: 0us, total: 138.73ms
train.py:449:<module>, cpu: 97.39ms, accelerator: 79us, total: 97.47ms
  summary.py:146:image, cpu: 97.35ms, accelerator: 0us, total: 97.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_49250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.95%)
top 2 operation type: ImageSummary, cpu: 330.43ms, accelerator: 0us, total: 330.43ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 102.99ms, accelerator: 0us, total: 102.99ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.53ms, accelerator: 0us, total: 138.53ms
top 3 graph node: difference, cpu: 97.35ms, accelerator: 0us, total: 97.35ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.15ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.23ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.23ms, total: 7.13ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.93ms, total: 6.65ms
train.py:448:<module>, cpu: 138.54ms, accelerator: 0us, total: 138.54ms
train.py:449:<module>, cpu: 97.39ms, accelerator: 78us, total: 97.47ms
  summary.py:146:image, cpu: 97.36ms, accelerator: 0us, total: 97.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_49500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.94%)
top 2 operation type: ImageSummary, cpu: 330.41ms, accelerator: 0us, total: 330.41ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 102.87ms, accelerator: 0us, total: 102.87ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.62ms, accelerator: 0us, total: 138.62ms
top 3 graph node: difference, cpu: 97.35ms, accelerator: 0us, total: 97.35ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.14ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.22ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.22ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.92ms, total: 6.65ms
train.py:448:<module>, cpu: 138.63ms, accelerator: 0us, total: 138.63ms
train.py:449:<module>, cpu: 97.39ms, accelerator: 78us, total: 97.47ms
  summary.py:146:image, cpu: 97.36ms, accelerator: 0us, total: 97.36ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_49750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.96ms, accelerator: 0us, total: 329.96ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 102.84ms, accelerator: 0us, total: 102.84ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.48ms, accelerator: 0us, total: 138.48ms
top 3 graph node: difference, cpu: 97.20ms, accelerator: 0us, total: 97.20ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.23ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.21ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.21ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 3.02ms, total: 6.79ms
train.py:448:<module>, cpu: 138.49ms, accelerator: 0us, total: 138.49ms
train.py:449:<module>, cpu: 97.24ms, accelerator: 78us, total: 97.32ms
  summary.py:146:image, cpu: 97.21ms, accelerator: 0us, total: 97.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_50000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.84ms, accelerator: 0us, total: 329.84ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.85ms, accelerator: 0us, total: 102.85ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.47ms, accelerator: 0us, total: 138.47ms
top 3 graph node: difference, cpu: 97.19ms, accelerator: 0us, total: 97.19ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.21ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.20ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.20ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 3.01ms, total: 6.77ms
train.py:448:<module>, cpu: 138.47ms, accelerator: 0us, total: 138.47ms
train.py:449:<module>, cpu: 97.22ms, accelerator: 77us, total: 97.30ms
  summary.py:146:image, cpu: 97.19ms, accelerator: 0us, total: 97.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_50250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.94%)
top 2 operation type: ImageSummary, cpu: 330.19ms, accelerator: 0us, total: 330.19ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 103.02ms, accelerator: 0us, total: 103.02ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.54ms, accelerator: 0us, total: 138.54ms
top 3 graph node: difference, cpu: 97.33ms, accelerator: 0us, total: 97.33ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.22ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.19ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 2.19ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 3.03ms, total: 6.78ms
train.py:448:<module>, cpu: 138.55ms, accelerator: 0us, total: 138.55ms
train.py:449:<module>, cpu: 97.37ms, accelerator: 77us, total: 97.45ms
  summary.py:146:image, cpu: 97.34ms, accelerator: 0us, total: 97.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_50500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.93%)
top 2 operation type: ImageSummary, cpu: 329.97ms, accelerator: 0us, total: 329.97ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 103.01ms, accelerator: 0us, total: 103.01ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.37ms, accelerator: 0us, total: 138.37ms
top 3 graph node: difference, cpu: 97.32ms, accelerator: 0us, total: 97.32ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.20ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.18ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 2.18ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 3.02ms, total: 6.76ms
train.py:448:<module>, cpu: 138.37ms, accelerator: 0us, total: 138.37ms
train.py:449:<module>, cpu: 97.36ms, accelerator: 77us, total: 97.44ms
  summary.py:146:image, cpu: 97.33ms, accelerator: 0us, total: 97.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_50750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.50ms, accelerator: 0us, total: 329.50ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.89ms, accelerator: 0us, total: 102.89ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.16ms, accelerator: 0us, total: 138.16ms
top 3 graph node: difference, cpu: 97.23ms, accelerator: 0us, total: 97.23ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.19ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.18ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 2.18ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 3.01ms, total: 6.74ms
train.py:448:<module>, cpu: 138.16ms, accelerator: 0us, total: 138.16ms
train.py:449:<module>, cpu: 97.27ms, accelerator: 76us, total: 97.35ms
  summary.py:146:image, cpu: 97.24ms, accelerator: 0us, total: 97.24ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_51000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.48ms, accelerator: 0us, total: 329.48ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.81ms, accelerator: 0us, total: 102.81ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.99ms, accelerator: 0us, total: 137.99ms
top 3 graph node: difference, cpu: 97.21ms, accelerator: 0us, total: 97.21ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.17ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.17ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 2.17ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 3.00ms, total: 6.71ms
train.py:448:<module>, cpu: 137.99ms, accelerator: 0us, total: 137.99ms
train.py:449:<module>, cpu: 97.25ms, accelerator: 76us, total: 97.33ms
  summary.py:146:image, cpu: 97.22ms, accelerator: 0us, total: 97.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_51250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.94%)
top 2 operation type: ImageSummary, cpu: 329.53ms, accelerator: 0us, total: 329.53ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.82ms, accelerator: 0us, total: 102.82ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
top 3 graph node: difference, cpu: 97.26ms, accelerator: 0us, total: 97.26ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.23ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.16ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 2.16ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 3.06ms, total: 6.77ms
train.py:448:<module>, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
train.py:449:<module>, cpu: 97.29ms, accelerator: 75us, total: 97.37ms
  summary.py:146:image, cpu: 97.26ms, accelerator: 0us, total: 97.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_51500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.43ms, accelerator: 0us, total: 329.43ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.76ms, accelerator: 0us, total: 102.76ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.92ms, accelerator: 0us, total: 137.92ms
top 3 graph node: difference, cpu: 97.49ms, accelerator: 0us, total: 97.49ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.20ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.15ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 2.15ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 3.05ms, total: 6.75ms
train.py:448:<module>, cpu: 137.93ms, accelerator: 0us, total: 137.93ms
train.py:449:<module>, cpu: 97.53ms, accelerator: 75us, total: 97.61ms
  summary.py:146:image, cpu: 97.50ms, accelerator: 0us, total: 97.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_51750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.23ms, accelerator: 0us, total: 329.23ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 102.94ms, accelerator: 0us, total: 102.94ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.98ms, accelerator: 0us, total: 137.98ms
top 3 graph node: difference, cpu: 97.36ms, accelerator: 0us, total: 97.36ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.19ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.15ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 2.15ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 3.04ms, total: 6.73ms
train.py:448:<module>, cpu: 137.99ms, accelerator: 0us, total: 137.99ms
train.py:449:<module>, cpu: 97.40ms, accelerator: 75us, total: 97.47ms
  summary.py:146:image, cpu: 97.37ms, accelerator: 0us, total: 97.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_52000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.95%)
top 2 operation type: ImageSummary, cpu: 329.07ms, accelerator: 0us, total: 329.07ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.88ms, accelerator: 0us, total: 102.88ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.90ms, accelerator: 0us, total: 137.90ms
top 3 graph node: difference, cpu: 97.44ms, accelerator: 0us, total: 97.44ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.17ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.14ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 2.14ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 3.03ms, total: 6.72ms
train.py:448:<module>, cpu: 137.90ms, accelerator: 0us, total: 137.90ms
train.py:449:<module>, cpu: 97.48ms, accelerator: 74us, total: 97.55ms
  summary.py:146:image, cpu: 97.44ms, accelerator: 0us, total: 97.44ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_52250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.95%)
top 2 operation type: ImageSummary, cpu: 328.81ms, accelerator: 0us, total: 328.81ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.84ms, accelerator: 0us, total: 102.84ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.73ms, accelerator: 0us, total: 137.73ms
top 3 graph node: difference, cpu: 97.34ms, accelerator: 0us, total: 97.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.15ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.13ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 2.13ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 3.02ms, total: 6.70ms
train.py:448:<module>, cpu: 137.74ms, accelerator: 0us, total: 137.74ms
train.py:449:<module>, cpu: 97.38ms, accelerator: 74us, total: 97.45ms
  summary.py:146:image, cpu: 97.35ms, accelerator: 0us, total: 97.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_52500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.95%)
top 2 operation type: ImageSummary, cpu: 328.61ms, accelerator: 0us, total: 328.61ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.74ms, accelerator: 0us, total: 102.74ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.67ms, accelerator: 0us, total: 137.67ms
top 3 graph node: difference, cpu: 97.33ms, accelerator: 0us, total: 97.33ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.13ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.12ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 2.12ms, total: 7.13ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 3.01ms, total: 6.68ms
train.py:448:<module>, cpu: 137.68ms, accelerator: 0us, total: 137.68ms
train.py:449:<module>, cpu: 97.36ms, accelerator: 74us, total: 97.44ms
  summary.py:146:image, cpu: 97.33ms, accelerator: 0us, total: 97.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_52750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.95%)
top 2 operation type: ImageSummary, cpu: 328.66ms, accelerator: 0us, total: 328.66ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.85ms, accelerator: 0us, total: 102.85ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.79ms, accelerator: 0us, total: 137.79ms
top 3 graph node: difference, cpu: 97.36ms, accelerator: 0us, total: 97.36ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.11ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.11ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 2.11ms, total: 7.11ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 3.00ms, total: 6.66ms
train.py:448:<module>, cpu: 137.79ms, accelerator: 0us, total: 137.79ms
train.py:449:<module>, cpu: 97.40ms, accelerator: 74us, total: 97.47ms
  summary.py:146:image, cpu: 97.37ms, accelerator: 0us, total: 97.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2122.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_53000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.95%)
top 2 operation type: ImageSummary, cpu: 328.68ms, accelerator: 0us, total: 328.68ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.80ms, accelerator: 0us, total: 102.80ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.83ms, accelerator: 0us, total: 137.83ms
top 3 graph node: difference, cpu: 97.35ms, accelerator: 0us, total: 97.35ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.09ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.10ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.10ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.99ms, total: 6.64ms
train.py:448:<module>, cpu: 137.84ms, accelerator: 0us, total: 137.84ms
train.py:449:<module>, cpu: 97.39ms, accelerator: 73us, total: 97.47ms
  summary.py:146:image, cpu: 97.36ms, accelerator: 0us, total: 97.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2127.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_53250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.31ms, accelerator: 0us, total: 328.31ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 102.68ms, accelerator: 0us, total: 102.68ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.68ms, accelerator: 0us, total: 137.68ms
top 3 graph node: difference, cpu: 97.24ms, accelerator: 0us, total: 97.24ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.07ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.09ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.09ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 2.98ms, total: 6.62ms
train.py:448:<module>, cpu: 137.69ms, accelerator: 0us, total: 137.69ms
train.py:449:<module>, cpu: 97.28ms, accelerator: 73us, total: 97.36ms
  summary.py:146:image, cpu: 97.25ms, accelerator: 0us, total: 97.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_53500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.97%)
top 2 operation type: ImageSummary, cpu: 328.23ms, accelerator: 0us, total: 328.23ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 102.64ms, accelerator: 0us, total: 102.64ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.47ms, accelerator: 0us, total: 137.47ms
top 3 graph node: difference, cpu: 97.26ms, accelerator: 0us, total: 97.26ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.04ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.08ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.08ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 2.96ms, total: 6.61ms
train.py:448:<module>, cpu: 137.48ms, accelerator: 0us, total: 137.48ms
train.py:449:<module>, cpu: 97.30ms, accelerator: 73us, total: 97.37ms
  summary.py:146:image, cpu: 97.27ms, accelerator: 0us, total: 97.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_53750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.63ms, accelerator: 0us, total: 328.63ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.50ms, accelerator: 0us, total: 102.50ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.60ms, accelerator: 0us, total: 137.60ms
top 3 graph node: difference, cpu: 97.36ms, accelerator: 0us, total: 97.36ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.03ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.08ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 2.08ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.96ms, total: 6.61ms
train.py:448:<module>, cpu: 137.61ms, accelerator: 0us, total: 137.61ms
train.py:449:<module>, cpu: 97.40ms, accelerator: 72us, total: 97.47ms
  summary.py:146:image, cpu: 97.37ms, accelerator: 0us, total: 97.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_54000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.30ms, accelerator: 0us, total: 328.30ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.46ms, accelerator: 0us, total: 102.46ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.48ms, accelerator: 0us, total: 137.48ms
top 3 graph node: difference, cpu: 97.31ms, accelerator: 0us, total: 97.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.01ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.07ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 2.07ms, total: 7.14ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.94ms, total: 6.60ms
train.py:448:<module>, cpu: 137.48ms, accelerator: 0us, total: 137.48ms
train.py:449:<module>, cpu: 97.34ms, accelerator: 72us, total: 97.42ms
  summary.py:146:image, cpu: 97.31ms, accelerator: 0us, total: 97.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_54250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.21ms, accelerator: 0us, total: 328.21ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.28ms, accelerator: 0us, total: 102.28ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.35ms, accelerator: 0us, total: 137.35ms
top 3 graph node: difference, cpu: 97.25ms, accelerator: 0us, total: 97.25ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.99ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.06ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.04ms, accelerator: 2.06ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 2.93ms, total: 6.58ms
train.py:448:<module>, cpu: 137.36ms, accelerator: 0us, total: 137.36ms
train.py:449:<module>, cpu: 97.28ms, accelerator: 72us, total: 97.36ms
  summary.py:146:image, cpu: 97.25ms, accelerator: 0us, total: 97.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_54500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.62ms, accelerator: 0us, total: 328.62ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.28ms, accelerator: 0us, total: 102.28ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.47ms, accelerator: 0us, total: 137.47ms
top 3 graph node: difference, cpu: 97.43ms, accelerator: 0us, total: 97.43ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.97ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.05ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.02ms, accelerator: 2.05ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 2.92ms, total: 6.56ms
train.py:448:<module>, cpu: 137.47ms, accelerator: 0us, total: 137.47ms
train.py:449:<module>, cpu: 97.47ms, accelerator: 71us, total: 97.54ms
  summary.py:146:image, cpu: 97.43ms, accelerator: 0us, total: 97.43ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_54750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.97%)
top 2 operation type: ImageSummary, cpu: 328.67ms, accelerator: 0us, total: 328.67ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.10ms, accelerator: 0us, total: 102.10ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.50ms, accelerator: 0us, total: 137.50ms
top 3 graph node: difference, cpu: 97.33ms, accelerator: 0us, total: 97.33ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.95ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.04ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.03ms, accelerator: 2.04ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 2.91ms, total: 6.55ms
train.py:448:<module>, cpu: 137.50ms, accelerator: 0us, total: 137.50ms
train.py:449:<module>, cpu: 97.37ms, accelerator: 71us, total: 97.44ms
  summary.py:146:image, cpu: 97.34ms, accelerator: 0us, total: 97.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_55000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.49ms, accelerator: 0us, total: 328.49ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.02ms, accelerator: 0us, total: 102.02ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.29ms, accelerator: 0us, total: 137.29ms
top 3 graph node: difference, cpu: 97.37ms, accelerator: 0us, total: 97.37ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.12ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 2.15ms, total: 7.19ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 2.96ms, total: 6.62ms
train.py:448:<module>, cpu: 137.30ms, accelerator: 0us, total: 137.30ms
train.py:449:<module>, cpu: 97.41ms, accelerator: 71us, total: 97.48ms
  summary.py:146:image, cpu: 97.38ms, accelerator: 0us, total: 97.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_55250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.52ms, accelerator: 0us, total: 328.52ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.03ms, accelerator: 0us, total: 102.03ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.25ms, accelerator: 0us, total: 137.25ms
top 3 graph node: difference, cpu: 97.33ms, accelerator: 0us, total: 97.33ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.09ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 2.14ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 2.95ms, total: 6.59ms
train.py:448:<module>, cpu: 137.25ms, accelerator: 0us, total: 137.25ms
train.py:449:<module>, cpu: 97.36ms, accelerator: 70us, total: 97.44ms
  summary.py:146:image, cpu: 97.33ms, accelerator: 0us, total: 97.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_55500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.40ms, accelerator: 0us, total: 328.40ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.00ms, accelerator: 0us, total: 102.00ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.28ms, accelerator: 0us, total: 137.28ms
top 3 graph node: difference, cpu: 97.22ms, accelerator: 0us, total: 97.22ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.07ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.13ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 2.13ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 2.94ms, total: 6.58ms
train.py:448:<module>, cpu: 137.29ms, accelerator: 0us, total: 137.29ms
train.py:449:<module>, cpu: 97.25ms, accelerator: 70us, total: 97.33ms
  summary.py:146:image, cpu: 97.22ms, accelerator: 0us, total: 97.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_55750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.74ms, accelerator: 0us, total: 328.74ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.20ms, accelerator: 0us, total: 102.20ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.30ms, accelerator: 0us, total: 137.30ms
top 3 graph node: difference, cpu: 97.30ms, accelerator: 0us, total: 97.30ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.05ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.02ms, accelerator: 2.13ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.93ms, total: 6.59ms
train.py:448:<module>, cpu: 137.30ms, accelerator: 0us, total: 137.30ms
train.py:449:<module>, cpu: 97.34ms, accelerator: 70us, total: 97.41ms
  summary.py:146:image, cpu: 97.30ms, accelerator: 0us, total: 97.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_56000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.45ms, accelerator: 0us, total: 328.45ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.08ms, accelerator: 0us, total: 102.08ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.10ms, accelerator: 0us, total: 137.10ms
top 3 graph node: difference, cpu: 97.15ms, accelerator: 0us, total: 97.15ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.04ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.12ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 2.12ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 2.92ms, total: 6.57ms
train.py:448:<module>, cpu: 137.11ms, accelerator: 0us, total: 137.11ms
train.py:449:<module>, cpu: 97.19ms, accelerator: 69us, total: 97.26ms
  summary.py:146:image, cpu: 97.16ms, accelerator: 0us, total: 97.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_56250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.66ms, accelerator: 0us, total: 328.66ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.30ms, accelerator: 0us, total: 102.30ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.25ms, accelerator: 0us, total: 137.25ms
top 3 graph node: difference, cpu: 97.29ms, accelerator: 0us, total: 97.29ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.03ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.12ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.09ms, accelerator: 2.12ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 2.91ms, total: 6.56ms
train.py:448:<module>, cpu: 137.26ms, accelerator: 0us, total: 137.26ms
train.py:449:<module>, cpu: 97.32ms, accelerator: 69us, total: 97.39ms
  summary.py:146:image, cpu: 97.29ms, accelerator: 0us, total: 97.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_56500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.24ms, accelerator: 0us, total: 328.24ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.19ms, accelerator: 0us, total: 102.19ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.09ms, accelerator: 0us, total: 137.09ms
top 3 graph node: difference, cpu: 97.18ms, accelerator: 0us, total: 97.18ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.07ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.08ms, accelerator: 2.16ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 2.91ms, total: 6.56ms
train.py:448:<module>, cpu: 137.10ms, accelerator: 0us, total: 137.10ms
train.py:449:<module>, cpu: 97.22ms, accelerator: 69us, total: 97.29ms
  summary.py:146:image, cpu: 97.19ms, accelerator: 0us, total: 97.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_56750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.97%)
top 2 operation type: ImageSummary, cpu: 328.16ms, accelerator: 0us, total: 328.16ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 102.15ms, accelerator: 0us, total: 102.15ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.12ms, accelerator: 0us, total: 137.12ms
top 3 graph node: difference, cpu: 97.17ms, accelerator: 0us, total: 97.17ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.06ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.07ms, accelerator: 2.15ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 2.90ms, total: 6.54ms
train.py:448:<module>, cpu: 137.12ms, accelerator: 0us, total: 137.12ms
train.py:449:<module>, cpu: 97.21ms, accelerator: 69us, total: 97.28ms
  summary.py:146:image, cpu: 97.18ms, accelerator: 0us, total: 97.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_57000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 327.90ms, accelerator: 0us, total: 327.90ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 102.49ms, accelerator: 0us, total: 102.49ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.98ms, accelerator: 0us, total: 136.98ms
top 3 graph node: difference, cpu: 97.09ms, accelerator: 0us, total: 97.09ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.06ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.06ms, accelerator: 2.15ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 2.91ms, total: 6.54ms
train.py:448:<module>, cpu: 136.99ms, accelerator: 0us, total: 136.99ms
train.py:449:<module>, cpu: 97.13ms, accelerator: 68us, total: 97.20ms
  summary.py:146:image, cpu: 97.10ms, accelerator: 0us, total: 97.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_57250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.96%)
top 2 operation type: ImageSummary, cpu: 328.07ms, accelerator: 0us, total: 328.07ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 102.97ms, accelerator: 0us, total: 102.97ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.08ms, accelerator: 0us, total: 137.08ms
top 3 graph node: difference, cpu: 97.10ms, accelerator: 0us, total: 97.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.03ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 2.13ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 2.90ms, total: 6.53ms
train.py:448:<module>, cpu: 137.09ms, accelerator: 0us, total: 137.09ms
train.py:449:<module>, cpu: 97.14ms, accelerator: 68us, total: 97.21ms
  summary.py:146:image, cpu: 97.11ms, accelerator: 0us, total: 97.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_57500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.97%)
top 2 operation type: ImageSummary, cpu: 327.60ms, accelerator: 0us, total: 327.60ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.77ms, accelerator: 0us, total: 102.77ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.97ms, accelerator: 0us, total: 136.97ms
top 3 graph node: difference, cpu: 96.92ms, accelerator: 0us, total: 96.92ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.02ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.13ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.04ms, accelerator: 2.13ms, total: 7.19ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.89ms, total: 6.56ms
train.py:448:<module>, cpu: 136.98ms, accelerator: 0us, total: 136.98ms
train.py:449:<module>, cpu: 96.96ms, accelerator: 68us, total: 97.03ms
  summary.py:146:image, cpu: 96.93ms, accelerator: 0us, total: 96.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_57750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.97%)
top 2 operation type: ImageSummary, cpu: 327.73ms, accelerator: 0us, total: 327.73ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 102.65ms, accelerator: 0us, total: 102.65ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.87ms, accelerator: 0us, total: 136.87ms
top 3 graph node: difference, cpu: 96.97ms, accelerator: 0us, total: 96.97ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.01ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.12ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.03ms, accelerator: 2.12ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 2.89ms, total: 6.54ms
train.py:448:<module>, cpu: 136.87ms, accelerator: 0us, total: 136.87ms
train.py:449:<module>, cpu: 97.01ms, accelerator: 67us, total: 97.08ms
  summary.py:146:image, cpu: 96.97ms, accelerator: 0us, total: 96.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_58000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.97%)
top 2 operation type: ImageSummary, cpu: 327.42ms, accelerator: 0us, total: 327.42ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.66ms, accelerator: 0us, total: 102.66ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.68ms, accelerator: 0us, total: 136.68ms
top 3 graph node: difference, cpu: 96.95ms, accelerator: 0us, total: 96.95ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.00ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.12ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.03ms, accelerator: 2.12ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 2.88ms, total: 6.54ms
train.py:448:<module>, cpu: 136.69ms, accelerator: 0us, total: 136.69ms
train.py:449:<module>, cpu: 96.99ms, accelerator: 67us, total: 97.06ms
  summary.py:146:image, cpu: 96.96ms, accelerator: 0us, total: 96.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_58250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.97%)
top 2 operation type: ImageSummary, cpu: 327.51ms, accelerator: 0us, total: 327.51ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 102.56ms, accelerator: 0us, total: 102.56ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.77ms, accelerator: 0us, total: 136.77ms
top 3 graph node: difference, cpu: 96.80ms, accelerator: 0us, total: 96.80ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.03ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 2.16ms, total: 7.19ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.87ms, total: 6.58ms
train.py:448:<module>, cpu: 136.77ms, accelerator: 0us, total: 136.77ms
train.py:449:<module>, cpu: 96.83ms, accelerator: 67us, total: 96.90ms
  summary.py:146:image, cpu: 96.80ms, accelerator: 0us, total: 96.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_58500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.98%)
top 2 operation type: ImageSummary, cpu: 327.18ms, accelerator: 0us, total: 327.18ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.51ms, accelerator: 0us, total: 102.51ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.60ms, accelerator: 0us, total: 136.60ms
top 3 graph node: difference, cpu: 96.65ms, accelerator: 0us, total: 96.65ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.00ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 2.15ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.86ms, total: 6.58ms
train.py:448:<module>, cpu: 136.61ms, accelerator: 0us, total: 136.61ms
train.py:449:<module>, cpu: 96.69ms, accelerator: 67us, total: 96.75ms
  summary.py:146:image, cpu: 96.65ms, accelerator: 0us, total: 96.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_58750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.98%)
top 2 operation type: ImageSummary, cpu: 326.87ms, accelerator: 0us, total: 326.87ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.53ms, accelerator: 0us, total: 102.53ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.40ms, accelerator: 0us, total: 136.40ms
top 3 graph node: difference, cpu: 96.64ms, accelerator: 0us, total: 96.64ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.99ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 2.14ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.85ms, total: 6.56ms
train.py:448:<module>, cpu: 136.41ms, accelerator: 0us, total: 136.41ms
train.py:449:<module>, cpu: 96.68ms, accelerator: 66us, total: 96.75ms
  summary.py:146:image, cpu: 96.65ms, accelerator: 0us, total: 96.65ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_59000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.98%)
top 2 operation type: ImageSummary, cpu: 327.02ms, accelerator: 0us, total: 327.02ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.45ms, accelerator: 0us, total: 102.45ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.50ms, accelerator: 0us, total: 136.50ms
top 3 graph node: difference, cpu: 96.74ms, accelerator: 0us, total: 96.74ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.97ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 2.13ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.84ms, total: 6.54ms
train.py:448:<module>, cpu: 136.51ms, accelerator: 0us, total: 136.51ms
train.py:449:<module>, cpu: 96.78ms, accelerator: 66us, total: 96.84ms
  summary.py:146:image, cpu: 96.74ms, accelerator: 0us, total: 96.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_59250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.98%)
top 2 operation type: ImageSummary, cpu: 326.82ms, accelerator: 0us, total: 326.82ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.46ms, accelerator: 0us, total: 102.46ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.52ms, accelerator: 0us, total: 136.52ms
top 3 graph node: difference, cpu: 96.63ms, accelerator: 0us, total: 96.63ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.95ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.12ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 2.12ms, total: 7.14ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.82ms, total: 6.53ms
train.py:448:<module>, cpu: 136.53ms, accelerator: 0us, total: 136.53ms
train.py:449:<module>, cpu: 96.67ms, accelerator: 66us, total: 96.74ms
  summary.py:146:image, cpu: 96.64ms, accelerator: 0us, total: 96.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_59500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.98%)
top 2 operation type: ImageSummary, cpu: 326.74ms, accelerator: 0us, total: 326.74ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.44ms, accelerator: 0us, total: 102.44ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.40ms, accelerator: 0us, total: 136.40ms
top 3 graph node: difference, cpu: 96.70ms, accelerator: 0us, total: 96.70ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.96ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.12ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 2.12ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.84ms, total: 6.54ms
train.py:448:<module>, cpu: 136.40ms, accelerator: 0us, total: 136.40ms
train.py:449:<module>, cpu: 96.74ms, accelerator: 66us, total: 96.81ms
  summary.py:146:image, cpu: 96.71ms, accelerator: 0us, total: 96.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_59750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.98%)
top 2 operation type: ImageSummary, cpu: 326.52ms, accelerator: 0us, total: 326.52ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.42ms, accelerator: 0us, total: 102.42ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.26ms, accelerator: 0us, total: 136.26ms
top 3 graph node: difference, cpu: 96.78ms, accelerator: 0us, total: 96.78ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.96ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.11ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.97ms, accelerator: 2.11ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.85ms, total: 6.58ms
train.py:448:<module>, cpu: 136.26ms, accelerator: 0us, total: 136.26ms
train.py:449:<module>, cpu: 96.82ms, accelerator: 65us, total: 96.89ms
  summary.py:146:image, cpu: 96.79ms, accelerator: 0us, total: 96.79ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_60000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.98%)
top 2 operation type: ImageSummary, cpu: 327.13ms, accelerator: 0us, total: 327.13ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.34ms, accelerator: 0us, total: 102.34ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.35ms, accelerator: 0us, total: 136.35ms
top 3 graph node: difference, cpu: 97.00ms, accelerator: 0us, total: 97.00ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.94ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.10ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.10ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.84ms, total: 6.57ms
train.py:448:<module>, cpu: 136.35ms, accelerator: 0us, total: 136.35ms
train.py:449:<module>, cpu: 97.04ms, accelerator: 65us, total: 97.10ms
  summary.py:146:image, cpu: 97.00ms, accelerator: 0us, total: 97.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_60250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.98%)
top 2 operation type: ImageSummary, cpu: 327.30ms, accelerator: 0us, total: 327.30ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.23ms, accelerator: 0us, total: 102.23ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.39ms, accelerator: 0us, total: 136.39ms
top 3 graph node: difference, cpu: 96.94ms, accelerator: 0us, total: 96.94ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.92ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.10ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.10ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.82ms, total: 6.56ms
train.py:448:<module>, cpu: 136.40ms, accelerator: 0us, total: 136.40ms
train.py:449:<module>, cpu: 96.98ms, accelerator: 65us, total: 97.05ms
  summary.py:146:image, cpu: 96.95ms, accelerator: 0us, total: 96.95ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_60500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.98%)
top 2 operation type: ImageSummary, cpu: 327.29ms, accelerator: 0us, total: 327.29ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.23ms, accelerator: 0us, total: 102.23ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.42ms, accelerator: 0us, total: 136.42ms
top 3 graph node: difference, cpu: 96.96ms, accelerator: 0us, total: 96.96ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.91ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.09ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 2.09ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.82ms, total: 6.54ms
train.py:448:<module>, cpu: 136.42ms, accelerator: 0us, total: 136.42ms
train.py:449:<module>, cpu: 97.00ms, accelerator: 65us, total: 97.06ms
  summary.py:146:image, cpu: 96.97ms, accelerator: 0us, total: 96.97ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_60750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.99%)
top 2 operation type: ImageSummary, cpu: 327.14ms, accelerator: 0us, total: 327.14ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.12ms, accelerator: 0us, total: 102.12ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.26ms, accelerator: 0us, total: 136.26ms
top 3 graph node: difference, cpu: 97.00ms, accelerator: 0us, total: 97.00ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.89ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.08ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.08ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.81ms, total: 6.52ms
train.py:448:<module>, cpu: 136.27ms, accelerator: 0us, total: 136.27ms
train.py:449:<module>, cpu: 97.04ms, accelerator: 64us, total: 97.11ms
  summary.py:146:image, cpu: 97.01ms, accelerator: 0us, total: 97.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_61000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.99%)
top 2 operation type: ImageSummary, cpu: 327.19ms, accelerator: 0us, total: 327.19ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.11ms, accelerator: 0us, total: 102.11ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.32ms, accelerator: 0us, total: 136.32ms
top 3 graph node: difference, cpu: 97.10ms, accelerator: 0us, total: 97.10ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.87ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.07ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.97ms, accelerator: 2.07ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.80ms, total: 6.51ms
train.py:448:<module>, cpu: 136.33ms, accelerator: 0us, total: 136.33ms
train.py:449:<module>, cpu: 97.14ms, accelerator: 64us, total: 97.21ms
  summary.py:146:image, cpu: 97.11ms, accelerator: 0us, total: 97.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_61250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.99%)
top 2 operation type: ImageSummary, cpu: 327.18ms, accelerator: 0us, total: 327.18ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.10ms, accelerator: 0us, total: 102.10ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.38ms, accelerator: 0us, total: 136.38ms
top 3 graph node: difference, cpu: 97.11ms, accelerator: 0us, total: 97.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.90ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.11ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.11ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.79ms, total: 6.50ms
train.py:448:<module>, cpu: 136.38ms, accelerator: 0us, total: 136.38ms
train.py:449:<module>, cpu: 97.15ms, accelerator: 64us, total: 97.22ms
  summary.py:146:image, cpu: 97.12ms, accelerator: 0us, total: 97.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_61500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (94.00%)
top 2 operation type: ImageSummary, cpu: 327.00ms, accelerator: 0us, total: 327.00ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 102.07ms, accelerator: 0us, total: 102.07ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.32ms, accelerator: 0us, total: 136.32ms
top 3 graph node: difference, cpu: 97.09ms, accelerator: 0us, total: 97.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.89ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.10ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.10ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.79ms, total: 6.49ms
train.py:448:<module>, cpu: 136.33ms, accelerator: 0us, total: 136.33ms
train.py:449:<module>, cpu: 97.13ms, accelerator: 64us, total: 97.19ms
  summary.py:146:image, cpu: 97.09ms, accelerator: 0us, total: 97.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_61750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (94.00%)
top 2 operation type: ImageSummary, cpu: 327.20ms, accelerator: 0us, total: 327.20ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.93ms, accelerator: 0us, total: 101.93ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.51ms, accelerator: 0us, total: 136.51ms
top 3 graph node: difference, cpu: 97.09ms, accelerator: 0us, total: 97.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.87ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.09ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.09ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.78ms, total: 6.47ms
train.py:448:<module>, cpu: 136.52ms, accelerator: 0us, total: 136.52ms
train.py:449:<module>, cpu: 97.12ms, accelerator: 64us, total: 97.19ms
  summary.py:146:image, cpu: 97.09ms, accelerator: 0us, total: 97.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_62000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.99%)
top 2 operation type: ImageSummary, cpu: 327.18ms, accelerator: 0us, total: 327.18ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.85ms, accelerator: 0us, total: 101.85ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.48ms, accelerator: 0us, total: 136.48ms
top 3 graph node: difference, cpu: 97.02ms, accelerator: 0us, total: 97.02ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.88ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.09ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.09ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.80ms, total: 6.48ms
train.py:448:<module>, cpu: 136.49ms, accelerator: 0us, total: 136.49ms
train.py:449:<module>, cpu: 97.06ms, accelerator: 63us, total: 97.12ms
  summary.py:146:image, cpu: 97.02ms, accelerator: 0us, total: 97.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_62250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (94.00%)
top 2 operation type: ImageSummary, cpu: 327.16ms, accelerator: 0us, total: 327.16ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.82ms, accelerator: 0us, total: 101.82ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.49ms, accelerator: 0us, total: 136.49ms
top 3 graph node: difference, cpu: 96.85ms, accelerator: 0us, total: 96.85ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.87ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.08ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.08ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.79ms, total: 6.47ms
train.py:448:<module>, cpu: 136.50ms, accelerator: 0us, total: 136.50ms
train.py:449:<module>, cpu: 96.89ms, accelerator: 63us, total: 96.95ms
  summary.py:146:image, cpu: 96.86ms, accelerator: 0us, total: 96.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_62500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (94.00%)
top 2 operation type: ImageSummary, cpu: 327.00ms, accelerator: 0us, total: 327.00ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.68ms, accelerator: 0us, total: 101.68ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.57ms, accelerator: 0us, total: 136.57ms
top 3 graph node: difference, cpu: 96.75ms, accelerator: 0us, total: 96.75ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.86ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.08ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.08ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.78ms, total: 6.48ms
train.py:448:<module>, cpu: 136.58ms, accelerator: 0us, total: 136.58ms
train.py:449:<module>, cpu: 96.79ms, accelerator: 63us, total: 96.85ms
  summary.py:146:image, cpu: 96.76ms, accelerator: 0us, total: 96.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_62750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.99%)
top 2 operation type: ImageSummary, cpu: 327.14ms, accelerator: 0us, total: 327.14ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 101.56ms, accelerator: 0us, total: 101.56ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.46ms, accelerator: 0us, total: 136.46ms
top 3 graph node: difference, cpu: 96.76ms, accelerator: 0us, total: 96.76ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.94ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.17ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.17ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.77ms, total: 6.46ms
train.py:448:<module>, cpu: 136.47ms, accelerator: 0us, total: 136.47ms
train.py:449:<module>, cpu: 96.79ms, accelerator: 66us, total: 96.86ms
  summary.py:146:image, cpu: 96.76ms, accelerator: 0us, total: 96.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_63000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.99%)
top 2 operation type: ImageSummary, cpu: 326.88ms, accelerator: 0us, total: 326.88ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.46ms, accelerator: 0us, total: 101.46ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.30ms, accelerator: 0us, total: 136.30ms
top 3 graph node: difference, cpu: 96.78ms, accelerator: 0us, total: 96.78ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.99ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.21ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.21ms, total: 7.13ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.78ms, total: 6.46ms
train.py:448:<module>, cpu: 136.31ms, accelerator: 0us, total: 136.31ms
train.py:449:<module>, cpu: 96.82ms, accelerator: 66us, total: 96.88ms
  summary.py:146:image, cpu: 96.78ms, accelerator: 0us, total: 96.78ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_63250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (94.00%)
top 2 operation type: ImageSummary, cpu: 326.95ms, accelerator: 0us, total: 326.95ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.44ms, accelerator: 0us, total: 101.44ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.35ms, accelerator: 0us, total: 136.35ms
top 3 graph node: difference, cpu: 96.70ms, accelerator: 0us, total: 96.70ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.98ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.21ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.21ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.77ms, total: 6.45ms
train.py:448:<module>, cpu: 136.35ms, accelerator: 0us, total: 136.35ms
train.py:449:<module>, cpu: 96.74ms, accelerator: 65us, total: 96.81ms
  summary.py:146:image, cpu: 96.71ms, accelerator: 0us, total: 96.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_63500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (94.00%)
top 2 operation type: ImageSummary, cpu: 326.69ms, accelerator: 0us, total: 326.69ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.34ms, accelerator: 0us, total: 101.34ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.27ms, accelerator: 0us, total: 136.27ms
top 3 graph node: difference, cpu: 96.63ms, accelerator: 0us, total: 96.63ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.96ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.20ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.20ms, total: 7.13ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.76ms, total: 6.44ms
train.py:448:<module>, cpu: 136.28ms, accelerator: 0us, total: 136.28ms
train.py:449:<module>, cpu: 96.66ms, accelerator: 65us, total: 96.73ms
  summary.py:146:image, cpu: 96.63ms, accelerator: 0us, total: 96.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_63750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (94.01%)
top 2 operation type: ImageSummary, cpu: 326.68ms, accelerator: 0us, total: 326.68ms (3.82%)
top 3 operation type: HistogramSummary, cpu: 101.26ms, accelerator: 0us, total: 101.26ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.22ms, accelerator: 0us, total: 136.22ms
top 3 graph node: difference, cpu: 96.69ms, accelerator: 0us, total: 96.69ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.93ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.19ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.19ms, total: 7.11ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.75ms, total: 6.43ms
train.py:448:<module>, cpu: 136.22ms, accelerator: 0us, total: 136.22ms
train.py:449:<module>, cpu: 96.73ms, accelerator: 65us, total: 96.80ms
  summary.py:146:image, cpu: 96.70ms, accelerator: 0us, total: 96.70ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2135.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_64000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (94.01%)
top 2 operation type: ImageSummary, cpu: 326.45ms, accelerator: 0us, total: 326.45ms (3.81%)
top 3 operation type: HistogramSummary, cpu: 101.24ms, accelerator: 0us, total: 101.24ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.26ms, accelerator: 0us, total: 136.26ms
top 3 graph node: difference, cpu: 96.60ms, accelerator: 0us, total: 96.60ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.92ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.18ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.18ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.74ms, total: 6.42ms
train.py:448:<module>, cpu: 136.26ms, accelerator: 0us, total: 136.26ms
train.py:449:<module>, cpu: 96.64ms, accelerator: 65us, total: 96.70ms
  summary.py:146:image, cpu: 96.61ms, accelerator: 0us, total: 96.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_64250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 92us, accelerator: 71499007.83sec, total: 71499007.83sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.57ms, accelerator: 0us, total: 326.57ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.36ms, accelerator: 0us, total: 136.36ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.91ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.17ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.73ms, total: 6.46ms
train.py:448:<module>, cpu: 136.36ms, accelerator: 0us, total: 136.36ms
train.py:449:<module>, cpu: 96.78ms, accelerator: 65us, total: 96.84ms
  summary.py:146:image, cpu: 96.74ms, accelerator: 0us, total: 96.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.50
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_64500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 92us, accelerator: 71222949.89sec, total: 71222949.89sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.35ms, accelerator: 0us, total: 326.35ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.37ms, accelerator: 0us, total: 136.37ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.92ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.17ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.17ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.75ms, total: 6.47ms
train.py:448:<module>, cpu: 136.38ms, accelerator: 0us, total: 136.38ms
train.py:449:<module>, cpu: 96.64ms, accelerator: 64us, total: 96.70ms
  summary.py:146:image, cpu: 96.61ms, accelerator: 0us, total: 96.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_64750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 91us, accelerator: 70949015.47sec, total: 70949015.47sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.59ms, accelerator: 0us, total: 326.59ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.49ms, accelerator: 0us, total: 136.49ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.91ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.16ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.16ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.75ms, total: 6.47ms
train.py:448:<module>, cpu: 136.49ms, accelerator: 0us, total: 136.49ms
train.py:449:<module>, cpu: 96.85ms, accelerator: 64us, total: 96.91ms
  summary.py:146:image, cpu: 96.81ms, accelerator: 0us, total: 96.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_65000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 91us, accelerator: 70677180.16sec, total: 70677180.16sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.41ms, accelerator: 0us, total: 326.41ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.33ms, accelerator: 0us, total: 136.33ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.89ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.15ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.15ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.74ms, total: 6.45ms
train.py:448:<module>, cpu: 136.33ms, accelerator: 0us, total: 136.33ms
train.py:449:<module>, cpu: 96.94ms, accelerator: 64us, total: 97.00ms
  summary.py:146:image, cpu: 96.90ms, accelerator: 0us, total: 96.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_65250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 91us, accelerator: 70407419.93sec, total: 70407419.93sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.26ms, accelerator: 0us, total: 326.26ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.38ms, accelerator: 0us, total: 136.38ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.88ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.15ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.15ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.73ms, total: 6.44ms
train.py:448:<module>, cpu: 136.38ms, accelerator: 0us, total: 136.38ms
train.py:449:<module>, cpu: 96.91ms, accelerator: 64us, total: 96.97ms
  summary.py:146:image, cpu: 96.88ms, accelerator: 0us, total: 96.88ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_65500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 91us, accelerator: 70139711.11sec, total: 70139711.11sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.37ms, accelerator: 0us, total: 326.37ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.44ms, accelerator: 0us, total: 136.44ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.86ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.14ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.14ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.72ms, total: 6.42ms
train.py:448:<module>, cpu: 136.45ms, accelerator: 0us, total: 136.45ms
train.py:449:<module>, cpu: 96.97ms, accelerator: 63us, total: 97.03ms
  summary.py:146:image, cpu: 96.93ms, accelerator: 0us, total: 96.93ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_65750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 90us, accelerator: 69874030.38sec, total: 69874030.38sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.45ms, accelerator: 0us, total: 326.45ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.39ms, accelerator: 0us, total: 136.39ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.84ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.13ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.13ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.71ms, total: 6.41ms
train.py:448:<module>, cpu: 136.40ms, accelerator: 0us, total: 136.40ms
train.py:449:<module>, cpu: 96.86ms, accelerator: 63us, total: 96.92ms
  summary.py:146:image, cpu: 96.83ms, accelerator: 0us, total: 96.83ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_66000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 90us, accelerator: 69610354.80sec, total: 69610354.80sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.29ms, accelerator: 0us, total: 326.29ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.47ms, accelerator: 0us, total: 136.47ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.83ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.12ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.12ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.70ms, total: 6.39ms
train.py:448:<module>, cpu: 136.48ms, accelerator: 0us, total: 136.48ms
train.py:449:<module>, cpu: 96.77ms, accelerator: 63us, total: 96.84ms
  summary.py:146:image, cpu: 96.74ms, accelerator: 0us, total: 96.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_66250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 90us, accelerator: 69348661.73sec, total: 69348661.73sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.33ms, accelerator: 0us, total: 326.33ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.56ms, accelerator: 0us, total: 136.56ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.82ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.12ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.12ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.70ms, total: 6.44ms
train.py:448:<module>, cpu: 136.56ms, accelerator: 0us, total: 136.56ms
train.py:449:<module>, cpu: 96.82ms, accelerator: 63us, total: 96.88ms
  summary.py:146:image, cpu: 96.79ms, accelerator: 0us, total: 96.79ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_66500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 90us, accelerator: 69088928.92sec, total: 69088928.92sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.21ms, accelerator: 0us, total: 326.21ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.62ms, accelerator: 0us, total: 136.62ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.80ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.11ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.11ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.69ms, total: 6.43ms
train.py:448:<module>, cpu: 136.63ms, accelerator: 0us, total: 136.63ms
train.py:449:<module>, cpu: 96.69ms, accelerator: 63us, total: 96.76ms
  summary.py:146:image, cpu: 96.66ms, accelerator: 0us, total: 96.66ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_66750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 89us, accelerator: 68831134.41sec, total: 68831134.41sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.87ms, accelerator: 0us, total: 325.87ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.49ms, accelerator: 0us, total: 136.49ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.88ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.19ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 2.19ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.69ms, total: 6.43ms
train.py:448:<module>, cpu: 136.49ms, accelerator: 0us, total: 136.49ms
train.py:449:<module>, cpu: 96.58ms, accelerator: 62us, total: 96.65ms
  summary.py:146:image, cpu: 96.55ms, accelerator: 0us, total: 96.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_67000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 89us, accelerator: 68575256.58sec, total: 68575256.58sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.80ms, accelerator: 0us, total: 325.80ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.37ms, accelerator: 0us, total: 136.37ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.87ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.19ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 2.19ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.69ms, total: 6.42ms
train.py:448:<module>, cpu: 136.38ms, accelerator: 0us, total: 136.38ms
train.py:449:<module>, cpu: 96.43ms, accelerator: 62us, total: 96.49ms
  summary.py:146:image, cpu: 96.39ms, accelerator: 0us, total: 96.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_67250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 89us, accelerator: 68321274.15sec, total: 68321274.15sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.80ms, accelerator: 0us, total: 325.80ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.39ms, accelerator: 0us, total: 136.39ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.87ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.18ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.18ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.69ms, total: 6.41ms
train.py:448:<module>, cpu: 136.39ms, accelerator: 0us, total: 136.39ms
train.py:449:<module>, cpu: 96.43ms, accelerator: 62us, total: 96.49ms
  summary.py:146:image, cpu: 96.40ms, accelerator: 0us, total: 96.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_67500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 89us, accelerator: 68069166.13sec, total: 68069166.13sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.68ms, accelerator: 0us, total: 325.68ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.46ms, accelerator: 0us, total: 136.46ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.85ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.17ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.17ms, total: 7.11ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.68ms, total: 6.40ms
train.py:448:<module>, cpu: 136.46ms, accelerator: 0us, total: 136.46ms
train.py:449:<module>, cpu: 96.35ms, accelerator: 62us, total: 96.41ms
  summary.py:146:image, cpu: 96.32ms, accelerator: 0us, total: 96.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_67750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 67818911.84sec, total: 67818911.84sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.62ms, accelerator: 0us, total: 325.62ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.30ms, accelerator: 0us, total: 136.30ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.84ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.17ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.17ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.67ms, total: 6.40ms
train.py:448:<module>, cpu: 136.31ms, accelerator: 0us, total: 136.31ms
train.py:449:<module>, cpu: 96.37ms, accelerator: 61us, total: 96.44ms
  summary.py:146:image, cpu: 96.34ms, accelerator: 0us, total: 96.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_68000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 67570490.92sec, total: 67570490.92sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.41ms, accelerator: 0us, total: 325.41ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.27ms, accelerator: 0us, total: 136.27ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.82ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.16ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.16ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.67ms, total: 6.38ms
train.py:448:<module>, cpu: 136.27ms, accelerator: 0us, total: 136.27ms
train.py:449:<module>, cpu: 96.34ms, accelerator: 61us, total: 96.41ms
  summary.py:146:image, cpu: 96.31ms, accelerator: 0us, total: 96.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_68250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 67323883.29sec, total: 67323883.29sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.56ms, accelerator: 0us, total: 325.56ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.23ms, accelerator: 0us, total: 136.23ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.81ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.15ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.15ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.66ms, total: 6.38ms
train.py:448:<module>, cpu: 136.24ms, accelerator: 0us, total: 136.24ms
train.py:449:<module>, cpu: 96.42ms, accelerator: 61us, total: 96.48ms
  summary.py:146:image, cpu: 96.39ms, accelerator: 0us, total: 96.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_68500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 67079069.17sec, total: 67079069.17sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.37ms, accelerator: 0us, total: 325.37ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.24ms, accelerator: 0us, total: 136.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.79ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.15ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.15ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.65ms, total: 6.36ms
train.py:448:<module>, cpu: 136.25ms, accelerator: 0us, total: 136.25ms
train.py:449:<module>, cpu: 96.32ms, accelerator: 61us, total: 96.38ms
  summary.py:146:image, cpu: 96.29ms, accelerator: 0us, total: 96.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_68750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 66836029.06sec, total: 66836029.06sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.48ms, accelerator: 0us, total: 325.48ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.25ms, accelerator: 0us, total: 136.25ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.80ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.14ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.14ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.66ms, total: 6.38ms
train.py:448:<module>, cpu: 136.25ms, accelerator: 0us, total: 136.25ms
train.py:449:<module>, cpu: 96.36ms, accelerator: 61us, total: 96.42ms
  summary.py:146:image, cpu: 96.33ms, accelerator: 0us, total: 96.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_69000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 66594743.76sec, total: 66594743.76sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.16ms, accelerator: 0us, total: 325.16ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.18ms, accelerator: 0us, total: 136.18ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.79ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.14ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.14ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.65ms, total: 6.37ms
train.py:448:<module>, cpu: 136.19ms, accelerator: 0us, total: 136.19ms
train.py:449:<module>, cpu: 96.20ms, accelerator: 60us, total: 96.27ms
  summary.py:146:image, cpu: 96.17ms, accelerator: 0us, total: 96.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_69250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 66355194.32sec, total: 66355194.32sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.92ms, accelerator: 0us, total: 324.92ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.19ms, accelerator: 0us, total: 136.19ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.77ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.13ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.13ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.64ms, total: 6.35ms
train.py:448:<module>, cpu: 136.19ms, accelerator: 0us, total: 136.19ms
train.py:449:<module>, cpu: 96.06ms, accelerator: 60us, total: 96.12ms
  summary.py:146:image, cpu: 96.03ms, accelerator: 0us, total: 96.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_69500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 66117362.08sec, total: 66117362.08sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.94ms, accelerator: 0us, total: 324.94ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.25ms, accelerator: 0us, total: 136.25ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.76ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.12ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 2.12ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.64ms, total: 6.35ms
train.py:448:<module>, cpu: 136.26ms, accelerator: 0us, total: 136.26ms
train.py:449:<module>, cpu: 96.09ms, accelerator: 60us, total: 96.15ms
  summary.py:146:image, cpu: 96.06ms, accelerator: 0us, total: 96.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_69750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 65881228.65sec, total: 65881228.65sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.91ms, accelerator: 0us, total: 324.91ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.37ms, accelerator: 0us, total: 136.37ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.75ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.12ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.12ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.63ms, total: 6.33ms
train.py:448:<module>, cpu: 136.37ms, accelerator: 0us, total: 136.37ms
train.py:449:<module>, cpu: 96.01ms, accelerator: 60us, total: 96.07ms
  summary.py:146:image, cpu: 95.97ms, accelerator: 0us, total: 95.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_70000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 65646775.88sec, total: 65646775.88sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.90ms, accelerator: 0us, total: 324.90ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.29ms, accelerator: 0us, total: 136.29ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.73ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.10ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.10ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.62ms, total: 6.32ms
train.py:448:<module>, cpu: 136.30ms, accelerator: 0us, total: 136.30ms
train.py:449:<module>, cpu: 96.04ms, accelerator: 60us, total: 96.10ms
  summary.py:146:image, cpu: 96.01ms, accelerator: 0us, total: 96.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_70250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 65413985.89sec, total: 65413985.89sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.09ms, accelerator: 0us, total: 325.09ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.37ms, accelerator: 0us, total: 136.37ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.71ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.10ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.10ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.62ms, total: 6.33ms
train.py:448:<module>, cpu: 136.38ms, accelerator: 0us, total: 136.38ms
train.py:449:<module>, cpu: 96.04ms, accelerator: 60us, total: 96.10ms
  summary.py:146:image, cpu: 96.01ms, accelerator: 0us, total: 96.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_70500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 65182841.06sec, total: 65182841.06sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.19ms, accelerator: 0us, total: 325.19ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.43ms, accelerator: 0us, total: 136.43ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.70ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.09ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.97ms, accelerator: 2.09ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.61ms, total: 6.32ms
train.py:448:<module>, cpu: 136.44ms, accelerator: 0us, total: 136.44ms
train.py:449:<module>, cpu: 96.10ms, accelerator: 59us, total: 96.16ms
  summary.py:146:image, cpu: 96.06ms, accelerator: 0us, total: 96.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_70750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 64953324.02sec, total: 64953324.02sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.23ms, accelerator: 0us, total: 325.23ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.42ms, accelerator: 0us, total: 136.42ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.69ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.09ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.09ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.60ms, total: 6.31ms
train.py:448:<module>, cpu: 136.43ms, accelerator: 0us, total: 136.43ms
train.py:449:<module>, cpu: 96.08ms, accelerator: 59us, total: 96.14ms
  summary.py:146:image, cpu: 96.04ms, accelerator: 0us, total: 96.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_71000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 64725417.62sec, total: 64725417.62sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.12ms, accelerator: 0us, total: 325.12ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.37ms, accelerator: 0us, total: 136.37ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.89ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.27ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.27ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.62ms, total: 6.31ms
train.py:448:<module>, cpu: 136.37ms, accelerator: 0us, total: 136.37ms
train.py:449:<module>, cpu: 96.06ms, accelerator: 59us, total: 96.12ms
  summary.py:146:image, cpu: 96.03ms, accelerator: 0us, total: 96.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_71250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 64499104.97sec, total: 64499104.97sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.10ms, accelerator: 0us, total: 325.10ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.43ms, accelerator: 0us, total: 136.43ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.87ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.26ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.26ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.61ms, total: 6.30ms
train.py:448:<module>, cpu: 136.43ms, accelerator: 0us, total: 136.43ms
train.py:449:<module>, cpu: 96.01ms, accelerator: 59us, total: 96.07ms
  summary.py:146:image, cpu: 95.98ms, accelerator: 0us, total: 95.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_71500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 64274369.41sec, total: 64274369.41sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.99ms, accelerator: 0us, total: 324.99ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.28ms, accelerator: 0us, total: 136.28ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.86ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.25ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.25ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.60ms, total: 6.28ms
train.py:448:<module>, cpu: 136.29ms, accelerator: 0us, total: 136.29ms
train.py:449:<module>, cpu: 96.05ms, accelerator: 59us, total: 96.11ms
  summary.py:146:image, cpu: 96.02ms, accelerator: 0us, total: 96.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_71750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 64051194.52sec, total: 64051194.52sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.91ms, accelerator: 0us, total: 324.91ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.19ms, accelerator: 0us, total: 136.19ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.84ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.25ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.25ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.59ms, total: 6.27ms
train.py:448:<module>, cpu: 136.20ms, accelerator: 0us, total: 136.20ms
train.py:449:<module>, cpu: 96.15ms, accelerator: 58us, total: 96.21ms
  summary.py:146:image, cpu: 96.11ms, accelerator: 0us, total: 96.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_72000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 63829564.09sec, total: 63829564.09sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.72ms, accelerator: 0us, total: 324.72ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.18ms, accelerator: 0us, total: 136.18ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.84ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.24ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.24ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.60ms, total: 6.28ms
train.py:448:<module>, cpu: 136.18ms, accelerator: 0us, total: 136.18ms
train.py:449:<module>, cpu: 96.01ms, accelerator: 58us, total: 96.07ms
  summary.py:146:image, cpu: 95.98ms, accelerator: 0us, total: 95.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_72250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 63609462.14sec, total: 63609462.14sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.81ms, accelerator: 0us, total: 324.81ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.04ms, accelerator: 0us, total: 136.04ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.84ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.23ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.23ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.61ms, total: 6.29ms
train.py:448:<module>, cpu: 136.05ms, accelerator: 0us, total: 136.05ms
train.py:449:<module>, cpu: 96.01ms, accelerator: 61us, total: 96.07ms
  summary.py:146:image, cpu: 95.98ms, accelerator: 0us, total: 95.98ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_72500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 94us, accelerator: 63390872.92sec, total: 63390872.92sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.94ms, accelerator: 0us, total: 324.94ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.12ms, accelerator: 0us, total: 136.12ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.83ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.23ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.23ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.60ms, total: 6.29ms
train.py:448:<module>, cpu: 136.13ms, accelerator: 0us, total: 136.13ms
train.py:449:<module>, cpu: 96.10ms, accelerator: 61us, total: 96.17ms
  summary.py:146:image, cpu: 96.07ms, accelerator: 0us, total: 96.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_72750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 94us, accelerator: 63173780.89sec, total: 63173780.89sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.63ms, accelerator: 0us, total: 324.63ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.00ms, accelerator: 0us, total: 136.00ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.89ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.28ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.28ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.62ms, total: 6.29ms
train.py:448:<module>, cpu: 136.01ms, accelerator: 0us, total: 136.01ms
train.py:449:<module>, cpu: 95.97ms, accelerator: 61us, total: 96.03ms
  summary.py:146:image, cpu: 95.94ms, accelerator: 0us, total: 95.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_73000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 94us, accelerator: 62958170.72sec, total: 62958170.72sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.64ms, accelerator: 0us, total: 324.64ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.10ms, accelerator: 0us, total: 136.10ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.88ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.27ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.27ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.61ms, total: 6.28ms
train.py:448:<module>, cpu: 136.10ms, accelerator: 0us, total: 136.10ms
train.py:449:<module>, cpu: 96.02ms, accelerator: 60us, total: 96.08ms
  summary.py:146:image, cpu: 95.99ms, accelerator: 0us, total: 95.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_73250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 93us, accelerator: 62744027.28sec, total: 62744027.28sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.56ms, accelerator: 0us, total: 324.56ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.02ms, accelerator: 0us, total: 136.02ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.89ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.29ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.29ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.61ms, total: 6.28ms
train.py:448:<module>, cpu: 136.03ms, accelerator: 0us, total: 136.03ms
train.py:449:<module>, cpu: 96.04ms, accelerator: 60us, total: 96.10ms
  summary.py:146:image, cpu: 96.00ms, accelerator: 0us, total: 96.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_73500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 93us, accelerator: 62531335.66sec, total: 62531335.66sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.71ms, accelerator: 0us, total: 324.71ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.19ms, accelerator: 0us, total: 136.19ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.88ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.28ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 2.28ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.60ms, total: 6.26ms
train.py:448:<module>, cpu: 136.20ms, accelerator: 0us, total: 136.20ms
train.py:449:<module>, cpu: 96.02ms, accelerator: 60us, total: 96.08ms
  summary.py:146:image, cpu: 95.99ms, accelerator: 0us, total: 95.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_73750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 93us, accelerator: 62320081.15sec, total: 62320081.15sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.54ms, accelerator: 0us, total: 324.54ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.25ms, accelerator: 0us, total: 136.25ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.86ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.27ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.27ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.59ms, total: 6.29ms
train.py:448:<module>, cpu: 136.25ms, accelerator: 0us, total: 136.25ms
train.py:449:<module>, cpu: 95.91ms, accelerator: 60us, total: 95.97ms
  summary.py:146:image, cpu: 95.88ms, accelerator: 0us, total: 95.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_74000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 93us, accelerator: 62110249.23sec, total: 62110249.23sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.38ms, accelerator: 0us, total: 324.38ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.09ms, accelerator: 0us, total: 136.09ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.86ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.27ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 2.27ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.59ms, total: 6.28ms
train.py:448:<module>, cpu: 136.10ms, accelerator: 0us, total: 136.10ms
train.py:449:<module>, cpu: 95.93ms, accelerator: 60us, total: 95.99ms
  summary.py:146:image, cpu: 95.90ms, accelerator: 0us, total: 95.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_74250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 93us, accelerator: 61901825.57sec, total: 61901825.57sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.48ms, accelerator: 0us, total: 324.48ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.09ms, accelerator: 0us, total: 136.09ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.84ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.26ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.26ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.58ms, total: 6.27ms
train.py:448:<module>, cpu: 136.09ms, accelerator: 0us, total: 136.09ms
train.py:449:<module>, cpu: 95.91ms, accelerator: 59us, total: 95.97ms
  summary.py:146:image, cpu: 95.87ms, accelerator: 0us, total: 95.87ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_74500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 92us, accelerator: 61694796.06sec, total: 61694796.06sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.62ms, accelerator: 0us, total: 324.62ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.07ms, accelerator: 0us, total: 136.07ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.83ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.25ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.25ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.57ms, total: 6.25ms
train.py:448:<module>, cpu: 136.08ms, accelerator: 0us, total: 136.08ms
train.py:449:<module>, cpu: 96.00ms, accelerator: 59us, total: 96.05ms
  summary.py:146:image, cpu: 95.96ms, accelerator: 0us, total: 95.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_74750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 92us, accelerator: 61489146.74sec, total: 61489146.74sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.30ms, accelerator: 0us, total: 324.30ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 135.99ms, accelerator: 0us, total: 135.99ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.82ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.25ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 2.25ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.57ms, total: 6.24ms
train.py:448:<module>, cpu: 136.00ms, accelerator: 0us, total: 136.00ms
train.py:449:<module>, cpu: 95.86ms, accelerator: 59us, total: 95.92ms
  summary.py:146:image, cpu: 95.82ms, accelerator: 0us, total: 95.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_75000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 92us, accelerator: 61284863.86sec, total: 61284863.86sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.47ms, accelerator: 0us, total: 324.47ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.04ms, accelerator: 0us, total: 136.04ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.80ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.24ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 2.24ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.56ms, total: 6.23ms
train.py:448:<module>, cpu: 136.04ms, accelerator: 0us, total: 136.04ms
train.py:449:<module>, cpu: 95.88ms, accelerator: 59us, total: 95.94ms
  summary.py:146:image, cpu: 95.85ms, accelerator: 0us, total: 95.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_75250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 92us, accelerator: 61081933.84sec, total: 61081933.84sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.36ms, accelerator: 0us, total: 324.36ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.09ms, accelerator: 0us, total: 136.09ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.78ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.23ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.23ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.56ms, total: 6.22ms
train.py:448:<module>, cpu: 136.09ms, accelerator: 0us, total: 136.09ms
train.py:449:<module>, cpu: 95.80ms, accelerator: 59us, total: 95.86ms
  summary.py:146:image, cpu: 95.77ms, accelerator: 0us, total: 95.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_75500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 92us, accelerator: 60880343.30sec, total: 60880343.30sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.82ms, accelerator: 0us, total: 324.82ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.22ms, accelerator: 0us, total: 136.22ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.79ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.22ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.22ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.56ms, total: 6.24ms
train.py:448:<module>, cpu: 136.23ms, accelerator: 0us, total: 136.23ms
train.py:449:<module>, cpu: 95.92ms, accelerator: 59us, total: 95.98ms
  summary.py:146:image, cpu: 95.89ms, accelerator: 0us, total: 95.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_75750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 91us, accelerator: 60680079.02sec, total: 60680079.02sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.87ms, accelerator: 0us, total: 324.87ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.17ms, accelerator: 0us, total: 136.17ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.77ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.22ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.22ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.55ms, total: 6.24ms
train.py:448:<module>, cpu: 136.17ms, accelerator: 0us, total: 136.17ms
train.py:449:<module>, cpu: 95.89ms, accelerator: 58us, total: 95.95ms
  summary.py:146:image, cpu: 95.86ms, accelerator: 0us, total: 95.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_76000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 91us, accelerator: 60481127.94sec, total: 60481127.94sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.01ms, accelerator: 0us, total: 325.01ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.25ms, accelerator: 0us, total: 136.25ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.77ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.22ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.22ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.55ms, total: 6.23ms
train.py:448:<module>, cpu: 136.26ms, accelerator: 0us, total: 136.26ms
train.py:449:<module>, cpu: 95.97ms, accelerator: 58us, total: 96.03ms
  summary.py:146:image, cpu: 95.94ms, accelerator: 0us, total: 95.94ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_76250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 91us, accelerator: 60283477.19sec, total: 60283477.19sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.24ms, accelerator: 0us, total: 325.24ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.31ms, accelerator: 0us, total: 136.31ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.89ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.31ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.31ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 2.59ms, total: 6.27ms
train.py:448:<module>, cpu: 136.31ms, accelerator: 0us, total: 136.31ms
train.py:449:<module>, cpu: 96.03ms, accelerator: 58us, total: 96.09ms
  summary.py:146:image, cpu: 96.00ms, accelerator: 0us, total: 96.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_76500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 91us, accelerator: 60087114.08sec, total: 60087114.08sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.09ms, accelerator: 0us, total: 325.09ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.23ms, accelerator: 0us, total: 136.23ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.88ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.30ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.30ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.58ms, total: 6.26ms
train.py:448:<module>, cpu: 136.24ms, accelerator: 0us, total: 136.24ms
train.py:449:<module>, cpu: 95.97ms, accelerator: 58us, total: 96.03ms
  summary.py:146:image, cpu: 95.94ms, accelerator: 0us, total: 95.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_76750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 90us, accelerator: 59892026.04sec, total: 59892026.04sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.89ms, accelerator: 0us, total: 324.89ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.15ms, accelerator: 0us, total: 136.15ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.91ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.33ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.33ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.57ms, total: 6.25ms
train.py:448:<module>, cpu: 136.16ms, accelerator: 0us, total: 136.16ms
train.py:449:<module>, cpu: 95.97ms, accelerator: 58us, total: 96.03ms
  summary.py:146:image, cpu: 95.94ms, accelerator: 0us, total: 95.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_77000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 90us, accelerator: 59698200.72sec, total: 59698200.72sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.89ms, accelerator: 0us, total: 324.89ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.22ms, accelerator: 0us, total: 136.22ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.89ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.32ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.32ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.57ms, total: 6.23ms
train.py:448:<module>, cpu: 136.23ms, accelerator: 0us, total: 136.23ms
train.py:449:<module>, cpu: 95.95ms, accelerator: 57us, total: 96.00ms
  summary.py:146:image, cpu: 95.91ms, accelerator: 0us, total: 95.91ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_77250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 90us, accelerator: 59505625.87sec, total: 59505625.87sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.98ms, accelerator: 0us, total: 324.98ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.12ms, accelerator: 0us, total: 136.12ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.88ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.32ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.32ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.56ms, total: 6.23ms
train.py:448:<module>, cpu: 136.12ms, accelerator: 0us, total: 136.12ms
train.py:449:<module>, cpu: 96.03ms, accelerator: 57us, total: 96.09ms
  summary.py:146:image, cpu: 96.00ms, accelerator: 0us, total: 96.00ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_77500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 90us, accelerator: 59314289.46sec, total: 59314289.46sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.50ms, accelerator: 0us, total: 325.50ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.29ms, accelerator: 0us, total: 136.29ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.87ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.31ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.31ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 2.55ms, total: 6.22ms
train.py:448:<module>, cpu: 136.30ms, accelerator: 0us, total: 136.30ms
train.py:449:<module>, cpu: 96.22ms, accelerator: 57us, total: 96.28ms
  summary.py:146:image, cpu: 96.19ms, accelerator: 0us, total: 96.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_77750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 90us, accelerator: 59124179.55sec, total: 59124179.55sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.91ms, accelerator: 0us, total: 325.91ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.43ms, accelerator: 0us, total: 136.43ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.85ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.31ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.31ms, total: 7.19ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.55ms, total: 6.21ms
train.py:448:<module>, cpu: 136.44ms, accelerator: 0us, total: 136.44ms
train.py:449:<module>, cpu: 96.34ms, accelerator: 57us, total: 96.40ms
  summary.py:146:image, cpu: 96.31ms, accelerator: 0us, total: 96.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_78000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 89us, accelerator: 58935284.41sec, total: 58935284.41sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.74ms, accelerator: 0us, total: 325.74ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.30ms, accelerator: 0us, total: 136.30ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.88ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.33ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.33ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 2.54ms, total: 6.21ms
train.py:448:<module>, cpu: 136.31ms, accelerator: 0us, total: 136.31ms
train.py:449:<module>, cpu: 96.30ms, accelerator: 57us, total: 96.36ms
  summary.py:146:image, cpu: 96.27ms, accelerator: 0us, total: 96.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_78250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 89us, accelerator: 58747592.42sec, total: 58747592.42sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.05ms, accelerator: 0us, total: 326.05ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.42ms, accelerator: 0us, total: 136.42ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.91ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.36ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.36ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.54ms, total: 6.26ms
train.py:448:<module>, cpu: 136.43ms, accelerator: 0us, total: 136.43ms
train.py:449:<module>, cpu: 96.41ms, accelerator: 57us, total: 96.47ms
  summary.py:146:image, cpu: 96.38ms, accelerator: 0us, total: 96.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_78500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 89us, accelerator: 58561092.13sec, total: 58561092.13sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.04ms, accelerator: 0us, total: 326.04ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.46ms, accelerator: 0us, total: 136.46ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.97ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.42ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.42ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.55ms, total: 6.31ms
train.py:448:<module>, cpu: 136.46ms, accelerator: 0us, total: 136.46ms
train.py:449:<module>, cpu: 96.42ms, accelerator: 57us, total: 96.47ms
  summary.py:146:image, cpu: 96.39ms, accelerator: 0us, total: 96.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_78750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 89us, accelerator: 58375772.22sec, total: 58375772.22sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.06ms, accelerator: 0us, total: 326.06ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.50ms, accelerator: 0us, total: 136.50ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.96ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.41ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.41ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.55ms, total: 6.30ms
train.py:448:<module>, cpu: 136.51ms, accelerator: 0us, total: 136.51ms
train.py:449:<module>, cpu: 96.42ms, accelerator: 56us, total: 96.48ms
  summary.py:146:image, cpu: 96.39ms, accelerator: 0us, total: 96.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_79000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 89us, accelerator: 58191621.52sec, total: 58191621.52sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.10ms, accelerator: 0us, total: 326.10ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.53ms, accelerator: 0us, total: 136.53ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.94ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.40ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.40ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.54ms, total: 6.30ms
train.py:448:<module>, cpu: 136.53ms, accelerator: 0us, total: 136.53ms
train.py:449:<module>, cpu: 96.41ms, accelerator: 56us, total: 96.46ms
  summary.py:146:image, cpu: 96.37ms, accelerator: 0us, total: 96.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_79250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 58008629.00sec, total: 58008629.00sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.31ms, accelerator: 0us, total: 326.31ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.60ms, accelerator: 0us, total: 136.60ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.93ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.39ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.39ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.54ms, total: 6.34ms
train.py:448:<module>, cpu: 136.61ms, accelerator: 0us, total: 136.61ms
train.py:449:<module>, cpu: 96.47ms, accelerator: 56us, total: 96.53ms
  summary.py:146:image, cpu: 96.44ms, accelerator: 0us, total: 96.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_79500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 57826783.77sec, total: 57826783.77sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 326.15ms, accelerator: 0us, total: 326.15ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.53ms, accelerator: 0us, total: 136.53ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.92ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.38ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.38ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.53ms, total: 6.33ms
train.py:448:<module>, cpu: 136.53ms, accelerator: 0us, total: 136.53ms
train.py:449:<module>, cpu: 96.47ms, accelerator: 56us, total: 96.52ms
  summary.py:146:image, cpu: 96.43ms, accelerator: 0us, total: 96.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_79750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 57646075.07sec, total: 57646075.07sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.99ms, accelerator: 0us, total: 325.99ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.42ms, accelerator: 0us, total: 136.42ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.91ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.38ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.38ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.53ms, total: 6.32ms
train.py:448:<module>, cpu: 136.43ms, accelerator: 0us, total: 136.43ms
train.py:449:<module>, cpu: 96.36ms, accelerator: 56us, total: 96.42ms
  summary.py:146:image, cpu: 96.33ms, accelerator: 0us, total: 96.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_80000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 57466492.28sec, total: 57466492.28sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.89ms, accelerator: 0us, total: 325.89ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.35ms, accelerator: 0us, total: 136.35ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.90ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.38ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.38ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.52ms, total: 6.31ms
train.py:448:<module>, cpu: 136.35ms, accelerator: 0us, total: 136.35ms
train.py:449:<module>, cpu: 96.35ms, accelerator: 56us, total: 96.40ms
  summary.py:146:image, cpu: 96.31ms, accelerator: 0us, total: 96.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_80250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 57288024.91sec, total: 57288024.91sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.81ms, accelerator: 0us, total: 325.81ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.28ms, accelerator: 0us, total: 136.28ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.88ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.37ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.37ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.51ms, total: 6.31ms
train.py:448:<module>, cpu: 136.28ms, accelerator: 0us, total: 136.28ms
train.py:449:<module>, cpu: 96.36ms, accelerator: 55us, total: 96.41ms
  summary.py:146:image, cpu: 96.32ms, accelerator: 0us, total: 96.32ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_80500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 57110662.60sec, total: 57110662.60sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.44ms, accelerator: 0us, total: 325.44ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.18ms, accelerator: 0us, total: 136.18ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.92ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.40ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.40ms, total: 7.35ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.52ms, total: 6.31ms
train.py:448:<module>, cpu: 136.19ms, accelerator: 0us, total: 136.19ms
train.py:449:<module>, cpu: 96.20ms, accelerator: 57us, total: 96.26ms
  summary.py:146:image, cpu: 96.17ms, accelerator: 0us, total: 96.17ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_80750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 88us, accelerator: 56934395.13sec, total: 56934395.13sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.30ms, accelerator: 0us, total: 325.30ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.18ms, accelerator: 0us, total: 136.18ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.91ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.39ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.39ms, total: 7.33ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.52ms, total: 6.33ms
train.py:448:<module>, cpu: 136.19ms, accelerator: 0us, total: 136.19ms
train.py:449:<module>, cpu: 96.09ms, accelerator: 57us, total: 96.14ms
  summary.py:146:image, cpu: 96.05ms, accelerator: 0us, total: 96.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_81000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 56759212.37sec, total: 56759212.37sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.42ms, accelerator: 0us, total: 325.42ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.22ms, accelerator: 0us, total: 136.22ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.90ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.39ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 2.39ms, total: 7.35ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.51ms, total: 6.31ms
train.py:448:<module>, cpu: 136.23ms, accelerator: 0us, total: 136.23ms
train.py:449:<module>, cpu: 96.09ms, accelerator: 57us, total: 96.15ms
  summary.py:146:image, cpu: 96.06ms, accelerator: 0us, total: 96.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_81250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 56585104.36sec, total: 56585104.36sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.45ms, accelerator: 0us, total: 325.45ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.19ms, accelerator: 0us, total: 136.19ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.89ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.38ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 2.38ms, total: 7.33ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.50ms, total: 6.34ms
train.py:448:<module>, cpu: 136.20ms, accelerator: 0us, total: 136.20ms
train.py:449:<module>, cpu: 95.99ms, accelerator: 56us, total: 96.05ms
  summary.py:146:image, cpu: 95.96ms, accelerator: 0us, total: 95.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_81500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 56412061.23sec, total: 56412061.23sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.51ms, accelerator: 0us, total: 325.51ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.16ms, accelerator: 0us, total: 136.16ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.87ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.37ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.37ms, total: 7.33ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.50ms, total: 6.33ms
train.py:448:<module>, cpu: 136.16ms, accelerator: 0us, total: 136.16ms
train.py:449:<module>, cpu: 96.07ms, accelerator: 56us, total: 96.12ms
  summary.py:146:image, cpu: 96.03ms, accelerator: 0us, total: 96.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_81750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 56240073.23sec, total: 56240073.24sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.60ms, accelerator: 0us, total: 325.60ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.10ms, accelerator: 0us, total: 136.10ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.86ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.36ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.36ms, total: 7.31ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.50ms, total: 6.32ms
train.py:448:<module>, cpu: 136.11ms, accelerator: 0us, total: 136.11ms
train.py:449:<module>, cpu: 96.09ms, accelerator: 56us, total: 96.15ms
  summary.py:146:image, cpu: 96.06ms, accelerator: 0us, total: 96.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_82000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 56069130.76sec, total: 56069130.76sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.62ms, accelerator: 0us, total: 325.62ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.14ms, accelerator: 0us, total: 136.14ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.86ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.36ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.36ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.50ms, total: 6.33ms
train.py:448:<module>, cpu: 136.15ms, accelerator: 0us, total: 136.15ms
train.py:449:<module>, cpu: 96.00ms, accelerator: 56us, total: 96.06ms
  summary.py:146:image, cpu: 95.97ms, accelerator: 0us, total: 95.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_82250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 55899224.31sec, total: 55899224.31sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.39ms, accelerator: 0us, total: 325.39ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.13ms, accelerator: 0us, total: 136.13ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.84ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.35ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.35ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.49ms, total: 6.33ms
train.py:448:<module>, cpu: 136.14ms, accelerator: 0us, total: 136.14ms
train.py:449:<module>, cpu: 95.92ms, accelerator: 56us, total: 95.97ms
  summary.py:146:image, cpu: 95.88ms, accelerator: 0us, total: 95.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_82500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 55730344.47sec, total: 55730344.47sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.30ms, accelerator: 0us, total: 325.30ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.16ms, accelerator: 0us, total: 136.16ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.83ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.35ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.35ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.48ms, total: 6.33ms
train.py:448:<module>, cpu: 136.17ms, accelerator: 0us, total: 136.17ms
train.py:449:<module>, cpu: 95.80ms, accelerator: 56us, total: 95.85ms
  summary.py:146:image, cpu: 95.76ms, accelerator: 0us, total: 95.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_82750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 55562481.99sec, total: 55562481.99sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.30ms, accelerator: 0us, total: 325.30ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.21ms, accelerator: 0us, total: 136.21ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.82ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.34ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.34ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.48ms, total: 6.31ms
train.py:448:<module>, cpu: 136.22ms, accelerator: 0us, total: 136.22ms
train.py:449:<module>, cpu: 95.79ms, accelerator: 55us, total: 95.84ms
  summary.py:146:image, cpu: 95.75ms, accelerator: 0us, total: 95.75ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_83000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 55395627.69sec, total: 55395627.69sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 325.22ms, accelerator: 0us, total: 325.22ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.24ms, accelerator: 0us, total: 136.24ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.81ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.34ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.34ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.47ms, total: 6.31ms
train.py:448:<module>, cpu: 136.25ms, accelerator: 0us, total: 136.25ms
train.py:449:<module>, cpu: 95.74ms, accelerator: 55us, total: 95.80ms
  summary.py:146:image, cpu: 95.71ms, accelerator: 0us, total: 95.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_83250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 55229772.52sec, total: 55229772.52sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.87ms, accelerator: 0us, total: 324.87ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.10ms, accelerator: 0us, total: 136.10ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.80ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.33ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.33ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.47ms, total: 6.29ms
train.py:448:<module>, cpu: 136.11ms, accelerator: 0us, total: 136.11ms
train.py:449:<module>, cpu: 95.63ms, accelerator: 55us, total: 95.69ms
  summary.py:146:image, cpu: 95.60ms, accelerator: 0us, total: 95.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_83500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 55064907.53sec, total: 55064907.53sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.63ms, accelerator: 0us, total: 324.63ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.03ms, accelerator: 0us, total: 136.03ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.87ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.40ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.40ms, total: 7.31ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.46ms, total: 6.29ms
train.py:448:<module>, cpu: 136.04ms, accelerator: 0us, total: 136.04ms
train.py:449:<module>, cpu: 95.53ms, accelerator: 55us, total: 95.58ms
  summary.py:146:image, cpu: 95.49ms, accelerator: 0us, total: 95.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_83750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 54901023.87sec, total: 54901023.87sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.36ms, accelerator: 0us, total: 324.36ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 135.93ms, accelerator: 0us, total: 135.93ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.87ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.40ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.40ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.47ms, total: 6.31ms
train.py:448:<module>, cpu: 135.94ms, accelerator: 0us, total: 135.94ms
train.py:449:<module>, cpu: 95.47ms, accelerator: 55us, total: 95.53ms
  summary.py:146:image, cpu: 95.44ms, accelerator: 0us, total: 95.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_84000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 54738112.82sec, total: 54738112.82sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.38ms, accelerator: 0us, total: 324.38ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 135.95ms, accelerator: 0us, total: 135.95ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.88ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.38ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.38ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.50ms, total: 6.34ms
train.py:448:<module>, cpu: 135.96ms, accelerator: 0us, total: 135.96ms
train.py:449:<module>, cpu: 95.41ms, accelerator: 55us, total: 95.47ms
  summary.py:146:image, cpu: 95.38ms, accelerator: 0us, total: 95.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_84250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 54576165.74sec, total: 54576165.74sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.19ms, accelerator: 0us, total: 324.19ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 135.93ms, accelerator: 0us, total: 135.93ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.90ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.38ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.38ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.52ms, total: 6.37ms
train.py:448:<module>, cpu: 135.93ms, accelerator: 0us, total: 135.93ms
train.py:449:<module>, cpu: 95.32ms, accelerator: 54us, total: 95.37ms
  summary.py:146:image, cpu: 95.28ms, accelerator: 0us, total: 95.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_84500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 54415174.10sec, total: 54415174.10sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.49ms, accelerator: 0us, total: 324.49ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.02ms, accelerator: 0us, total: 136.02ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.89ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.38ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.38ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.52ms, total: 6.36ms
train.py:448:<module>, cpu: 136.02ms, accelerator: 0us, total: 136.02ms
train.py:449:<module>, cpu: 95.45ms, accelerator: 54us, total: 95.50ms
  summary.py:146:image, cpu: 95.42ms, accelerator: 0us, total: 95.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_84750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 54255129.47sec, total: 54255129.47sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.26ms, accelerator: 0us, total: 324.26ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 135.92ms, accelerator: 0us, total: 135.92ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.88ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.37ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.37ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.51ms, total: 6.35ms
train.py:448:<module>, cpu: 135.93ms, accelerator: 0us, total: 135.93ms
train.py:449:<module>, cpu: 95.42ms, accelerator: 54us, total: 95.47ms
  summary.py:146:image, cpu: 95.38ms, accelerator: 0us, total: 95.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_85000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 54096023.52sec, total: 54096023.52sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.14ms, accelerator: 0us, total: 324.14ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 135.78ms, accelerator: 0us, total: 135.78ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.87ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.36ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.36ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.51ms, total: 6.34ms
train.py:448:<module>, cpu: 135.79ms, accelerator: 0us, total: 135.79ms
train.py:449:<module>, cpu: 95.50ms, accelerator: 54us, total: 95.55ms
  summary.py:146:image, cpu: 95.47ms, accelerator: 0us, total: 95.47ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_85250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 53937848.01sec, total: 53937848.01sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.34ms, accelerator: 0us, total: 324.34ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 135.85ms, accelerator: 0us, total: 135.85ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.86ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.36ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.36ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.50ms, total: 6.35ms
train.py:448:<module>, cpu: 135.85ms, accelerator: 0us, total: 135.85ms
train.py:449:<module>, cpu: 95.50ms, accelerator: 54us, total: 95.55ms
  summary.py:146:image, cpu: 95.46ms, accelerator: 0us, total: 95.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_85500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 53780594.81sec, total: 53780594.81sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 3 operation type: ImageSummary, cpu: 324.36ms, accelerator: 0us, total: 324.36ms (0.00%)
top 1 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 135.92ms, accelerator: 0us, total: 135.92ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.85ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.35ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.35ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.50ms, total: 6.35ms
train.py:448:<module>, cpu: 135.93ms, accelerator: 0us, total: 135.93ms
train.py:449:<module>, cpu: 95.40ms, accelerator: 54us, total: 95.45ms
  summary.py:146:image, cpu: 95.36ms, accelerator: 0us, total: 95.36ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_85750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 53624255.88sec, total: 53624255.88sec (33.33%)
top 2 operation type: Mean, cpu: 783us, accelerator: 53624255.88sec, total: 53624255.88sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 53624255.88sec, total: 53624255.88sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 53624255.88sec, total: 53624255.89sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 53624255.88sec, total: 53624255.88sec
  train.py:357:image_losses, cpu: 266us, accelerator: 53624255.88sec, total: 53624255.88sec
    train.py:322:loss_fn, cpu: 243us, accelerator: 53624255.88sec, total: 53624255.88sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 1.46ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 1.46ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.81ms, accelerator: 1.44ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.80ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.80ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 561us, total: 1.77ms
      train.py:343:hfe, cpu: 531us, accelerator: 621us, total: 1.16ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.89ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.38ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.38ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.51ms, total: 6.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_86000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 53468823.25sec, total: 53468823.25sec (33.33%)
top 2 operation type: Mean, cpu: 783us, accelerator: 53468823.25sec, total: 53468823.25sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 53468823.25sec, total: 53468823.25sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 53468823.26sec, total: 53468823.26sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 53468823.25sec, total: 53468823.26sec
  train.py:357:image_losses, cpu: 266us, accelerator: 53468823.25sec, total: 53468823.25sec
    train.py:322:loss_fn, cpu: 243us, accelerator: 53468823.25sec, total: 53468823.25sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 1.46ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 1.46ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.80ms, accelerator: 1.44ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.79ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.79ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 559us, total: 1.77ms
      train.py:343:hfe, cpu: 531us, accelerator: 618us, total: 1.15ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.88ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.38ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.38ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.50ms, total: 6.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_86250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 53314289.08sec, total: 53314289.08sec (33.33%)
top 2 operation type: Mean, cpu: 782us, accelerator: 53314289.08sec, total: 53314289.08sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 53314289.08sec, total: 53314289.08sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 53314289.08sec, total: 53314289.09sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 53314289.08sec, total: 53314289.09sec
  train.py:357:image_losses, cpu: 264us, accelerator: 53314289.08sec, total: 53314289.08sec
    train.py:322:loss_fn, cpu: 241us, accelerator: 53314289.08sec, total: 53314289.08sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 1.45ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 1.45ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.80ms, accelerator: 1.43ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.79ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.00ms, accelerator: 1.79ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 557us, total: 1.76ms
      train.py:343:hfe, cpu: 539us, accelerator: 617us, total: 1.16ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.87ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.37ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.37ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.49ms, total: 6.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2136.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_86500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 53160645.60sec, total: 53160645.60sec (33.33%)
top 2 operation type: Mean, cpu: 781us, accelerator: 53160645.60sec, total: 53160645.60sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 53160645.59sec, total: 53160645.59sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 53160645.60sec, total: 53160645.60sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 53160645.60sec, total: 53160645.60sec
  train.py:357:image_losses, cpu: 264us, accelerator: 53160645.59sec, total: 53160645.59sec
    train.py:322:loss_fn, cpu: 241us, accelerator: 53160645.59sec, total: 53160645.59sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 1.45ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 1.45ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.80ms, accelerator: 1.43ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.78ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.00ms, accelerator: 1.78ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 557us, total: 1.76ms
      train.py:343:hfe, cpu: 538us, accelerator: 615us, total: 1.16ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.86ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.37ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.37ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.49ms, total: 6.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_86750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 53007885.12sec, total: 53007885.12sec (33.33%)
top 2 operation type: Mean, cpu: 781us, accelerator: 53007885.12sec, total: 53007885.12sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 53007885.12sec, total: 53007885.12sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 53007885.12sec, total: 53007885.13sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 53007885.12sec, total: 53007885.13sec
  train.py:357:image_losses, cpu: 264us, accelerator: 53007885.12sec, total: 53007885.12sec
    train.py:322:loss_fn, cpu: 241us, accelerator: 53007885.12sec, total: 53007885.12sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.45ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.45ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.43ms, total: 4.31ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.78ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.78ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 555us, total: 1.79ms
      train.py:343:hfe, cpu: 537us, accelerator: 614us, total: 1.15ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.85ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.36ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.36ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.48ms, total: 6.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_87000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 52856000.06sec, total: 52856000.06sec (33.33%)
top 2 operation type: Mean, cpu: 781us, accelerator: 52856000.06sec, total: 52856000.06sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 52856000.06sec, total: 52856000.06sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 52856000.07sec, total: 52856000.07sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 52856000.06sec, total: 52856000.07sec
  train.py:357:image_losses, cpu: 264us, accelerator: 52856000.06sec, total: 52856000.06sec
    train.py:322:loss_fn, cpu: 241us, accelerator: 52856000.06sec, total: 52856000.06sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.45ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.45ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.43ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.79ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.79ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 553us, total: 1.79ms
      train.py:343:hfe, cpu: 535us, accelerator: 618us, total: 1.16ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.91ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.40ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.40ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.51ms, total: 6.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_87250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 52704982.92sec, total: 52704982.92sec (33.33%)
top 2 operation type: Mean, cpu: 780us, accelerator: 52704982.92sec, total: 52704982.92sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 52704982.92sec, total: 52704982.92sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 52704982.92sec, total: 52704982.93sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 52704982.92sec, total: 52704982.93sec
  train.py:357:image_losses, cpu: 264us, accelerator: 52704982.92sec, total: 52704982.92sec
    train.py:322:loss_fn, cpu: 241us, accelerator: 52704982.92sec, total: 52704982.92sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.44ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.44ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.42ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.78ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.78ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 552us, total: 1.81ms
      train.py:343:hfe, cpu: 534us, accelerator: 618us, total: 1.16ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.89ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.39ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.39ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.51ms, total: 6.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_87500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 52554826.27sec, total: 52554826.27sec (33.33%)
top 2 operation type: Mean, cpu: 780us, accelerator: 52554826.27sec, total: 52554826.27sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 52554826.27sec, total: 52554826.27sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 52554826.28sec, total: 52554826.28sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 52554826.28sec, total: 52554826.28sec
  train.py:357:image_losses, cpu: 264us, accelerator: 52554826.27sec, total: 52554826.27sec
    train.py:322:loss_fn, cpu: 241us, accelerator: 52554826.27sec, total: 52554826.27sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.44ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.44ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.42ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.78ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.78ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 550us, total: 1.81ms
      train.py:343:hfe, cpu: 533us, accelerator: 616us, total: 1.15ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.89ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.38ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.38ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.50ms, total: 6.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_87750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 52405522.79sec, total: 52405522.79sec (33.33%)
top 2 operation type: Mean, cpu: 777us, accelerator: 52405522.79sec, total: 52405522.79sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 52405522.79sec, total: 52405522.79sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 52405522.79sec, total: 52405522.80sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 52405522.79sec, total: 52405522.80sec
  train.py:357:image_losses, cpu: 263us, accelerator: 52405522.79sec, total: 52405522.79sec
    train.py:322:loss_fn, cpu: 240us, accelerator: 52405522.79sec, total: 52405522.79sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.44ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.44ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.42ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.77ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.77ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 549us, total: 1.80ms
      train.py:343:hfe, cpu: 532us, accelerator: 614us, total: 1.15ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.87ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.38ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.38ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.50ms, total: 6.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_88000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 52257065.22sec, total: 52257065.22sec (33.33%)
top 2 operation type: Mean, cpu: 774us, accelerator: 52257065.22sec, total: 52257065.22sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 52257065.22sec, total: 52257065.22sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 52257065.22sec, total: 52257065.23sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 52257065.22sec, total: 52257065.23sec
  train.py:357:image_losses, cpu: 263us, accelerator: 52257065.22sec, total: 52257065.22sec
    train.py:322:loss_fn, cpu: 240us, accelerator: 52257065.22sec, total: 52257065.22sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.44ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.44ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.42ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.77ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.77ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 547us, total: 1.82ms
      train.py:343:hfe, cpu: 532us, accelerator: 613us, total: 1.15ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.87ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.37ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.37ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.50ms, total: 6.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_88250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 52109446.39sec, total: 52109446.39sec (33.33%)
top 2 operation type: Mean, cpu: 789us, accelerator: 52109446.39sec, total: 52109446.39sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 52109446.39sec, total: 52109446.39sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 52109446.39sec, total: 52109446.40sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 52109446.39sec, total: 52109446.40sec
  train.py:357:image_losses, cpu: 263us, accelerator: 52109446.39sec, total: 52109446.39sec
    train.py:322:loss_fn, cpu: 240us, accelerator: 52109446.39sec, total: 52109446.39sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.44ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.44ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.41ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.76ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.76ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 545us, total: 1.81ms
      train.py:343:hfe, cpu: 538us, accelerator: 610us, total: 1.15ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.85ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.37ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.37ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.49ms, total: 6.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_88500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 51962659.22sec, total: 51962659.22sec (33.33%)
top 2 operation type: Mean, cpu: 787us, accelerator: 51962659.22sec, total: 51962659.22sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 51962659.21sec, total: 51962659.21sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 51962659.22sec, total: 51962659.22sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 51962659.22sec, total: 51962659.22sec
  train.py:357:image_losses, cpu: 263us, accelerator: 51962659.22sec, total: 51962659.22sec
    train.py:322:loss_fn, cpu: 240us, accelerator: 51962659.22sec, total: 51962659.22sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.43ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.43ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.41ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.79ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.79ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 551us, total: 1.81ms
      train.py:343:hfe, cpu: 537us, accelerator: 630us, total: 1.17ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.85ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.36ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.36ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.49ms, total: 6.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_88750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 51816696.69sec, total: 51816696.69sec (33.33%)
top 2 operation type: Mean, cpu: 788us, accelerator: 51816696.69sec, total: 51816696.69sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 51816696.69sec, total: 51816696.69sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 51816696.69sec, total: 51816696.70sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 51816696.69sec, total: 51816696.70sec
  train.py:357:image_losses, cpu: 262us, accelerator: 51816696.69sec, total: 51816696.69sec
    train.py:322:loss_fn, cpu: 239us, accelerator: 51816696.69sec, total: 51816696.69sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.43ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.43ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.41ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.81ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 549us, total: 1.81ms
      train.py:343:hfe, cpu: 536us, accelerator: 646us, total: 1.19ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.89ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.41ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.41ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.48ms, total: 6.29ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2127.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_89000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 51671551.88sec, total: 51671551.88sec (33.33%)
top 2 operation type: Mean, cpu: 787us, accelerator: 51671551.88sec, total: 51671551.88sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 51671551.88sec, total: 51671551.88sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 51671551.89sec, total: 51671551.89sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 51671551.88sec, total: 51671551.89sec
  train.py:357:image_losses, cpu: 262us, accelerator: 51671551.88sec, total: 51671551.88sec
    train.py:322:loss_fn, cpu: 239us, accelerator: 51671551.88sec, total: 51671551.88sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.46ms, total: 4.40ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.46ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.44ms, total: 4.31ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.80ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.80ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 549us, total: 1.81ms
      train.py:343:hfe, cpu: 535us, accelerator: 644us, total: 1.18ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.88ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.40ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.40ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.48ms, total: 6.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_89250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 51527217.94sec, total: 51527217.94sec (33.33%)
top 2 operation type: Mean, cpu: 789us, accelerator: 51527217.94sec, total: 51527217.94sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 51527217.94sec, total: 51527217.94sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 51527217.94sec, total: 51527217.95sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 51527217.94sec, total: 51527217.95sec
  train.py:357:image_losses, cpu: 262us, accelerator: 51527217.94sec, total: 51527217.94sec
    train.py:322:loss_fn, cpu: 239us, accelerator: 51527217.94sec, total: 51527217.94sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.46ms, total: 4.40ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.46ms, total: 4.39ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.44ms, total: 4.32ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.80ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.80ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 547us, total: 1.81ms
      train.py:343:hfe, cpu: 534us, accelerator: 640us, total: 1.18ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.90ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.42ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.42ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.48ms, total: 6.27ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_89500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 51383688.08sec, total: 51383688.08sec (33.33%)
top 2 operation type: Mean, cpu: 788us, accelerator: 51383688.08sec, total: 51383688.08sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 51383688.08sec, total: 51383688.08sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 51383688.09sec, total: 51383688.09sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 51383688.09sec, total: 51383688.09sec
  train.py:357:image_losses, cpu: 262us, accelerator: 51383688.08sec, total: 51383688.08sec
    train.py:322:loss_fn, cpu: 239us, accelerator: 51383688.08sec, total: 51383688.08sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.46ms, total: 4.40ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.46ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.44ms, total: 4.31ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.79ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.79ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 545us, total: 1.80ms
      train.py:343:hfe, cpu: 534us, accelerator: 640us, total: 1.18ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.89ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.42ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.42ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.47ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_89750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 51240955.62sec, total: 51240955.62sec (33.33%)
top 2 operation type: Mean, cpu: 787us, accelerator: 51240955.62sec, total: 51240955.62sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 51240955.61sec, total: 51240955.61sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 51240955.62sec, total: 51240955.62sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 51240955.62sec, total: 51240955.62sec
  train.py:357:image_losses, cpu: 261us, accelerator: 51240955.61sec, total: 51240955.62sec
    train.py:322:loss_fn, cpu: 238us, accelerator: 51240955.61sec, total: 51240955.62sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.46ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.46ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.44ms, total: 4.31ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.79ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.79ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 542us, total: 1.80ms
      train.py:343:hfe, cpu: 533us, accelerator: 639us, total: 1.18ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.87ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.41ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.41ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.46ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_90000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 51099013.91sec, total: 51099013.91sec (33.33%)
top 2 operation type: Mean, cpu: 786us, accelerator: 51099013.91sec, total: 51099013.91sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 51099013.91sec, total: 51099013.91sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 51099013.91sec, total: 51099013.92sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 51099013.91sec, total: 51099013.92sec
  train.py:357:image_losses, cpu: 261us, accelerator: 51099013.91sec, total: 51099013.91sec
    train.py:322:loss_fn, cpu: 238us, accelerator: 51099013.91sec, total: 51099013.91sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.45ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.45ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.43ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.79ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.79ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 550us, total: 1.80ms
      train.py:343:hfe, cpu: 533us, accelerator: 639us, total: 1.18ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.89ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.42ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.42ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.47ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_90250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 50957856.41sec, total: 50957856.42sec (33.33%)
top 2 operation type: Mean, cpu: 784us, accelerator: 50957856.41sec, total: 50957856.41sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 50957856.41sec, total: 50957856.41sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 50957856.42sec, total: 50957856.42sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 50957856.42sec, total: 50957856.42sec
  train.py:357:image_losses, cpu: 261us, accelerator: 50957856.41sec, total: 50957856.41sec
    train.py:322:loss_fn, cpu: 238us, accelerator: 50957856.41sec, total: 50957856.41sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.45ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.45ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.43ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.79ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.79ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 549us, total: 1.81ms
      train.py:343:hfe, cpu: 531us, accelerator: 638us, total: 1.17ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.88ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.41ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.80ms, accelerator: 2.41ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.47ms, total: 6.24ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_90500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 50817476.64sec, total: 50817476.65sec (33.33%)
top 2 operation type: Mean, cpu: 783us, accelerator: 50817476.64sec, total: 50817476.64sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 50817476.64sec, total: 50817476.64sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 50817476.65sec, total: 50817476.65sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 50817476.65sec, total: 50817476.65sec
  train.py:357:image_losses, cpu: 260us, accelerator: 50817476.64sec, total: 50817476.64sec
    train.py:322:loss_fn, cpu: 238us, accelerator: 50817476.64sec, total: 50817476.64sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.45ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.45ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.43ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.78ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.78ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 547us, total: 1.80ms
      train.py:343:hfe, cpu: 531us, accelerator: 636us, total: 1.17ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.87ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.40ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.79ms, accelerator: 2.40ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.46ms, total: 6.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_90750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 50677868.19sec, total: 50677868.19sec (33.33%)
top 2 operation type: Mean, cpu: 783us, accelerator: 50677868.19sec, total: 50677868.19sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 50677868.19sec, total: 50677868.19sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 50677868.20sec, total: 50677868.20sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 50677868.19sec, total: 50677868.20sec
  train.py:357:image_losses, cpu: 260us, accelerator: 50677868.19sec, total: 50677868.19sec
    train.py:322:loss_fn, cpu: 238us, accelerator: 50677868.19sec, total: 50677868.19sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.45ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.45ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.43ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.80ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.80ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 545us, total: 1.80ms
      train.py:343:hfe, cpu: 529us, accelerator: 643us, total: 1.18ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.90ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.43ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.43ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.46ms, total: 6.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_91000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 50539024.72sec, total: 50539024.72sec (33.33%)
top 2 operation type: Mean, cpu: 782us, accelerator: 50539024.72sec, total: 50539024.72sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 50539024.72sec, total: 50539024.72sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 50539024.72sec, total: 50539024.73sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 50539024.72sec, total: 50539024.73sec
  train.py:357:image_losses, cpu: 259us, accelerator: 50539024.72sec, total: 50539024.72sec
    train.py:322:loss_fn, cpu: 237us, accelerator: 50539024.72sec, total: 50539024.72sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.45ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.45ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.43ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.79ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.79ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 545us, total: 1.80ms
      train.py:343:hfe, cpu: 527us, accelerator: 641us, total: 1.17ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.89ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.43ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.43ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.46ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_91250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 50400939.95sec, total: 50400939.95sec (33.33%)
top 2 operation type: Mean, cpu: 780us, accelerator: 50400939.95sec, total: 50400939.95sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 50400939.95sec, total: 50400939.95sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 50400939.95sec, total: 50400939.96sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 50400939.95sec, total: 50400939.96sec
  train.py:357:image_losses, cpu: 258us, accelerator: 50400939.95sec, total: 50400939.95sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 50400939.95sec, total: 50400939.95sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.45ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.45ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.43ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.79ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.79ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 545us, total: 1.80ms
      train.py:343:hfe, cpu: 526us, accelerator: 639us, total: 1.17ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.90ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.45ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.45ms, total: 7.31ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.45ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_91500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 50263607.69sec, total: 50263607.69sec (33.33%)
top 2 operation type: Mean, cpu: 780us, accelerator: 50263607.69sec, total: 50263607.69sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 50263607.69sec, total: 50263607.69sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 50263607.69sec, total: 50263607.70sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 50263607.69sec, total: 50263607.70sec
  train.py:357:image_losses, cpu: 258us, accelerator: 50263607.69sec, total: 50263607.69sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 50263607.69sec, total: 50263607.69sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.44ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.44ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.42ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.78ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.78ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 542us, total: 1.79ms
      train.py:343:hfe, cpu: 526us, accelerator: 638us, total: 1.17ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.89ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.45ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.45ms, total: 7.33ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.44ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_91750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 50127021.80sec, total: 50127021.80sec (33.33%)
top 2 operation type: Mean, cpu: 780us, accelerator: 50127021.80sec, total: 50127021.80sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 50127021.80sec, total: 50127021.80sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 50127021.80sec, total: 50127021.81sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 50127021.80sec, total: 50127021.81sec
  train.py:357:image_losses, cpu: 258us, accelerator: 50127021.80sec, total: 50127021.80sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 50127021.80sec, total: 50127021.80sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.44ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.44ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.42ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.78ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.78ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 542us, total: 1.79ms
      train.py:343:hfe, cpu: 526us, accelerator: 637us, total: 1.17ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.88ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.44ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.44ms, total: 7.33ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.44ms, total: 6.24ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_92000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 49991176.21sec, total: 49991176.21sec (33.33%)
top 2 operation type: Mean, cpu: 778us, accelerator: 49991176.21sec, total: 49991176.21sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 49991176.21sec, total: 49991176.21sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 49991176.21sec, total: 49991176.22sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 49991176.21sec, total: 49991176.22sec
  train.py:357:image_losses, cpu: 258us, accelerator: 49991176.21sec, total: 49991176.21sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 49991176.21sec, total: 49991176.21sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.44ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.44ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.42ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.78ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.78ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 541us, total: 1.80ms
      train.py:343:hfe, cpu: 525us, accelerator: 635us, total: 1.16ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.87ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.44ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.44ms, total: 7.32ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.44ms, total: 6.23ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_92250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 49856064.92sec, total: 49856064.93sec (33.33%)
top 2 operation type: Mean, cpu: 777us, accelerator: 49856064.92sec, total: 49856064.92sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 49856064.92sec, total: 49856064.92sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 49856064.93sec, total: 49856064.93sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 49856064.93sec, total: 49856064.93sec
  train.py:357:image_losses, cpu: 257us, accelerator: 49856064.92sec, total: 49856064.92sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 49856064.92sec, total: 49856064.92sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.44ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.44ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.42ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.78ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.78ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 541us, total: 1.79ms
      train.py:343:hfe, cpu: 523us, accelerator: 634us, total: 1.16ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.87ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.43ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.43ms, total: 7.31ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.44ms, total: 6.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_92500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 49721682.00sec, total: 49721682.00sec (33.33%)
top 2 operation type: Mean, cpu: 777us, accelerator: 49721682.00sec, total: 49721682.00sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 49721682.00sec, total: 49721682.00sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 49721682.00sec, total: 49721682.01sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 49721682.00sec, total: 49721682.01sec
  train.py:357:image_losses, cpu: 257us, accelerator: 49721682.00sec, total: 49721682.00sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 49721682.00sec, total: 49721682.00sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.43ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.43ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.41ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.77ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.77ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 538us, total: 1.79ms
      train.py:343:hfe, cpu: 523us, accelerator: 636us, total: 1.16ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.91ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.42ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.42ms, total: 7.30ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.48ms, total: 6.26ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_92750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 49588021.56sec, total: 49588021.57sec (33.33%)
top 2 operation type: Mean, cpu: 775us, accelerator: 49588021.56sec, total: 49588021.56sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 49588021.56sec, total: 49588021.56sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 49588021.57sec, total: 49588021.57sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 49588021.57sec, total: 49588021.57sec
  train.py:357:image_losses, cpu: 257us, accelerator: 49588021.56sec, total: 49588021.56sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 49588021.56sec, total: 49588021.56sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.43ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.43ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.41ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.77ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.77ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 538us, total: 1.78ms
      train.py:343:hfe, cpu: 522us, accelerator: 635us, total: 1.16ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.89ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.42ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.42ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.48ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_93000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 49455077.81sec, total: 49455077.81sec (33.33%)
top 2 operation type: Mean, cpu: 773us, accelerator: 49455077.81sec, total: 49455077.81sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 49455077.80sec, total: 49455077.80sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 49455077.81sec, total: 49455077.81sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 49455077.81sec, total: 49455077.81sec
  train.py:357:image_losses, cpu: 256us, accelerator: 49455077.81sec, total: 49455077.81sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 49455077.81sec, total: 49455077.81sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.43ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.43ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.41ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.77ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.77ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 543us, total: 1.79ms
      train.py:343:hfe, cpu: 520us, accelerator: 631us, total: 1.16ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.88ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.41ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.41ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.47ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_93250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 49322844.98sec, total: 49322844.98sec (33.33%)
top 2 operation type: Mean, cpu: 773us, accelerator: 49322844.98sec, total: 49322844.98sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 49322844.98sec, total: 49322844.98sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 49322844.98sec, total: 49322844.99sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 49322844.98sec, total: 49322844.99sec
  train.py:357:image_losses, cpu: 256us, accelerator: 49322844.98sec, total: 49322844.98sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 49322844.98sec, total: 49322844.98sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.43ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.43ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.41ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.76ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.76ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 540us, total: 1.78ms
      train.py:343:hfe, cpu: 520us, accelerator: 631us, total: 1.16ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.87ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.40ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.40ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.46ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_93500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 49191317.39sec, total: 49191317.39sec (33.33%)
top 2 operation type: Mean, cpu: 772us, accelerator: 49191317.39sec, total: 49191317.39sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 49191317.39sec, total: 49191317.39sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 49191317.40sec, total: 49191317.40sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 49191317.39sec, total: 49191317.40sec
  train.py:357:image_losses, cpu: 256us, accelerator: 49191317.39sec, total: 49191317.39sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 49191317.39sec, total: 49191317.39sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.45ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.45ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.43ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.82ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.82ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 539us, total: 1.78ms
      train.py:343:hfe, cpu: 519us, accelerator: 685us, total: 1.21ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.86ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.40ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.40ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.46ms, total: 6.24ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_93750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 49060489.42sec, total: 49060489.42sec (33.33%)
top 2 operation type: Mean, cpu: 773us, accelerator: 49060489.42sec, total: 49060489.42sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 49060489.42sec, total: 49060489.42sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 49060489.42sec, total: 49060489.43sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 49060489.42sec, total: 49060489.43sec
  train.py:357:image_losses, cpu: 257us, accelerator: 49060489.42sec, total: 49060489.42sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 49060489.42sec, total: 49060489.42sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.45ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.45ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.43ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.81ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.81ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 538us, total: 1.78ms
      train.py:343:hfe, cpu: 519us, accelerator: 682us, total: 1.21ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.85ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.40ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.40ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.45ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_94000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 48930355.50sec, total: 48930355.50sec (33.33%)
top 2 operation type: Mean, cpu: 773us, accelerator: 48930355.49sec, total: 48930355.50sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 48930355.49sec, total: 48930355.49sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 48930355.50sec, total: 48930355.50sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 48930355.50sec, total: 48930355.50sec
  train.py:357:image_losses, cpu: 257us, accelerator: 48930355.49sec, total: 48930355.49sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 48930355.49sec, total: 48930355.49sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.44ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.44ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.42ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.81ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.81ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 538us, total: 1.78ms
      train.py:343:hfe, cpu: 519us, accelerator: 680us, total: 1.20ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.84ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.39ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.39ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.45ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_94250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 48800910.11sec, total: 48800910.11sec (33.33%)
top 2 operation type: Mean, cpu: 772us, accelerator: 48800910.11sec, total: 48800910.11sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 48800910.11sec, total: 48800910.11sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 48800910.11sec, total: 48800910.12sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 48800910.11sec, total: 48800910.12sec
  train.py:357:image_losses, cpu: 256us, accelerator: 48800910.11sec, total: 48800910.11sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 48800910.11sec, total: 48800910.11sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.44ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.44ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.42ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.82ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.00ms, accelerator: 1.82ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 535us, total: 1.77ms
      train.py:343:hfe, cpu: 517us, accelerator: 688us, total: 1.21ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.96ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.48ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.48ms, total: 7.32ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.48ms, total: 6.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_94500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 48672147.81sec, total: 48672147.82sec (33.33%)
top 2 operation type: Mean, cpu: 772us, accelerator: 48672147.81sec, total: 48672147.81sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 48672147.81sec, total: 48672147.81sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 48672147.82sec, total: 48672147.82sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 48672147.82sec, total: 48672147.82sec
  train.py:357:image_losses, cpu: 256us, accelerator: 48672147.81sec, total: 48672147.81sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 48672147.81sec, total: 48672147.81sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.44ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.44ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.42ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.82ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.00ms, accelerator: 1.82ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 535us, total: 1.77ms
      train.py:343:hfe, cpu: 516us, accelerator: 687us, total: 1.21ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.95ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.48ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.80ms, accelerator: 2.48ms, total: 7.30ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.48ms, total: 6.26ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_94750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 48544063.22sec, total: 48544063.22sec (33.33%)
top 2 operation type: Mean, cpu: 769us, accelerator: 48544063.21sec, total: 48544063.22sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 48544063.21sec, total: 48544063.21sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 48544063.22sec, total: 48544063.22sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 48544063.22sec, total: 48544063.22sec
  train.py:357:image_losses, cpu: 255us, accelerator: 48544063.21sec, total: 48544063.21sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 48544063.21sec, total: 48544063.21sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.44ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.44ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.42ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.81ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.81ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 533us, total: 1.76ms
      train.py:343:hfe, cpu: 515us, accelerator: 683us, total: 1.20ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.94ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 2.47ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.47ms, total: 7.33ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.47ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_95000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 48416650.98sec, total: 48416650.98sec (33.33%)
top 2 operation type: Mean, cpu: 769us, accelerator: 48416650.98sec, total: 48416650.98sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 48416650.97sec, total: 48416650.97sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 48416650.98sec, total: 48416650.98sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 48416650.98sec, total: 48416650.98sec
  train.py:357:image_losses, cpu: 255us, accelerator: 48416650.97sec, total: 48416650.97sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 48416650.97sec, total: 48416650.97sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.43ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.43ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.41ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.81ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.81ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 532us, total: 1.76ms
      train.py:343:hfe, cpu: 514us, accelerator: 683us, total: 1.20ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.92ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.46ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.46ms, total: 7.32ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.46ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_95250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 48289905.82sec, total: 48289905.82sec (33.33%)
top 2 operation type: Mean, cpu: 767us, accelerator: 48289905.82sec, total: 48289905.82sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 48289905.81sec, total: 48289905.81sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 48289905.82sec, total: 48289905.82sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 48289905.82sec, total: 48289905.82sec
  train.py:357:image_losses, cpu: 255us, accelerator: 48289905.82sec, total: 48289905.82sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 48289905.82sec, total: 48289905.82sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.43ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.43ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.41ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.80ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.80ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 532us, total: 1.76ms
      train.py:343:hfe, cpu: 548us, accelerator: 681us, total: 1.23ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.93ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.46ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.46ms, total: 7.30ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.47ms, total: 6.25ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_95500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 48163822.51sec, total: 48163822.51sec (33.33%)
top 2 operation type: Mean, cpu: 766us, accelerator: 48163822.51sec, total: 48163822.51sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 48163822.51sec, total: 48163822.51sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 48163822.52sec, total: 48163822.52sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 48163822.51sec, total: 48163822.52sec
  train.py:357:image_losses, cpu: 255us, accelerator: 48163822.51sec, total: 48163822.51sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 48163822.51sec, total: 48163822.51sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.43ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.43ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.41ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.80ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.80ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 530us, total: 1.77ms
      train.py:343:hfe, cpu: 547us, accelerator: 680us, total: 1.23ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.92ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.46ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.46ms, total: 7.30ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.46ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_95750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 48038395.89sec, total: 48038395.89sec (33.33%)
top 2 operation type: Mean, cpu: 766us, accelerator: 48038395.89sec, total: 48038395.89sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 48038395.89sec, total: 48038395.89sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 48038395.89sec, total: 48038395.90sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 48038395.89sec, total: 48038395.90sec
  train.py:357:image_losses, cpu: 255us, accelerator: 48038395.89sec, total: 48038395.89sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 48038395.89sec, total: 48038395.89sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.43ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.43ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.41ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.83ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.83ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 529us, total: 1.76ms
      train.py:343:hfe, cpu: 546us, accelerator: 705us, total: 1.26ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.91ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.45ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.45ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.46ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_96000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 47913620.84sec, total: 47913620.84sec (33.33%)
top 2 operation type: Mean, cpu: 767us, accelerator: 47913620.84sec, total: 47913620.84sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 47913620.83sec, total: 47913620.83sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 47913620.84sec, total: 47913620.84sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 47913620.84sec, total: 47913620.84sec
  train.py:357:image_losses, cpu: 255us, accelerator: 47913620.83sec, total: 47913620.83sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 47913620.83sec, total: 47913620.83sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.43ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.43ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.41ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.85ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.85ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 528us, total: 1.76ms
      train.py:343:hfe, cpu: 545us, accelerator: 731us, total: 1.28ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.91ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.44ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.44ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.47ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_96250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 47789492.28sec, total: 47789492.29sec (33.33%)
top 2 operation type: Mean, cpu: 766us, accelerator: 47789492.28sec, total: 47789492.28sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 47789492.28sec, total: 47789492.28sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 47789492.29sec, total: 47789492.29sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 47789492.29sec, total: 47789492.29sec
  train.py:357:image_losses, cpu: 254us, accelerator: 47789492.28sec, total: 47789492.28sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 47789492.28sec, total: 47789492.28sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.42ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.42ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.40ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.85ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.85ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 527us, total: 1.75ms
      train.py:343:hfe, cpu: 545us, accelerator: 729us, total: 1.28ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.90ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.44ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.44ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.46ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_96500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 47666005.22sec, total: 47666005.23sec (33.33%)
top 2 operation type: Mean, cpu: 765us, accelerator: 47666005.22sec, total: 47666005.22sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 47666005.22sec, total: 47666005.22sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 47666005.23sec, total: 47666005.23sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 47666005.23sec, total: 47666005.23sec
  train.py:357:image_losses, cpu: 254us, accelerator: 47666005.22sec, total: 47666005.22sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 47666005.22sec, total: 47666005.22sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.42ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.42ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.40ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.84ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.84ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 526us, total: 1.75ms
      train.py:343:hfe, cpu: 544us, accelerator: 727us, total: 1.27ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.89ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.43ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.80ms, accelerator: 2.43ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.46ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_96750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 47543154.70sec, total: 47543154.70sec (33.33%)
top 2 operation type: Mean, cpu: 764us, accelerator: 47543154.69sec, total: 47543154.70sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 47543154.69sec, total: 47543154.69sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 47543154.70sec, total: 47543154.70sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 47543154.70sec, total: 47543154.70sec
  train.py:357:image_losses, cpu: 254us, accelerator: 47543154.69sec, total: 47543154.69sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 47543154.69sec, total: 47543154.69sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.42ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.42ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.40ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.85ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.85ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 529us, total: 1.75ms
      train.py:343:hfe, cpu: 544us, accelerator: 727us, total: 1.27ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.88ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.42ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.80ms, accelerator: 2.42ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.45ms, total: 6.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_97000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 47420935.79sec, total: 47420935.79sec (33.33%)
top 2 operation type: Mean, cpu: 763us, accelerator: 47420935.79sec, total: 47420935.79sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 47420935.79sec, total: 47420935.79sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 47420935.79sec, total: 47420935.80sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 47420935.79sec, total: 47420935.80sec
  train.py:357:image_losses, cpu: 253us, accelerator: 47420935.79sec, total: 47420935.79sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 47420935.79sec, total: 47420935.79sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.42ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.42ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.40ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.84ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.84ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 527us, total: 1.75ms
      train.py:343:hfe, cpu: 542us, accelerator: 725us, total: 1.27ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.87ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.42ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.79ms, accelerator: 2.42ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.45ms, total: 6.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_97250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 47299343.65sec, total: 47299343.65sec (33.33%)
top 2 operation type: Mean, cpu: 763us, accelerator: 47299343.64sec, total: 47299343.65sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 47299343.64sec, total: 47299343.64sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 47299343.65sec, total: 47299343.65sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 47299343.65sec, total: 47299343.65sec
  train.py:357:image_losses, cpu: 253us, accelerator: 47299343.64sec, total: 47299343.64sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 47299343.64sec, total: 47299343.64sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.42ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.42ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.40ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.84ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.84ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 526us, total: 1.76ms
      train.py:343:hfe, cpu: 541us, accelerator: 722us, total: 1.27ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.85ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.41ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.78ms, accelerator: 2.41ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.44ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_97500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 47178373.46sec, total: 47178373.46sec (33.33%)
top 2 operation type: Mean, cpu: 760us, accelerator: 47178373.46sec, total: 47178373.46sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 47178373.46sec, total: 47178373.46sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 47178373.46sec, total: 47178373.47sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 47178373.46sec, total: 47178373.47sec
  train.py:357:image_losses, cpu: 252us, accelerator: 47178373.46sec, total: 47178373.46sec
    train.py:322:loss_fn, cpu: 230us, accelerator: 47178373.46sec, total: 47178373.46sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.42ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.42ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.40ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.83ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.83ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 525us, total: 1.75ms
      train.py:343:hfe, cpu: 540us, accelerator: 720us, total: 1.26ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.84ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.41ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.77ms, accelerator: 2.41ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.44ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_97750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 47058020.46sec, total: 47058020.47sec (33.33%)
top 2 operation type: Mean, cpu: 760us, accelerator: 47058020.46sec, total: 47058020.46sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 47058020.46sec, total: 47058020.46sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 47058020.47sec, total: 47058020.47sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 47058020.47sec, total: 47058020.47sec
  train.py:357:image_losses, cpu: 252us, accelerator: 47058020.46sec, total: 47058020.46sec
    train.py:322:loss_fn, cpu: 230us, accelerator: 47058020.46sec, total: 47058020.46sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 1.42ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.42ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.40ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.83ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.83ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 525us, total: 1.75ms
      train.py:343:hfe, cpu: 540us, accelerator: 719us, total: 1.26ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.84ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.41ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.79ms, accelerator: 2.41ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.43ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_98000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 46938279.95sec, total: 46938279.96sec (33.33%)
top 2 operation type: Mean, cpu: 760us, accelerator: 46938279.95sec, total: 46938279.95sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 46938279.95sec, total: 46938279.95sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 46938279.96sec, total: 46938279.96sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 46938279.96sec, total: 46938279.96sec
  train.py:357:image_losses, cpu: 252us, accelerator: 46938279.95sec, total: 46938279.95sec
    train.py:322:loss_fn, cpu: 230us, accelerator: 46938279.95sec, total: 46938279.95sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.41ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.41ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.39ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.82ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.82ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 522us, total: 1.75ms
      train.py:343:hfe, cpu: 540us, accelerator: 717us, total: 1.26ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.83ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.40ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.40ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.43ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_98250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 46819147.26sec, total: 46819147.27sec (33.33%)
top 2 operation type: Mean, cpu: 759us, accelerator: 46819147.26sec, total: 46819147.26sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 46819147.26sec, total: 46819147.26sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 46819147.27sec, total: 46819147.27sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 46819147.27sec, total: 46819147.27sec
  train.py:357:image_losses, cpu: 252us, accelerator: 46819147.26sec, total: 46819147.26sec
    train.py:322:loss_fn, cpu: 230us, accelerator: 46819147.26sec, total: 46819147.26sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.41ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.41ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.39ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.82ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.82ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 522us, total: 1.75ms
      train.py:343:hfe, cpu: 563us, accelerator: 716us, total: 1.28ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.82ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.39ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.39ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.43ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_98500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 46700617.78sec, total: 46700617.78sec (33.33%)
top 2 operation type: Mean, cpu: 759us, accelerator: 46700617.78sec, total: 46700617.78sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 46700617.77sec, total: 46700617.77sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 46700617.78sec, total: 46700617.78sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 46700617.78sec, total: 46700617.78sec
  train.py:357:image_losses, cpu: 252us, accelerator: 46700617.78sec, total: 46700617.78sec
    train.py:322:loss_fn, cpu: 230us, accelerator: 46700617.78sec, total: 46700617.78sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.41ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.41ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.39ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.81ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.81ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 521us, total: 1.75ms
      train.py:343:hfe, cpu: 561us, accelerator: 713us, total: 1.28ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.81ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.39ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.39ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.42ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_98750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 46582686.92sec, total: 46582686.93sec (33.33%)
top 2 operation type: Mean, cpu: 759us, accelerator: 46582686.92sec, total: 46582686.92sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 46582686.92sec, total: 46582686.92sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 46582686.93sec, total: 46582686.93sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 46582686.93sec, total: 46582686.93sec
  train.py:357:image_losses, cpu: 252us, accelerator: 46582686.92sec, total: 46582686.92sec
    train.py:322:loss_fn, cpu: 230us, accelerator: 46582686.92sec, total: 46582686.92sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.41ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.41ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.39ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.81ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.81ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 523us, total: 1.76ms
      train.py:343:hfe, cpu: 561us, accelerator: 712us, total: 1.27ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.84ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.40ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.80ms, accelerator: 2.40ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.43ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_99000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 46465350.18sec, total: 46465350.18sec (33.33%)
top 2 operation type: Mean, cpu: 756us, accelerator: 46465350.18sec, total: 46465350.18sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 46465350.18sec, total: 46465350.18sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 46465350.18sec, total: 46465350.19sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 46465350.18sec, total: 46465350.19sec
  train.py:357:image_losses, cpu: 251us, accelerator: 46465350.18sec, total: 46465350.18sec
    train.py:322:loss_fn, cpu: 229us, accelerator: 46465350.18sec, total: 46465350.18sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.40ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.40ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.38ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.81ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.81ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 522us, total: 1.76ms
      train.py:343:hfe, cpu: 559us, accelerator: 710us, total: 1.27ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.83ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.40ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.80ms, accelerator: 2.40ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.43ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_99250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 46348603.07sec, total: 46348603.07sec (33.33%)
top 2 operation type: Mean, cpu: 754us, accelerator: 46348603.07sec, total: 46348603.07sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 46348603.07sec, total: 46348603.07sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 46348603.07sec, total: 46348603.08sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 46348603.07sec, total: 46348603.08sec
  train.py:357:image_losses, cpu: 251us, accelerator: 46348603.07sec, total: 46348603.07sec
    train.py:322:loss_fn, cpu: 229us, accelerator: 46348603.07sec, total: 46348603.07sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.40ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.40ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.38ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.81ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.81ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 522us, total: 1.76ms
      train.py:343:hfe, cpu: 559us, accelerator: 708us, total: 1.27ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.82ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.39ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.39ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.43ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_99500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 46232441.16sec, total: 46232441.16sec (33.33%)
top 2 operation type: Mean, cpu: 754us, accelerator: 46232441.16sec, total: 46232441.16sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 46232441.16sec, total: 46232441.16sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 46232441.16sec, total: 46232441.17sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 46232441.16sec, total: 46232441.17sec
  train.py:357:image_losses, cpu: 251us, accelerator: 46232441.16sec, total: 46232441.16sec
    train.py:322:loss_fn, cpu: 229us, accelerator: 46232441.16sec, total: 46232441.16sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.40ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.40ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.38ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.82ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.82ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 521us, total: 1.75ms
      train.py:343:hfe, cpu: 559us, accelerator: 711us, total: 1.27ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.89ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.46ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.46ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.42ms, total: 6.23ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_99750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 46116860.05sec, total: 46116860.06sec (33.33%)
top 2 operation type: Mean, cpu: 754us, accelerator: 46116860.05sec, total: 46116860.05sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 46116860.05sec, total: 46116860.05sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 46116860.06sec, total: 46116860.06sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 46116860.06sec, total: 46116860.06sec
  train.py:357:image_losses, cpu: 251us, accelerator: 46116860.05sec, total: 46116860.05sec
    train.py:322:loss_fn, cpu: 229us, accelerator: 46116860.05sec, total: 46116860.05sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.40ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.40ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.38ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.82ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.82ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 520us, total: 1.75ms
      train.py:343:hfe, cpu: 556us, accelerator: 711us, total: 1.27ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.88ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.46ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 4.80ms, accelerator: 2.46ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.42ms, total: 6.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_100000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 46001855.42sec, total: 46001855.42sec (33.33%)
top 2 operation type: Mean, cpu: 754us, accelerator: 46001855.42sec, total: 46001855.42sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 46001855.41sec, total: 46001855.41sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 46001855.42sec, total: 46001855.42sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 46001855.42sec, total: 46001855.42sec
  train.py:357:image_losses, cpu: 251us, accelerator: 46001855.41sec, total: 46001855.42sec
    train.py:322:loss_fn, cpu: 229us, accelerator: 46001855.41sec, total: 46001855.42sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.41ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.41ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.39ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.82ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.82ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 519us, total: 1.75ms
      train.py:343:hfe, cpu: 555us, accelerator: 710us, total: 1.27ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.87ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.45ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.79ms, accelerator: 2.45ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.42ms, total: 6.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_100250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 45887422.94sec, total: 45887422.94sec (33.33%)
top 2 operation type: Mean, cpu: 752us, accelerator: 45887422.94sec, total: 45887422.94sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 45887422.94sec, total: 45887422.94sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 45887422.94sec, total: 45887422.95sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 45887422.94sec, total: 45887422.95sec
  train.py:357:image_losses, cpu: 250us, accelerator: 45887422.94sec, total: 45887422.94sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 45887422.94sec, total: 45887422.94sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.41ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.41ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.39ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.81ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 518us, total: 1.75ms
      train.py:343:hfe, cpu: 555us, accelerator: 708us, total: 1.26ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.86ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.45ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.45ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.41ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_100500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 45773558.37sec, total: 45773558.37sec (33.33%)
top 2 operation type: Mean, cpu: 751us, accelerator: 45773558.37sec, total: 45773558.37sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 45773558.36sec, total: 45773558.36sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 45773558.37sec, total: 45773558.37sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 45773558.37sec, total: 45773558.37sec
  train.py:357:image_losses, cpu: 250us, accelerator: 45773558.37sec, total: 45773558.37sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 45773558.37sec, total: 45773558.37sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.41ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.41ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.39ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.81ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.81ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 518us, total: 1.74ms
      train.py:343:hfe, cpu: 555us, accelerator: 707us, total: 1.26ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.85ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.44ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.44ms, total: 7.30ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.40ms, total: 6.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_100750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 45660257.48sec, total: 45660257.48sec (33.33%)
top 2 operation type: Mean, cpu: 751us, accelerator: 45660257.48sec, total: 45660257.48sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 45660257.48sec, total: 45660257.48sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 45660257.48sec, total: 45660257.49sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 45660257.48sec, total: 45660257.49sec
  train.py:357:image_losses, cpu: 250us, accelerator: 45660257.48sec, total: 45660257.48sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 45660257.48sec, total: 45660257.48sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.41ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.41ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.39ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.80ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.80ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 516us, total: 1.74ms
      train.py:343:hfe, cpu: 555us, accelerator: 705us, total: 1.26ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.84ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.44ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.44ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.40ms, total: 6.20ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_101000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 45547516.10sec, total: 45547516.11sec (33.33%)
top 2 operation type: Mean, cpu: 751us, accelerator: 45547516.10sec, total: 45547516.10sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 45547516.10sec, total: 45547516.10sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 45547516.11sec, total: 45547516.11sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 45547516.11sec, total: 45547516.11sec
  train.py:357:image_losses, cpu: 250us, accelerator: 45547516.10sec, total: 45547516.10sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 45547516.10sec, total: 45547516.10sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.41ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.41ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.39ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.80ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.80ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 514us, total: 1.75ms
      train.py:343:hfe, cpu: 553us, accelerator: 704us, total: 1.26ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.83ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.43ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.43ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.40ms, total: 6.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_101250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 45435330.10sec, total: 45435330.11sec (33.33%)
top 2 operation type: Mean, cpu: 751us, accelerator: 45435330.10sec, total: 45435330.10sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 45435330.10sec, total: 45435330.10sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 45435330.11sec, total: 45435330.11sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 45435330.11sec, total: 45435330.11sec
  train.py:357:image_losses, cpu: 250us, accelerator: 45435330.10sec, total: 45435330.10sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 45435330.10sec, total: 45435330.10sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.41ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.41ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.39ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.79ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.79ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 512us, total: 1.75ms
      train.py:343:hfe, cpu: 553us, accelerator: 702us, total: 1.26ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.81ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.42ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.42ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.39ms, total: 6.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2124.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_101500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 45323695.39sec, total: 45323695.39sec (33.33%)
top 2 operation type: Mean, cpu: 751us, accelerator: 45323695.38sec, total: 45323695.39sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 45323695.38sec, total: 45323695.38sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 45323695.39sec, total: 45323695.39sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 45323695.39sec, total: 45323695.39sec
  train.py:357:image_losses, cpu: 250us, accelerator: 45323695.38sec, total: 45323695.38sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 45323695.38sec, total: 45323695.38sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.40ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.40ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.38ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.79ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.79ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 511us, total: 1.76ms
      train.py:343:hfe, cpu: 554us, accelerator: 700us, total: 1.26ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.80ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.42ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.42ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.38ms, total: 6.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_101750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 45212607.90sec, total: 45212607.90sec (33.33%)
top 2 operation type: Mean, cpu: 751us, accelerator: 45212607.90sec, total: 45212607.90sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 45212607.89sec, total: 45212607.89sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 45212607.90sec, total: 45212607.90sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 45212607.90sec, total: 45212607.90sec
  train.py:357:image_losses, cpu: 250us, accelerator: 45212607.90sec, total: 45212607.90sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 45212607.90sec, total: 45212607.90sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.40ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.40ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.38ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.79ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.79ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 510us, total: 1.76ms
      train.py:343:hfe, cpu: 553us, accelerator: 698us, total: 1.25ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.80ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.42ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.83ms, accelerator: 2.42ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.38ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_102000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 45102063.62sec, total: 45102063.63sec (33.33%)
top 2 operation type: Mean, cpu: 749us, accelerator: 45102063.62sec, total: 45102063.62sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 45102063.62sec, total: 45102063.62sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 45102063.63sec, total: 45102063.63sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 45102063.63sec, total: 45102063.63sec
  train.py:357:image_losses, cpu: 250us, accelerator: 45102063.62sec, total: 45102063.62sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 45102063.62sec, total: 45102063.62sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.40ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.40ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.38ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.78ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.78ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 510us, total: 1.75ms
      train.py:343:hfe, cpu: 551us, accelerator: 697us, total: 1.25ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.79ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.41ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.41ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.38ms, total: 6.17ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_102250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 44992058.59sec, total: 44992058.59sec (33.33%)
top 2 operation type: Mean, cpu: 750us, accelerator: 44992058.59sec, total: 44992058.59sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 44992058.59sec, total: 44992058.59sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 44992058.59sec, total: 44992058.60sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 44992058.59sec, total: 44992058.60sec
  train.py:357:image_losses, cpu: 250us, accelerator: 44992058.59sec, total: 44992058.59sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 44992058.59sec, total: 44992058.59sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.40ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.40ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.38ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.78ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.78ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 508us, total: 1.75ms
      train.py:343:hfe, cpu: 551us, accelerator: 695us, total: 1.25ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.81ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.41ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.41ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.40ms, total: 6.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_102500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 44882588.86sec, total: 44882588.86sec (33.33%)
top 2 operation type: Mean, cpu: 749us, accelerator: 44882588.86sec, total: 44882588.86sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 44882588.86sec, total: 44882588.86sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 44882588.86sec, total: 44882588.87sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 44882588.86sec, total: 44882588.87sec
  train.py:357:image_losses, cpu: 250us, accelerator: 44882588.86sec, total: 44882588.86sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 44882588.86sec, total: 44882588.86sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.40ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.40ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.38ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.77ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.77ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 508us, total: 1.74ms
      train.py:343:hfe, cpu: 549us, accelerator: 693us, total: 1.25ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.80ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.40ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.40ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.40ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_102750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 44773650.54sec, total: 44773650.54sec (33.33%)
top 2 operation type: Mean, cpu: 748us, accelerator: 44773650.54sec, total: 44773650.54sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 44773650.54sec, total: 44773650.54sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 44773650.54sec, total: 44773650.55sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 44773650.54sec, total: 44773650.55sec
  train.py:357:image_losses, cpu: 249us, accelerator: 44773650.54sec, total: 44773650.54sec
    train.py:322:loss_fn, cpu: 227us, accelerator: 44773650.54sec, total: 44773650.54sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.39ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.39ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.37ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.77ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.77ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 507us, total: 1.74ms
      train.py:343:hfe, cpu: 548us, accelerator: 692us, total: 1.24ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.79ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.40ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.82ms, accelerator: 2.40ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.39ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_103000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 44665239.76sec, total: 44665239.76sec (33.33%)
top 2 operation type: Mean, cpu: 749us, accelerator: 44665239.76sec, total: 44665239.76sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 44665239.76sec, total: 44665239.76sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 44665239.77sec, total: 44665239.77sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 44665239.76sec, total: 44665239.77sec
  train.py:357:image_losses, cpu: 251us, accelerator: 44665239.76sec, total: 44665239.76sec
    train.py:322:loss_fn, cpu: 229us, accelerator: 44665239.76sec, total: 44665239.76sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.39ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.39ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.37ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.77ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.77ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 506us, total: 1.75ms
      train.py:343:hfe, cpu: 548us, accelerator: 690us, total: 1.24ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.78ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.40ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.81ms, accelerator: 2.40ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.39ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_103250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 44557352.71sec, total: 44557352.71sec (33.33%)
top 2 operation type: Mean, cpu: 749us, accelerator: 44557352.71sec, total: 44557352.71sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 44557352.71sec, total: 44557352.71sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 44557352.71sec, total: 44557352.72sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 44557352.71sec, total: 44557352.72sec
  train.py:357:image_losses, cpu: 251us, accelerator: 44557352.71sec, total: 44557352.71sec
    train.py:322:loss_fn, cpu: 229us, accelerator: 44557352.71sec, total: 44557352.71sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.39ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.39ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.37ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.77ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.77ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 506us, total: 1.75ms
      train.py:343:hfe, cpu: 548us, accelerator: 690us, total: 1.24ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.78ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.39ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.39ms, total: 7.32ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.38ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_103500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 44449985.59sec, total: 44449985.60sec (33.33%)
top 2 operation type: Mean, cpu: 748us, accelerator: 44449985.59sec, total: 44449985.59sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 44449985.59sec, total: 44449985.59sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 44449985.60sec, total: 44449985.60sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 44449985.60sec, total: 44449985.60sec
  train.py:357:image_losses, cpu: 251us, accelerator: 44449985.59sec, total: 44449985.59sec
    train.py:322:loss_fn, cpu: 229us, accelerator: 44449985.59sec, total: 44449985.59sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.38ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.38ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.36ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.76ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.76ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 503us, total: 1.74ms
      train.py:343:hfe, cpu: 546us, accelerator: 689us, total: 1.24ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.76ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.38ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.38ms, total: 7.32ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.38ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_103750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 44343134.67sec, total: 44343134.67sec (33.33%)
top 2 operation type: Mean, cpu: 746us, accelerator: 44343134.67sec, total: 44343134.67sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 44343134.67sec, total: 44343134.67sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 44343134.67sec, total: 44343134.68sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 44343134.67sec, total: 44343134.68sec
  train.py:357:image_losses, cpu: 250us, accelerator: 44343134.67sec, total: 44343134.67sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 44343134.67sec, total: 44343134.67sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.38ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.38ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.36ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.76ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.76ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 502us, total: 1.74ms
      train.py:343:hfe, cpu: 545us, accelerator: 687us, total: 1.24ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.75ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.38ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.38ms, total: 7.32ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_104000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 44236796.22sec, total: 44236796.22sec (33.33%)
top 2 operation type: Mean, cpu: 746us, accelerator: 44236796.21sec, total: 44236796.22sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 44236796.21sec, total: 44236796.21sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 44236796.22sec, total: 44236796.22sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 44236796.22sec, total: 44236796.22sec
  train.py:357:image_losses, cpu: 250us, accelerator: 44236796.21sec, total: 44236796.21sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 44236796.21sec, total: 44236796.21sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.38ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.38ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.36ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.75ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.75ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 501us, total: 1.74ms
      train.py:343:hfe, cpu: 545us, accelerator: 687us, total: 1.23ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.74ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 2.37ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.37ms, total: 7.30ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.37ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_104250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 44130966.56sec, total: 44130966.56sec (33.33%)
top 2 operation type: Mean, cpu: 746us, accelerator: 44130966.56sec, total: 44130966.56sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 44130966.56sec, total: 44130966.56sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 44130966.56sec, total: 44130966.57sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 44130966.56sec, total: 44130966.57sec
  train.py:357:image_losses, cpu: 250us, accelerator: 44130966.56sec, total: 44130966.56sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 44130966.56sec, total: 44130966.56sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.38ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.38ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.36ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.75ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.75ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 501us, total: 1.73ms
      train.py:343:hfe, cpu: 544us, accelerator: 685us, total: 1.23ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.74ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.37ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.37ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.37ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_104500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 44025642.06sec, total: 44025642.06sec (33.33%)
top 2 operation type: Mean, cpu: 745us, accelerator: 44025642.06sec, total: 44025642.06sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 44025642.06sec, total: 44025642.06sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 44025642.06sec, total: 44025642.06sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 44025642.06sec, total: 44025642.06sec
  train.py:357:image_losses, cpu: 250us, accelerator: 44025642.06sec, total: 44025642.06sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 44025642.06sec, total: 44025642.06sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.37ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.77ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.77ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 500us, total: 1.73ms
      train.py:343:hfe, cpu: 544us, accelerator: 691us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.73ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.37ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.37ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.37ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_104750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 43920819.10sec, total: 43920819.10sec (33.33%)
top 2 operation type: Mean, cpu: 744us, accelerator: 43920819.10sec, total: 43920819.10sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 43920819.10sec, total: 43920819.10sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 43920819.10sec, total: 43920819.11sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 43920819.10sec, total: 43920819.11sec
  train.py:357:image_losses, cpu: 250us, accelerator: 43920819.10sec, total: 43920819.10sec
    train.py:322:loss_fn, cpu: 228us, accelerator: 43920819.10sec, total: 43920819.10sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.37ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.77ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.77ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 499us, total: 1.73ms
      train.py:343:hfe, cpu: 544us, accelerator: 690us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.72ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.36ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 2.36ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.36ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_105000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 43816494.11sec, total: 43816494.12sec (33.33%)
top 2 operation type: Mean, cpu: 742us, accelerator: 43816494.11sec, total: 43816494.11sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 43816494.11sec, total: 43816494.11sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 43816494.12sec, total: 43816494.12sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 43816494.12sec, total: 43816494.12sec
  train.py:357:image_losses, cpu: 249us, accelerator: 43816494.11sec, total: 43816494.11sec
    train.py:322:loss_fn, cpu: 227us, accelerator: 43816494.11sec, total: 43816494.11sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.37ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.77ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.77ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 498us, total: 1.73ms
      train.py:343:hfe, cpu: 542us, accelerator: 688us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.71ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.35ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.35ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.35ms, total: 6.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_105250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 43712663.56sec, total: 43712663.56sec (33.33%)
top 2 operation type: Mean, cpu: 742us, accelerator: 43712663.56sec, total: 43712663.56sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 43712663.56sec, total: 43712663.56sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 43712663.56sec, total: 43712663.57sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 43712663.56sec, total: 43712663.57sec
  train.py:357:image_losses, cpu: 249us, accelerator: 43712663.56sec, total: 43712663.56sec
    train.py:322:loss_fn, cpu: 227us, accelerator: 43712663.56sec, total: 43712663.56sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.37ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.76ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.76ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 497us, total: 1.72ms
      train.py:343:hfe, cpu: 541us, accelerator: 686us, total: 1.23ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.70ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.35ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 2.35ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.35ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_105500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 43609323.93sec, total: 43609323.93sec (33.33%)
top 2 operation type: Mean, cpu: 742us, accelerator: 43609323.93sec, total: 43609323.93sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 79us, accelerator: 43609323.93sec, total: 43609323.93sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 43609323.93sec, total: 43609323.94sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 43609323.93sec, total: 43609323.94sec
  train.py:357:image_losses, cpu: 248us, accelerator: 43609323.93sec, total: 43609323.93sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 43609323.93sec, total: 43609323.93sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.37ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.79ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.79ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 506us, total: 1.73ms
      train.py:343:hfe, cpu: 541us, accelerator: 702us, total: 1.25ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.70ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.35ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.35ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.36ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_105750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 43506471.75sec, total: 43506471.75sec (33.33%)
top 2 operation type: Mean, cpu: 742us, accelerator: 43506471.75sec, total: 43506471.75sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 79us, accelerator: 43506471.75sec, total: 43506471.75sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.26ms, accelerator: 43506471.75sec, total: 43506471.76sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 43506471.75sec, total: 43506471.76sec
  train.py:357:image_losses, cpu: 248us, accelerator: 43506471.75sec, total: 43506471.75sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 43506471.75sec, total: 43506471.75sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.78ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.78ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 504us, total: 1.73ms
      train.py:343:hfe, cpu: 539us, accelerator: 700us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.70ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.34ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 2.34ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.35ms, total: 6.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_106000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 43404103.58sec, total: 43404103.58sec (33.33%)
top 2 operation type: Mean, cpu: 775us, accelerator: 43404103.58sec, total: 43404103.58sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 79us, accelerator: 43404103.58sec, total: 43404103.58sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.26ms, accelerator: 43404103.58sec, total: 43404103.59sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 43404103.58sec, total: 43404103.59sec
  train.py:357:image_losses, cpu: 248us, accelerator: 43404103.58sec, total: 43404103.58sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 43404103.58sec, total: 43404103.58sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.36ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.36ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.34ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.78ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.78ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 503us, total: 1.72ms
      train.py:343:hfe, cpu: 538us, accelerator: 698us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.69ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.34ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 2.34ms, total: 7.26ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.35ms, total: 6.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_106250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 43302216.01sec, total: 43302216.02sec (33.33%)
top 2 operation type: Mean, cpu: 774us, accelerator: 43302216.01sec, total: 43302216.01sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 79us, accelerator: 43302216.01sec, total: 43302216.01sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 43302216.02sec, total: 43302216.02sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 43302216.02sec, total: 43302216.02sec
  train.py:357:image_losses, cpu: 249us, accelerator: 43302216.01sec, total: 43302216.01sec
    train.py:322:loss_fn, cpu: 227us, accelerator: 43302216.01sec, total: 43302216.01sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.36ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.36ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.34ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.78ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.78ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 502us, total: 1.72ms
      train.py:343:hfe, cpu: 538us, accelerator: 697us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.68ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.33ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.33ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.35ms, total: 6.13ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_106500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 43200805.67sec, total: 43200805.67sec (33.33%)
top 2 operation type: Mean, cpu: 773us, accelerator: 43200805.67sec, total: 43200805.67sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 79us, accelerator: 43200805.67sec, total: 43200805.67sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 43200805.68sec, total: 43200805.68sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 43200805.67sec, total: 43200805.68sec
  train.py:357:image_losses, cpu: 249us, accelerator: 43200805.67sec, total: 43200805.67sec
    train.py:322:loss_fn, cpu: 227us, accelerator: 43200805.67sec, total: 43200805.67sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.36ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.34ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.78ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.78ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 502us, total: 1.72ms
      train.py:343:hfe, cpu: 538us, accelerator: 698us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.68ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.32ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.32ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.35ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_106750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 43099869.21sec, total: 43099869.21sec (33.33%)
top 2 operation type: Mean, cpu: 773us, accelerator: 43099869.21sec, total: 43099869.21sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 79us, accelerator: 43099869.21sec, total: 43099869.21sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 43099869.21sec, total: 43099869.22sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 43099869.21sec, total: 43099869.22sec
  train.py:357:image_losses, cpu: 249us, accelerator: 43099869.21sec, total: 43099869.21sec
    train.py:322:loss_fn, cpu: 227us, accelerator: 43099869.21sec, total: 43099869.21sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.36ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.34ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.77ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.77ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 501us, total: 1.72ms
      train.py:343:hfe, cpu: 538us, accelerator: 696us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.67ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.32ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.32ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.35ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_107000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 42999403.31sec, total: 42999403.32sec (33.33%)
top 2 operation type: Mean, cpu: 771us, accelerator: 42999403.31sec, total: 42999403.31sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 79us, accelerator: 42999403.31sec, total: 42999403.31sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 42999403.32sec, total: 42999403.32sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 42999403.32sec, total: 42999403.32sec
  train.py:357:image_losses, cpu: 248us, accelerator: 42999403.31sec, total: 42999403.31sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 42999403.31sec, total: 42999403.31sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.36ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.34ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.77ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.77ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 500us, total: 1.72ms
      train.py:343:hfe, cpu: 538us, accelerator: 693us, total: 1.23ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.66ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.31ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.31ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.35ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_107250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 42899404.70sec, total: 42899404.70sec (33.33%)
top 2 operation type: Mean, cpu: 771us, accelerator: 42899404.70sec, total: 42899404.70sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 78us, accelerator: 42899404.70sec, total: 42899404.70sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 42899404.71sec, total: 42899404.71sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 42899404.70sec, total: 42899404.71sec
  train.py:357:image_losses, cpu: 248us, accelerator: 42899404.70sec, total: 42899404.70sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 42899404.70sec, total: 42899404.70sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.77ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.77ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 499us, total: 1.71ms
      train.py:343:hfe, cpu: 534us, accelerator: 693us, total: 1.23ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.68ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.31ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.31ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.36ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_107500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 42799870.12sec, total: 42799870.12sec (33.33%)
top 2 operation type: Mean, cpu: 771us, accelerator: 42799870.12sec, total: 42799870.12sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 78us, accelerator: 42799870.12sec, total: 42799870.12sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 42799870.12sec, total: 42799870.13sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 42799870.12sec, total: 42799870.13sec
  train.py:357:image_losses, cpu: 248us, accelerator: 42799870.12sec, total: 42799870.12sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 42799870.12sec, total: 42799870.12sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.35ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.76ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.76ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 498us, total: 1.71ms
      train.py:343:hfe, cpu: 534us, accelerator: 691us, total: 1.23ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.67ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.31ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.31ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.36ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_107750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 42700796.35sec, total: 42700796.35sec (33.33%)
top 2 operation type: Mean, cpu: 771us, accelerator: 42700796.35sec, total: 42700796.35sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 78us, accelerator: 42700796.35sec, total: 42700796.35sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 42700796.35sec, total: 42700796.36sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 42700796.35sec, total: 42700796.35sec
  train.py:357:image_losses, cpu: 248us, accelerator: 42700796.35sec, total: 42700796.35sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 42700796.35sec, total: 42700796.35sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.35ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.35ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.33ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.76ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.76ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 498us, total: 1.71ms
      train.py:343:hfe, cpu: 534us, accelerator: 690us, total: 1.23ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.69ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.31ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.31ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.38ms, total: 6.17ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2121.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_108000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 42602180.19sec, total: 42602180.19sec (33.33%)
top 2 operation type: Mean, cpu: 769us, accelerator: 42602180.19sec, total: 42602180.19sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 78us, accelerator: 42602180.19sec, total: 42602180.19sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 42602180.19sec, total: 42602180.20sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 42602180.19sec, total: 42602180.20sec
  train.py:357:image_losses, cpu: 247us, accelerator: 42602180.19sec, total: 42602180.19sec
    train.py:322:loss_fn, cpu: 225us, accelerator: 42602180.19sec, total: 42602180.19sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.38ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.38ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.78ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.78ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 498us, total: 1.71ms
      train.py:343:hfe, cpu: 533us, accelerator: 700us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.68ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.31ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.31ms, total: 7.19ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.38ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_108250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 42504018.48sec, total: 42504018.49sec (33.33%)
top 2 operation type: Mean, cpu: 771us, accelerator: 42504018.48sec, total: 42504018.48sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 78us, accelerator: 42504018.48sec, total: 42504018.48sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 42504018.49sec, total: 42504018.49sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 42504018.49sec, total: 42504018.49sec
  train.py:357:image_losses, cpu: 249us, accelerator: 42504018.48sec, total: 42504018.48sec
    train.py:322:loss_fn, cpu: 227us, accelerator: 42504018.48sec, total: 42504018.48sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.38ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.38ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.78ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.78ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 496us, total: 1.71ms
      train.py:343:hfe, cpu: 534us, accelerator: 706us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.67ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.30ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.30ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.37ms, total: 6.16ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_108500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 42406308.10sec, total: 42406308.10sec (33.33%)
top 2 operation type: Mean, cpu: 770us, accelerator: 42406308.10sec, total: 42406308.10sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 78us, accelerator: 42406308.09sec, total: 42406308.09sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 42406308.10sec, total: 42406308.10sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 42406308.10sec, total: 42406308.10sec
  train.py:357:image_losses, cpu: 248us, accelerator: 42406308.10sec, total: 42406308.10sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 42406308.10sec, total: 42406308.10sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.38ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.38ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.78ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.78ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 495us, total: 1.70ms
      train.py:343:hfe, cpu: 533us, accelerator: 704us, total: 1.24ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.66ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 2.30ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.30ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.36ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_108750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 42309045.92sec, total: 42309045.92sec (33.33%)
top 2 operation type: Mean, cpu: 770us, accelerator: 42309045.92sec, total: 42309045.92sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 78us, accelerator: 42309045.92sec, total: 42309045.92sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 42309045.93sec, total: 42309045.93sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 42309045.92sec, total: 42309045.93sec
  train.py:357:image_losses, cpu: 248us, accelerator: 42309045.92sec, total: 42309045.92sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 42309045.92sec, total: 42309045.92sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.38ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.38ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.79ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.79ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 493us, total: 1.70ms
      train.py:343:hfe, cpu: 531us, accelerator: 708us, total: 1.25ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.65ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.29ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.29ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.36ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_109000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 42212228.88sec, total: 42212228.88sec (33.33%)
top 2 operation type: Mean, cpu: 769us, accelerator: 42212228.88sec, total: 42212228.88sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 78us, accelerator: 42212228.88sec, total: 42212228.88sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 42212228.89sec, total: 42212228.89sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 42212228.89sec, total: 42212228.89sec
  train.py:357:image_losses, cpu: 247us, accelerator: 42212228.88sec, total: 42212228.88sec
    train.py:322:loss_fn, cpu: 225us, accelerator: 42212228.88sec, total: 42212228.88sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.37ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.35ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.79ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.79ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 493us, total: 1.70ms
      train.py:343:hfe, cpu: 530us, accelerator: 710us, total: 1.25ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.71ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.35ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.35ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.36ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_109250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 42115853.93sec, total: 42115853.93sec (33.33%)
top 2 operation type: Mean, cpu: 785us, accelerator: 42115853.93sec, total: 42115853.93sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 77us, accelerator: 42115853.93sec, total: 42115853.93sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 42115853.94sec, total: 42115853.94sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 42115853.93sec, total: 42115853.94sec
  train.py:357:image_losses, cpu: 247us, accelerator: 42115853.93sec, total: 42115853.93sec
    train.py:322:loss_fn, cpu: 225us, accelerator: 42115853.93sec, total: 42115853.93sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.37ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.35ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.81ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.81ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 493us, total: 1.70ms
      train.py:343:hfe, cpu: 530us, accelerator: 718us, total: 1.25ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.70ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.35ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.35ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.36ms, total: 6.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_109500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 42019918.05sec, total: 42019918.05sec (33.33%)
top 2 operation type: Mean, cpu: 786us, accelerator: 42019918.04sec, total: 42019918.05sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 77us, accelerator: 42019918.04sec, total: 42019918.04sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 42019918.05sec, total: 42019918.05sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 42019918.05sec, total: 42019918.05sec
  train.py:357:image_losses, cpu: 247us, accelerator: 42019918.04sec, total: 42019918.04sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 42019918.04sec, total: 42019918.04sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.37ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.80ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.80ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 491us, total: 1.69ms
      train.py:343:hfe, cpu: 530us, accelerator: 717us, total: 1.25ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.71ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.34ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.34ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.14ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_109750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 41924418.23sec, total: 41924418.23sec (33.33%)
top 2 operation type: Mean, cpu: 785us, accelerator: 41924418.23sec, total: 41924418.23sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 77us, accelerator: 41924418.23sec, total: 41924418.23sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 41924418.24sec, total: 41924418.24sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 41924418.23sec, total: 41924418.24sec
  train.py:357:image_losses, cpu: 247us, accelerator: 41924418.23sec, total: 41924418.23sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 41924418.23sec, total: 41924418.23sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.37ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.80ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.80ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 491us, total: 1.69ms
      train.py:343:hfe, cpu: 530us, accelerator: 717us, total: 1.25ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.70ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.33ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.33ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.37ms, total: 6.14ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_110000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 41829351.52sec, total: 41829351.53sec (33.33%)
top 2 operation type: Mean, cpu: 784us, accelerator: 41829351.52sec, total: 41829351.52sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 77us, accelerator: 41829351.52sec, total: 41829351.52sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 41829351.53sec, total: 41829351.53sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 41829351.53sec, total: 41829351.53sec
  train.py:357:image_losses, cpu: 248us, accelerator: 41829351.52sec, total: 41829351.52sec
    train.py:322:loss_fn, cpu: 226us, accelerator: 41829351.52sec, total: 41829351.52sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.37ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.81ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.81ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 489us, total: 1.69ms
      train.py:343:hfe, cpu: 529us, accelerator: 726us, total: 1.26ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.69ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.33ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.33ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.36ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_110250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 41734714.98sec, total: 41734714.98sec (33.33%)
top 2 operation type: Mean, cpu: 784us, accelerator: 41734714.98sec, total: 41734714.98sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 77us, accelerator: 41734714.98sec, total: 41734714.98sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 41734714.99sec, total: 41734714.99sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 41734714.98sec, total: 41734714.99sec
  train.py:357:image_losses, cpu: 246us, accelerator: 41734714.98sec, total: 41734714.98sec
    train.py:322:loss_fn, cpu: 225us, accelerator: 41734714.98sec, total: 41734714.98sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.37ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.81ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.81ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 489us, total: 1.69ms
      train.py:343:hfe, cpu: 528us, accelerator: 723us, total: 1.26ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.70ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.33ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.33ms, total: 7.23ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_110500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 41640505.69sec, total: 41640505.69sec (33.33%)
top 2 operation type: Mean, cpu: 783us, accelerator: 41640505.69sec, total: 41640505.69sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 77us, accelerator: 41640505.69sec, total: 41640505.69sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 41640505.70sec, total: 41640505.70sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 41640505.69sec, total: 41640505.70sec
  train.py:357:image_losses, cpu: 245us, accelerator: 41640505.69sec, total: 41640505.69sec
    train.py:322:loss_fn, cpu: 224us, accelerator: 41640505.69sec, total: 41640505.69sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.37ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.80ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.80ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 489us, total: 1.68ms
      train.py:343:hfe, cpu: 527us, accelerator: 721us, total: 1.25ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.69ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.32ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.32ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_110750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 41546720.77sec, total: 41546720.77sec (33.33%)
top 2 operation type: Mean, cpu: 783us, accelerator: 41546720.77sec, total: 41546720.77sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 77us, accelerator: 41546720.77sec, total: 41546720.77sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 41546720.77sec, total: 41546720.78sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 41546720.77sec, total: 41546720.78sec
  train.py:357:image_losses, cpu: 246us, accelerator: 41546720.77sec, total: 41546720.77sec
    train.py:322:loss_fn, cpu: 225us, accelerator: 41546720.77sec, total: 41546720.77sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.37ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.35ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.80ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.80ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 487us, total: 1.69ms
      train.py:343:hfe, cpu: 527us, accelerator: 720us, total: 1.25ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.68ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.31ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.31ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.36ms, total: 6.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_111000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 41453357.35sec, total: 41453357.35sec (33.33%)
top 2 operation type: Mean, cpu: 783us, accelerator: 41453357.35sec, total: 41453357.35sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 77us, accelerator: 41453357.35sec, total: 41453357.35sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 41453357.36sec, total: 41453357.36sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 41453357.35sec, total: 41453357.36sec
  train.py:357:image_losses, cpu: 246us, accelerator: 41453357.35sec, total: 41453357.35sec
    train.py:322:loss_fn, cpu: 225us, accelerator: 41453357.35sec, total: 41453357.35sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.80ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.80ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 487us, total: 1.68ms
      train.py:343:hfe, cpu: 527us, accelerator: 720us, total: 1.25ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.69ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.31ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 2.31ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.38ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_111250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 41360412.60sec, total: 41360412.61sec (33.33%)
top 2 operation type: Mean, cpu: 795us, accelerator: 41360412.60sec, total: 41360412.61sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 77us, accelerator: 41360412.60sec, total: 41360412.60sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 41360412.61sec, total: 41360412.61sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 41360412.61sec, total: 41360412.61sec
  train.py:357:image_losses, cpu: 258us, accelerator: 41360412.60sec, total: 41360412.60sec
    train.py:322:loss_fn, cpu: 237us, accelerator: 41360412.60sec, total: 41360412.60sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.80ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.80ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 485us, total: 1.68ms
      train.py:343:hfe, cpu: 526us, accelerator: 722us, total: 1.25ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.68ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.30ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.30ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.38ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2116.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_111500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 41267883.72sec, total: 41267883.72sec (33.33%)
top 2 operation type: Mean, cpu: 795us, accelerator: 41267883.72sec, total: 41267883.72sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 41267883.72sec, total: 41267883.72sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 41267883.72sec, total: 41267883.73sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 41267883.72sec, total: 41267883.73sec
  train.py:357:image_losses, cpu: 258us, accelerator: 41267883.72sec, total: 41267883.72sec
    train.py:322:loss_fn, cpu: 237us, accelerator: 41267883.72sec, total: 41267883.72sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.80ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.80ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 484us, total: 1.68ms
      train.py:343:hfe, cpu: 527us, accelerator: 720us, total: 1.25ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.67ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.30ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.30ms, total: 7.19ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.37ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_111750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 41175767.91sec, total: 41175767.91sec (33.33%)
top 2 operation type: Mean, cpu: 794us, accelerator: 41175767.91sec, total: 41175767.91sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 41175767.90sec, total: 41175767.90sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 41175767.91sec, total: 41175767.91sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 41175767.91sec, total: 41175767.91sec
  train.py:357:image_losses, cpu: 258us, accelerator: 41175767.90sec, total: 41175767.91sec
    train.py:322:loss_fn, cpu: 237us, accelerator: 41175767.90sec, total: 41175767.91sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.83ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.83ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 486us, total: 1.69ms
      train.py:343:hfe, cpu: 525us, accelerator: 735us, total: 1.26ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.67ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.30ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.30ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.37ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_112000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 41084062.41sec, total: 41084062.41sec (33.33%)
top 2 operation type: Mean, cpu: 795us, accelerator: 41084062.41sec, total: 41084062.41sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 41084062.41sec, total: 41084062.41sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 41084062.41sec, total: 41084062.42sec
train.py:442:<module>, cpu: 5.64ms, accelerator: 41084062.41sec, total: 41084062.42sec
  train.py:357:image_losses, cpu: 258us, accelerator: 41084062.41sec, total: 41084062.41sec
    train.py:322:loss_fn, cpu: 237us, accelerator: 41084062.41sec, total: 41084062.41sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.85ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 484us, total: 1.69ms
      train.py:343:hfe, cpu: 603us, accelerator: 752us, total: 1.36ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.67ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.30ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.30ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.37ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_112250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 40992764.49sec, total: 40992764.50sec (33.33%)
top 2 operation type: Mean, cpu: 793us, accelerator: 40992764.49sec, total: 40992764.49sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 40992764.49sec, total: 40992764.49sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 40992764.50sec, total: 40992764.50sec
train.py:442:<module>, cpu: 5.63ms, accelerator: 40992764.50sec, total: 40992764.50sec
  train.py:357:image_losses, cpu: 258us, accelerator: 40992764.49sec, total: 40992764.49sec
    train.py:322:loss_fn, cpu: 237us, accelerator: 40992764.49sec, total: 40992764.49sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.85ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 484us, total: 1.69ms
      train.py:343:hfe, cpu: 601us, accelerator: 749us, total: 1.36ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.67ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.29ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.29ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.38ms, total: 6.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_112500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 40901871.45sec, total: 40901871.45sec (33.33%)
top 2 operation type: Mean, cpu: 790us, accelerator: 40901871.44sec, total: 40901871.45sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 40901871.44sec, total: 40901871.44sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 40901871.45sec, total: 40901871.45sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 40901871.45sec, total: 40901871.45sec
  train.py:357:image_losses, cpu: 257us, accelerator: 40901871.44sec, total: 40901871.44sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 40901871.44sec, total: 40901871.44sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.84ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.84ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 484us, total: 1.68ms
      train.py:343:hfe, cpu: 600us, accelerator: 749us, total: 1.35ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.67ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.29ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.29ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.38ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_112750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 40811380.58sec, total: 40811380.58sec (33.33%)
top 2 operation type: Mean, cpu: 790us, accelerator: 40811380.58sec, total: 40811380.58sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 40811380.58sec, total: 40811380.58sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 40811380.58sec, total: 40811380.59sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 40811380.58sec, total: 40811380.59sec
  train.py:357:image_losses, cpu: 257us, accelerator: 40811380.58sec, total: 40811380.58sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 40811380.58sec, total: 40811380.58sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.33ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.84ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 482us, total: 1.68ms
      train.py:343:hfe, cpu: 600us, accelerator: 746us, total: 1.35ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.66ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.28ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.28ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.37ms, total: 6.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_113000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 40721289.23sec, total: 40721289.23sec (33.33%)
top 2 operation type: Mean, cpu: 790us, accelerator: 40721289.23sec, total: 40721289.23sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 40721289.23sec, total: 40721289.23sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 40721289.24sec, total: 40721289.24sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 40721289.23sec, total: 40721289.24sec
  train.py:357:image_losses, cpu: 257us, accelerator: 40721289.23sec, total: 40721289.23sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 40721289.23sec, total: 40721289.23sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.33ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.84ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 482us, total: 1.68ms
      train.py:343:hfe, cpu: 599us, accelerator: 745us, total: 1.35ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.65ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.28ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.28ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.37ms, total: 6.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_113250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 40631594.76sec, total: 40631594.76sec (33.33%)
top 2 operation type: Mean, cpu: 790us, accelerator: 40631594.76sec, total: 40631594.76sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 40631594.76sec, total: 40631594.76sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 40631594.77sec, total: 40631594.77sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 40631594.76sec, total: 40631594.77sec
  train.py:357:image_losses, cpu: 257us, accelerator: 40631594.76sec, total: 40631594.76sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 40631594.76sec, total: 40631594.76sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.33ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.83ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.83ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 482us, total: 1.68ms
      train.py:343:hfe, cpu: 597us, accelerator: 743us, total: 1.35ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.68ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.27ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.27ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.41ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_113500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 40542294.55sec, total: 40542294.56sec (33.33%)
top 2 operation type: Mean, cpu: 790us, accelerator: 40542294.55sec, total: 40542294.55sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 40542294.55sec, total: 40542294.55sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 40542294.56sec, total: 40542294.56sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 40542294.56sec, total: 40542294.56sec
  train.py:357:image_losses, cpu: 257us, accelerator: 40542294.55sec, total: 40542294.55sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 40542294.55sec, total: 40542294.55sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.33ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.83ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.83ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 481us, total: 1.68ms
      train.py:343:hfe, cpu: 596us, accelerator: 741us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.69ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.28ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.28ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.41ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_113750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 40453386.01sec, total: 40453386.01sec (33.33%)
top 2 operation type: Mean, cpu: 790us, accelerator: 40453386.01sec, total: 40453386.01sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 40453386.01sec, total: 40453386.01sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 40453386.02sec, total: 40453386.02sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 40453386.02sec, total: 40453386.02sec
  train.py:357:image_losses, cpu: 257us, accelerator: 40453386.01sec, total: 40453386.01sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 40453386.01sec, total: 40453386.01sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.82ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.82ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 480us, total: 1.68ms
      train.py:343:hfe, cpu: 596us, accelerator: 740us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.71ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.30ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.30ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.41ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_114000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 40364866.57sec, total: 40364866.57sec (33.33%)
top 2 operation type: Mean, cpu: 788us, accelerator: 40364866.57sec, total: 40364866.57sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 40364866.57sec, total: 40364866.57sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 40364866.57sec, total: 40364866.58sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 40364866.57sec, total: 40364866.58sec
  train.py:357:image_losses, cpu: 256us, accelerator: 40364866.57sec, total: 40364866.57sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 40364866.57sec, total: 40364866.57sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.84ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 479us, total: 1.67ms
      train.py:343:hfe, cpu: 596us, accelerator: 747us, total: 1.35ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.70ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.29ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.29ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.41ms, total: 6.25ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_114250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 40276733.67sec, total: 40276733.67sec (33.33%)
top 2 operation type: Mean, cpu: 786us, accelerator: 40276733.67sec, total: 40276733.67sec (33.33%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 40276733.67sec, total: 40276733.67sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 40276733.68sec, total: 40276733.68sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 40276733.67sec, total: 40276733.68sec
  train.py:357:image_losses, cpu: 255us, accelerator: 40276733.67sec, total: 40276733.67sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 40276733.67sec, total: 40276733.67sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.84ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 479us, total: 1.67ms
      train.py:343:hfe, cpu: 595us, accelerator: 749us, total: 1.35ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.70ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.29ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.84ms, accelerator: 2.29ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.41ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2117.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_114500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 40188984.80sec, total: 40188984.80sec (25.00%)
top 2 operation type: Mean, cpu: 786us, accelerator: 40188984.80sec, total: 40188984.80sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 40188984.80sec, total: 40188984.80sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 40188984.80sec, total: 40188984.81sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 40188984.80sec, total: 40188984.81sec
  train.py:357:image_losses, cpu: 255us, accelerator: 40188984.80sec, total: 40188984.80sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 40188984.80sec, total: 40188984.80sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.37ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.86ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.86ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 504us, total: 1.69ms
      train.py:343:hfe, cpu: 593us, accelerator: 746us, total: 1.34ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.69ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.29ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 4.86ms, accelerator: 2.29ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.40ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.50
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_114750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 40101617.44sec, total: 40101617.44sec (25.00%)
top 2 operation type: Mean, cpu: 785us, accelerator: 40101617.44sec, total: 40101617.44sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 40101617.44sec, total: 40101617.44sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 40101617.44sec, total: 40101617.45sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 40101617.44sec, total: 40101617.45sec
  train.py:357:image_losses, cpu: 255us, accelerator: 40101617.44sec, total: 40101617.44sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 40101617.44sec, total: 40101617.44sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.86ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.86ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 503us, total: 1.69ms
      train.py:343:hfe, cpu: 592us, accelerator: 752us, total: 1.35ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.71ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.31ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.85ms, accelerator: 2.31ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.40ms, total: 6.24ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_115000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 40014629.11sec, total: 40014629.12sec (25.00%)
top 2 operation type: Mean, cpu: 785us, accelerator: 40014629.11sec, total: 40014629.11sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 40014629.11sec, total: 40014629.11sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 40014629.12sec, total: 40014629.12sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 40014629.12sec, total: 40014629.12sec
  train.py:357:image_losses, cpu: 255us, accelerator: 40014629.11sec, total: 40014629.11sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 40014629.11sec, total: 40014629.11sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.86ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.86ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 500us, total: 1.69ms
      train.py:343:hfe, cpu: 591us, accelerator: 750us, total: 1.34ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.71ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.31ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 4.87ms, accelerator: 2.31ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.40ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_115250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 39928017.36sec, total: 39928017.37sec (25.00%)
top 2 operation type: Mean, cpu: 783us, accelerator: 39928017.36sec, total: 39928017.36sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 39928017.36sec, total: 39928017.36sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 39928017.37sec, total: 39928017.37sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 39928017.37sec, total: 39928017.37sec
  train.py:357:image_losses, cpu: 255us, accelerator: 39928017.36sec, total: 39928017.36sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 39928017.36sec, total: 39928017.36sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.85ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.85ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 498us, total: 1.69ms
      train.py:343:hfe, cpu: 591us, accelerator: 747us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.70ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.30ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 2.30ms, total: 7.33ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.40ms, total: 6.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_115500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 39841779.74sec, total: 39841779.75sec (25.00%)
top 2 operation type: Mean, cpu: 784us, accelerator: 39841779.74sec, total: 39841779.75sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 39841779.74sec, total: 39841779.74sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 39841779.75sec, total: 39841779.75sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 39841779.75sec, total: 39841779.75sec
  train.py:357:image_losses, cpu: 255us, accelerator: 39841779.74sec, total: 39841779.74sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 39841779.74sec, total: 39841779.74sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.37ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.85ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 497us, total: 1.68ms
      train.py:343:hfe, cpu: 591us, accelerator: 746us, total: 1.34ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.69ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.30ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.06ms, accelerator: 2.30ms, total: 7.38ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.39ms, total: 6.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_115750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 39755913.84sec, total: 39755913.84sec (25.00%)
top 2 operation type: Mean, cpu: 782us, accelerator: 39755913.84sec, total: 39755913.84sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 39755913.84sec, total: 39755913.84sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 39755913.84sec, total: 39755913.85sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 39755913.84sec, total: 39755913.85sec
  train.py:357:image_losses, cpu: 254us, accelerator: 39755913.84sec, total: 39755913.84sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 39755913.84sec, total: 39755913.84sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.39ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.39ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.37ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.86ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.86ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 504us, total: 1.69ms
      train.py:343:hfe, cpu: 591us, accelerator: 749us, total: 1.34ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.69ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.29ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.06ms, accelerator: 2.29ms, total: 7.38ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.39ms, total: 6.21ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_116000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 39670417.25sec, total: 39670417.25sec (25.00%)
top 2 operation type: Mean, cpu: 781us, accelerator: 39670417.25sec, total: 39670417.25sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 39670417.25sec, total: 39670417.25sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 39670417.26sec, total: 39670417.26sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 39670417.25sec, total: 39670417.26sec
  train.py:357:image_losses, cpu: 254us, accelerator: 39670417.25sec, total: 39670417.25sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 39670417.25sec, total: 39670417.25sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.39ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.39ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.37ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.86ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.86ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 504us, total: 1.69ms
      train.py:343:hfe, cpu: 588us, accelerator: 748us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.67ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.29ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.07ms, accelerator: 2.29ms, total: 7.38ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.38ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_116250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 39585287.60sec, total: 39585287.60sec (25.00%)
top 2 operation type: Mean, cpu: 781us, accelerator: 39585287.60sec, total: 39585287.60sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 39585287.60sec, total: 39585287.60sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 39585287.60sec, total: 39585287.61sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 39585287.60sec, total: 39585287.61sec
  train.py:357:image_losses, cpu: 254us, accelerator: 39585287.60sec, total: 39585287.60sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 39585287.60sec, total: 39585287.60sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.39ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.39ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.37ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.86ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.86ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 503us, total: 1.70ms
      train.py:343:hfe, cpu: 588us, accelerator: 745us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.67ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.29ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 2.29ms, total: 7.37ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.38ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_116500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.10ms, accelerator: 39500522.53sec, total: 39500522.53sec (25.00%)
top 2 operation type: Mean, cpu: 781us, accelerator: 39500522.53sec, total: 39500522.53sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 39500522.53sec, total: 39500522.53sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 39500522.53sec, total: 39500522.54sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 39500522.53sec, total: 39500522.54sec
  train.py:357:image_losses, cpu: 254us, accelerator: 39500522.53sec, total: 39500522.53sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 39500522.53sec, total: 39500522.53sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.38ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.36ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.85ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.85ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 502us, total: 1.69ms
      train.py:343:hfe, cpu: 587us, accelerator: 744us, total: 1.33ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.66ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.28ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 2.28ms, total: 7.36ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.38ms, total: 6.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_116750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.10ms, accelerator: 39416119.70sec, total: 39416119.71sec (25.00%)
top 2 operation type: Mean, cpu: 782us, accelerator: 39416119.70sec, total: 39416119.71sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 39416119.70sec, total: 39416119.70sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 39416119.71sec, total: 39416119.71sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 39416119.71sec, total: 39416119.71sec
  train.py:357:image_losses, cpu: 255us, accelerator: 39416119.70sec, total: 39416119.70sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 39416119.70sec, total: 39416119.70sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.38ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.85ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.85ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 502us, total: 1.69ms
      train.py:343:hfe, cpu: 588us, accelerator: 742us, total: 1.33ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.65ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.28ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.04ms, accelerator: 2.28ms, total: 7.34ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.37ms, total: 6.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_117000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.10ms, accelerator: 39332076.81sec, total: 39332076.81sec (25.00%)
top 2 operation type: Mean, cpu: 781us, accelerator: 39332076.81sec, total: 39332076.81sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 39332076.80sec, total: 39332076.80sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 39332076.81sec, total: 39332076.81sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 39332076.81sec, total: 39332076.81sec
  train.py:357:image_losses, cpu: 254us, accelerator: 39332076.80sec, total: 39332076.80sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 39332076.80sec, total: 39332076.80sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.85ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 501us, total: 1.69ms
      train.py:343:hfe, cpu: 588us, accelerator: 743us, total: 1.33ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.64ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.27ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.10ms, accelerator: 2.27ms, total: 7.39ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.37ms, total: 6.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_117250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 39248391.54sec, total: 39248391.54sec (25.00%)
top 2 operation type: Mean, cpu: 781us, accelerator: 39248391.54sec, total: 39248391.54sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 39248391.53sec, total: 39248391.53sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 39248391.54sec, total: 39248391.54sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 39248391.54sec, total: 39248391.54sec
  train.py:357:image_losses, cpu: 255us, accelerator: 39248391.53sec, total: 39248391.54sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 39248391.53sec, total: 39248391.54sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.38ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.85ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.85ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 500us, total: 1.68ms
      train.py:343:hfe, cpu: 596us, accelerator: 743us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.63ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.27ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.11ms, accelerator: 2.27ms, total: 7.40ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.37ms, total: 6.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_117500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 39165061.62sec, total: 39165061.62sec (25.00%)
top 2 operation type: Mean, cpu: 782us, accelerator: 39165061.62sec, total: 39165061.62sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 39165061.62sec, total: 39165061.62sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 39165061.62sec, total: 39165061.63sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 39165061.62sec, total: 39165061.63sec
  train.py:357:image_losses, cpu: 255us, accelerator: 39165061.62sec, total: 39165061.62sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 39165061.62sec, total: 39165061.62sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.38ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.86ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.86ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 499us, total: 1.68ms
      train.py:343:hfe, cpu: 597us, accelerator: 744us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.63ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.27ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.11ms, accelerator: 2.27ms, total: 7.40ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.36ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_117750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 39082084.79sec, total: 39082084.79sec (25.00%)
top 2 operation type: Mean, cpu: 781us, accelerator: 39082084.79sec, total: 39082084.79sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 39082084.79sec, total: 39082084.79sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 39082084.80sec, total: 39082084.80sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 39082084.79sec, total: 39082084.80sec
  train.py:357:image_losses, cpu: 255us, accelerator: 39082084.79sec, total: 39082084.79sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 39082084.79sec, total: 39082084.79sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.37ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.37ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.35ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.85ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.85ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 497us, total: 1.68ms
      train.py:343:hfe, cpu: 597us, accelerator: 745us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.26ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.11ms, accelerator: 2.26ms, total: 7.40ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.36ms, total: 6.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_118000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 38999458.82sec, total: 38999458.82sec (25.00%)
top 2 operation type: Mean, cpu: 780us, accelerator: 38999458.82sec, total: 38999458.82sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 38999458.82sec, total: 38999458.82sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 38999458.82sec, total: 38999458.83sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 38999458.82sec, total: 38999458.83sec
  train.py:357:image_losses, cpu: 254us, accelerator: 38999458.82sec, total: 38999458.82sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 38999458.82sec, total: 38999458.82sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.37ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.37ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.35ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.85ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.85ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 497us, total: 1.68ms
      train.py:343:hfe, cpu: 595us, accelerator: 745us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.61ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.26ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.12ms, accelerator: 2.26ms, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.35ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_118250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 38917181.48sec, total: 38917181.48sec (25.00%)
top 2 operation type: Mean, cpu: 777us, accelerator: 38917181.48sec, total: 38917181.48sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 38917181.48sec, total: 38917181.48sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 38917181.48sec, total: 38917181.49sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 38917181.48sec, total: 38917181.49sec
  train.py:357:image_losses, cpu: 254us, accelerator: 38917181.48sec, total: 38917181.48sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 38917181.48sec, total: 38917181.48sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.37ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.37ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.35ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.85ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.85ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 496us, total: 1.69ms
      train.py:343:hfe, cpu: 593us, accelerator: 743us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.62ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.26ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.12ms, accelerator: 2.26ms, total: 7.39ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.36ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_118500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 38835250.57sec, total: 38835250.57sec (25.00%)
top 2 operation type: Mean, cpu: 778us, accelerator: 38835250.57sec, total: 38835250.57sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 38835250.57sec, total: 38835250.57sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 38835250.58sec, total: 38835250.58sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 38835250.57sec, total: 38835250.58sec
  train.py:357:image_losses, cpu: 255us, accelerator: 38835250.57sec, total: 38835250.57sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 38835250.57sec, total: 38835250.57sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.37ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.85ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.85ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 495us, total: 1.69ms
      train.py:343:hfe, cpu: 594us, accelerator: 743us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.62ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.25ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.12ms, accelerator: 2.25ms, total: 7.39ms
  __init__.py:185:compute_gradients, cpu: 3.82ms, accelerator: 2.36ms, total: 6.22ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_118750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 38753663.91sec, total: 38753663.91sec (25.00%)
top 2 operation type: Mean, cpu: 778us, accelerator: 38753663.91sec, total: 38753663.91sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 38753663.91sec, total: 38753663.91sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 38753663.92sec, total: 38753663.92sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 38753663.91sec, total: 38753663.92sec
  train.py:357:image_losses, cpu: 255us, accelerator: 38753663.91sec, total: 38753663.91sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 38753663.91sec, total: 38753663.91sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.37ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.84ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.84ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 493us, total: 1.69ms
      train.py:343:hfe, cpu: 593us, accelerator: 740us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.61ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.25ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.25ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.36ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_119000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 38672419.33sec, total: 38672419.34sec (25.00%)
top 2 operation type: Mean, cpu: 778us, accelerator: 38672419.33sec, total: 38672419.33sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 38672419.33sec, total: 38672419.33sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 38672419.34sec, total: 38672419.34sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 38672419.34sec, total: 38672419.34sec
  train.py:357:image_losses, cpu: 255us, accelerator: 38672419.33sec, total: 38672419.33sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 38672419.33sec, total: 38672419.33sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.84ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.84ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 493us, total: 1.68ms
      train.py:343:hfe, cpu: 593us, accelerator: 739us, total: 1.34ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.59ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.24ms, total: 7.42ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.35ms, total: 6.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_119250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 38591514.69sec, total: 38591514.69sec (25.00%)
top 2 operation type: Mean, cpu: 777us, accelerator: 38591514.69sec, total: 38591514.69sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 38591514.69sec, total: 38591514.69sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 38591514.69sec, total: 38591514.70sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 38591514.69sec, total: 38591514.70sec
  train.py:357:image_losses, cpu: 254us, accelerator: 38591514.69sec, total: 38591514.69sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 38591514.69sec, total: 38591514.69sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.83ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.83ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 492us, total: 1.68ms
      train.py:343:hfe, cpu: 591us, accelerator: 738us, total: 1.33ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.61ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.24ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.82ms, accelerator: 2.37ms, total: 6.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_119500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 38510947.85sec, total: 38510947.86sec (25.00%)
top 2 operation type: Mean, cpu: 776us, accelerator: 38510947.85sec, total: 38510947.85sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 73us, accelerator: 38510947.85sec, total: 38510947.85sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 38510947.86sec, total: 38510947.86sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 38510947.86sec, total: 38510947.86sec
  train.py:357:image_losses, cpu: 253us, accelerator: 38510947.85sec, total: 38510947.85sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 38510947.85sec, total: 38510947.85sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.34ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.83ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.83ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 492us, total: 1.68ms
      train.py:343:hfe, cpu: 591us, accelerator: 736us, total: 1.33ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.61ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.23ms, total: 7.42ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.37ms, total: 6.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_119750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.09ms, accelerator: 38430716.71sec, total: 38430716.71sec (25.00%)
top 2 operation type: Mean, cpu: 774us, accelerator: 38430716.71sec, total: 38430716.71sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 73us, accelerator: 38430716.71sec, total: 38430716.71sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 38430716.72sec, total: 38430716.72sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 38430716.71sec, total: 38430716.72sec
  train.py:357:image_losses, cpu: 253us, accelerator: 38430716.71sec, total: 38430716.71sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 38430716.71sec, total: 38430716.71sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.83ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.83ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 492us, total: 1.68ms
      train.py:343:hfe, cpu: 591us, accelerator: 735us, total: 1.33ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 2.23ms, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.37ms, total: 6.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_120000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 38350819.17sec, total: 38350819.17sec (25.00%)
top 2 operation type: Mean, cpu: 774us, accelerator: 38350819.17sec, total: 38350819.17sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 73us, accelerator: 38350819.17sec, total: 38350819.17sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 38350819.18sec, total: 38350819.18sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 38350819.17sec, total: 38350819.18sec
  train.py:357:image_losses, cpu: 253us, accelerator: 38350819.17sec, total: 38350819.17sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 38350819.17sec, total: 38350819.17sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.82ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.82ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 490us, total: 1.69ms
      train.py:343:hfe, cpu: 591us, accelerator: 734us, total: 1.33ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 2.23ms, total: 7.44ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.37ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_120250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 38271253.16sec, total: 38271253.16sec (25.00%)
top 2 operation type: Mean, cpu: 773us, accelerator: 38271253.16sec, total: 38271253.16sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 73us, accelerator: 38271253.16sec, total: 38271253.16sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 38271253.16sec, total: 38271253.17sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 38271253.16sec, total: 38271253.17sec
  train.py:357:image_losses, cpu: 253us, accelerator: 38271253.16sec, total: 38271253.16sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 38271253.16sec, total: 38271253.16sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.82ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.82ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 489us, total: 1.69ms
      train.py:343:hfe, cpu: 590us, accelerator: 732us, total: 1.32ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.58ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 2.23ms, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.36ms, total: 6.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_120500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 38192016.61sec, total: 38192016.61sec (25.00%)
top 2 operation type: Mean, cpu: 773us, accelerator: 38192016.61sec, total: 38192016.61sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 73us, accelerator: 38192016.61sec, total: 38192016.61sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 38192016.61sec, total: 38192016.62sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 38192016.61sec, total: 38192016.62sec
  train.py:357:image_losses, cpu: 253us, accelerator: 38192016.61sec, total: 38192016.61sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 38192016.61sec, total: 38192016.61sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.82ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.82ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 488us, total: 1.68ms
      train.py:343:hfe, cpu: 588us, accelerator: 730us, total: 1.32ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.61ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 2.24ms, total: 7.46ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.37ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_120750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 38113107.48sec, total: 38113107.49sec (25.00%)
top 2 operation type: Mean, cpu: 773us, accelerator: 38113107.48sec, total: 38113107.48sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 73us, accelerator: 38113107.48sec, total: 38113107.48sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 38113107.49sec, total: 38113107.49sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 38113107.49sec, total: 38113107.49sec
  train.py:357:image_losses, cpu: 253us, accelerator: 38113107.48sec, total: 38113107.48sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 38113107.48sec, total: 38113107.48sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.81ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.81ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 488us, total: 1.68ms
      train.py:343:hfe, cpu: 586us, accelerator: 728us, total: 1.32ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.61ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 2.24ms, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.37ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_121000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 38034523.76sec, total: 38034523.76sec (25.00%)
top 2 operation type: Mean, cpu: 772us, accelerator: 38034523.76sec, total: 38034523.76sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 73us, accelerator: 38034523.75sec, total: 38034523.75sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 38034523.76sec, total: 38034523.76sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 38034523.76sec, total: 38034523.76sec
  train.py:357:image_losses, cpu: 252us, accelerator: 38034523.76sec, total: 38034523.76sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 38034523.76sec, total: 38034523.76sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.39ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.39ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.37ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.83ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.83ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 489us, total: 1.71ms
      train.py:343:hfe, cpu: 586us, accelerator: 727us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.61ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 2.24ms, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.37ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_121250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 37956263.42sec, total: 37956263.42sec (25.00%)
top 2 operation type: Mean, cpu: 771us, accelerator: 37956263.42sec, total: 37956263.42sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 73us, accelerator: 37956263.42sec, total: 37956263.42sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37956263.42sec, total: 37956263.43sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 37956263.42sec, total: 37956263.43sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37956263.42sec, total: 37956263.42sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37956263.42sec, total: 37956263.42sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 1.39ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.39ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.37ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.83ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 488us, total: 1.71ms
      train.py:343:hfe, cpu: 586us, accelerator: 727us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.61ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 2.24ms, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.37ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_121500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 37878324.48sec, total: 37878324.48sec (25.00%)
top 2 operation type: Mean, cpu: 771us, accelerator: 37878324.48sec, total: 37878324.48sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 73us, accelerator: 37878324.48sec, total: 37878324.48sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37878324.48sec, total: 37878324.49sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 37878324.48sec, total: 37878324.49sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37878324.48sec, total: 37878324.48sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37878324.48sec, total: 37878324.48sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 1.39ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.39ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.37ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.83ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 488us, total: 1.70ms
      train.py:343:hfe, cpu: 585us, accelerator: 725us, total: 1.31ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 2.23ms, total: 7.44ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.37ms, total: 6.21ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_121750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 37800704.96sec, total: 37800704.96sec (25.00%)
top 2 operation type: Mean, cpu: 770us, accelerator: 37800704.96sec, total: 37800704.96sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 73us, accelerator: 37800704.96sec, total: 37800704.96sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37800704.97sec, total: 37800704.97sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 37800704.97sec, total: 37800704.97sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37800704.96sec, total: 37800704.96sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37800704.96sec, total: 37800704.96sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.38ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.36ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.82ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.82ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 487us, total: 1.71ms
      train.py:343:hfe, cpu: 585us, accelerator: 724us, total: 1.31ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.59ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 2.23ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.37ms, total: 6.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_122000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 37723402.91sec, total: 37723402.91sec (25.00%)
top 2 operation type: Mean, cpu: 769us, accelerator: 37723402.91sec, total: 37723402.91sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 72us, accelerator: 37723402.91sec, total: 37723402.91sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37723402.91sec, total: 37723402.92sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 37723402.91sec, total: 37723402.92sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37723402.91sec, total: 37723402.91sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37723402.91sec, total: 37723402.91sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.82ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.82ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 486us, total: 1.72ms
      train.py:343:hfe, cpu: 582us, accelerator: 723us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.58ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.21ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.21ms, total: 7.42ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.36ms, total: 6.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_122250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 37646416.37sec, total: 37646416.37sec (25.00%)
top 2 operation type: Mean, cpu: 768us, accelerator: 37646416.37sec, total: 37646416.37sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 72us, accelerator: 37646416.37sec, total: 37646416.37sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37646416.38sec, total: 37646416.38sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 37646416.37sec, total: 37646416.38sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37646416.37sec, total: 37646416.37sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37646416.37sec, total: 37646416.37sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.82ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.82ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 485us, total: 1.71ms
      train.py:343:hfe, cpu: 581us, accelerator: 720us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.57ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.21ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 2.21ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.36ms, total: 6.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_122500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 37569743.43sec, total: 37569743.43sec (25.00%)
top 2 operation type: Mean, cpu: 767us, accelerator: 37569743.42sec, total: 37569743.43sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 72us, accelerator: 37569743.42sec, total: 37569743.42sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37569743.43sec, total: 37569743.43sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 37569743.43sec, total: 37569743.43sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37569743.42sec, total: 37569743.42sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37569743.42sec, total: 37569743.42sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.38ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.83ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.83ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 484us, total: 1.71ms
      train.py:343:hfe, cpu: 582us, accelerator: 727us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.57ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.22ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 2.22ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.35ms, total: 6.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_122750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 37493382.16sec, total: 37493382.16sec (25.00%)
top 2 operation type: Mean, cpu: 767us, accelerator: 37493382.16sec, total: 37493382.16sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 72us, accelerator: 37493382.16sec, total: 37493382.16sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37493382.16sec, total: 37493382.17sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 37493382.16sec, total: 37493382.17sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37493382.16sec, total: 37493382.16sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37493382.16sec, total: 37493382.16sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.39ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.39ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.38ms, total: 4.31ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.83ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 484us, total: 1.71ms
      train.py:343:hfe, cpu: 582us, accelerator: 726us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.65ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.21ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.24ms, accelerator: 2.21ms, total: 7.48ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.44ms, total: 6.28ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_123000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 37417330.67sec, total: 37417330.68sec (25.00%)
top 2 operation type: Mean, cpu: 766us, accelerator: 37417330.67sec, total: 37417330.67sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 72us, accelerator: 37417330.67sec, total: 37417330.67sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37417330.68sec, total: 37417330.68sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 37417330.68sec, total: 37417330.68sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37417330.67sec, total: 37417330.67sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37417330.67sec, total: 37417330.67sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.39ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.39ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.38ms, total: 4.31ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.84ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 484us, total: 1.70ms
      train.py:343:hfe, cpu: 581us, accelerator: 743us, total: 1.33ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.65ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.21ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 2.21ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.44ms, total: 6.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_123250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.08ms, accelerator: 37341587.09sec, total: 37341587.09sec (25.00%)
top 2 operation type: Mean, cpu: 766us, accelerator: 37341587.09sec, total: 37341587.09sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 72us, accelerator: 37341587.09sec, total: 37341587.09sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37341587.09sec, total: 37341587.10sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 37341587.09sec, total: 37341587.10sec
  train.py:357:image_losses, cpu: 251us, accelerator: 37341587.09sec, total: 37341587.09sec
    train.py:322:loss_fn, cpu: 230us, accelerator: 37341587.09sec, total: 37341587.09sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.39ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.39ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.37ms, total: 4.31ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.84ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 482us, total: 1.70ms
      train.py:343:hfe, cpu: 580us, accelerator: 742us, total: 1.33ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.64ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.20ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 2.20ms, total: 7.46ms
  __init__.py:185:compute_gradients, cpu: 3.82ms, accelerator: 2.44ms, total: 6.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2116.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_123500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 37266149.54sec, total: 37266149.54sec (25.00%)
top 2 operation type: Mean, cpu: 765us, accelerator: 37266149.54sec, total: 37266149.54sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 72us, accelerator: 37266149.54sec, total: 37266149.54sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37266149.54sec, total: 37266149.55sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 37266149.54sec, total: 37266149.55sec
  train.py:357:image_losses, cpu: 250us, accelerator: 37266149.54sec, total: 37266149.54sec
    train.py:322:loss_fn, cpu: 229us, accelerator: 37266149.54sec, total: 37266149.54sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.39ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.39ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.37ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.83ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 482us, total: 1.70ms
      train.py:343:hfe, cpu: 578us, accelerator: 740us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.64ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.20ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 2.20ms, total: 7.46ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.44ms, total: 6.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_123750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 37191016.17sec, total: 37191016.18sec (25.00%)
top 2 operation type: Mean, cpu: 767us, accelerator: 37191016.17sec, total: 37191016.17sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 72us, accelerator: 37191016.17sec, total: 37191016.17sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 37191016.18sec, total: 37191016.18sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 37191016.18sec, total: 37191016.18sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37191016.17sec, total: 37191016.17sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37191016.17sec, total: 37191016.17sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.39ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.39ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.37ms, total: 4.31ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.83ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 481us, total: 1.70ms
      train.py:343:hfe, cpu: 578us, accelerator: 739us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.63ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.20ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 2.20ms, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.43ms, total: 6.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_124000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 37116185.15sec, total: 37116185.16sec (25.00%)
top 2 operation type: Mean, cpu: 767us, accelerator: 37116185.15sec, total: 37116185.15sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 72us, accelerator: 37116185.15sec, total: 37116185.15sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 37116185.16sec, total: 37116185.16sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 37116185.16sec, total: 37116185.16sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37116185.15sec, total: 37116185.15sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37116185.15sec, total: 37116185.15sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.38ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.36ms, total: 4.31ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.83ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.83ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 480us, total: 1.69ms
      train.py:343:hfe, cpu: 578us, accelerator: 739us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.62ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.19ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 2.19ms, total: 7.44ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.43ms, total: 6.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_124250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 37041654.66sec, total: 37041654.66sec (25.00%)
top 2 operation type: Mean, cpu: 767us, accelerator: 37041654.66sec, total: 37041654.66sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 72us, accelerator: 37041654.66sec, total: 37041654.66sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 37041654.67sec, total: 37041654.67sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 37041654.66sec, total: 37041654.67sec
  train.py:357:image_losses, cpu: 252us, accelerator: 37041654.66sec, total: 37041654.66sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 37041654.66sec, total: 37041654.66sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.38ms, total: 4.38ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.36ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.82ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.82ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 479us, total: 1.69ms
      train.py:343:hfe, cpu: 576us, accelerator: 737us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.61ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.19ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 2.19ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.42ms, total: 6.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_124500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 36967422.89sec, total: 36967422.89sec (25.00%)
top 2 operation type: Mean, cpu: 765us, accelerator: 36967422.89sec, total: 36967422.89sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36967422.89sec, total: 36967422.89sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 36967422.89sec, total: 36967422.90sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 36967422.89sec, total: 36967422.90sec
  train.py:357:image_losses, cpu: 252us, accelerator: 36967422.89sec, total: 36967422.89sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 36967422.89sec, total: 36967422.89sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.38ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.36ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.82ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.82ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 479us, total: 1.69ms
      train.py:343:hfe, cpu: 576us, accelerator: 736us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.19ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 2.19ms, total: 7.42ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.42ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_124750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 36893488.04sec, total: 36893488.05sec (25.00%)
top 2 operation type: Mean, cpu: 765us, accelerator: 36893488.04sec, total: 36893488.04sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36893488.04sec, total: 36893488.04sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 36893488.05sec, total: 36893488.05sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 36893488.05sec, total: 36893488.05sec
  train.py:357:image_losses, cpu: 252us, accelerator: 36893488.04sec, total: 36893488.04sec
    train.py:322:loss_fn, cpu: 231us, accelerator: 36893488.04sec, total: 36893488.04sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.38ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.30ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.82ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.82ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 479us, total: 1.69ms
      train.py:343:hfe, cpu: 577us, accelerator: 735us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.18ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 2.18ms, total: 7.42ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.41ms, total: 6.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_125000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 36819848.35sec, total: 36819848.35sec (25.00%)
top 2 operation type: Mean, cpu: 767us, accelerator: 36819848.35sec, total: 36819848.35sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36819848.35sec, total: 36819848.35sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 36819848.35sec, total: 36819848.36sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 36819848.35sec, total: 36819848.36sec
  train.py:357:image_losses, cpu: 253us, accelerator: 36819848.35sec, total: 36819848.35sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 36819848.35sec, total: 36819848.35sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.38ms, total: 4.37ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.81ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.81ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 477us, total: 1.68ms
      train.py:343:hfe, cpu: 573us, accelerator: 732us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.61ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.18ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 2.18ms, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.43ms, total: 6.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_125250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 36746502.04sec, total: 36746502.04sec (25.00%)
top 2 operation type: Mean, cpu: 765us, accelerator: 36746502.04sec, total: 36746502.04sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36746502.03sec, total: 36746502.03sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 36746502.04sec, total: 36746502.04sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 36746502.04sec, total: 36746502.04sec
  train.py:357:image_losses, cpu: 253us, accelerator: 36746502.03sec, total: 36746502.03sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 36746502.03sec, total: 36746502.03sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 477us, total: 1.70ms
      train.py:343:hfe, cpu: 573us, accelerator: 731us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.61ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.18ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 2.18ms, total: 7.44ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.43ms, total: 6.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_125500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 36673447.36sec, total: 36673447.36sec (25.00%)
top 2 operation type: Mean, cpu: 765us, accelerator: 36673447.36sec, total: 36673447.36sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36673447.36sec, total: 36673447.36sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 36673447.36sec, total: 36673447.37sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 36673447.36sec, total: 36673447.37sec
  train.py:357:image_losses, cpu: 253us, accelerator: 36673447.36sec, total: 36673447.36sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 36673447.36sec, total: 36673447.36sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.85ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.85ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 516us, total: 1.73ms
      train.py:343:hfe, cpu: 573us, accelerator: 730us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.60ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.24ms, accelerator: 2.17ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 2.43ms, total: 6.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_125750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 36600682.58sec, total: 36600682.59sec (25.00%)
top 2 operation type: Mean, cpu: 765us, accelerator: 36600682.58sec, total: 36600682.58sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36600682.58sec, total: 36600682.58sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 36600682.59sec, total: 36600682.59sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 36600682.59sec, total: 36600682.59sec
  train.py:357:image_losses, cpu: 253us, accelerator: 36600682.58sec, total: 36600682.58sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 36600682.58sec, total: 36600682.58sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.38ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.85ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.85ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 515us, total: 1.74ms
      train.py:343:hfe, cpu: 573us, accelerator: 729us, total: 1.31ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.59ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 2.17ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.42ms, total: 6.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_126000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 36528205.98sec, total: 36528205.99sec (25.00%)
top 2 operation type: Mean, cpu: 767us, accelerator: 36528205.98sec, total: 36528205.98sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36528205.98sec, total: 36528205.98sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 36528205.99sec, total: 36528205.99sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 36528205.99sec, total: 36528205.99sec
  train.py:357:image_losses, cpu: 253us, accelerator: 36528205.98sec, total: 36528205.98sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 36528205.98sec, total: 36528205.98sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.38ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.38ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.36ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.86ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.86ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 513us, total: 1.73ms
      train.py:343:hfe, cpu: 573us, accelerator: 749us, total: 1.33ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.58ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 2.17ms, total: 7.42ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.42ms, total: 6.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_126250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 36456015.85sec, total: 36456015.86sec (25.00%)
top 2 operation type: Mean, cpu: 766us, accelerator: 36456015.85sec, total: 36456015.85sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36456015.85sec, total: 36456015.85sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 36456015.86sec, total: 36456015.86sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 36456015.86sec, total: 36456015.86sec
  train.py:357:image_losses, cpu: 253us, accelerator: 36456015.85sec, total: 36456015.85sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 36456015.85sec, total: 36456015.85sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.37ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.36ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.35ms, total: 4.29ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.86ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.86ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 511us, total: 1.74ms
      train.py:343:hfe, cpu: 572us, accelerator: 749us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.58ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 2.16ms, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.42ms, total: 6.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_126500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 36384110.50sec, total: 36384110.50sec (25.00%)
top 2 operation type: Mean, cpu: 765us, accelerator: 36384110.50sec, total: 36384110.50sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36384110.50sec, total: 36384110.50sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 36384110.50sec, total: 36384110.51sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 36384110.50sec, total: 36384110.50sec
  train.py:357:image_losses, cpu: 253us, accelerator: 36384110.50sec, total: 36384110.50sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 36384110.50sec, total: 36384110.50sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.37ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.86ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.86ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 511us, total: 1.74ms
      train.py:343:hfe, cpu: 571us, accelerator: 750us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.57ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 2.16ms, total: 7.40ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 2.42ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_126750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 36312488.23sec, total: 36312488.23sec (25.00%)
top 2 operation type: Mean, cpu: 764us, accelerator: 36312488.23sec, total: 36312488.23sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36312488.23sec, total: 36312488.23sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 36312488.24sec, total: 36312488.24sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 36312488.23sec, total: 36312488.24sec
  train.py:357:image_losses, cpu: 256us, accelerator: 36312488.23sec, total: 36312488.23sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 36312488.23sec, total: 36312488.23sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.37ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.85ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.85ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 510us, total: 1.74ms
      train.py:343:hfe, cpu: 570us, accelerator: 747us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.57ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 2.15ms, total: 7.39ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.41ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_127000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 36241147.39sec, total: 36241147.39sec (25.00%)
top 2 operation type: Mean, cpu: 764us, accelerator: 36241147.39sec, total: 36241147.39sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 36241147.39sec, total: 36241147.39sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 36241147.39sec, total: 36241147.40sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 36241147.39sec, total: 36241147.40sec
  train.py:357:image_losses, cpu: 256us, accelerator: 36241147.39sec, total: 36241147.39sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 36241147.39sec, total: 36241147.39sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.37ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.85ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.85ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 511us, total: 1.73ms
      train.py:343:hfe, cpu: 570us, accelerator: 746us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.56ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 2.15ms, total: 7.39ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.40ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_127250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 36170086.32sec, total: 36170086.32sec (25.00%)
top 2 operation type: Mean, cpu: 764us, accelerator: 36170086.32sec, total: 36170086.32sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 36170086.32sec, total: 36170086.32sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 36170086.32sec, total: 36170086.33sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 36170086.32sec, total: 36170086.33sec
  train.py:357:image_losses, cpu: 258us, accelerator: 36170086.32sec, total: 36170086.32sec
    train.py:322:loss_fn, cpu: 237us, accelerator: 36170086.32sec, total: 36170086.32sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.37ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.37ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.85ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.85ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 511us, total: 1.73ms
      train.py:343:hfe, cpu: 570us, accelerator: 746us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.55ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 2.15ms, total: 7.38ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 2.40ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_127500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 36099303.37sec, total: 36099303.37sec (25.00%)
top 2 operation type: Mean, cpu: 768us, accelerator: 36099303.37sec, total: 36099303.37sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 36099303.37sec, total: 36099303.37sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 36099303.37sec, total: 36099303.38sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 36099303.37sec, total: 36099303.38sec
  train.py:357:image_losses, cpu: 258us, accelerator: 36099303.37sec, total: 36099303.37sec
    train.py:322:loss_fn, cpu: 237us, accelerator: 36099303.37sec, total: 36099303.37sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.86ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.86ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 510us, total: 1.73ms
      train.py:343:hfe, cpu: 570us, accelerator: 747us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.58ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 2.14ms, total: 7.39ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.44ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_127750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 36028796.92sec, total: 36028796.92sec (25.00%)
top 2 operation type: Mean, cpu: 768us, accelerator: 36028796.92sec, total: 36028796.92sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 36028796.92sec, total: 36028796.92sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 36028796.92sec, total: 36028796.93sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 36028796.92sec, total: 36028796.93sec
  train.py:357:image_losses, cpu: 257us, accelerator: 36028796.92sec, total: 36028796.92sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 36028796.92sec, total: 36028796.92sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.88ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.88ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 509us, total: 1.73ms
      train.py:343:hfe, cpu: 570us, accelerator: 753us, total: 1.33ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.58ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 2.14ms, total: 7.38ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.44ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_128000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35958565.34sec, total: 35958565.35sec (25.00%)
top 2 operation type: Mean, cpu: 768us, accelerator: 35958565.34sec, total: 35958565.35sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 35958565.34sec, total: 35958565.34sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35958565.35sec, total: 35958565.35sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 35958565.35sec, total: 35958565.35sec
  train.py:357:image_losses, cpu: 258us, accelerator: 35958565.34sec, total: 35958565.34sec
    train.py:322:loss_fn, cpu: 237us, accelerator: 35958565.34sec, total: 35958565.34sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.88ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.88ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 509us, total: 1.74ms
      train.py:343:hfe, cpu: 570us, accelerator: 751us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.58ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 2.14ms, total: 7.37ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.44ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_128250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35888607.05sec, total: 35888607.05sec (25.00%)
top 2 operation type: Mean, cpu: 766us, accelerator: 35888607.05sec, total: 35888607.05sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 35888607.04sec, total: 35888607.04sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35888607.05sec, total: 35888607.05sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 35888607.05sec, total: 35888607.05sec
  train.py:357:image_losses, cpu: 257us, accelerator: 35888607.05sec, total: 35888607.05sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 35888607.05sec, total: 35888607.05sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.87ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.87ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 507us, total: 1.74ms
      train.py:343:hfe, cpu: 570us, accelerator: 748us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.66ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.22ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 2.22ms, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.44ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_128500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35818920.43sec, total: 35818920.43sec (25.00%)
top 2 operation type: Mean, cpu: 765us, accelerator: 35818920.43sec, total: 35818920.43sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 35818920.43sec, total: 35818920.43sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35818920.43sec, total: 35818920.44sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 35818920.43sec, total: 35818920.44sec
  train.py:357:image_losses, cpu: 256us, accelerator: 35818920.43sec, total: 35818920.43sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 35818920.43sec, total: 35818920.43sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.87ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.87ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 507us, total: 1.74ms
      train.py:343:hfe, cpu: 569us, accelerator: 747us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.66ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.22ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 2.22ms, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.44ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_128750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35749503.92sec, total: 35749503.92sec (25.00%)
top 2 operation type: Mean, cpu: 764us, accelerator: 35749503.92sec, total: 35749503.92sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 35749503.92sec, total: 35749503.92sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35749503.92sec, total: 35749503.93sec
train.py:442:<module>, cpu: 5.63ms, accelerator: 35749503.92sec, total: 35749503.93sec
  train.py:357:image_losses, cpu: 256us, accelerator: 35749503.92sec, total: 35749503.92sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 35749503.92sec, total: 35749503.92sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.88ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.88ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 510us, total: 1.76ms
      train.py:343:hfe, cpu: 568us, accelerator: 748us, total: 1.32ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.68ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.25ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 2.25ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.44ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_129000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35680355.94sec, total: 35680355.94sec (25.00%)
top 2 operation type: Mean, cpu: 763us, accelerator: 35680355.94sec, total: 35680355.94sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 35680355.94sec, total: 35680355.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35680355.95sec, total: 35680355.95sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 35680355.94sec, total: 35680355.95sec
  train.py:357:image_losses, cpu: 256us, accelerator: 35680355.94sec, total: 35680355.94sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 35680355.94sec, total: 35680355.94sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.35ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.87ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.87ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 509us, total: 1.75ms
      train.py:343:hfe, cpu: 567us, accelerator: 748us, total: 1.32ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.67ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.24ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 2.24ms, total: 7.46ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.42ms, total: 6.25ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_129250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 35611474.95sec, total: 35611474.95sec (25.00%)
top 2 operation type: Mean, cpu: 763us, accelerator: 35611474.95sec, total: 35611474.95sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 35611474.94sec, total: 35611474.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35611474.95sec, total: 35611474.95sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 35611474.95sec, total: 35611474.95sec
  train.py:357:image_losses, cpu: 256us, accelerator: 35611474.94sec, total: 35611474.95sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 35611474.94sec, total: 35611474.95sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.88ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.88ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 508us, total: 1.75ms
      train.py:343:hfe, cpu: 567us, accelerator: 750us, total: 1.32ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.68ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.26ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.26ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.42ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_129500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 35542859.39sec, total: 35542859.39sec (25.00%)
top 2 operation type: Mean, cpu: 763us, accelerator: 35542859.39sec, total: 35542859.39sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 35542859.39sec, total: 35542859.39sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35542859.39sec, total: 35542859.40sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 35542859.39sec, total: 35542859.40sec
  train.py:357:image_losses, cpu: 256us, accelerator: 35542859.39sec, total: 35542859.39sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 35542859.39sec, total: 35542859.39sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.87ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.87ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 507us, total: 1.75ms
      train.py:343:hfe, cpu: 566us, accelerator: 747us, total: 1.32ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.69ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.26ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.26ms, total: 7.46ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.43ms, total: 6.24ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_129750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35474507.73sec, total: 35474507.74sec (25.00%)
top 2 operation type: Mean, cpu: 763us, accelerator: 35474507.73sec, total: 35474507.73sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 35474507.73sec, total: 35474507.73sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35474507.74sec, total: 35474507.74sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 35474507.74sec, total: 35474507.74sec
  train.py:357:image_losses, cpu: 256us, accelerator: 35474507.73sec, total: 35474507.73sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 35474507.73sec, total: 35474507.73sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.35ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.87ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.87ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 506us, total: 1.75ms
      train.py:343:hfe, cpu: 566us, accelerator: 745us, total: 1.31ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.74ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.31ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.31ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.43ms, total: 6.24ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_130000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35406418.47sec, total: 35406418.47sec (25.00%)
top 2 operation type: Mean, cpu: 765us, accelerator: 35406418.47sec, total: 35406418.47sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 35406418.47sec, total: 35406418.47sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35406418.47sec, total: 35406418.48sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 35406418.47sec, total: 35406418.48sec
  train.py:357:image_losses, cpu: 256us, accelerator: 35406418.47sec, total: 35406418.47sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 35406418.47sec, total: 35406418.47sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.87ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.87ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 505us, total: 1.74ms
      train.py:343:hfe, cpu: 565us, accelerator: 744us, total: 1.31ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.73ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.30ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.30ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.43ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_130250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35338590.08sec, total: 35338590.08sec (25.00%)
top 2 operation type: Mean, cpu: 764us, accelerator: 35338590.08sec, total: 35338590.08sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 35338590.08sec, total: 35338590.08sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 35338590.08sec, total: 35338590.09sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 35338590.08sec, total: 35338590.09sec
  train.py:357:image_losses, cpu: 256us, accelerator: 35338590.08sec, total: 35338590.08sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 35338590.08sec, total: 35338590.08sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.86ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.86ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 505us, total: 1.74ms
      train.py:343:hfe, cpu: 565us, accelerator: 743us, total: 1.31ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.72ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.30ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.30ms, total: 7.50ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.42ms, total: 6.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_130500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35271021.07sec, total: 35271021.08sec (25.00%)
top 2 operation type: Mean, cpu: 763us, accelerator: 35271021.07sec, total: 35271021.07sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 35271021.07sec, total: 35271021.07sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 35271021.08sec, total: 35271021.08sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 35271021.08sec, total: 35271021.08sec
  train.py:357:image_losses, cpu: 255us, accelerator: 35271021.07sec, total: 35271021.07sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 35271021.07sec, total: 35271021.07sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.86ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.86ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 503us, total: 1.74ms
      train.py:343:hfe, cpu: 564us, accelerator: 741us, total: 1.31ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.71ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.30ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.30ms, total: 7.50ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.42ms, total: 6.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_130750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35203709.97sec, total: 35203709.97sec (25.00%)
top 2 operation type: Mean, cpu: 763us, accelerator: 35203709.96sec, total: 35203709.97sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 35203709.96sec, total: 35203709.96sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 35203709.97sec, total: 35203709.97sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 35203709.97sec, total: 35203709.97sec
  train.py:357:image_losses, cpu: 255us, accelerator: 35203709.96sec, total: 35203709.96sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 35203709.96sec, total: 35203709.96sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.86ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.86ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 503us, total: 1.74ms
      train.py:343:hfe, cpu: 564us, accelerator: 741us, total: 1.31ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.71ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.29ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.29ms, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.42ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_131000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35136655.28sec, total: 35136655.28sec (25.00%)
top 2 operation type: Mean, cpu: 763us, accelerator: 35136655.28sec, total: 35136655.28sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 35136655.28sec, total: 35136655.28sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35136655.28sec, total: 35136655.29sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 35136655.28sec, total: 35136655.29sec
  train.py:357:image_losses, cpu: 255us, accelerator: 35136655.28sec, total: 35136655.28sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 35136655.28sec, total: 35136655.28sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.35ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.86ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.86ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 503us, total: 1.74ms
      train.py:343:hfe, cpu: 562us, accelerator: 740us, total: 1.31ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.70ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.29ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 2.29ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.41ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_131250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35069855.55sec, total: 35069855.56sec (25.00%)
top 2 operation type: Mean, cpu: 764us, accelerator: 35069855.55sec, total: 35069855.56sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 35069855.55sec, total: 35069855.55sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 35069855.56sec, total: 35069855.56sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 35069855.56sec, total: 35069855.56sec
  train.py:357:image_losses, cpu: 255us, accelerator: 35069855.55sec, total: 35069855.55sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 35069855.55sec, total: 35069855.55sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.35ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 502us, total: 1.74ms
      train.py:343:hfe, cpu: 561us, accelerator: 738us, total: 1.30ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.70ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.28ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 2.28ms, total: 7.50ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.42ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_131500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 35003309.34sec, total: 35003309.34sec (25.00%)
top 2 operation type: Mean, cpu: 762us, accelerator: 35003309.34sec, total: 35003309.34sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 35003309.34sec, total: 35003309.34sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 35003309.34sec, total: 35003309.35sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 35003309.34sec, total: 35003309.35sec
  train.py:357:image_losses, cpu: 255us, accelerator: 35003309.34sec, total: 35003309.34sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 35003309.34sec, total: 35003309.34sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.35ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 501us, total: 1.74ms
      train.py:343:hfe, cpu: 561us, accelerator: 736us, total: 1.30ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.69ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.28ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.28ms, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.41ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_131750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 34937015.19sec, total: 34937015.20sec (25.00%)
top 2 operation type: Mean, cpu: 778us, accelerator: 34937015.19sec, total: 34937015.19sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34937015.19sec, total: 34937015.19sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34937015.20sec, total: 34937015.20sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 34937015.20sec, total: 34937015.20sec
  train.py:357:image_losses, cpu: 254us, accelerator: 34937015.19sec, total: 34937015.19sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 34937015.19sec, total: 34937015.19sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.35ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 1.35ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.90ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 501us, total: 1.74ms
      train.py:343:hfe, cpu: 561us, accelerator: 739us, total: 1.30ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.71ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.30ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.30ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.41ms, total: 6.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_132000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 34870971.69sec, total: 34870971.69sec (25.00%)
top 2 operation type: Mean, cpu: 778us, accelerator: 34870971.69sec, total: 34870971.69sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34870971.68sec, total: 34870971.68sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34870971.69sec, total: 34870971.69sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 34870971.69sec, total: 34870971.69sec
  train.py:357:image_losses, cpu: 254us, accelerator: 34870971.69sec, total: 34870971.69sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 34870971.69sec, total: 34870971.69sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.35ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.85ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 501us, total: 1.73ms
      train.py:343:hfe, cpu: 558us, accelerator: 738us, total: 1.30ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.71ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.30ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.30ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.41ms, total: 6.23ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_132250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 34805177.40sec, total: 34805177.40sec (25.00%)
top 2 operation type: Mean, cpu: 778us, accelerator: 34805177.40sec, total: 34805177.40sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34805177.40sec, total: 34805177.40sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 34805177.40sec, total: 34805177.41sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 34805177.40sec, total: 34805177.41sec
  train.py:357:image_losses, cpu: 254us, accelerator: 34805177.40sec, total: 34805177.40sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 34805177.40sec, total: 34805177.40sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.35ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.33ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.85ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.85ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 500us, total: 1.73ms
      train.py:343:hfe, cpu: 558us, accelerator: 737us, total: 1.30ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.70ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.29ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.29ms, total: 7.50ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.40ms, total: 6.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_132500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 34739630.93sec, total: 34739630.93sec (25.00%)
top 2 operation type: Mean, cpu: 778us, accelerator: 34739630.93sec, total: 34739630.93sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 34739630.92sec, total: 34739630.92sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34739630.93sec, total: 34739630.93sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 34739630.93sec, total: 34739630.93sec
  train.py:357:image_losses, cpu: 254us, accelerator: 34739630.93sec, total: 34739630.93sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 34739630.93sec, total: 34739630.93sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.35ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.33ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.84ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 500us, total: 1.73ms
      train.py:343:hfe, cpu: 557us, accelerator: 733us, total: 1.30ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.70ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.29ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.29ms, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.40ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_132750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 34674330.87sec, total: 34674330.87sec (25.00%)
top 2 operation type: Mean, cpu: 777us, accelerator: 34674330.87sec, total: 34674330.87sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 34674330.87sec, total: 34674330.87sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34674330.87sec, total: 34674330.88sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 34674330.87sec, total: 34674330.88sec
  train.py:357:image_losses, cpu: 254us, accelerator: 34674330.87sec, total: 34674330.87sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 34674330.87sec, total: 34674330.87sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 1.35ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.33ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.84ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 498us, total: 1.73ms
      train.py:343:hfe, cpu: 557us, accelerator: 733us, total: 1.30ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.69ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.29ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.29ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.40ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_133000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 34609275.84sec, total: 34609275.84sec (25.00%)
top 2 operation type: Mean, cpu: 778us, accelerator: 34609275.84sec, total: 34609275.84sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 34609275.84sec, total: 34609275.84sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34609275.84sec, total: 34609275.85sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 34609275.84sec, total: 34609275.85sec
  train.py:357:image_losses, cpu: 254us, accelerator: 34609275.84sec, total: 34609275.84sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 34609275.84sec, total: 34609275.84sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.35ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.33ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.85ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.85ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 498us, total: 1.73ms
      train.py:343:hfe, cpu: 557us, accelerator: 735us, total: 1.30ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.69ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.29ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.29ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.40ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_133250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 34544464.46sec, total: 34544464.46sec (25.00%)
top 2 operation type: Mean, cpu: 787us, accelerator: 34544464.46sec, total: 34544464.46sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34544464.46sec, total: 34544464.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 34544464.46sec, total: 34544464.47sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 34544464.46sec, total: 34544464.47sec
  train.py:357:image_losses, cpu: 254us, accelerator: 34544464.46sec, total: 34544464.46sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 34544464.46sec, total: 34544464.46sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.35ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.33ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.85ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.85ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 497us, total: 1.72ms
      train.py:343:hfe, cpu: 557us, accelerator: 734us, total: 1.30ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.71ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.28ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.28ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 2.42ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_133500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 34479895.37sec, total: 34479895.37sec (25.00%)
top 2 operation type: Mean, cpu: 787us, accelerator: 34479895.37sec, total: 34479895.37sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34479895.37sec, total: 34479895.37sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34479895.37sec, total: 34479895.38sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 34479895.37sec, total: 34479895.38sec
  train.py:357:image_losses, cpu: 254us, accelerator: 34479895.37sec, total: 34479895.37sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 34479895.37sec, total: 34479895.37sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.35ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.33ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.85ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.85ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 497us, total: 1.72ms
      train.py:343:hfe, cpu: 557us, accelerator: 733us, total: 1.29ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.72ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.30ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.30ms, total: 7.48ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.42ms, total: 6.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_133750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 34415567.21sec, total: 34415567.21sec (25.00%)
top 2 operation type: Mean, cpu: 811us, accelerator: 34415567.20sec, total: 34415567.21sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34415567.20sec, total: 34415567.20sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34415567.21sec, total: 34415567.21sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 34415567.21sec, total: 34415567.21sec
  train.py:357:image_losses, cpu: 257us, accelerator: 34415567.20sec, total: 34415567.20sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 34415567.20sec, total: 34415567.20sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.34ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.34ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.33ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.84ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.84ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 496us, total: 1.72ms
      train.py:343:hfe, cpu: 557us, accelerator: 731us, total: 1.29ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.72ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.31ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.31ms, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.42ms, total: 6.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_134000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 34351478.63sec, total: 34351478.63sec (25.00%)
top 2 operation type: Mean, cpu: 810us, accelerator: 34351478.63sec, total: 34351478.63sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34351478.62sec, total: 34351478.62sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34351478.63sec, total: 34351478.63sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 34351478.63sec, total: 34351478.63sec
  train.py:357:image_losses, cpu: 257us, accelerator: 34351478.62sec, total: 34351478.62sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 34351478.62sec, total: 34351478.62sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.84ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.84ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 495us, total: 1.72ms
      train.py:343:hfe, cpu: 556us, accelerator: 731us, total: 1.29ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.71ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.30ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.30ms, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 2.41ms, total: 6.22ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_134250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.07ms, accelerator: 34287628.29sec, total: 34287628.30sec (25.00%)
top 2 operation type: Mean, cpu: 810us, accelerator: 34287628.29sec, total: 34287628.29sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34287628.29sec, total: 34287628.29sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34287628.30sec, total: 34287628.30sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 34287628.30sec, total: 34287628.30sec
  train.py:357:image_losses, cpu: 257us, accelerator: 34287628.29sec, total: 34287628.29sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 34287628.29sec, total: 34287628.29sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.36ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.84ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 494us, total: 1.73ms
      train.py:343:hfe, cpu: 554us, accelerator: 730us, total: 1.29ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.70ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.30ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.30ms, total: 7.48ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.41ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_134500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 34224014.88sec, total: 34224014.89sec (25.00%)
top 2 operation type: Mean, cpu: 809us, accelerator: 34224014.88sec, total: 34224014.88sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34224014.88sec, total: 34224014.88sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34224014.89sec, total: 34224014.89sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 34224014.89sec, total: 34224014.89sec
  train.py:357:image_losses, cpu: 257us, accelerator: 34224014.88sec, total: 34224014.88sec
    train.py:322:loss_fn, cpu: 236us, accelerator: 34224014.88sec, total: 34224014.88sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.89ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.83ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 494us, total: 1.72ms
      train.py:343:hfe, cpu: 554us, accelerator: 728us, total: 1.29ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.70ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.30ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.30ms, total: 7.48ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.40ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_134750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 34160637.08sec, total: 34160637.08sec (25.00%)
top 2 operation type: Mean, cpu: 806us, accelerator: 34160637.08sec, total: 34160637.08sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34160637.08sec, total: 34160637.08sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34160637.08sec, total: 34160637.09sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 34160637.08sec, total: 34160637.09sec
  train.py:357:image_losses, cpu: 256us, accelerator: 34160637.08sec, total: 34160637.08sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 34160637.08sec, total: 34160637.08sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.84ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.84ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 494us, total: 1.72ms
      train.py:343:hfe, cpu: 553us, accelerator: 733us, total: 1.29ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.69ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.29ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.29ms, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.40ms, total: 6.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_135000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 34097493.57sec, total: 34097493.57sec (25.00%)
top 2 operation type: Mean, cpu: 806us, accelerator: 34097493.57sec, total: 34097493.57sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34097493.57sec, total: 34097493.57sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 34097493.58sec, total: 34097493.58sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 34097493.57sec, total: 34097493.58sec
  train.py:357:image_losses, cpu: 256us, accelerator: 34097493.57sec, total: 34097493.57sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 34097493.57sec, total: 34097493.57sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.83ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 493us, total: 1.72ms
      train.py:343:hfe, cpu: 553us, accelerator: 731us, total: 1.29ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.68ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.29ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.29ms, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.40ms, total: 6.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_135250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 34034583.07sec, total: 34034583.07sec (25.00%)
top 2 operation type: Mean, cpu: 805us, accelerator: 34034583.07sec, total: 34034583.07sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 34034583.06sec, total: 34034583.06sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 34034583.07sec, total: 34034583.07sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 34034583.07sec, total: 34034583.07sec
  train.py:357:image_losses, cpu: 255us, accelerator: 34034583.07sec, total: 34034583.07sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 34034583.07sec, total: 34034583.07sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.83ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.83ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 493us, total: 1.72ms
      train.py:343:hfe, cpu: 553us, accelerator: 729us, total: 1.28ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.67ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.28ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 2.28ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.39ms, total: 6.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_135500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33971904.28sec, total: 33971904.28sec (25.00%)
top 2 operation type: Mean, cpu: 805us, accelerator: 33971904.28sec, total: 33971904.28sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 33971904.27sec, total: 33971904.27sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33971904.28sec, total: 33971904.28sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 33971904.28sec, total: 33971904.28sec
  train.py:357:image_losses, cpu: 255us, accelerator: 33971904.28sec, total: 33971904.28sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 33971904.28sec, total: 33971904.28sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.83ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.83ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 492us, total: 1.72ms
      train.py:343:hfe, cpu: 553us, accelerator: 728us, total: 1.28ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.67ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.28ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 2.28ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.39ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_135750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33909455.92sec, total: 33909455.92sec (25.00%)
top 2 operation type: Mean, cpu: 805us, accelerator: 33909455.92sec, total: 33909455.92sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 33909455.92sec, total: 33909455.92sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 33909455.93sec, total: 33909455.93sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 33909455.93sec, total: 33909455.93sec
  train.py:357:image_losses, cpu: 255us, accelerator: 33909455.92sec, total: 33909455.92sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 33909455.92sec, total: 33909455.92sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.82ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.82ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 490us, total: 1.72ms
      train.py:343:hfe, cpu: 553us, accelerator: 726us, total: 1.28ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.66ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.27ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 2.27ms, total: 7.50ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.38ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_136000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33847236.74sec, total: 33847236.74sec (25.00%)
top 2 operation type: Mean, cpu: 805us, accelerator: 33847236.74sec, total: 33847236.74sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 33847236.74sec, total: 33847236.74sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33847236.74sec, total: 33847236.75sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 33847236.74sec, total: 33847236.75sec
  train.py:357:image_losses, cpu: 255us, accelerator: 33847236.74sec, total: 33847236.74sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 33847236.74sec, total: 33847236.74sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.82ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.82ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 489us, total: 1.73ms
      train.py:343:hfe, cpu: 551us, accelerator: 726us, total: 1.28ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.67ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.27ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 2.27ms, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.40ms, total: 6.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_136250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33785245.46sec, total: 33785245.46sec (25.00%)
top 2 operation type: Mean, cpu: 804us, accelerator: 33785245.46sec, total: 33785245.46sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33785245.46sec, total: 33785245.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33785245.47sec, total: 33785245.47sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 33785245.46sec, total: 33785245.47sec
  train.py:357:image_losses, cpu: 255us, accelerator: 33785245.46sec, total: 33785245.46sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 33785245.46sec, total: 33785245.46sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.35ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.81ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 487us, total: 1.73ms
      train.py:343:hfe, cpu: 551us, accelerator: 725us, total: 1.28ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.67ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.27ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 2.27ms, total: 7.48ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.40ms, total: 6.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_136500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33723480.84sec, total: 33723480.85sec (25.00%)
top 2 operation type: Mean, cpu: 802us, accelerator: 33723480.84sec, total: 33723480.84sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33723480.84sec, total: 33723480.84sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33723480.85sec, total: 33723480.85sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 33723480.85sec, total: 33723480.85sec
  train.py:357:image_losses, cpu: 254us, accelerator: 33723480.84sec, total: 33723480.84sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 33723480.84sec, total: 33723480.84sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.81ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 487us, total: 1.72ms
      train.py:343:hfe, cpu: 550us, accelerator: 722us, total: 1.28ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.66ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.26ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.26ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.40ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_136750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33661941.65sec, total: 33661941.65sec (25.00%)
top 2 operation type: Mean, cpu: 800us, accelerator: 33661941.65sec, total: 33661941.65sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33661941.64sec, total: 33661941.64sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33661941.65sec, total: 33661941.65sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 33661941.65sec, total: 33661941.65sec
  train.py:357:image_losses, cpu: 254us, accelerator: 33661941.64sec, total: 33661941.65sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 33661941.64sec, total: 33661941.65sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 487us, total: 1.72ms
      train.py:343:hfe, cpu: 549us, accelerator: 722us, total: 1.27ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.67ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.26ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.26ms, total: 7.46ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.41ms, total: 6.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_137000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33600626.63sec, total: 33600626.64sec (25.00%)
top 2 operation type: Mean, cpu: 803us, accelerator: 33600626.63sec, total: 33600626.63sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33600626.63sec, total: 33600626.63sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33600626.64sec, total: 33600626.64sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 33600626.64sec, total: 33600626.64sec
  train.py:357:image_losses, cpu: 255us, accelerator: 33600626.63sec, total: 33600626.63sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 33600626.63sec, total: 33600626.63sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 486us, total: 1.72ms
      train.py:343:hfe, cpu: 549us, accelerator: 722us, total: 1.27ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.66ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.26ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.26ms, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.40ms, total: 6.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_137250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33539534.59sec, total: 33539534.59sec (25.00%)
top 2 operation type: Mean, cpu: 804us, accelerator: 33539534.58sec, total: 33539534.59sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33539534.58sec, total: 33539534.58sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33539534.59sec, total: 33539534.59sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 33539534.59sec, total: 33539534.59sec
  train.py:357:image_losses, cpu: 256us, accelerator: 33539534.58sec, total: 33539534.58sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 33539534.58sec, total: 33539534.58sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.80ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.80ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 486us, total: 1.72ms
      train.py:343:hfe, cpu: 548us, accelerator: 719us, total: 1.27ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.65ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.25ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.25ms, total: 7.44ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.40ms, total: 6.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_137500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33478664.29sec, total: 33478664.29sec (25.00%)
top 2 operation type: Mean, cpu: 803us, accelerator: 33478664.29sec, total: 33478664.29sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33478664.29sec, total: 33478664.29sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33478664.29sec, total: 33478664.30sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 33478664.29sec, total: 33478664.29sec
  train.py:357:image_losses, cpu: 255us, accelerator: 33478664.29sec, total: 33478664.29sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 33478664.29sec, total: 33478664.29sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.80ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.80ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 485us, total: 1.72ms
      train.py:343:hfe, cpu: 548us, accelerator: 719us, total: 1.27ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.65ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.25ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.25ms, total: 7.44ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.40ms, total: 6.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_137750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33418014.53sec, total: 33418014.53sec (25.00%)
top 2 operation type: Mean, cpu: 800us, accelerator: 33418014.53sec, total: 33418014.53sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33418014.53sec, total: 33418014.53sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33418014.54sec, total: 33418014.54sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 33418014.53sec, total: 33418014.54sec
  train.py:357:image_losses, cpu: 254us, accelerator: 33418014.53sec, total: 33418014.53sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 33418014.53sec, total: 33418014.53sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.80ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.80ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 484us, total: 1.72ms
      train.py:343:hfe, cpu: 547us, accelerator: 717us, total: 1.27ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.63ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.24ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.39ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2126.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_138000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33357584.13sec, total: 33357584.13sec (25.00%)
top 2 operation type: Mean, cpu: 802us, accelerator: 33357584.13sec, total: 33357584.13sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33357584.12sec, total: 33357584.12sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33357584.13sec, total: 33357584.13sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 33357584.13sec, total: 33357584.13sec
  train.py:357:image_losses, cpu: 254us, accelerator: 33357584.13sec, total: 33357584.13sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 33357584.13sec, total: 33357584.13sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.34ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.79ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.79ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 483us, total: 1.72ms
      train.py:343:hfe, cpu: 547us, accelerator: 715us, total: 1.27ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.63ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.24ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.39ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_138250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33297371.88sec, total: 33297371.88sec (25.00%)
top 2 operation type: Mean, cpu: 803us, accelerator: 33297371.88sec, total: 33297371.88sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33297371.88sec, total: 33297371.88sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 33297371.88sec, total: 33297371.89sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 33297371.88sec, total: 33297371.89sec
  train.py:357:image_losses, cpu: 256us, accelerator: 33297371.88sec, total: 33297371.88sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 33297371.88sec, total: 33297371.88sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.34ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.80ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.80ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 483us, total: 1.72ms
      train.py:343:hfe, cpu: 547us, accelerator: 717us, total: 1.27ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.24ms, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.39ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_138500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33237376.62sec, total: 33237376.62sec (25.00%)
top 2 operation type: Mean, cpu: 802us, accelerator: 33237376.62sec, total: 33237376.62sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33237376.61sec, total: 33237376.61sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 33237376.62sec, total: 33237376.62sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 33237376.62sec, total: 33237376.62sec
  train.py:357:image_losses, cpu: 254us, accelerator: 33237376.62sec, total: 33237376.62sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 33237376.62sec, total: 33237376.62sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.34ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.79ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.79ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 482us, total: 1.72ms
      train.py:343:hfe, cpu: 547us, accelerator: 716us, total: 1.27ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 2.23ms, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.38ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_138750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33177597.16sec, total: 33177597.16sec (25.00%)
top 2 operation type: Mean, cpu: 803us, accelerator: 33177597.16sec, total: 33177597.16sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33177597.16sec, total: 33177597.16sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 33177597.17sec, total: 33177597.17sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 33177597.16sec, total: 33177597.17sec
  train.py:357:image_losses, cpu: 256us, accelerator: 33177597.16sec, total: 33177597.16sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 33177597.16sec, total: 33177597.16sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.34ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.79ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.79ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 482us, total: 1.71ms
      train.py:343:hfe, cpu: 547us, accelerator: 714us, total: 1.26ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.61ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.23ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.38ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_139000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33118032.36sec, total: 33118032.36sec (25.00%)
top 2 operation type: Mean, cpu: 803us, accelerator: 33118032.35sec, total: 33118032.36sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33118032.35sec, total: 33118032.35sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33118032.36sec, total: 33118032.36sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 33118032.36sec, total: 33118032.36sec
  train.py:357:image_losses, cpu: 256us, accelerator: 33118032.35sec, total: 33118032.35sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 33118032.35sec, total: 33118032.35sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.79ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.79ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 480us, total: 1.72ms
      train.py:343:hfe, cpu: 547us, accelerator: 713us, total: 1.26ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.23ms, total: 7.42ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.38ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_139250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 33058681.04sec, total: 33058681.04sec (25.00%)
top 2 operation type: Mean, cpu: 802us, accelerator: 33058681.04sec, total: 33058681.04sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 33058681.04sec, total: 33058681.04sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 33058681.05sec, total: 33058681.05sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 33058681.05sec, total: 33058681.05sec
  train.py:357:image_losses, cpu: 256us, accelerator: 33058681.04sec, total: 33058681.04sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 33058681.04sec, total: 33058681.04sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.78ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.78ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 480us, total: 1.71ms
      train.py:343:hfe, cpu: 547us, accelerator: 713us, total: 1.26ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.22ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.22ms, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.38ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_139500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 32999542.08sec, total: 32999542.08sec (25.00%)
top 2 operation type: Mean, cpu: 799us, accelerator: 32999542.08sec, total: 32999542.08sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 32999542.08sec, total: 32999542.08sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 32999542.08sec, total: 32999542.09sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32999542.08sec, total: 32999542.09sec
  train.py:357:image_losses, cpu: 255us, accelerator: 32999542.08sec, total: 32999542.08sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 32999542.08sec, total: 32999542.08sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.35ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.78ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.78ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 479us, total: 1.71ms
      train.py:343:hfe, cpu: 546us, accelerator: 711us, total: 1.26ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.59ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.22ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 2.22ms, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_139750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 32940614.32sec, total: 32940614.33sec (25.00%)
top 2 operation type: Mean, cpu: 819us, accelerator: 32940614.32sec, total: 32940614.33sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 32940614.32sec, total: 32940614.32sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 32940614.33sec, total: 32940614.33sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32940614.33sec, total: 32940614.33sec
  train.py:357:image_losses, cpu: 255us, accelerator: 32940614.32sec, total: 32940614.32sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 32940614.32sec, total: 32940614.32sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.35ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.78ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.78ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 478us, total: 1.71ms
      train.py:343:hfe, cpu: 545us, accelerator: 716us, total: 1.26ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.64ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.26ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.26ms, total: 7.44ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.38ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_140000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 32881896.65sec, total: 32881896.65sec (25.00%)
top 2 operation type: Mean, cpu: 817us, accelerator: 32881896.65sec, total: 32881896.65sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 32881896.65sec, total: 32881896.65sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 32881896.66sec, total: 32881896.66sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32881896.65sec, total: 32881896.66sec
  train.py:357:image_losses, cpu: 255us, accelerator: 32881896.65sec, total: 32881896.65sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 32881896.65sec, total: 32881896.65sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.78ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.78ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 476us, total: 1.71ms
      train.py:343:hfe, cpu: 544us, accelerator: 713us, total: 1.26ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.63ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.26ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.26ms, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.37ms, total: 6.15ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_140250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 32823387.94sec, total: 32823387.94sec (25.00%)
top 2 operation type: Mean, cpu: 819us, accelerator: 32823387.94sec, total: 32823387.94sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32823387.94sec, total: 32823387.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 32823387.94sec, total: 32823387.95sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32823387.94sec, total: 32823387.95sec
  train.py:357:image_losses, cpu: 255us, accelerator: 32823387.94sec, total: 32823387.94sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 32823387.94sec, total: 32823387.94sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.78ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.78ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 476us, total: 1.71ms
      train.py:343:hfe, cpu: 544us, accelerator: 711us, total: 1.26ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.25ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 2.25ms, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.15ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_140500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.06ms, accelerator: 32765087.07sec, total: 32765087.07sec (25.00%)
top 2 operation type: Mean, cpu: 818us, accelerator: 32765087.07sec, total: 32765087.07sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 32765087.07sec, total: 32765087.07sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 32765087.08sec, total: 32765087.08sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 32765087.08sec, total: 32765087.08sec
  train.py:357:image_losses, cpu: 254us, accelerator: 32765087.07sec, total: 32765087.07sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 32765087.07sec, total: 32765087.07sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.78ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.78ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 475us, total: 1.71ms
      train.py:343:hfe, cpu: 544us, accelerator: 714us, total: 1.26ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.25ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.25ms, total: 7.66ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_140750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32706992.95sec, total: 32706992.95sec (25.00%)
top 2 operation type: Mean, cpu: 817us, accelerator: 32706992.95sec, total: 32706992.95sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32706992.95sec, total: 32706992.95sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 32706992.95sec, total: 32706992.96sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 32706992.95sec, total: 32706992.95sec
  train.py:357:image_losses, cpu: 254us, accelerator: 32706992.95sec, total: 32706992.95sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 32706992.95sec, total: 32706992.95sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.78ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.78ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 474us, total: 1.71ms
      train.py:343:hfe, cpu: 563us, accelerator: 713us, total: 1.28ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.25ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 2.25ms, total: 7.68ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.37ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_141000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32649104.46sec, total: 32649104.47sec (25.00%)
top 2 operation type: Mean, cpu: 815us, accelerator: 32649104.46sec, total: 32649104.46sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32649104.46sec, total: 32649104.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32649104.47sec, total: 32649104.47sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 32649104.47sec, total: 32649104.47sec
  train.py:357:image_losses, cpu: 254us, accelerator: 32649104.46sec, total: 32649104.46sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 32649104.46sec, total: 32649104.46sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.78ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.78ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 474us, total: 1.70ms
      train.py:343:hfe, cpu: 562us, accelerator: 713us, total: 1.28ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.24ms, total: 7.67ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.37ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_141250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32591420.53sec, total: 32591420.54sec (25.00%)
top 2 operation type: Mean, cpu: 815us, accelerator: 32591420.53sec, total: 32591420.53sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32591420.53sec, total: 32591420.53sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32591420.54sec, total: 32591420.54sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 32591420.54sec, total: 32591420.54sec
  train.py:357:image_losses, cpu: 254us, accelerator: 32591420.53sec, total: 32591420.53sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 32591420.53sec, total: 32591420.53sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.78ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.78ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 473us, total: 1.70ms
      train.py:343:hfe, cpu: 561us, accelerator: 713us, total: 1.28ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.61ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.24ms, total: 7.66ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.37ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_141500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32533940.07sec, total: 32533940.08sec (25.00%)
top 2 operation type: Mean, cpu: 815us, accelerator: 32533940.07sec, total: 32533940.07sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32533940.07sec, total: 32533940.07sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32533940.08sec, total: 32533940.08sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 32533940.08sec, total: 32533940.08sec
  train.py:357:image_losses, cpu: 255us, accelerator: 32533940.07sec, total: 32533940.07sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 32533940.07sec, total: 32533940.07sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.77ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.77ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 473us, total: 1.70ms
      train.py:343:hfe, cpu: 561us, accelerator: 711us, total: 1.28ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.24ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.38ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_141750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32476662.01sec, total: 32476662.01sec (25.00%)
top 2 operation type: Mean, cpu: 813us, accelerator: 32476662.01sec, total: 32476662.01sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32476662.01sec, total: 32476662.01sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32476662.01sec, total: 32476662.02sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32476662.01sec, total: 32476662.02sec
  train.py:357:image_losses, cpu: 255us, accelerator: 32476662.01sec, total: 32476662.01sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 32476662.01sec, total: 32476662.01sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.77ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.77ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 473us, total: 1.70ms
      train.py:343:hfe, cpu: 560us, accelerator: 711us, total: 1.27ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.61ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.23ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.38ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_142000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32419585.28sec, total: 32419585.28sec (25.00%)
top 2 operation type: Mean, cpu: 813us, accelerator: 32419585.28sec, total: 32419585.28sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32419585.27sec, total: 32419585.27sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32419585.28sec, total: 32419585.28sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32419585.28sec, total: 32419585.28sec
  train.py:357:image_losses, cpu: 255us, accelerator: 32419585.27sec, total: 32419585.28sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 32419585.27sec, total: 32419585.28sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.77ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.77ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 473us, total: 1.70ms
      train.py:343:hfe, cpu: 560us, accelerator: 709us, total: 1.27ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.23ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_142250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32362708.81sec, total: 32362708.81sec (25.00%)
top 2 operation type: Mean, cpu: 813us, accelerator: 32362708.81sec, total: 32362708.81sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32362708.81sec, total: 32362708.81sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32362708.81sec, total: 32362708.82sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32362708.81sec, total: 32362708.82sec
  train.py:357:image_losses, cpu: 256us, accelerator: 32362708.81sec, total: 32362708.81sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 32362708.81sec, total: 32362708.81sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.77ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.77ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 470us, total: 1.70ms
      train.py:343:hfe, cpu: 560us, accelerator: 709us, total: 1.27ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.23ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_142500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32306031.56sec, total: 32306031.56sec (25.00%)
top 2 operation type: Mean, cpu: 813us, accelerator: 32306031.56sec, total: 32306031.56sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32306031.56sec, total: 32306031.56sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32306031.57sec, total: 32306031.57sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32306031.56sec, total: 32306031.57sec
  train.py:357:image_losses, cpu: 256us, accelerator: 32306031.56sec, total: 32306031.56sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 32306031.56sec, total: 32306031.56sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.76ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.76ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 470us, total: 1.69ms
      train.py:343:hfe, cpu: 560us, accelerator: 707us, total: 1.27ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.59ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.22ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.22ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_142750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32249552.49sec, total: 32249552.49sec (25.00%)
top 2 operation type: Mean, cpu: 813us, accelerator: 32249552.49sec, total: 32249552.49sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32249552.48sec, total: 32249552.48sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32249552.49sec, total: 32249552.49sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32249552.49sec, total: 32249552.49sec
  train.py:357:image_losses, cpu: 256us, accelerator: 32249552.48sec, total: 32249552.49sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 32249552.48sec, total: 32249552.49sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.76ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.76ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 470us, total: 1.69ms
      train.py:343:hfe, cpu: 559us, accelerator: 705us, total: 1.27ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.25ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.25ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_143000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32193270.54sec, total: 32193270.55sec (25.00%)
top 2 operation type: Mean, cpu: 813us, accelerator: 32193270.54sec, total: 32193270.54sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32193270.54sec, total: 32193270.54sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32193270.55sec, total: 32193270.55sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 32193270.55sec, total: 32193270.55sec
  train.py:357:image_losses, cpu: 256us, accelerator: 32193270.54sec, total: 32193270.54sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 32193270.54sec, total: 32193270.54sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.77ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.77ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 472us, total: 1.69ms
      train.py:343:hfe, cpu: 559us, accelerator: 711us, total: 1.27ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.63ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.25ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 2.25ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.37ms, total: 6.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_143250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32137184.71sec, total: 32137184.71sec (25.00%)
top 2 operation type: Mean, cpu: 813us, accelerator: 32137184.71sec, total: 32137184.71sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32137184.71sec, total: 32137184.71sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32137184.71sec, total: 32137184.72sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 32137184.71sec, total: 32137184.72sec
  train.py:357:image_losses, cpu: 256us, accelerator: 32137184.71sec, total: 32137184.71sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 32137184.71sec, total: 32137184.71sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.77ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.77ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 470us, total: 1.69ms
      train.py:343:hfe, cpu: 558us, accelerator: 709us, total: 1.27ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.63ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.26ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 2.26ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.37ms, total: 6.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_143500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32081293.95sec, total: 32081293.95sec (25.00%)
top 2 operation type: Mean, cpu: 811us, accelerator: 32081293.95sec, total: 32081293.95sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32081293.95sec, total: 32081293.95sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32081293.96sec, total: 32081293.96sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32081293.95sec, total: 32081293.96sec
  train.py:357:image_losses, cpu: 255us, accelerator: 32081293.95sec, total: 32081293.95sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 32081293.95sec, total: 32081293.95sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.96ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.96ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 470us, total: 1.70ms
      train.py:343:hfe, cpu: 557us, accelerator: 708us, total: 1.27ms
      train.py:344:hfe, cpu: 315us, accelerator: 782us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.25ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 2.25ms, total: 7.62ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.37ms, total: 6.12ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2116.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_143750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.05ms, accelerator: 32025597.26sec, total: 32025597.26sec (25.00%)
top 2 operation type: Mean, cpu: 813us, accelerator: 32025597.26sec, total: 32025597.26sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 32025597.26sec, total: 32025597.26sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 32025597.26sec, total: 32025597.27sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 32025597.26sec, total: 32025597.27sec
  train.py:357:image_losses, cpu: 256us, accelerator: 32025597.26sec, total: 32025597.26sec
    train.py:322:loss_fn, cpu: 235us, accelerator: 32025597.26sec, total: 32025597.26sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.96ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.96ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 470us, total: 1.70ms
      train.py:343:hfe, cpu: 556us, accelerator: 707us, total: 1.27ms
      train.py:344:hfe, cpu: 315us, accelerator: 781us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.61ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.25ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 2.25ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.36ms, total: 6.12ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_144000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31970093.63sec, total: 31970093.63sec (25.00%)
top 2 operation type: Mean, cpu: 810us, accelerator: 31970093.63sec, total: 31970093.63sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 31970093.62sec, total: 31970093.62sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31970093.63sec, total: 31970093.63sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 31970093.63sec, total: 31970093.63sec
  train.py:357:image_losses, cpu: 254us, accelerator: 31970093.62sec, total: 31970093.62sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 31970093.62sec, total: 31970093.62sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.95ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.95ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 468us, total: 1.70ms
      train.py:343:hfe, cpu: 559us, accelerator: 705us, total: 1.27ms
      train.py:344:hfe, cpu: 315us, accelerator: 778us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.61ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 2.24ms, total: 7.60ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.36ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_144250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31914782.04sec, total: 31914782.05sec (25.00%)
top 2 operation type: Mean, cpu: 809us, accelerator: 31914782.04sec, total: 31914782.05sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31914782.04sec, total: 31914782.04sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31914782.05sec, total: 31914782.05sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 31914782.05sec, total: 31914782.05sec
  train.py:357:image_losses, cpu: 253us, accelerator: 31914782.04sec, total: 31914782.04sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 31914782.04sec, total: 31914782.04sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.95ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.95ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 467us, total: 1.69ms
      train.py:343:hfe, cpu: 558us, accelerator: 704us, total: 1.27ms
      train.py:344:hfe, cpu: 314us, accelerator: 777us, total: 1.09ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 2.24ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.36ms, total: 6.12ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_144500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31859661.52sec, total: 31859661.53sec (25.00%)
top 2 operation type: Mean, cpu: 809us, accelerator: 31859661.52sec, total: 31859661.52sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31859661.52sec, total: 31859661.52sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31859661.53sec, total: 31859661.53sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 31859661.53sec, total: 31859661.53sec
  train.py:357:image_losses, cpu: 255us, accelerator: 31859661.52sec, total: 31859661.52sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 31859661.52sec, total: 31859661.52sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.96ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.96ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 466us, total: 1.69ms
      train.py:343:hfe, cpu: 559us, accelerator: 711us, total: 1.27ms
      train.py:344:hfe, cpu: 314us, accelerator: 783us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 2.24ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.36ms, total: 6.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_144750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31804731.07sec, total: 31804731.07sec (25.00%)
top 2 operation type: Mean, cpu: 816us, accelerator: 31804731.07sec, total: 31804731.07sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31804731.07sec, total: 31804731.07sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31804731.08sec, total: 31804731.08sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 31804731.07sec, total: 31804731.08sec
  train.py:357:image_losses, cpu: 255us, accelerator: 31804731.07sec, total: 31804731.07sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 31804731.07sec, total: 31804731.07sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.96ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.96ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 466us, total: 1.69ms
      train.py:343:hfe, cpu: 560us, accelerator: 709us, total: 1.27ms
      train.py:344:hfe, cpu: 315us, accelerator: 782us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.59ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.24ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 2.24ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.36ms, total: 6.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_145000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31749989.71sec, total: 31749989.71sec (25.00%)
top 2 operation type: Mean, cpu: 815us, accelerator: 31749989.71sec, total: 31749989.71sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31749989.71sec, total: 31749989.71sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31749989.71sec, total: 31749989.72sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 31749989.71sec, total: 31749989.72sec
  train.py:357:image_losses, cpu: 255us, accelerator: 31749989.71sec, total: 31749989.71sec
    train.py:322:loss_fn, cpu: 234us, accelerator: 31749989.71sec, total: 31749989.71sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.34ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.97ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.97ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 466us, total: 1.69ms
      train.py:343:hfe, cpu: 559us, accelerator: 723us, total: 1.28ms
      train.py:344:hfe, cpu: 314us, accelerator: 781us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.61ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.23ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 2.23ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.38ms, total: 6.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_145250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31695436.46sec, total: 31695436.47sec (25.00%)
top 2 operation type: Mean, cpu: 814us, accelerator: 31695436.46sec, total: 31695436.46sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31695436.46sec, total: 31695436.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31695436.47sec, total: 31695436.47sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 31695436.47sec, total: 31695436.47sec
  train.py:357:image_losses, cpu: 254us, accelerator: 31695436.46sec, total: 31695436.46sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 31695436.46sec, total: 31695436.46sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.39ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.39ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.37ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.97ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.97ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 466us, total: 1.68ms
      train.py:343:hfe, cpu: 557us, accelerator: 721us, total: 1.28ms
      train.py:344:hfe, cpu: 314us, accelerator: 780us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.60ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 2.23ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.37ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_145500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31641070.36sec, total: 31641070.37sec (25.00%)
top 2 operation type: Mean, cpu: 833us, accelerator: 31641070.36sec, total: 31641070.36sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31641070.36sec, total: 31641070.36sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 31641070.37sec, total: 31641070.37sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 31641070.37sec, total: 31641070.37sec
  train.py:357:image_losses, cpu: 254us, accelerator: 31641070.36sec, total: 31641070.36sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 31641070.36sec, total: 31641070.36sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.39ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.39ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.37ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.96ms, total: 4.11ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.96ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 465us, total: 1.68ms
      train.py:343:hfe, cpu: 558us, accelerator: 720us, total: 1.28ms
      train.py:344:hfe, cpu: 333us, accelerator: 778us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.59ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.22ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 2.22ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.37ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_145750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31586890.45sec, total: 31586890.45sec (25.00%)
top 2 operation type: Mean, cpu: 833us, accelerator: 31586890.45sec, total: 31586890.45sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31586890.45sec, total: 31586890.45sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 31586890.45sec, total: 31586890.46sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 31586890.45sec, total: 31586890.46sec
  train.py:357:image_losses, cpu: 254us, accelerator: 31586890.45sec, total: 31586890.45sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 31586890.45sec, total: 31586890.45sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.39ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.39ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.37ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.96ms, total: 4.11ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.96ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 464us, total: 1.68ms
      train.py:343:hfe, cpu: 557us, accelerator: 721us, total: 1.28ms
      train.py:344:hfe, cpu: 333us, accelerator: 778us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.63ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.27ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 2.27ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.37ms, total: 6.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_146000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31532895.76sec, total: 31532895.77sec (25.00%)
top 2 operation type: Mean, cpu: 833us, accelerator: 31532895.76sec, total: 31532895.76sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31532895.76sec, total: 31532895.76sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31532895.77sec, total: 31532895.77sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 31532895.77sec, total: 31532895.77sec
  train.py:357:image_losses, cpu: 254us, accelerator: 31532895.76sec, total: 31532895.76sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 31532895.76sec, total: 31532895.76sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.39ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.39ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.37ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.96ms, total: 4.11ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.96ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 464us, total: 1.68ms
      train.py:343:hfe, cpu: 560us, accelerator: 720us, total: 1.29ms
      train.py:344:hfe, cpu: 333us, accelerator: 778us, total: 1.11ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.63ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.26ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 2.26ms, total: 7.60ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.37ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_146250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31479085.36sec, total: 31479085.36sec (25.00%)
top 2 operation type: Mean, cpu: 832us, accelerator: 31479085.36sec, total: 31479085.36sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31479085.36sec, total: 31479085.36sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 31479085.37sec, total: 31479085.37sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 31479085.36sec, total: 31479085.37sec
  train.py:357:image_losses, cpu: 254us, accelerator: 31479085.36sec, total: 31479085.36sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 31479085.36sec, total: 31479085.36sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.39ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.39ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.37ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.96ms, total: 4.12ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.96ms, total: 4.09ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 463us, total: 1.68ms
      train.py:343:hfe, cpu: 571us, accelerator: 720us, total: 1.30ms
      train.py:344:hfe, cpu: 333us, accelerator: 775us, total: 1.11ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.63ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.26ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 2.26ms, total: 7.60ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.37ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_146500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31425458.30sec, total: 31425458.30sec (25.00%)
top 2 operation type: Mean, cpu: 830us, accelerator: 31425458.30sec, total: 31425458.30sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31425458.30sec, total: 31425458.30sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 31425458.30sec, total: 31425458.31sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 31425458.30sec, total: 31425458.31sec
  train.py:357:image_losses, cpu: 254us, accelerator: 31425458.30sec, total: 31425458.30sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 31425458.30sec, total: 31425458.30sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.39ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.39ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.37ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.96ms, total: 4.12ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.96ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 462us, total: 1.68ms
      train.py:343:hfe, cpu: 571us, accelerator: 719us, total: 1.30ms
      train.py:344:hfe, cpu: 333us, accelerator: 774us, total: 1.11ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.62ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.25ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 2.25ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.36ms, total: 6.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_146750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31372013.64sec, total: 31372013.64sec (25.00%)
top 2 operation type: Mean, cpu: 830us, accelerator: 31372013.64sec, total: 31372013.64sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31372013.64sec, total: 31372013.64sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31372013.65sec, total: 31372013.65sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 31372013.65sec, total: 31372013.65sec
  train.py:357:image_losses, cpu: 254us, accelerator: 31372013.64sec, total: 31372013.64sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 31372013.64sec, total: 31372013.64sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.38ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.38ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.37ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.95ms, total: 4.11ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.95ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 461us, total: 1.67ms
      train.py:343:hfe, cpu: 571us, accelerator: 719us, total: 1.29ms
      train.py:344:hfe, cpu: 333us, accelerator: 773us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.61ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.25ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.30ms, accelerator: 2.25ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.36ms, total: 6.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_147000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31318750.46sec, total: 31318750.46sec (25.00%)
top 2 operation type: Mean, cpu: 830us, accelerator: 31318750.46sec, total: 31318750.46sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 66us, accelerator: 31318750.46sec, total: 31318750.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31318750.47sec, total: 31318750.47sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 31318750.46sec, total: 31318750.47sec
  train.py:357:image_losses, cpu: 254us, accelerator: 31318750.46sec, total: 31318750.46sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 31318750.46sec, total: 31318750.46sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.38ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.38ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.95ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.95ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 460us, total: 1.67ms
      train.py:343:hfe, cpu: 571us, accelerator: 718us, total: 1.29ms
      train.py:344:hfe, cpu: 333us, accelerator: 772us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.60ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 2.24ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.36ms, total: 6.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_147250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31265667.83sec, total: 31265667.84sec (25.00%)
top 2 operation type: Mean, cpu: 829us, accelerator: 31265667.83sec, total: 31265667.83sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 31265667.83sec, total: 31265667.83sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31265667.84sec, total: 31265667.84sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 31265667.84sec, total: 31265667.84sec
  train.py:357:image_losses, cpu: 253us, accelerator: 31265667.83sec, total: 31265667.83sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 31265667.83sec, total: 31265667.83sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.38ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.38ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.95ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.95ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 460us, total: 1.67ms
      train.py:343:hfe, cpu: 570us, accelerator: 717us, total: 1.29ms
      train.py:344:hfe, cpu: 333us, accelerator: 772us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.60ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 2.24ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.36ms, total: 6.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_147500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31212764.84sec, total: 31212764.84sec (25.00%)
top 2 operation type: Mean, cpu: 830us, accelerator: 31212764.84sec, total: 31212764.84sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 31212764.84sec, total: 31212764.84sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31212764.85sec, total: 31212764.85sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 31212764.85sec, total: 31212764.85sec
  train.py:357:image_losses, cpu: 253us, accelerator: 31212764.84sec, total: 31212764.84sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 31212764.84sec, total: 31212764.84sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.38ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.38ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.95ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.95ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 460us, total: 1.67ms
      train.py:343:hfe, cpu: 570us, accelerator: 715us, total: 1.29ms
      train.py:344:hfe, cpu: 334us, accelerator: 771us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.59ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.24ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 2.24ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.35ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_147750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31160040.58sec, total: 31160040.58sec (25.00%)
top 2 operation type: Mean, cpu: 830us, accelerator: 31160040.58sec, total: 31160040.58sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 31160040.58sec, total: 31160040.58sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31160040.58sec, total: 31160040.59sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 31160040.58sec, total: 31160040.59sec
  train.py:357:image_losses, cpu: 254us, accelerator: 31160040.58sec, total: 31160040.58sec
    train.py:322:loss_fn, cpu: 233us, accelerator: 31160040.58sec, total: 31160040.58sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.38ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.38ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 458us, total: 1.66ms
      train.py:343:hfe, cpu: 569us, accelerator: 715us, total: 1.29ms
      train.py:344:hfe, cpu: 334us, accelerator: 770us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.59ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.28ms, accelerator: 2.24ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.35ms, total: 6.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_148000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31107494.13sec, total: 31107494.14sec (25.00%)
top 2 operation type: Mean, cpu: 827us, accelerator: 31107494.13sec, total: 31107494.14sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 31107494.13sec, total: 31107494.13sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31107494.14sec, total: 31107494.14sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 31107494.14sec, total: 31107494.14sec
  train.py:357:image_losses, cpu: 253us, accelerator: 31107494.13sec, total: 31107494.13sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 31107494.13sec, total: 31107494.13sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.37ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.37ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 458us, total: 1.66ms
      train.py:343:hfe, cpu: 568us, accelerator: 716us, total: 1.29ms
      train.py:344:hfe, cpu: 334us, accelerator: 767us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.60ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.28ms, accelerator: 2.24ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.36ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_148250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31055124.62sec, total: 31055124.62sec (25.00%)
top 2 operation type: Mean, cpu: 828us, accelerator: 31055124.62sec, total: 31055124.62sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 31055124.61sec, total: 31055124.61sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31055124.62sec, total: 31055124.62sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 31055124.62sec, total: 31055124.62sec
  train.py:357:image_losses, cpu: 253us, accelerator: 31055124.62sec, total: 31055124.62sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 31055124.62sec, total: 31055124.62sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.37ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.37ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.35ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.94ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 458us, total: 1.66ms
      train.py:343:hfe, cpu: 576us, accelerator: 714us, total: 1.29ms
      train.py:344:hfe, cpu: 333us, accelerator: 764us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.60ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.26ms, accelerator: 2.24ms, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.36ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_148500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 31002931.13sec, total: 31002931.13sec (25.00%)
top 2 operation type: Mean, cpu: 828us, accelerator: 31002931.13sec, total: 31002931.13sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 31002931.13sec, total: 31002931.13sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 31002931.13sec, total: 31002931.14sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 31002931.13sec, total: 31002931.14sec
  train.py:357:image_losses, cpu: 253us, accelerator: 31002931.13sec, total: 31002931.13sec
    train.py:322:loss_fn, cpu: 232us, accelerator: 31002931.13sec, total: 31002931.13sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.37ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.37ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.95ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.95ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 464us, total: 1.67ms
      train.py:343:hfe, cpu: 576us, accelerator: 713us, total: 1.30ms
      train.py:344:hfe, cpu: 332us, accelerator: 770us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.59ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.26ms, accelerator: 2.24ms, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.35ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_148750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30950912.79sec, total: 30950912.79sec (25.00%)
top 2 operation type: Mean, cpu: 854us, accelerator: 30950912.79sec, total: 30950912.79sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 30950912.79sec, total: 30950912.79sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30950912.79sec, total: 30950912.80sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 30950912.79sec, total: 30950912.80sec
  train.py:357:image_losses, cpu: 278us, accelerator: 30950912.79sec, total: 30950912.79sec
    train.py:322:loss_fn, cpu: 257us, accelerator: 30950912.79sec, total: 30950912.79sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.37ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.37ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.36ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.95ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.95ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 464us, total: 1.67ms
      train.py:343:hfe, cpu: 575us, accelerator: 713us, total: 1.29ms
      train.py:344:hfe, cpu: 334us, accelerator: 769us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.58ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.26ms, accelerator: 2.23ms, total: 7.52ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.35ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_149000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30899068.71sec, total: 30899068.72sec (25.00%)
top 2 operation type: Mean, cpu: 854us, accelerator: 30899068.71sec, total: 30899068.71sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 30899068.71sec, total: 30899068.71sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30899068.72sec, total: 30899068.72sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 30899068.72sec, total: 30899068.72sec
  train.py:357:image_losses, cpu: 278us, accelerator: 30899068.71sec, total: 30899068.71sec
    train.py:322:loss_fn, cpu: 257us, accelerator: 30899068.71sec, total: 30899068.71sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.37ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.37ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.35ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 463us, total: 1.66ms
      train.py:343:hfe, cpu: 574us, accelerator: 712us, total: 1.29ms
      train.py:344:hfe, cpu: 335us, accelerator: 769us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.57ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.23ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 2.23ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.34ms, total: 6.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_149250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30847398.03sec, total: 30847398.03sec (25.00%)
top 2 operation type: Mean, cpu: 852us, accelerator: 30847398.03sec, total: 30847398.03sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 30847398.03sec, total: 30847398.03sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30847398.03sec, total: 30847398.04sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 30847398.03sec, total: 30847398.04sec
  train.py:357:image_losses, cpu: 277us, accelerator: 30847398.03sec, total: 30847398.03sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 30847398.03sec, total: 30847398.03sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.37ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.37ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.35ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 462us, total: 1.66ms
      train.py:343:hfe, cpu: 574us, accelerator: 712us, total: 1.29ms
      train.py:344:hfe, cpu: 334us, accelerator: 768us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.57ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.26ms, accelerator: 2.23ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.34ms, total: 6.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_149500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30795899.87sec, total: 30795899.87sec (25.00%)
top 2 operation type: Mean, cpu: 852us, accelerator: 30795899.87sec, total: 30795899.87sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 30795899.87sec, total: 30795899.87sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30795899.87sec, total: 30795899.88sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 30795899.87sec, total: 30795899.88sec
  train.py:357:image_losses, cpu: 277us, accelerator: 30795899.87sec, total: 30795899.87sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 30795899.87sec, total: 30795899.87sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.37ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 462us, total: 1.66ms
      train.py:343:hfe, cpu: 574us, accelerator: 712us, total: 1.29ms
      train.py:344:hfe, cpu: 334us, accelerator: 768us, total: 1.10ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.57ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.23ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.34ms, total: 6.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_149750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30744573.37sec, total: 30744573.37sec (25.00%)
top 2 operation type: Mean, cpu: 852us, accelerator: 30744573.37sec, total: 30744573.37sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 30744573.37sec, total: 30744573.37sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30744573.37sec, total: 30744573.38sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 30744573.37sec, total: 30744573.38sec
  train.py:357:image_losses, cpu: 277us, accelerator: 30744573.37sec, total: 30744573.37sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 30744573.37sec, total: 30744573.37sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.37ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.95ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.95ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 461us, total: 1.66ms
      train.py:343:hfe, cpu: 574us, accelerator: 717us, total: 1.30ms
      train.py:344:hfe, cpu: 334us, accelerator: 772us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.59ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.25ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 2.25ms, total: 7.68ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.34ms, total: 6.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_150000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30693417.67sec, total: 30693417.68sec (25.00%)
top 2 operation type: Mean, cpu: 851us, accelerator: 30693417.67sec, total: 30693417.67sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 30693417.67sec, total: 30693417.67sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 30693417.68sec, total: 30693417.68sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 30693417.68sec, total: 30693417.68sec
  train.py:357:image_losses, cpu: 277us, accelerator: 30693417.67sec, total: 30693417.67sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 30693417.67sec, total: 30693417.67sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.37ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 459us, total: 1.65ms
      train.py:343:hfe, cpu: 574us, accelerator: 715us, total: 1.29ms
      train.py:344:hfe, cpu: 334us, accelerator: 769us, total: 1.11ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.58ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.25ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.25ms, total: 7.67ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.34ms, total: 6.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_150250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30642431.93sec, total: 30642431.93sec (25.00%)
top 2 operation type: Mean, cpu: 849us, accelerator: 30642431.93sec, total: 30642431.93sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 71us, accelerator: 30642431.93sec, total: 30642431.93sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 30642431.93sec, total: 30642431.94sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 30642431.93sec, total: 30642431.94sec
  train.py:357:image_losses, cpu: 277us, accelerator: 30642431.93sec, total: 30642431.93sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 30642431.93sec, total: 30642431.93sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.38ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.38ms, total: 4.34ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.36ms, total: 4.27ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.94ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 459us, total: 1.65ms
      train.py:343:hfe, cpu: 574us, accelerator: 714us, total: 1.29ms
      train.py:344:hfe, cpu: 333us, accelerator: 768us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.58ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.24ms, total: 7.67ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.33ms, total: 6.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_150500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30591615.29sec, total: 30591615.30sec (25.00%)
top 2 operation type: Mean, cpu: 855us, accelerator: 30591615.29sec, total: 30591615.29sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30591615.29sec, total: 30591615.29sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 30591615.30sec, total: 30591615.30sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 30591615.30sec, total: 30591615.30sec
  train.py:357:image_losses, cpu: 283us, accelerator: 30591615.29sec, total: 30591615.29sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 30591615.29sec, total: 30591615.29sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.38ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.38ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.36ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.94ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.94ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 458us, total: 1.65ms
      train.py:343:hfe, cpu: 572us, accelerator: 714us, total: 1.29ms
      train.py:344:hfe, cpu: 333us, accelerator: 766us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.58ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.24ms, total: 7.66ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.33ms, total: 6.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_150750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30540966.92sec, total: 30540966.93sec (25.00%)
top 2 operation type: Mean, cpu: 855us, accelerator: 30540966.92sec, total: 30540966.92sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30540966.92sec, total: 30540966.92sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 30540966.93sec, total: 30540966.93sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 30540966.93sec, total: 30540966.93sec
  train.py:357:image_losses, cpu: 282us, accelerator: 30540966.92sec, total: 30540966.92sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 30540966.92sec, total: 30540966.92sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.38ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.38ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.36ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.94ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.94ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 458us, total: 1.65ms
      train.py:343:hfe, cpu: 571us, accelerator: 714us, total: 1.29ms
      train.py:344:hfe, cpu: 332us, accelerator: 766us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.57ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.24ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.33ms, total: 6.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_151000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30490485.99sec, total: 30490485.99sec (25.00%)
top 2 operation type: Mean, cpu: 855us, accelerator: 30490485.99sec, total: 30490485.99sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30490485.99sec, total: 30490485.99sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 30490485.99sec, total: 30490486.00sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 30490485.99sec, total: 30490485.99sec
  train.py:357:image_losses, cpu: 282us, accelerator: 30490485.99sec, total: 30490485.99sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 30490485.99sec, total: 30490485.99sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.38ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.38ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.36ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.93ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.93ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 457us, total: 1.66ms
      train.py:343:hfe, cpu: 571us, accelerator: 712us, total: 1.28ms
      train.py:344:hfe, cpu: 332us, accelerator: 764us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.57ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.24ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.24ms, total: 7.66ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.33ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_151250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30440171.65sec, total: 30440171.66sec (25.00%)
top 2 operation type: Mean, cpu: 854us, accelerator: 30440171.65sec, total: 30440171.65sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30440171.65sec, total: 30440171.65sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 30440171.66sec, total: 30440171.66sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 30440171.66sec, total: 30440171.66sec
  train.py:357:image_losses, cpu: 283us, accelerator: 30440171.65sec, total: 30440171.65sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 30440171.65sec, total: 30440171.65sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.37ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.36ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.93ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.93ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 456us, total: 1.67ms
      train.py:343:hfe, cpu: 571us, accelerator: 711us, total: 1.28ms
      train.py:344:hfe, cpu: 332us, accelerator: 764us, total: 1.10ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.56ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.23ms, total: 7.66ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.33ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_151500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30390023.10sec, total: 30390023.10sec (25.00%)
top 2 operation type: Mean, cpu: 855us, accelerator: 30390023.10sec, total: 30390023.10sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30390023.10sec, total: 30390023.10sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30390023.10sec, total: 30390023.11sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 30390023.10sec, total: 30390023.11sec
  train.py:357:image_losses, cpu: 283us, accelerator: 30390023.10sec, total: 30390023.10sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 30390023.10sec, total: 30390023.10sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.37ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.36ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.93ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.93ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 456us, total: 1.67ms
      train.py:343:hfe, cpu: 571us, accelerator: 710us, total: 1.28ms
      train.py:344:hfe, cpu: 333us, accelerator: 763us, total: 1.10ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.56ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.23ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.23ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.33ms, total: 6.05ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_151750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30340039.51sec, total: 30340039.51sec (25.00%)
top 2 operation type: Mean, cpu: 855us, accelerator: 30340039.51sec, total: 30340039.51sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30340039.51sec, total: 30340039.51sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30340039.51sec, total: 30340039.52sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 30340039.51sec, total: 30340039.52sec
  train.py:357:image_losses, cpu: 283us, accelerator: 30340039.51sec, total: 30340039.51sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 30340039.51sec, total: 30340039.51sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.37ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.92ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.92ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 454us, total: 1.67ms
      train.py:343:hfe, cpu: 571us, accelerator: 709us, total: 1.28ms
      train.py:344:hfe, cpu: 333us, accelerator: 761us, total: 1.10ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.54ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.22ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.22ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.32ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_152000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30290220.07sec, total: 30290220.07sec (25.00%)
top 2 operation type: Mean, cpu: 854us, accelerator: 30290220.07sec, total: 30290220.07sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30290220.07sec, total: 30290220.07sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30290220.07sec, total: 30290220.08sec
train.py:442:<module>, cpu: 5.63ms, accelerator: 30290220.07sec, total: 30290220.08sec
  train.py:357:image_losses, cpu: 283us, accelerator: 30290220.07sec, total: 30290220.07sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 30290220.07sec, total: 30290220.07sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.37ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.92ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.92ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 454us, total: 1.68ms
      train.py:343:hfe, cpu: 571us, accelerator: 708us, total: 1.28ms
      train.py:344:hfe, cpu: 333us, accelerator: 760us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.54ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.22ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.22ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.32ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_152250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30240563.97sec, total: 30240563.97sec (25.00%)
top 2 operation type: Mean, cpu: 851us, accelerator: 30240563.97sec, total: 30240563.97sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30240563.97sec, total: 30240563.97sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30240563.97sec, total: 30240563.98sec
train.py:442:<module>, cpu: 5.63ms, accelerator: 30240563.97sec, total: 30240563.98sec
  train.py:357:image_losses, cpu: 282us, accelerator: 30240563.97sec, total: 30240563.97sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 30240563.97sec, total: 30240563.97sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.37ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.37ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.35ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.92ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.92ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 454us, total: 1.68ms
      train.py:343:hfe, cpu: 570us, accelerator: 706us, total: 1.28ms
      train.py:344:hfe, cpu: 333us, accelerator: 758us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.54ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.22ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.22ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.32ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_152500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30191070.41sec, total: 30191070.41sec (25.00%)
top 2 operation type: Mean, cpu: 851us, accelerator: 30191070.41sec, total: 30191070.41sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30191070.41sec, total: 30191070.41sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30191070.42sec, total: 30191070.42sec
train.py:442:<module>, cpu: 5.64ms, accelerator: 30191070.41sec, total: 30191070.42sec
  train.py:357:image_losses, cpu: 282us, accelerator: 30191070.41sec, total: 30191070.41sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 30191070.41sec, total: 30191070.41sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.37ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.37ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.92ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.92ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 453us, total: 1.69ms
      train.py:343:hfe, cpu: 569us, accelerator: 706us, total: 1.28ms
      train.py:344:hfe, cpu: 333us, accelerator: 758us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.53ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.21ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.21ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.32ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_152750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30141738.60sec, total: 30141738.60sec (25.00%)
top 2 operation type: Mean, cpu: 850us, accelerator: 30141738.60sec, total: 30141738.60sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30141738.60sec, total: 30141738.60sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30141738.60sec, total: 30141738.61sec
train.py:442:<module>, cpu: 5.64ms, accelerator: 30141738.60sec, total: 30141738.61sec
  train.py:357:image_losses, cpu: 282us, accelerator: 30141738.60sec, total: 30141738.60sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 30141738.60sec, total: 30141738.60sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.37ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.37ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.91ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.91ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 452us, total: 1.69ms
      train.py:343:hfe, cpu: 567us, accelerator: 705us, total: 1.28ms
      train.py:344:hfe, cpu: 330us, accelerator: 757us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.52ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.21ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.21ms, total: 7.62ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.31ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_153000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30092567.74sec, total: 30092567.74sec (25.00%)
top 2 operation type: Mean, cpu: 849us, accelerator: 30092567.74sec, total: 30092567.74sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30092567.73sec, total: 30092567.73sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30092567.74sec, total: 30092567.74sec
train.py:442:<module>, cpu: 5.63ms, accelerator: 30092567.74sec, total: 30092567.74sec
  train.py:357:image_losses, cpu: 282us, accelerator: 30092567.73sec, total: 30092567.74sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 30092567.73sec, total: 30092567.74sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.35ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.91ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.91ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 452us, total: 1.69ms
      train.py:343:hfe, cpu: 567us, accelerator: 702us, total: 1.27ms
      train.py:344:hfe, cpu: 330us, accelerator: 756us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.52ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.21ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.21ms, total: 7.62ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.31ms, total: 6.03ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_153250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 30043557.04sec, total: 30043557.04sec (25.00%)
top 2 operation type: Mean, cpu: 849us, accelerator: 30043557.04sec, total: 30043557.04sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 30043557.04sec, total: 30043557.04sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 30043557.04sec, total: 30043557.05sec
train.py:442:<module>, cpu: 5.63ms, accelerator: 30043557.04sec, total: 30043557.05sec
  train.py:357:image_losses, cpu: 282us, accelerator: 30043557.04sec, total: 30043557.04sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 30043557.04sec, total: 30043557.04sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.35ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.93ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.93ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 452us, total: 1.68ms
      train.py:343:hfe, cpu: 565us, accelerator: 702us, total: 1.27ms
      train.py:344:hfe, cpu: 330us, accelerator: 771us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.52ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.21ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.21ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.31ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_153500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 29994705.73sec, total: 29994705.73sec (25.00%)
top 2 operation type: Mean, cpu: 849us, accelerator: 29994705.73sec, total: 29994705.73sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 29994705.73sec, total: 29994705.73sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29994705.73sec, total: 29994705.74sec
train.py:442:<module>, cpu: 5.63ms, accelerator: 29994705.73sec, total: 29994705.74sec
  train.py:357:image_losses, cpu: 282us, accelerator: 29994705.73sec, total: 29994705.73sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 29994705.73sec, total: 29994705.73sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.92ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.92ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 452us, total: 1.68ms
      train.py:343:hfe, cpu: 566us, accelerator: 700us, total: 1.27ms
      train.py:344:hfe, cpu: 330us, accelerator: 769us, total: 1.10ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.51ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.20ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.20ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.31ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_153750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 29946013.02sec, total: 29946013.02sec (25.00%)
top 2 operation type: Mean, cpu: 849us, accelerator: 29946013.02sec, total: 29946013.02sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 70us, accelerator: 29946013.02sec, total: 29946013.02sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29946013.03sec, total: 29946013.03sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 29946013.03sec, total: 29946013.03sec
  train.py:357:image_losses, cpu: 282us, accelerator: 29946013.02sec, total: 29946013.02sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 29946013.02sec, total: 29946013.02sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.92ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.92ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 450us, total: 1.68ms
      train.py:343:hfe, cpu: 565us, accelerator: 700us, total: 1.27ms
      train.py:344:hfe, cpu: 330us, accelerator: 768us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.50ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.20ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.20ms, total: 7.62ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.30ms, total: 6.01ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_154000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 29897478.16sec, total: 29897478.16sec (25.00%)
top 2 operation type: Mean, cpu: 846us, accelerator: 29897478.16sec, total: 29897478.16sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29897478.15sec, total: 29897478.15sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29897478.16sec, total: 29897478.16sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 29897478.16sec, total: 29897478.16sec
  train.py:357:image_losses, cpu: 281us, accelerator: 29897478.15sec, total: 29897478.15sec
    train.py:322:loss_fn, cpu: 260us, accelerator: 29897478.15sec, total: 29897478.15sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.36ms, total: 4.33ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.26ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.92ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.92ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 450us, total: 1.68ms
      train.py:343:hfe, cpu: 564us, accelerator: 700us, total: 1.27ms
      train.py:344:hfe, cpu: 330us, accelerator: 767us, total: 1.10ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.50ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.20ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.20ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.30ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_154250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 29849100.36sec, total: 29849100.36sec (25.00%)
top 2 operation type: Mean, cpu: 846us, accelerator: 29849100.36sec, total: 29849100.36sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29849100.36sec, total: 29849100.36sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29849100.36sec, total: 29849100.37sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 29849100.36sec, total: 29849100.37sec
  train.py:357:image_losses, cpu: 281us, accelerator: 29849100.36sec, total: 29849100.36sec
    train.py:322:loss_fn, cpu: 260us, accelerator: 29849100.36sec, total: 29849100.36sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.93ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.93ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 450us, total: 1.68ms
      train.py:343:hfe, cpu: 564us, accelerator: 699us, total: 1.27ms
      train.py:344:hfe, cpu: 329us, accelerator: 784us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.49ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.19ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.19ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.29ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_154500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 29800878.87sec, total: 29800878.87sec (25.00%)
top 2 operation type: Mean, cpu: 846us, accelerator: 29800878.87sec, total: 29800878.87sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29800878.87sec, total: 29800878.87sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29800878.88sec, total: 29800878.88sec
train.py:442:<module>, cpu: 5.62ms, accelerator: 29800878.87sec, total: 29800878.88sec
  train.py:357:image_losses, cpu: 281us, accelerator: 29800878.87sec, total: 29800878.87sec
    train.py:322:loss_fn, cpu: 260us, accelerator: 29800878.87sec, total: 29800878.87sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.36ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.36ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.94ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 449us, total: 1.67ms
      train.py:343:hfe, cpu: 564us, accelerator: 702us, total: 1.27ms
      train.py:344:hfe, cpu: 328us, accelerator: 790us, total: 1.12ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.48ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.19ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.19ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.29ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_154750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 29752812.94sec, total: 29752812.94sec (25.00%)
top 2 operation type: Mean, cpu: 845us, accelerator: 29752812.94sec, total: 29752812.94sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29752812.94sec, total: 29752812.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29752812.94sec, total: 29752812.95sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 29752812.94sec, total: 29752812.95sec
  train.py:357:image_losses, cpu: 281us, accelerator: 29752812.94sec, total: 29752812.94sec
    train.py:322:loss_fn, cpu: 260us, accelerator: 29752812.94sec, total: 29752812.94sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.34ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.94ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 448us, total: 1.67ms
      train.py:343:hfe, cpu: 563us, accelerator: 699us, total: 1.27ms
      train.py:344:hfe, cpu: 327us, accelerator: 790us, total: 1.12ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.18ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.18ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.29ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_155000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 29704901.81sec, total: 29704901.81sec (25.00%)
top 2 operation type: Mean, cpu: 844us, accelerator: 29704901.81sec, total: 29704901.81sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29704901.81sec, total: 29704901.81sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29704901.81sec, total: 29704901.82sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 29704901.81sec, total: 29704901.81sec
  train.py:357:image_losses, cpu: 280us, accelerator: 29704901.81sec, total: 29704901.81sec
    train.py:322:loss_fn, cpu: 259us, accelerator: 29704901.81sec, total: 29704901.81sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.33ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.94ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 454us, total: 1.68ms
      train.py:343:hfe, cpu: 563us, accelerator: 699us, total: 1.27ms
      train.py:344:hfe, cpu: 327us, accelerator: 789us, total: 1.12ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.18ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.18ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.29ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_155250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29657144.73sec, total: 29657144.73sec (25.00%)
top 2 operation type: Mean, cpu: 843us, accelerator: 29657144.73sec, total: 29657144.73sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29657144.73sec, total: 29657144.73sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29657144.73sec, total: 29657144.74sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 29657144.73sec, total: 29657144.74sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29657144.73sec, total: 29657144.73sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29657144.73sec, total: 29657144.73sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.32ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.33ms, total: 4.25ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.94ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 454us, total: 1.68ms
      train.py:343:hfe, cpu: 562us, accelerator: 698us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 787us, total: 1.12ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.18ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.18ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.29ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_155500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29609540.97sec, total: 29609540.97sec (25.00%)
top 2 operation type: Mean, cpu: 842us, accelerator: 29609540.97sec, total: 29609540.97sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29609540.96sec, total: 29609540.96sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29609540.97sec, total: 29609540.97sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 29609540.97sec, total: 29609540.97sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29609540.97sec, total: 29609540.97sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29609540.97sec, total: 29609540.97sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.94ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 454us, total: 1.68ms
      train.py:343:hfe, cpu: 562us, accelerator: 697us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 784us, total: 1.12ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.46ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.18ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.18ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.29ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_155750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29562089.78sec, total: 29562089.78sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 29562089.78sec, total: 29562089.78sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29562089.78sec, total: 29562089.78sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29562089.78sec, total: 29562089.79sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 29562089.78sec, total: 29562089.79sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29562089.78sec, total: 29562089.78sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29562089.78sec, total: 29562089.78sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.31ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.93ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.93ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 453us, total: 1.67ms
      train.py:343:hfe, cpu: 560us, accelerator: 696us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 785us, total: 1.12ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.46ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.17ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.29ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_156000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29514790.44sec, total: 29514790.44sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 29514790.43sec, total: 29514790.44sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29514790.43sec, total: 29514790.43sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29514790.44sec, total: 29514790.44sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 29514790.44sec, total: 29514790.44sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29514790.43sec, total: 29514790.43sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29514790.43sec, total: 29514790.43sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.93ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.93ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 452us, total: 1.67ms
      train.py:343:hfe, cpu: 561us, accelerator: 696us, total: 1.26ms
      train.py:344:hfe, cpu: 328us, accelerator: 783us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.45ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.17ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.28ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_156250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29467642.21sec, total: 29467642.21sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 29467642.21sec, total: 29467642.21sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29467642.21sec, total: 29467642.21sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 29467642.21sec, total: 29467642.22sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 29467642.21sec, total: 29467642.22sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29467642.21sec, total: 29467642.21sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29467642.21sec, total: 29467642.21sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.24ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.95ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.95ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 450us, total: 1.68ms
      train.py:343:hfe, cpu: 561us, accelerator: 708us, total: 1.27ms
      train.py:344:hfe, cpu: 327us, accelerator: 789us, total: 1.12ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.45ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.17ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.28ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_156500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29420644.37sec, total: 29420644.38sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 29420644.37sec, total: 29420644.37sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29420644.37sec, total: 29420644.37sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 29420644.38sec, total: 29420644.38sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 29420644.38sec, total: 29420644.38sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29420644.37sec, total: 29420644.37sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29420644.37sec, total: 29420644.37sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.35ms, total: 4.32ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.94ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 450us, total: 1.67ms
      train.py:343:hfe, cpu: 561us, accelerator: 706us, total: 1.27ms
      train.py:344:hfe, cpu: 328us, accelerator: 788us, total: 1.12ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.44ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.17ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.27ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_156750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29373796.21sec, total: 29373796.22sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 29373796.21sec, total: 29373796.21sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29373796.21sec, total: 29373796.21sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 29373796.22sec, total: 29373796.22sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 29373796.22sec, total: 29373796.22sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29373796.21sec, total: 29373796.21sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29373796.21sec, total: 29373796.21sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.35ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 450us, total: 1.67ms
      train.py:343:hfe, cpu: 560us, accelerator: 705us, total: 1.27ms
      train.py:344:hfe, cpu: 328us, accelerator: 786us, total: 1.12ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.44ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.16ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.28ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_157000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29327097.01sec, total: 29327097.02sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 29327097.01sec, total: 29327097.01sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29327097.01sec, total: 29327097.01sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 29327097.02sec, total: 29327097.02sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 29327097.02sec, total: 29327097.02sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29327097.01sec, total: 29327097.01sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29327097.01sec, total: 29327097.01sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.35ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.35ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.94ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 450us, total: 1.67ms
      train.py:343:hfe, cpu: 560us, accelerator: 705us, total: 1.27ms
      train.py:344:hfe, cpu: 328us, accelerator: 786us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.43ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.16ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.27ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_157250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29280546.07sec, total: 29280546.07sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 29280546.07sec, total: 29280546.07sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 69us, accelerator: 29280546.07sec, total: 29280546.07sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 29280546.07sec, total: 29280546.07sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 29280546.07sec, total: 29280546.07sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29280546.07sec, total: 29280546.07sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29280546.07sec, total: 29280546.07sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.94ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 450us, total: 1.67ms
      train.py:343:hfe, cpu: 560us, accelerator: 705us, total: 1.27ms
      train.py:344:hfe, cpu: 328us, accelerator: 784us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.16ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.27ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_157500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29234142.67sec, total: 29234142.67sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 29234142.67sec, total: 29234142.67sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 29234142.66sec, total: 29234142.66sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 29234142.67sec, total: 29234142.67sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 29234142.67sec, total: 29234142.67sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29234142.66sec, total: 29234142.66sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29234142.66sec, total: 29234142.66sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.94ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 449us, total: 1.67ms
      train.py:343:hfe, cpu: 560us, accelerator: 702us, total: 1.26ms
      train.py:344:hfe, cpu: 328us, accelerator: 784us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.44ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.17ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.27ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_157750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29187886.11sec, total: 29187886.11sec (25.00%)
top 2 operation type: Mean, cpu: 840us, accelerator: 29187886.11sec, total: 29187886.11sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 29187886.11sec, total: 29187886.11sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 29187886.11sec, total: 29187886.12sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 29187886.11sec, total: 29187886.12sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29187886.11sec, total: 29187886.11sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29187886.11sec, total: 29187886.11sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.93ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.93ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 449us, total: 1.66ms
      train.py:343:hfe, cpu: 558us, accelerator: 701us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 781us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.17ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.26ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_158000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29141775.71sec, total: 29141775.71sec (25.00%)
top 2 operation type: Mean, cpu: 840us, accelerator: 29141775.71sec, total: 29141775.71sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 29141775.70sec, total: 29141775.70sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 29141775.71sec, total: 29141775.71sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 29141775.71sec, total: 29141775.71sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29141775.71sec, total: 29141775.71sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29141775.71sec, total: 29141775.71sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.93ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.93ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 448us, total: 1.66ms
      train.py:343:hfe, cpu: 558us, accelerator: 701us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 781us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.17ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.26ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_158250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29095810.76sec, total: 29095810.76sec (25.00%)
top 2 operation type: Mean, cpu: 840us, accelerator: 29095810.76sec, total: 29095810.76sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 29095810.76sec, total: 29095810.76sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 29095810.76sec, total: 29095810.77sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 29095810.76sec, total: 29095810.77sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29095810.76sec, total: 29095810.76sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29095810.76sec, total: 29095810.76sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.93ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.93ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 447us, total: 1.66ms
      train.py:343:hfe, cpu: 558us, accelerator: 703us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 779us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.46ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.18ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.18ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.28ms, total: 6.01ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_158500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29049990.59sec, total: 29049990.59sec (25.00%)
top 2 operation type: Mean, cpu: 840us, accelerator: 29049990.59sec, total: 29049990.59sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 29049990.58sec, total: 29049990.58sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 29049990.59sec, total: 29049990.59sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 29049990.59sec, total: 29049990.59sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29049990.58sec, total: 29049990.59sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29049990.58sec, total: 29049990.59sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.93ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.93ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 446us, total: 1.66ms
      train.py:343:hfe, cpu: 558us, accelerator: 700us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 779us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.45ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.17ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.28ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_158750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29004314.50sec, total: 29004314.50sec (25.00%)
top 2 operation type: Mean, cpu: 837us, accelerator: 29004314.50sec, total: 29004314.50sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 29004314.50sec, total: 29004314.50sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 29004314.50sec, total: 29004314.51sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 29004314.50sec, total: 29004314.51sec
  train.py:357:image_losses, cpu: 279us, accelerator: 29004314.50sec, total: 29004314.50sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 29004314.50sec, total: 29004314.50sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.33ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.92ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.92ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 446us, total: 1.66ms
      train.py:343:hfe, cpu: 558us, accelerator: 700us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 778us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.45ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.17ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.27ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_159000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 28958781.82sec, total: 28958781.83sec (25.00%)
top 2 operation type: Mean, cpu: 836us, accelerator: 28958781.82sec, total: 28958781.82sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28958781.82sec, total: 28958781.82sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 28958781.83sec, total: 28958781.83sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 28958781.83sec, total: 28958781.83sec
  train.py:357:image_losses, cpu: 279us, accelerator: 28958781.82sec, total: 28958781.82sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 28958781.82sec, total: 28958781.82sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.93ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.93ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 451us, total: 1.66ms
      train.py:343:hfe, cpu: 558us, accelerator: 700us, total: 1.26ms
      train.py:344:hfe, cpu: 326us, accelerator: 777us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.45ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.17ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.28ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_159250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 28913391.88sec, total: 28913391.89sec (25.00%)
top 2 operation type: Mean, cpu: 837us, accelerator: 28913391.88sec, total: 28913391.88sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28913391.88sec, total: 28913391.88sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 28913391.89sec, total: 28913391.89sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 28913391.89sec, total: 28913391.89sec
  train.py:357:image_losses, cpu: 279us, accelerator: 28913391.88sec, total: 28913391.88sec
    train.py:322:loss_fn, cpu: 258us, accelerator: 28913391.88sec, total: 28913391.88sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.94ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.94ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 452us, total: 1.66ms
      train.py:343:hfe, cpu: 556us, accelerator: 704us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 788us, total: 1.12ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.46ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 2.17ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.29ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_159500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 28868144.01sec, total: 28868144.01sec (25.00%)
top 2 operation type: Mean, cpu: 836us, accelerator: 28868144.01sec, total: 28868144.01sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28868144.01sec, total: 28868144.01sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 28868144.01sec, total: 28868144.02sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 28868144.01sec, total: 28868144.02sec
  train.py:357:image_losses, cpu: 278us, accelerator: 28868144.01sec, total: 28868144.01sec
    train.py:322:loss_fn, cpu: 257us, accelerator: 28868144.01sec, total: 28868144.01sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.23ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.95ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.95ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 452us, total: 1.66ms
      train.py:343:hfe, cpu: 554us, accelerator: 710us, total: 1.27ms
      train.py:344:hfe, cpu: 327us, accelerator: 788us, total: 1.12ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.46ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 2.17ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.28ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_159750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 28823037.53sec, total: 28823037.54sec (25.00%)
top 2 operation type: Mean, cpu: 835us, accelerator: 28823037.53sec, total: 28823037.53sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28823037.53sec, total: 28823037.53sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 28823037.54sec, total: 28823037.54sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 28823037.54sec, total: 28823037.54sec
  train.py:357:image_losses, cpu: 278us, accelerator: 28823037.53sec, total: 28823037.53sec
    train.py:322:loss_fn, cpu: 257us, accelerator: 28823037.53sec, total: 28823037.53sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.95ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.95ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 452us, total: 1.66ms
      train.py:343:hfe, cpu: 554us, accelerator: 709us, total: 1.27ms
      train.py:344:hfe, cpu: 327us, accelerator: 786us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.45ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 2.17ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.28ms, total: 6.02ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_160000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 28778071.80sec, total: 28778071.80sec (25.00%)
top 2 operation type: Mean, cpu: 834us, accelerator: 28778071.80sec, total: 28778071.80sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28778071.80sec, total: 28778071.80sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 28778071.80sec, total: 28778071.81sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 28778071.80sec, total: 28778071.81sec
  train.py:357:image_losses, cpu: 278us, accelerator: 28778071.80sec, total: 28778071.80sec
    train.py:322:loss_fn, cpu: 257us, accelerator: 28778071.80sec, total: 28778071.80sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.94ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.94ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 452us, total: 1.65ms
      train.py:343:hfe, cpu: 554us, accelerator: 707us, total: 1.26ms
      train.py:344:hfe, cpu: 326us, accelerator: 784us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.45ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 2.17ms, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.28ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_160250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 28733246.14sec, total: 28733246.14sec (25.00%)
top 2 operation type: Mean, cpu: 835us, accelerator: 28733246.14sec, total: 28733246.14sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28733246.14sec, total: 28733246.14sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28733246.14sec, total: 28733246.15sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 28733246.14sec, total: 28733246.15sec
  train.py:357:image_losses, cpu: 278us, accelerator: 28733246.14sec, total: 28733246.14sec
    train.py:322:loss_fn, cpu: 257us, accelerator: 28733246.14sec, total: 28733246.14sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.94ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.94ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 451us, total: 1.65ms
      train.py:343:hfe, cpu: 554us, accelerator: 705us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 784us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.45ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.17ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.28ms, total: 6.01ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_160500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28688559.91sec, total: 28688559.91sec (25.00%)
top 2 operation type: Mean, cpu: 835us, accelerator: 28688559.91sec, total: 28688559.91sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28688559.91sec, total: 28688559.91sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28688559.91sec, total: 28688559.92sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 28688559.91sec, total: 28688559.92sec
  train.py:357:image_losses, cpu: 277us, accelerator: 28688559.91sec, total: 28688559.91sec
    train.py:322:loss_fn, cpu: 257us, accelerator: 28688559.91sec, total: 28688559.91sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.94ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.94ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 454us, total: 1.65ms
      train.py:343:hfe, cpu: 554us, accelerator: 703us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 783us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.44ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.16ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.28ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_160750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28644012.46sec, total: 28644012.46sec (25.00%)
top 2 operation type: Mean, cpu: 834us, accelerator: 28644012.46sec, total: 28644012.46sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28644012.46sec, total: 28644012.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28644012.46sec, total: 28644012.46sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 28644012.46sec, total: 28644012.46sec
  train.py:357:image_losses, cpu: 276us, accelerator: 28644012.46sec, total: 28644012.46sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 28644012.46sec, total: 28644012.46sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.33ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.94ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.94ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 459us, total: 1.66ms
      train.py:343:hfe, cpu: 554us, accelerator: 703us, total: 1.26ms
      train.py:344:hfe, cpu: 326us, accelerator: 781us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.16ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.27ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2117.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_161000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28599603.13sec, total: 28599603.14sec (25.00%)
top 2 operation type: Mean, cpu: 834us, accelerator: 28599603.13sec, total: 28599603.14sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28599603.13sec, total: 28599603.13sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28599603.14sec, total: 28599603.14sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 28599603.14sec, total: 28599603.14sec
  train.py:357:image_losses, cpu: 276us, accelerator: 28599603.13sec, total: 28599603.13sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 28599603.13sec, total: 28599603.13sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.94ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.94ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 457us, total: 1.66ms
      train.py:343:hfe, cpu: 554us, accelerator: 702us, total: 1.26ms
      train.py:344:hfe, cpu: 326us, accelerator: 780us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.42ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.15ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.27ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_161250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28555331.30sec, total: 28555331.31sec (25.00%)
top 2 operation type: Mean, cpu: 833us, accelerator: 28555331.30sec, total: 28555331.30sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28555331.30sec, total: 28555331.30sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28555331.31sec, total: 28555331.31sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 28555331.31sec, total: 28555331.31sec
  train.py:357:image_losses, cpu: 276us, accelerator: 28555331.30sec, total: 28555331.30sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 28555331.30sec, total: 28555331.30sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.94ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.94ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 457us, total: 1.65ms
      train.py:343:hfe, cpu: 554us, accelerator: 702us, total: 1.26ms
      train.py:344:hfe, cpu: 329us, accelerator: 779us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.42ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.15ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.27ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_161500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28511196.32sec, total: 28511196.33sec (25.00%)
top 2 operation type: Mean, cpu: 833us, accelerator: 28511196.32sec, total: 28511196.33sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28511196.32sec, total: 28511196.32sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28511196.33sec, total: 28511196.33sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 28511196.33sec, total: 28511196.33sec
  train.py:357:image_losses, cpu: 276us, accelerator: 28511196.32sec, total: 28511196.32sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 28511196.32sec, total: 28511196.32sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.94ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.94ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 457us, total: 1.67ms
      train.py:343:hfe, cpu: 553us, accelerator: 701us, total: 1.26ms
      train.py:344:hfe, cpu: 329us, accelerator: 777us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.41ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.15ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.26ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_161750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28467197.56sec, total: 28467197.57sec (25.00%)
top 2 operation type: Mean, cpu: 835us, accelerator: 28467197.56sec, total: 28467197.57sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28467197.56sec, total: 28467197.56sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28467197.57sec, total: 28467197.57sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 28467197.57sec, total: 28467197.57sec
  train.py:357:image_losses, cpu: 276us, accelerator: 28467197.56sec, total: 28467197.56sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 28467197.56sec, total: 28467197.56sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.93ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.93ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 456us, total: 1.67ms
      train.py:343:hfe, cpu: 553us, accelerator: 701us, total: 1.25ms
      train.py:344:hfe, cpu: 328us, accelerator: 776us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.42ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.14ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.28ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_162000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28423334.39sec, total: 28423334.40sec (25.00%)
top 2 operation type: Mean, cpu: 838us, accelerator: 28423334.39sec, total: 28423334.40sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28423334.39sec, total: 28423334.39sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28423334.40sec, total: 28423334.40sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 28423334.40sec, total: 28423334.40sec
  train.py:357:image_losses, cpu: 276us, accelerator: 28423334.39sec, total: 28423334.39sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 28423334.39sec, total: 28423334.39sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.93ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.93ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 456us, total: 1.67ms
      train.py:343:hfe, cpu: 552us, accelerator: 700us, total: 1.25ms
      train.py:344:hfe, cpu: 328us, accelerator: 775us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.42ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.15ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.27ms, total: 6.03ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_162250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28379606.19sec, total: 28379606.19sec (25.00%)
top 2 operation type: Mean, cpu: 838us, accelerator: 28379606.19sec, total: 28379606.19sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28379606.19sec, total: 28379606.19sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28379606.19sec, total: 28379606.20sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 28379606.19sec, total: 28379606.20sec
  train.py:357:image_losses, cpu: 276us, accelerator: 28379606.19sec, total: 28379606.19sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 28379606.19sec, total: 28379606.19sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.33ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.31ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.93ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.93ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 455us, total: 1.67ms
      train.py:343:hfe, cpu: 552us, accelerator: 700us, total: 1.25ms
      train.py:344:hfe, cpu: 328us, accelerator: 775us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.42ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.15ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.27ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_162500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28336012.32sec, total: 28336012.32sec (25.00%)
top 2 operation type: Mean, cpu: 838us, accelerator: 28336012.32sec, total: 28336012.32sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28336012.32sec, total: 28336012.32sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28336012.33sec, total: 28336012.33sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 28336012.33sec, total: 28336012.33sec
  train.py:357:image_losses, cpu: 276us, accelerator: 28336012.32sec, total: 28336012.32sec
    train.py:322:loss_fn, cpu: 256us, accelerator: 28336012.32sec, total: 28336012.32sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.33ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.31ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.93ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.93ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 455us, total: 1.67ms
      train.py:343:hfe, cpu: 552us, accelerator: 697us, total: 1.25ms
      train.py:344:hfe, cpu: 328us, accelerator: 773us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.41ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.15ms, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.26ms, total: 6.02ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_162750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28292552.18sec, total: 28292552.18sec (25.00%)
top 2 operation type: Mean, cpu: 837us, accelerator: 28292552.18sec, total: 28292552.18sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28292552.18sec, total: 28292552.18sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28292552.19sec, total: 28292552.19sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 28292552.18sec, total: 28292552.19sec
  train.py:357:image_losses, cpu: 275us, accelerator: 28292552.18sec, total: 28292552.18sec
    train.py:322:loss_fn, cpu: 255us, accelerator: 28292552.18sec, total: 28292552.18sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.33ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.33ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.31ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.92ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.92ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 454us, total: 1.67ms
      train.py:343:hfe, cpu: 551us, accelerator: 697us, total: 1.25ms
      train.py:344:hfe, cpu: 328us, accelerator: 773us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.41ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 2.14ms, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.26ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_163000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28249225.15sec, total: 28249225.15sec (25.00%)
top 2 operation type: Mean, cpu: 837us, accelerator: 28249225.15sec, total: 28249225.15sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28249225.15sec, total: 28249225.15sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28249225.15sec, total: 28249225.16sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 28249225.15sec, total: 28249225.16sec
  train.py:357:image_losses, cpu: 275us, accelerator: 28249225.15sec, total: 28249225.15sec
    train.py:322:loss_fn, cpu: 255us, accelerator: 28249225.15sec, total: 28249225.15sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.32ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.31ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.92ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.92ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 453us, total: 1.67ms
      train.py:343:hfe, cpu: 551us, accelerator: 696us, total: 1.25ms
      train.py:344:hfe, cpu: 328us, accelerator: 772us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.40ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 2.14ms, total: 7.52ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.26ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_163250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28206030.61sec, total: 28206030.62sec (25.00%)
top 2 operation type: Mean, cpu: 837us, accelerator: 28206030.61sec, total: 28206030.62sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28206030.61sec, total: 28206030.61sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 28206030.62sec, total: 28206030.62sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 28206030.62sec, total: 28206030.62sec
  train.py:357:image_losses, cpu: 275us, accelerator: 28206030.61sec, total: 28206030.61sec
    train.py:322:loss_fn, cpu: 255us, accelerator: 28206030.61sec, total: 28206030.61sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.92ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.92ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 453us, total: 1.67ms
      train.py:343:hfe, cpu: 550us, accelerator: 695us, total: 1.25ms
      train.py:344:hfe, cpu: 328us, accelerator: 770us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.40ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.14ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.26ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_163500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28162967.97sec, total: 28162967.97sec (25.00%)
top 2 operation type: Mean, cpu: 836us, accelerator: 28162967.97sec, total: 28162967.97sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28162967.97sec, total: 28162967.97sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28162967.98sec, total: 28162967.98sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 28162967.98sec, total: 28162967.98sec
  train.py:357:image_losses, cpu: 275us, accelerator: 28162967.97sec, total: 28162967.97sec
    train.py:322:loss_fn, cpu: 255us, accelerator: 28162967.97sec, total: 28162967.97sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.92ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.92ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 452us, total: 1.67ms
      train.py:343:hfe, cpu: 549us, accelerator: 700us, total: 1.25ms
      train.py:344:hfe, cpu: 328us, accelerator: 772us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.14ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.25ms, total: 6.05ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_163750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28120036.62sec, total: 28120036.62sec (25.00%)
top 2 operation type: Mean, cpu: 836us, accelerator: 28120036.62sec, total: 28120036.62sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28120036.62sec, total: 28120036.62sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28120036.62sec, total: 28120036.63sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 28120036.62sec, total: 28120036.63sec
  train.py:357:image_losses, cpu: 275us, accelerator: 28120036.62sec, total: 28120036.62sec
    train.py:322:loss_fn, cpu: 255us, accelerator: 28120036.62sec, total: 28120036.62sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.92ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.92ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 452us, total: 1.67ms
      train.py:343:hfe, cpu: 549us, accelerator: 697us, total: 1.25ms
      train.py:344:hfe, cpu: 328us, accelerator: 770us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.13ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.25ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_164000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28077235.95sec, total: 28077235.96sec (25.00%)
top 2 operation type: Mean, cpu: 836us, accelerator: 28077235.95sec, total: 28077235.95sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28077235.95sec, total: 28077235.95sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28077235.96sec, total: 28077235.96sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 28077235.96sec, total: 28077235.96sec
  train.py:357:image_losses, cpu: 275us, accelerator: 28077235.95sec, total: 28077235.95sec
    train.py:322:loss_fn, cpu: 255us, accelerator: 28077235.95sec, total: 28077235.95sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.93ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.93ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 452us, total: 1.67ms
      train.py:343:hfe, cpu: 549us, accelerator: 705us, total: 1.26ms
      train.py:344:hfe, cpu: 328us, accelerator: 772us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.13ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.25ms, total: 6.05ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_164250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28034565.38sec, total: 28034565.39sec (25.00%)
top 2 operation type: Mean, cpu: 835us, accelerator: 28034565.38sec, total: 28034565.38sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 28034565.38sec, total: 28034565.38sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 28034565.39sec, total: 28034565.39sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 28034565.39sec, total: 28034565.39sec
  train.py:357:image_losses, cpu: 275us, accelerator: 28034565.38sec, total: 28034565.38sec
    train.py:322:loss_fn, cpu: 255us, accelerator: 28034565.38sec, total: 28034565.38sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.94ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.94ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 452us, total: 1.67ms
      train.py:343:hfe, cpu: 549us, accelerator: 705us, total: 1.26ms
      train.py:344:hfe, cpu: 327us, accelerator: 779us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.13ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.13ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.25ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_164500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27992024.31sec, total: 27992024.31sec (25.00%)
top 2 operation type: Mean, cpu: 833us, accelerator: 27992024.31sec, total: 27992024.31sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 68us, accelerator: 27992024.31sec, total: 27992024.31sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 27992024.32sec, total: 27992024.32sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 27992024.32sec, total: 27992024.32sec
  train.py:357:image_losses, cpu: 275us, accelerator: 27992024.31sec, total: 27992024.31sec
    train.py:322:loss_fn, cpu: 255us, accelerator: 27992024.31sec, total: 27992024.31sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.94ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.94ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 451us, total: 1.67ms
      train.py:343:hfe, cpu: 548us, accelerator: 705us, total: 1.26ms
      train.py:344:hfe, cpu: 326us, accelerator: 779us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.18ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.18ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.26ms, total: 6.06ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_164750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27949612.15sec, total: 27949612.16sec (25.00%)
top 2 operation type: Mean, cpu: 832us, accelerator: 27949612.15sec, total: 27949612.16sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27949612.15sec, total: 27949612.15sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 27949612.16sec, total: 27949612.16sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27949612.16sec, total: 27949612.16sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27949612.15sec, total: 27949612.15sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27949612.15sec, total: 27949612.15sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.30ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.93ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.93ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 449us, total: 1.69ms
      train.py:343:hfe, cpu: 548us, accelerator: 704us, total: 1.26ms
      train.py:344:hfe, cpu: 326us, accelerator: 778us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 2.17ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.26ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_165000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27907328.32sec, total: 27907328.33sec (25.00%)
top 2 operation type: Mean, cpu: 831us, accelerator: 27907328.32sec, total: 27907328.32sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27907328.32sec, total: 27907328.32sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 27907328.33sec, total: 27907328.33sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27907328.33sec, total: 27907328.33sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27907328.32sec, total: 27907328.32sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27907328.32sec, total: 27907328.32sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.30ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.93ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.93ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 449us, total: 1.69ms
      train.py:343:hfe, cpu: 546us, accelerator: 703us, total: 1.25ms
      train.py:344:hfe, cpu: 326us, accelerator: 778us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.17ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.17ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.26ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_165250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27865172.24sec, total: 27865172.24sec (25.00%)
top 2 operation type: Mean, cpu: 832us, accelerator: 27865172.24sec, total: 27865172.24sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27865172.24sec, total: 27865172.24sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 27865172.24sec, total: 27865172.25sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27865172.24sec, total: 27865172.25sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27865172.24sec, total: 27865172.24sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27865172.24sec, total: 27865172.24sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.30ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.93ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.93ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 449us, total: 1.68ms
      train.py:343:hfe, cpu: 546us, accelerator: 702us, total: 1.25ms
      train.py:344:hfe, cpu: 326us, accelerator: 777us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.44ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.19ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.19ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.25ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_165500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27823143.32sec, total: 27823143.32sec (25.00%)
top 2 operation type: Mean, cpu: 832us, accelerator: 27823143.32sec, total: 27823143.32sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27823143.32sec, total: 27823143.32sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27823143.33sec, total: 27823143.33sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27823143.32sec, total: 27823143.33sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27823143.32sec, total: 27823143.32sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27823143.32sec, total: 27823143.32sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.32ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.30ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.93ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.93ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 449us, total: 1.68ms
      train.py:343:hfe, cpu: 546us, accelerator: 701us, total: 1.25ms
      train.py:344:hfe, cpu: 325us, accelerator: 777us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.44ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.18ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.18ms, total: 7.60ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.26ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_165750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27781241.00sec, total: 27781241.00sec (25.00%)
top 2 operation type: Mean, cpu: 832us, accelerator: 27781241.00sec, total: 27781241.00sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27781241.00sec, total: 27781241.00sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27781241.00sec, total: 27781241.01sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27781241.00sec, total: 27781241.01sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27781241.00sec, total: 27781241.00sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27781241.00sec, total: 27781241.00sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.33ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.92ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.92ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 448us, total: 1.68ms
      train.py:343:hfe, cpu: 546us, accelerator: 700us, total: 1.25ms
      train.py:344:hfe, cpu: 325us, accelerator: 773us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.18ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.18ms, total: 7.60ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.25ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_166000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27739464.69sec, total: 27739464.70sec (25.00%)
top 2 operation type: Mean, cpu: 832us, accelerator: 27739464.69sec, total: 27739464.70sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27739464.69sec, total: 27739464.69sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27739464.70sec, total: 27739464.70sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27739464.70sec, total: 27739464.70sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27739464.69sec, total: 27739464.69sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27739464.69sec, total: 27739464.69sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.92ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.92ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 446us, total: 1.68ms
      train.py:343:hfe, cpu: 546us, accelerator: 699us, total: 1.25ms
      train.py:344:hfe, cpu: 325us, accelerator: 772us, total: 1.10ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.42ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.17ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.17ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.25ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_166250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27697813.85sec, total: 27697813.85sec (25.00%)
top 2 operation type: Mean, cpu: 831us, accelerator: 27697813.85sec, total: 27697813.85sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27697813.85sec, total: 27697813.85sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27697813.85sec, total: 27697813.86sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 27697813.85sec, total: 27697813.86sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27697813.85sec, total: 27697813.85sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27697813.85sec, total: 27697813.85sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.33ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.91ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.91ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 445us, total: 1.68ms
      train.py:343:hfe, cpu: 544us, accelerator: 698us, total: 1.25ms
      train.py:344:hfe, cpu: 326us, accelerator: 770us, total: 1.10ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.42ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.17ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.17ms, total: 7.60ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.25ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_166500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27656287.89sec, total: 27656287.89sec (25.00%)
top 2 operation type: Mean, cpu: 830us, accelerator: 27656287.89sec, total: 27656287.89sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27656287.89sec, total: 27656287.89sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27656287.89sec, total: 27656287.90sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 27656287.89sec, total: 27656287.90sec
  train.py:357:image_losses, cpu: 273us, accelerator: 27656287.89sec, total: 27656287.89sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 27656287.89sec, total: 27656287.89sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.91ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.91ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 445us, total: 1.68ms
      train.py:343:hfe, cpu: 544us, accelerator: 697us, total: 1.24ms
      train.py:344:hfe, cpu: 325us, accelerator: 770us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.41ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.17ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.17ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.25ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_166750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27614886.26sec, total: 27614886.26sec (25.00%)
top 2 operation type: Mean, cpu: 829us, accelerator: 27614886.26sec, total: 27614886.26sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27614886.26sec, total: 27614886.26sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27614886.26sec, total: 27614886.27sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27614886.26sec, total: 27614886.27sec
  train.py:357:image_losses, cpu: 273us, accelerator: 27614886.26sec, total: 27614886.26sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 27614886.26sec, total: 27614886.26sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.91ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.91ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 444us, total: 1.68ms
      train.py:343:hfe, cpu: 542us, accelerator: 697us, total: 1.24ms
      train.py:344:hfe, cpu: 325us, accelerator: 769us, total: 1.10ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.41ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.17ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.17ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.24ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_167000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27573608.40sec, total: 27573608.41sec (25.00%)
top 2 operation type: Mean, cpu: 828us, accelerator: 27573608.40sec, total: 27573608.40sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27573608.40sec, total: 27573608.40sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 27573608.41sec, total: 27573608.41sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 27573608.41sec, total: 27573608.41sec
  train.py:357:image_losses, cpu: 273us, accelerator: 27573608.40sec, total: 27573608.40sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 27573608.40sec, total: 27573608.40sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.34ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.34ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.91ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.91ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 444us, total: 1.68ms
      train.py:343:hfe, cpu: 541us, accelerator: 695us, total: 1.24ms
      train.py:344:hfe, cpu: 324us, accelerator: 769us, total: 1.10ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.40ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.16ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.16ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.24ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_167250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27532453.76sec, total: 27532453.77sec (25.00%)
top 2 operation type: Mean, cpu: 827us, accelerator: 27532453.76sec, total: 27532453.76sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27532453.76sec, total: 27532453.76sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27532453.77sec, total: 27532453.77sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 27532453.77sec, total: 27532453.77sec
  train.py:357:image_losses, cpu: 273us, accelerator: 27532453.76sec, total: 27532453.76sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 27532453.76sec, total: 27532453.76sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.33ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.91ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.91ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 444us, total: 1.68ms
      train.py:343:hfe, cpu: 540us, accelerator: 695us, total: 1.24ms
      train.py:344:hfe, cpu: 323us, accelerator: 767us, total: 1.09ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.40ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.16ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.16ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.24ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_167500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27491421.79sec, total: 27491421.79sec (25.00%)
top 2 operation type: Mean, cpu: 827us, accelerator: 27491421.79sec, total: 27491421.79sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27491421.79sec, total: 27491421.79sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27491421.80sec, total: 27491421.80sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27491421.79sec, total: 27491421.80sec
  train.py:357:image_losses, cpu: 273us, accelerator: 27491421.79sec, total: 27491421.79sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 27491421.79sec, total: 27491421.79sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.33ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.90ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.90ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 443us, total: 1.69ms
      train.py:343:hfe, cpu: 540us, accelerator: 694us, total: 1.24ms
      train.py:344:hfe, cpu: 323us, accelerator: 766us, total: 1.09ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.16ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.16ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.23ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_167750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27450511.94sec, total: 27450511.94sec (25.00%)
top 2 operation type: Mean, cpu: 827us, accelerator: 27450511.94sec, total: 27450511.94sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27450511.94sec, total: 27450511.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27450511.94sec, total: 27450511.95sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27450511.94sec, total: 27450511.95sec
  train.py:357:image_losses, cpu: 273us, accelerator: 27450511.94sec, total: 27450511.94sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 27450511.94sec, total: 27450511.94sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.33ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.91ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.91ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 443us, total: 1.69ms
      train.py:343:hfe, cpu: 540us, accelerator: 692us, total: 1.24ms
      train.py:344:hfe, cpu: 323us, accelerator: 774us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.16ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.76ms, accelerator: 2.23ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_168000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27409723.66sec, total: 27409723.66sec (25.00%)
top 2 operation type: Mean, cpu: 828us, accelerator: 27409723.66sec, total: 27409723.66sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27409723.66sec, total: 27409723.66sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27409723.66sec, total: 27409723.67sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27409723.66sec, total: 27409723.67sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27409723.66sec, total: 27409723.66sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27409723.66sec, total: 27409723.66sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.33ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.91ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.91ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 443us, total: 1.69ms
      train.py:343:hfe, cpu: 540us, accelerator: 691us, total: 1.24ms
      train.py:344:hfe, cpu: 323us, accelerator: 774us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.15ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.15ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.23ms, total: 6.04ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_168250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27369056.41sec, total: 27369056.41sec (25.00%)
top 2 operation type: Mean, cpu: 828us, accelerator: 27369056.41sec, total: 27369056.41sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27369056.41sec, total: 27369056.41sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27369056.42sec, total: 27369056.42sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 27369056.42sec, total: 27369056.42sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27369056.41sec, total: 27369056.41sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27369056.41sec, total: 27369056.41sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.33ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.33ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.32ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.91ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.91ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 443us, total: 1.70ms
      train.py:343:hfe, cpu: 540us, accelerator: 690us, total: 1.23ms
      train.py:344:hfe, cpu: 325us, accelerator: 775us, total: 1.10ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.15ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.15ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.23ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_168500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27328509.66sec, total: 27328509.66sec (25.00%)
top 2 operation type: Mean, cpu: 828us, accelerator: 27328509.66sec, total: 27328509.66sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 67us, accelerator: 27328509.66sec, total: 27328509.66sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27328509.67sec, total: 27328509.67sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 27328509.66sec, total: 27328509.67sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27328509.66sec, total: 27328509.66sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27328509.66sec, total: 27328509.66sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.33ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.91ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.91ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 443us, total: 1.70ms
      train.py:343:hfe, cpu: 540us, accelerator: 690us, total: 1.23ms
      train.py:344:hfe, cpu: 325us, accelerator: 774us, total: 1.10ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.15ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.15ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.23ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_168750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27288082.87sec, total: 27288082.87sec (25.00%)
top 2 operation type: Mean, cpu: 828us, accelerator: 27288082.87sec, total: 27288082.87sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 76us, accelerator: 27288082.87sec, total: 27288082.87sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27288082.88sec, total: 27288082.88sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 27288082.88sec, total: 27288082.88sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27288082.87sec, total: 27288082.87sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27288082.87sec, total: 27288082.87sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.33ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.90ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.90ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 442us, total: 1.69ms
      train.py:343:hfe, cpu: 540us, accelerator: 687us, total: 1.23ms
      train.py:344:hfe, cpu: 325us, accelerator: 773us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.15ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.23ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_169000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27247775.51sec, total: 27247775.51sec (25.00%)
top 2 operation type: Mean, cpu: 828us, accelerator: 27247775.51sec, total: 27247775.51sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 27247775.51sec, total: 27247775.51sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27247775.52sec, total: 27247775.52sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 27247775.52sec, total: 27247775.52sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27247775.51sec, total: 27247775.51sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27247775.51sec, total: 27247775.51sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.33ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.33ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.90ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.90ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 440us, total: 1.69ms
      train.py:343:hfe, cpu: 540us, accelerator: 687us, total: 1.23ms
      train.py:344:hfe, cpu: 324us, accelerator: 771us, total: 1.10ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.37ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.15ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.15ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 2.23ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_169250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27207587.05sec, total: 27207587.06sec (25.00%)
top 2 operation type: Mean, cpu: 827us, accelerator: 27207587.05sec, total: 27207587.05sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 27207587.05sec, total: 27207587.05sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27207587.06sec, total: 27207587.06sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 27207587.06sec, total: 27207587.06sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27207587.05sec, total: 27207587.05sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27207587.05sec, total: 27207587.05sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.90ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.90ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 439us, total: 1.69ms
      train.py:343:hfe, cpu: 537us, accelerator: 687us, total: 1.23ms
      train.py:344:hfe, cpu: 324us, accelerator: 771us, total: 1.10ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.37ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.14ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.14ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.22ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_169500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27167516.97sec, total: 27167516.97sec (25.00%)
top 2 operation type: Mean, cpu: 827us, accelerator: 27167516.97sec, total: 27167516.97sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 27167516.97sec, total: 27167516.97sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27167516.97sec, total: 27167516.98sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 27167516.97sec, total: 27167516.98sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27167516.97sec, total: 27167516.97sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27167516.97sec, total: 27167516.97sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.89ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.89ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 438us, total: 1.69ms
      train.py:343:hfe, cpu: 537us, accelerator: 686us, total: 1.23ms
      train.py:344:hfe, cpu: 324us, accelerator: 768us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.36ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.14ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.14ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.22ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_169750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27127564.74sec, total: 27127564.74sec (25.00%)
top 2 operation type: Mean, cpu: 827us, accelerator: 27127564.74sec, total: 27127564.74sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 27127564.74sec, total: 27127564.74sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27127564.74sec, total: 27127564.75sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 27127564.74sec, total: 27127564.75sec
  train.py:357:image_losses, cpu: 274us, accelerator: 27127564.74sec, total: 27127564.74sec
    train.py:322:loss_fn, cpu: 254us, accelerator: 27127564.74sec, total: 27127564.74sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.89ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.89ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 438us, total: 1.69ms
      train.py:343:hfe, cpu: 537us, accelerator: 685us, total: 1.23ms
      train.py:344:hfe, cpu: 324us, accelerator: 768us, total: 1.09ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.36ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.14ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.22ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_170000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27087729.84sec, total: 27087729.84sec (25.00%)
top 2 operation type: Mean, cpu: 825us, accelerator: 27087729.84sec, total: 27087729.84sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 27087729.84sec, total: 27087729.84sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27087729.85sec, total: 27087729.85sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 27087729.84sec, total: 27087729.85sec
  train.py:357:image_losses, cpu: 273us, accelerator: 27087729.84sec, total: 27087729.84sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 27087729.84sec, total: 27087729.84sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.31ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.89ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.89ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 438us, total: 1.69ms
      train.py:343:hfe, cpu: 536us, accelerator: 684us, total: 1.22ms
      train.py:344:hfe, cpu: 324us, accelerator: 767us, total: 1.09ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.36ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.14ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.14ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.22ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_170250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27048011.76sec, total: 27048011.76sec (25.00%)
top 2 operation type: Mean, cpu: 824us, accelerator: 27048011.76sec, total: 27048011.76sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 27048011.76sec, total: 27048011.76sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27048011.77sec, total: 27048011.77sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 27048011.77sec, total: 27048011.77sec
  train.py:357:image_losses, cpu: 273us, accelerator: 27048011.76sec, total: 27048011.76sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 27048011.76sec, total: 27048011.76sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.32ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 1.32ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.30ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.90ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.90ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 442us, total: 1.70ms
      train.py:343:hfe, cpu: 536us, accelerator: 689us, total: 1.23ms
      train.py:344:hfe, cpu: 323us, accelerator: 773us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.36ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.14ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 2.22ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_170500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27008409.99sec, total: 27008409.99sec (25.00%)
top 2 operation type: Mean, cpu: 824us, accelerator: 27008409.99sec, total: 27008409.99sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 27008409.99sec, total: 27008409.99sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 27008409.99sec, total: 27008410.00sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 27008409.99sec, total: 27008410.00sec
  train.py:357:image_losses, cpu: 273us, accelerator: 27008409.99sec, total: 27008409.99sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 27008409.99sec, total: 27008409.99sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.32ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.88ms, accelerator: 1.30ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.90ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.90ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 442us, total: 1.70ms
      train.py:343:hfe, cpu: 536us, accelerator: 685us, total: 1.23ms
      train.py:344:hfe, cpu: 323us, accelerator: 773us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.40ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.16ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.23ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_170750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 26968924.01sec, total: 26968924.01sec (25.00%)
top 2 operation type: Mean, cpu: 824us, accelerator: 26968924.01sec, total: 26968924.01sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 26968924.01sec, total: 26968924.01sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 26968924.01sec, total: 26968924.02sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 26968924.01sec, total: 26968924.02sec
  train.py:357:image_losses, cpu: 273us, accelerator: 26968924.01sec, total: 26968924.01sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 26968924.01sec, total: 26968924.01sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.32ms, total: 4.30ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.32ms, total: 4.29ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.30ms, total: 4.22ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.90ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.90ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 441us, total: 1.69ms
      train.py:343:hfe, cpu: 536us, accelerator: 684us, total: 1.22ms
      train.py:344:hfe, cpu: 323us, accelerator: 771us, total: 1.10ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.39ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.16ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.23ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_171000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 26929553.32sec, total: 26929553.32sec (25.00%)
top 2 operation type: Mean, cpu: 823us, accelerator: 26929553.32sec, total: 26929553.32sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 26929553.32sec, total: 26929553.32sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 26929553.32sec, total: 26929553.33sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 26929553.32sec, total: 26929553.33sec
  train.py:357:image_losses, cpu: 273us, accelerator: 26929553.32sec, total: 26929553.32sec
    train.py:322:loss_fn, cpu: 253us, accelerator: 26929553.32sec, total: 26929553.32sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.30ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.89ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.89ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 439us, total: 1.69ms
      train.py:343:hfe, cpu: 536us, accelerator: 684us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 770us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.38ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.16ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.23ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_171250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26890297.41sec, total: 26890297.41sec (25.00%)
top 2 operation type: Mean, cpu: 822us, accelerator: 26890297.41sec, total: 26890297.41sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 26890297.41sec, total: 26890297.41sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 26890297.41sec, total: 26890297.42sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 26890297.41sec, total: 26890297.42sec
  train.py:357:image_losses, cpu: 272us, accelerator: 26890297.41sec, total: 26890297.41sec
    train.py:322:loss_fn, cpu: 252us, accelerator: 26890297.41sec, total: 26890297.41sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.30ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.90ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.90ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 439us, total: 1.69ms
      train.py:343:hfe, cpu: 534us, accelerator: 687us, total: 1.23ms
      train.py:344:hfe, cpu: 322us, accelerator: 769us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.39ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.15ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.24ms, total: 6.01ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_171500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26851155.78sec, total: 26851155.78sec (25.00%)
top 2 operation type: Mean, cpu: 821us, accelerator: 26851155.78sec, total: 26851155.78sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 26851155.78sec, total: 26851155.78sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 26851155.79sec, total: 26851155.79sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 26851155.78sec, total: 26851155.79sec
  train.py:357:image_losses, cpu: 271us, accelerator: 26851155.78sec, total: 26851155.78sec
    train.py:322:loss_fn, cpu: 251us, accelerator: 26851155.78sec, total: 26851155.78sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.30ms, total: 4.21ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.89ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.89ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 439us, total: 1.69ms
      train.py:343:hfe, cpu: 533us, accelerator: 686us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 769us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.42ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.15ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.27ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_171750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26812127.94sec, total: 26812127.94sec (25.00%)
top 2 operation type: Mean, cpu: 826us, accelerator: 26812127.94sec, total: 26812127.94sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 26812127.94sec, total: 26812127.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 26812127.94sec, total: 26812127.95sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 26812127.94sec, total: 26812127.95sec
  train.py:357:image_losses, cpu: 271us, accelerator: 26812127.94sec, total: 26812127.94sec
    train.py:322:loss_fn, cpu: 251us, accelerator: 26812127.94sec, total: 26812127.94sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.32ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.32ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.30ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.89ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.89ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 439us, total: 1.69ms
      train.py:343:hfe, cpu: 532us, accelerator: 685us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 767us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.42ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.15ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.27ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_172000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26773213.38sec, total: 26773213.39sec (25.00%)
top 2 operation type: Mean, cpu: 825us, accelerator: 26773213.38sec, total: 26773213.39sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 26773213.38sec, total: 26773213.38sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 26773213.39sec, total: 26773213.39sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 26773213.39sec, total: 26773213.39sec
  train.py:357:image_losses, cpu: 271us, accelerator: 26773213.38sec, total: 26773213.38sec
    train.py:322:loss_fn, cpu: 251us, accelerator: 26773213.38sec, total: 26773213.38sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.31ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.31ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.30ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.89ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.89ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 440us, total: 1.69ms
      train.py:343:hfe, cpu: 531us, accelerator: 686us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 767us, total: 1.09ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.41ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.15ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.27ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_172250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26734411.63sec, total: 26734411.63sec (25.00%)
top 2 operation type: Mean, cpu: 825us, accelerator: 26734411.63sec, total: 26734411.63sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 26734411.62sec, total: 26734411.62sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 26734411.63sec, total: 26734411.63sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 26734411.63sec, total: 26734411.63sec
  train.py:357:image_losses, cpu: 271us, accelerator: 26734411.63sec, total: 26734411.63sec
    train.py:322:loss_fn, cpu: 251us, accelerator: 26734411.63sec, total: 26734411.63sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.31ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.31ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.29ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.89ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.89ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 439us, total: 1.69ms
      train.py:343:hfe, cpu: 531us, accelerator: 684us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 766us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.41ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.14ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.27ms, total: 6.03ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_172500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26695722.17sec, total: 26695722.18sec (25.00%)
top 2 operation type: Mean, cpu: 825us, accelerator: 26695722.17sec, total: 26695722.17sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 26695722.17sec, total: 26695722.17sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 26695722.18sec, total: 26695722.18sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 26695722.18sec, total: 26695722.18sec
  train.py:357:image_losses, cpu: 271us, accelerator: 26695722.17sec, total: 26695722.17sec
    train.py:322:loss_fn, cpu: 251us, accelerator: 26695722.17sec, total: 26695722.17sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.31ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.31ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.29ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.89ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.89ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 438us, total: 1.68ms
      train.py:343:hfe, cpu: 531us, accelerator: 683us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 765us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.41ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.14ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.27ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_172750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26657144.54sec, total: 26657144.54sec (25.00%)
top 2 operation type: Mean, cpu: 825us, accelerator: 26657144.54sec, total: 26657144.54sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 26657144.54sec, total: 26657144.54sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 26657144.54sec, total: 26657144.55sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 26657144.54sec, total: 26657144.55sec
  train.py:357:image_losses, cpu: 271us, accelerator: 26657144.54sec, total: 26657144.54sec
    train.py:322:loss_fn, cpu: 251us, accelerator: 26657144.54sec, total: 26657144.54sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.31ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.31ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.29ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.89ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.89ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 437us, total: 1.68ms
      train.py:343:hfe, cpu: 531us, accelerator: 683us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 765us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.40ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.14ms, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.26ms, total: 6.03ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_173000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26618678.24sec, total: 26618678.24sec (25.00%)
top 2 operation type: Mean, cpu: 824us, accelerator: 26618678.24sec, total: 26618678.24sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 75us, accelerator: 26618678.24sec, total: 26618678.24sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 26618678.25sec, total: 26618678.25sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 26618678.25sec, total: 26618678.25sec
  train.py:357:image_losses, cpu: 286us, accelerator: 26618678.24sec, total: 26618678.24sec
    train.py:322:loss_fn, cpu: 266us, accelerator: 26618678.24sec, total: 26618678.24sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.31ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.31ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.29ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.88ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.88ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 437us, total: 1.68ms
      train.py:343:hfe, cpu: 533us, accelerator: 682us, total: 1.22ms
      train.py:344:hfe, cpu: 323us, accelerator: 762us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.40ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.14ms, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.26ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_173250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26580322.80sec, total: 26580322.80sec (25.00%)
top 2 operation type: Mean, cpu: 824us, accelerator: 26580322.80sec, total: 26580322.80sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 26580322.80sec, total: 26580322.80sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 26580322.80sec, total: 26580322.81sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 26580322.80sec, total: 26580322.81sec
  train.py:357:image_losses, cpu: 286us, accelerator: 26580322.80sec, total: 26580322.80sec
    train.py:322:loss_fn, cpu: 266us, accelerator: 26580322.80sec, total: 26580322.80sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.31ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.31ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.88ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.88ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 437us, total: 1.68ms
      train.py:343:hfe, cpu: 546us, accelerator: 682us, total: 1.23ms
      train.py:344:hfe, cpu: 322us, accelerator: 762us, total: 1.09ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.39ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.13ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.13ms, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.26ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_173500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26542077.73sec, total: 26542077.73sec (25.00%)
top 2 operation type: Mean, cpu: 823us, accelerator: 26542077.73sec, total: 26542077.73sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 26542077.73sec, total: 26542077.73sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 26542077.73sec, total: 26542077.74sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 26542077.73sec, total: 26542077.74sec
  train.py:357:image_losses, cpu: 286us, accelerator: 26542077.73sec, total: 26542077.73sec
    train.py:322:loss_fn, cpu: 266us, accelerator: 26542077.73sec, total: 26542077.73sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.31ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.31ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.88ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.88ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 436us, total: 1.68ms
      train.py:343:hfe, cpu: 546us, accelerator: 680us, total: 1.23ms
      train.py:344:hfe, cpu: 322us, accelerator: 760us, total: 1.08ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.43ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.13ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.13ms, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.30ms, total: 6.06ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_173750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26503942.56sec, total: 26503942.56sec (25.00%)
top 2 operation type: Mean, cpu: 823us, accelerator: 26503942.56sec, total: 26503942.56sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 74us, accelerator: 26503942.56sec, total: 26503942.56sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 26503942.56sec, total: 26503942.57sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 26503942.56sec, total: 26503942.57sec
  train.py:357:image_losses, cpu: 286us, accelerator: 26503942.56sec, total: 26503942.56sec
    train.py:322:loss_fn, cpu: 266us, accelerator: 26503942.56sec, total: 26503942.56sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.87ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.87ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 436us, total: 1.68ms
      train.py:343:hfe, cpu: 546us, accelerator: 678us, total: 1.23ms
      train.py:344:hfe, cpu: 321us, accelerator: 760us, total: 1.08ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.42ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.13ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.13ms, total: 7.52ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.29ms, total: 6.06ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_174000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26465916.82sec, total: 26465916.82sec (25.00%)
top 2 operation type: Mean, cpu: 821us, accelerator: 26465916.82sec, total: 26465916.82sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 26465916.82sec, total: 26465916.82sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26465916.82sec, total: 26465916.83sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 26465916.82sec, total: 26465916.83sec
  train.py:357:image_losses, cpu: 285us, accelerator: 26465916.82sec, total: 26465916.82sec
    train.py:322:loss_fn, cpu: 265us, accelerator: 26465916.82sec, total: 26465916.82sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.31ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.31ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.87ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.87ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 435us, total: 1.67ms
      train.py:343:hfe, cpu: 546us, accelerator: 678us, total: 1.23ms
      train.py:344:hfe, cpu: 320us, accelerator: 759us, total: 1.08ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.42ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.12ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.12ms, total: 7.52ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 2.29ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_174250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26428000.03sec, total: 26428000.03sec (25.00%)
top 2 operation type: Mean, cpu: 820us, accelerator: 26428000.03sec, total: 26428000.03sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 26428000.03sec, total: 26428000.03sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26428000.04sec, total: 26428000.04sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 26428000.03sec, total: 26428000.04sec
  train.py:357:image_losses, cpu: 285us, accelerator: 26428000.03sec, total: 26428000.03sec
    train.py:322:loss_fn, cpu: 265us, accelerator: 26428000.03sec, total: 26428000.03sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.87ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.87ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 435us, total: 1.67ms
      train.py:343:hfe, cpu: 545us, accelerator: 678us, total: 1.23ms
      train.py:344:hfe, cpu: 320us, accelerator: 758us, total: 1.08ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.46ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 2.16ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.30ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_174500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26390191.73sec, total: 26390191.74sec (25.00%)
top 2 operation type: Mean, cpu: 820us, accelerator: 26390191.73sec, total: 26390191.73sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 26390191.73sec, total: 26390191.73sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26390191.74sec, total: 26390191.74sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 26390191.74sec, total: 26390191.74sec
  train.py:357:image_losses, cpu: 285us, accelerator: 26390191.73sec, total: 26390191.73sec
    train.py:322:loss_fn, cpu: 265us, accelerator: 26390191.73sec, total: 26390191.73sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.87ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.87ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 435us, total: 1.69ms
      train.py:343:hfe, cpu: 545us, accelerator: 675us, total: 1.23ms
      train.py:344:hfe, cpu: 320us, accelerator: 757us, total: 1.08ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.16ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.31ms, total: 6.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_174750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26352491.46sec, total: 26352491.46sec (25.00%)
top 2 operation type: Mean, cpu: 820us, accelerator: 26352491.46sec, total: 26352491.46sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 87us, accelerator: 26352491.46sec, total: 26352491.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26352491.46sec, total: 26352491.47sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 26352491.46sec, total: 26352491.47sec
  train.py:357:image_losses, cpu: 285us, accelerator: 26352491.46sec, total: 26352491.46sec
    train.py:322:loss_fn, cpu: 265us, accelerator: 26352491.46sec, total: 26352491.46sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.86ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.86ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 434us, total: 1.68ms
      train.py:343:hfe, cpu: 544us, accelerator: 674us, total: 1.22ms
      train.py:344:hfe, cpu: 320us, accelerator: 756us, total: 1.08ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.16ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.31ms, total: 6.07ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_175000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26314898.75sec, total: 26314898.75sec (25.00%)
top 2 operation type: Mean, cpu: 820us, accelerator: 26314898.75sec, total: 26314898.75sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 26314898.75sec, total: 26314898.75sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26314898.75sec, total: 26314898.76sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 26314898.75sec, total: 26314898.76sec
  train.py:357:image_losses, cpu: 285us, accelerator: 26314898.75sec, total: 26314898.75sec
    train.py:322:loss_fn, cpu: 265us, accelerator: 26314898.75sec, total: 26314898.75sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 1.30ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.87ms, accelerator: 1.29ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.86ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.86ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 433us, total: 1.68ms
      train.py:343:hfe, cpu: 560us, accelerator: 673us, total: 1.24ms
      train.py:344:hfe, cpu: 320us, accelerator: 754us, total: 1.08ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.46ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.15ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.72ms, accelerator: 2.31ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2116.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_175250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26277413.14sec, total: 26277413.14sec (25.00%)
top 2 operation type: Mean, cpu: 819us, accelerator: 26277413.14sec, total: 26277413.14sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 26277413.14sec, total: 26277413.14sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26277413.14sec, total: 26277413.15sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 26277413.14sec, total: 26277413.14sec
  train.py:357:image_losses, cpu: 285us, accelerator: 26277413.14sec, total: 26277413.14sec
    train.py:322:loss_fn, cpu: 265us, accelerator: 26277413.14sec, total: 26277413.14sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.86ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.86ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 432us, total: 1.68ms
      train.py:343:hfe, cpu: 560us, accelerator: 673us, total: 1.24ms
      train.py:344:hfe, cpu: 320us, accelerator: 753us, total: 1.08ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.46ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.15ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.30ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_175500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26240034.17sec, total: 26240034.17sec (25.00%)
top 2 operation type: Mean, cpu: 819us, accelerator: 26240034.17sec, total: 26240034.17sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 26240034.17sec, total: 26240034.17sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26240034.17sec, total: 26240034.18sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 26240034.17sec, total: 26240034.18sec
  train.py:357:image_losses, cpu: 285us, accelerator: 26240034.17sec, total: 26240034.17sec
    train.py:322:loss_fn, cpu: 265us, accelerator: 26240034.17sec, total: 26240034.17sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.86ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.86ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 432us, total: 1.68ms
      train.py:343:hfe, cpu: 560us, accelerator: 672us, total: 1.24ms
      train.py:344:hfe, cpu: 320us, accelerator: 753us, total: 1.08ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.45ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 2.15ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.30ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_175750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26202761.40sec, total: 26202761.40sec (25.00%)
top 2 operation type: Mean, cpu: 819us, accelerator: 26202761.39sec, total: 26202761.40sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 26202761.39sec, total: 26202761.39sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26202761.40sec, total: 26202761.40sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 26202761.40sec, total: 26202761.40sec
  train.py:357:image_losses, cpu: 285us, accelerator: 26202761.39sec, total: 26202761.39sec
    train.py:322:loss_fn, cpu: 265us, accelerator: 26202761.39sec, total: 26202761.39sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.85ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.85ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 432us, total: 1.69ms
      train.py:343:hfe, cpu: 560us, accelerator: 670us, total: 1.24ms
      train.py:344:hfe, cpu: 320us, accelerator: 752us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.45ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 2.15ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.30ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_176000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26165594.36sec, total: 26165594.36sec (25.00%)
top 2 operation type: Mean, cpu: 818us, accelerator: 26165594.36sec, total: 26165594.36sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 26165594.36sec, total: 26165594.36sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26165594.36sec, total: 26165594.37sec
train.py:442:<module>, cpu: 5.61ms, accelerator: 26165594.36sec, total: 26165594.37sec
  train.py:357:image_losses, cpu: 284us, accelerator: 26165594.36sec, total: 26165594.36sec
    train.py:322:loss_fn, cpu: 264us, accelerator: 26165594.36sec, total: 26165594.36sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.85ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.85ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 431us, total: 1.69ms
      train.py:343:hfe, cpu: 560us, accelerator: 670us, total: 1.23ms
      train.py:344:hfe, cpu: 320us, accelerator: 750us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.44ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 2.15ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.30ms, total: 6.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_176250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 26128532.61sec, total: 26128532.61sec (25.00%)
top 2 operation type: Mean, cpu: 818us, accelerator: 26128532.61sec, total: 26128532.61sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 26128532.61sec, total: 26128532.61sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26128532.61sec, total: 26128532.62sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 26128532.61sec, total: 26128532.62sec
  train.py:357:image_losses, cpu: 284us, accelerator: 26128532.61sec, total: 26128532.61sec
    train.py:322:loss_fn, cpu: 264us, accelerator: 26128532.61sec, total: 26128532.61sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.29ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.85ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.85ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 431us, total: 1.69ms
      train.py:343:hfe, cpu: 560us, accelerator: 670us, total: 1.23ms
      train.py:344:hfe, cpu: 320us, accelerator: 749us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.44ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 2.14ms, total: 7.62ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.29ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2135.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_176500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26091575.70sec, total: 26091575.71sec (25.00%)
top 2 operation type: Mean, cpu: 817us, accelerator: 26091575.70sec, total: 26091575.70sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 26091575.70sec, total: 26091575.70sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26091575.71sec, total: 26091575.71sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 26091575.71sec, total: 26091575.71sec
  train.py:357:image_losses, cpu: 284us, accelerator: 26091575.70sec, total: 26091575.70sec
    train.py:322:loss_fn, cpu: 264us, accelerator: 26091575.70sec, total: 26091575.70sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.86ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.86ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 431us, total: 1.68ms
      train.py:343:hfe, cpu: 558us, accelerator: 675us, total: 1.24ms
      train.py:344:hfe, cpu: 320us, accelerator: 754us, total: 1.08ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.17ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 2.17ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 2.30ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_176750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 26054723.20sec, total: 26054723.20sec (25.00%)
top 2 operation type: Mean, cpu: 815us, accelerator: 26054723.19sec, total: 26054723.20sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 26054723.19sec, total: 26054723.19sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26054723.20sec, total: 26054723.20sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 26054723.20sec, total: 26054723.20sec
  train.py:357:image_losses, cpu: 285us, accelerator: 26054723.19sec, total: 26054723.19sec
    train.py:322:loss_fn, cpu: 264us, accelerator: 26054723.19sec, total: 26054723.19sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.86ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.86ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 431us, total: 1.68ms
      train.py:343:hfe, cpu: 557us, accelerator: 675us, total: 1.24ms
      train.py:344:hfe, cpu: 319us, accelerator: 753us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.46ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.16ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.30ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_177000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 26017974.64sec, total: 26017974.65sec (25.00%)
top 2 operation type: Mean, cpu: 814us, accelerator: 26017974.64sec, total: 26017974.64sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 26017974.64sec, total: 26017974.64sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 26017974.65sec, total: 26017974.65sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 26017974.65sec, total: 26017974.65sec
  train.py:357:image_losses, cpu: 284us, accelerator: 26017974.64sec, total: 26017974.64sec
    train.py:322:loss_fn, cpu: 264us, accelerator: 26017974.64sec, total: 26017974.64sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.30ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.86ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.86ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 431us, total: 1.69ms
      train.py:343:hfe, cpu: 555us, accelerator: 675us, total: 1.23ms
      train.py:344:hfe, cpu: 318us, accelerator: 752us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.46ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.16ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.16ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.30ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2121.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_177250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25981329.61sec, total: 25981329.61sec (25.00%)
top 2 operation type: Mean, cpu: 814us, accelerator: 25981329.61sec, total: 25981329.61sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 25981329.61sec, total: 25981329.61sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 25981329.61sec, total: 25981329.62sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 25981329.61sec, total: 25981329.62sec
  train.py:357:image_losses, cpu: 284us, accelerator: 25981329.61sec, total: 25981329.61sec
    train.py:322:loss_fn, cpu: 264us, accelerator: 25981329.61sec, total: 25981329.61sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.30ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 431us, total: 1.68ms
      train.py:343:hfe, cpu: 554us, accelerator: 672us, total: 1.23ms
      train.py:344:hfe, cpu: 318us, accelerator: 751us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.48ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.18ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.18ms, total: 7.66ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.30ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_177500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25944787.65sec, total: 25944787.66sec (25.00%)
top 2 operation type: Mean, cpu: 814us, accelerator: 25944787.65sec, total: 25944787.65sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 25944787.65sec, total: 25944787.65sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25944787.66sec, total: 25944787.66sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 25944787.66sec, total: 25944787.66sec
  train.py:357:image_losses, cpu: 284us, accelerator: 25944787.65sec, total: 25944787.65sec
    train.py:322:loss_fn, cpu: 264us, accelerator: 25944787.65sec, total: 25944787.65sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.29ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.29ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 429us, total: 1.68ms
      train.py:343:hfe, cpu: 554us, accelerator: 672us, total: 1.23ms
      train.py:344:hfe, cpu: 317us, accelerator: 750us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.18ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.18ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.29ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_177750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25908348.35sec, total: 25908348.35sec (25.00%)
top 2 operation type: Mean, cpu: 813us, accelerator: 25908348.35sec, total: 25908348.35sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 25908348.34sec, total: 25908348.34sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25908348.35sec, total: 25908348.35sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 25908348.35sec, total: 25908348.35sec
  train.py:357:image_losses, cpu: 283us, accelerator: 25908348.34sec, total: 25908348.34sec
    train.py:322:loss_fn, cpu: 263us, accelerator: 25908348.34sec, total: 25908348.34sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.29ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.29ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 429us, total: 1.68ms
      train.py:343:hfe, cpu: 554us, accelerator: 672us, total: 1.23ms
      train.py:344:hfe, cpu: 317us, accelerator: 749us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.18ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.18ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.29ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_178000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25872011.25sec, total: 25872011.25sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25872011.25sec, total: 25872011.25sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 25872011.25sec, total: 25872011.25sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25872011.26sec, total: 25872011.26sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 25872011.25sec, total: 25872011.26sec
  train.py:357:image_losses, cpu: 283us, accelerator: 25872011.25sec, total: 25872011.25sec
    train.py:322:loss_fn, cpu: 263us, accelerator: 25872011.25sec, total: 25872011.25sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 1.29ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.29ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 428us, total: 1.68ms
      train.py:343:hfe, cpu: 554us, accelerator: 673us, total: 1.23ms
      train.py:344:hfe, cpu: 317us, accelerator: 752us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.17ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.17ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.30ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_178250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25835775.94sec, total: 25835775.94sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25835775.94sec, total: 25835775.94sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 25835775.94sec, total: 25835775.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25835775.95sec, total: 25835775.95sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25835775.94sec, total: 25835775.95sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25835775.94sec, total: 25835775.94sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25835775.94sec, total: 25835775.94sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.29ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.29ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 428us, total: 1.68ms
      train.py:343:hfe, cpu: 554us, accelerator: 673us, total: 1.23ms
      train.py:344:hfe, cpu: 317us, accelerator: 752us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.17ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.17ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.30ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_178500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25799641.99sec, total: 25799641.99sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25799641.99sec, total: 25799641.99sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 25799641.99sec, total: 25799641.99sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25799641.99sec, total: 25799642.00sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 25799641.99sec, total: 25799642.00sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25799641.99sec, total: 25799641.99sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25799641.99sec, total: 25799641.99sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.29ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.29ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 428us, total: 1.68ms
      train.py:343:hfe, cpu: 554us, accelerator: 674us, total: 1.23ms
      train.py:344:hfe, cpu: 317us, accelerator: 750us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.46ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.17ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.17ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.30ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_178750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25763608.97sec, total: 25763608.97sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25763608.97sec, total: 25763608.97sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 86us, accelerator: 25763608.97sec, total: 25763608.97sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25763608.97sec, total: 25763608.98sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25763608.97sec, total: 25763608.98sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25763608.97sec, total: 25763608.97sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25763608.97sec, total: 25763608.97sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.29ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.29ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.28ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.86ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.86ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 428us, total: 1.68ms
      train.py:343:hfe, cpu: 553us, accelerator: 676us, total: 1.23ms
      train.py:344:hfe, cpu: 317us, accelerator: 755us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.52ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.21ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.21ms, total: 7.68ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.31ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_179000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25727676.46sec, total: 25727676.46sec (25.00%)
top 2 operation type: Mean, cpu: 817us, accelerator: 25727676.46sec, total: 25727676.46sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25727676.46sec, total: 25727676.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25727676.46sec, total: 25727676.47sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25727676.46sec, total: 25727676.47sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25727676.46sec, total: 25727676.46sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25727676.46sec, total: 25727676.46sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.29ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.29ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.28ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 428us, total: 1.68ms
      train.py:343:hfe, cpu: 557us, accelerator: 672us, total: 1.23ms
      train.py:344:hfe, cpu: 317us, accelerator: 755us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.51ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.21ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.21ms, total: 7.67ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.30ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_179250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25691844.04sec, total: 25691844.04sec (25.00%)
top 2 operation type: Mean, cpu: 816us, accelerator: 25691844.04sec, total: 25691844.04sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25691844.04sec, total: 25691844.04sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25691844.05sec, total: 25691844.05sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25691844.04sec, total: 25691844.05sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25691844.04sec, total: 25691844.04sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25691844.04sec, total: 25691844.04sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.32ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 428us, total: 1.68ms
      train.py:343:hfe, cpu: 557us, accelerator: 671us, total: 1.23ms
      train.py:344:hfe, cpu: 317us, accelerator: 754us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.51ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.21ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.21ms, total: 7.66ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.30ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_179500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25656111.30sec, total: 25656111.30sec (25.00%)
top 2 operation type: Mean, cpu: 816us, accelerator: 25656111.30sec, total: 25656111.30sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25656111.29sec, total: 25656111.30sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25656111.30sec, total: 25656111.30sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25656111.30sec, total: 25656111.30sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25656111.30sec, total: 25656111.30sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25656111.30sec, total: 25656111.30sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.30ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 427us, total: 1.68ms
      train.py:343:hfe, cpu: 557us, accelerator: 671us, total: 1.23ms
      train.py:344:hfe, cpu: 317us, accelerator: 754us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.50ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.20ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.20ms, total: 7.66ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.30ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_179750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25620477.81sec, total: 25620477.81sec (25.00%)
top 2 operation type: Mean, cpu: 815us, accelerator: 25620477.81sec, total: 25620477.81sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25620477.81sec, total: 25620477.81sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25620477.81sec, total: 25620477.82sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25620477.81sec, total: 25620477.82sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25620477.81sec, total: 25620477.81sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25620477.81sec, total: 25620477.81sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.30ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 427us, total: 1.68ms
      train.py:343:hfe, cpu: 556us, accelerator: 670us, total: 1.23ms
      train.py:344:hfe, cpu: 316us, accelerator: 753us, total: 1.07ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.50ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.20ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.20ms, total: 7.66ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.30ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_180000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25584943.17sec, total: 25584943.17sec (25.00%)
top 2 operation type: Mean, cpu: 815us, accelerator: 25584943.16sec, total: 25584943.17sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25584943.16sec, total: 25584943.16sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25584943.17sec, total: 25584943.17sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25584943.17sec, total: 25584943.17sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25584943.16sec, total: 25584943.16sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25584943.16sec, total: 25584943.16sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 1.32ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.86ms, accelerator: 1.30ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.85ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.85ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 427us, total: 1.67ms
      train.py:343:hfe, cpu: 557us, accelerator: 670us, total: 1.23ms
      train.py:344:hfe, cpu: 316us, accelerator: 751us, total: 1.07ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.50ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.20ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.20ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 2.29ms, total: 6.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_180250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25549506.96sec, total: 25549506.96sec (25.00%)
top 2 operation type: Mean, cpu: 815us, accelerator: 25549506.96sec, total: 25549506.96sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25549506.95sec, total: 25549506.95sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25549506.96sec, total: 25549506.96sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25549506.96sec, total: 25549506.96sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25549506.95sec, total: 25549506.96sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25549506.95sec, total: 25549506.96sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.32ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.84ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 427us, total: 1.67ms
      train.py:343:hfe, cpu: 556us, accelerator: 666us, total: 1.23ms
      train.py:344:hfe, cpu: 316us, accelerator: 751us, total: 1.07ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.49ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.20ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.20ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.29ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_180500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25514168.77sec, total: 25514168.77sec (25.00%)
top 2 operation type: Mean, cpu: 815us, accelerator: 25514168.77sec, total: 25514168.77sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25514168.77sec, total: 25514168.77sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25514168.78sec, total: 25514168.78sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 25514168.77sec, total: 25514168.78sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25514168.77sec, total: 25514168.77sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25514168.77sec, total: 25514168.77sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.32ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.84ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 427us, total: 1.67ms
      train.py:343:hfe, cpu: 555us, accelerator: 666us, total: 1.23ms
      train.py:344:hfe, cpu: 316us, accelerator: 749us, total: 1.07ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.48ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.19ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.19ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.29ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_180750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25478928.21sec, total: 25478928.21sec (25.00%)
top 2 operation type: Mean, cpu: 814us, accelerator: 25478928.21sec, total: 25478928.21sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25478928.21sec, total: 25478928.21sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25478928.21sec, total: 25478928.22sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 25478928.21sec, total: 25478928.22sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25478928.21sec, total: 25478928.21sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25478928.21sec, total: 25478928.21sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.32ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.84ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 426us, total: 1.67ms
      train.py:343:hfe, cpu: 555us, accelerator: 669us, total: 1.23ms
      train.py:344:hfe, cpu: 316us, accelerator: 749us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.49ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.20ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.20ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.29ms, total: 6.02ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_181000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25443784.86sec, total: 25443784.86sec (25.00%)
top 2 operation type: Mean, cpu: 814us, accelerator: 25443784.86sec, total: 25443784.86sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25443784.86sec, total: 25443784.86sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25443784.86sec, total: 25443784.87sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 25443784.86sec, total: 25443784.87sec
  train.py:357:image_losses, cpu: 282us, accelerator: 25443784.86sec, total: 25443784.86sec
    train.py:322:loss_fn, cpu: 262us, accelerator: 25443784.86sec, total: 25443784.86sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.31ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.84ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 425us, total: 1.67ms
      train.py:343:hfe, cpu: 556us, accelerator: 669us, total: 1.23ms
      train.py:344:hfe, cpu: 316us, accelerator: 750us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.48ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.19ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.19ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.29ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_181250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25408738.32sec, total: 25408738.32sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25408738.32sec, total: 25408738.32sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25408738.32sec, total: 25408738.32sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25408738.33sec, total: 25408738.33sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25408738.32sec, total: 25408738.33sec
  train.py:357:image_losses, cpu: 281us, accelerator: 25408738.32sec, total: 25408738.32sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 25408738.32sec, total: 25408738.32sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 1.32ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.32ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.84ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 424us, total: 1.68ms
      train.py:343:hfe, cpu: 555us, accelerator: 669us, total: 1.23ms
      train.py:344:hfe, cpu: 316us, accelerator: 749us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.19ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.19ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.28ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_181500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25373788.20sec, total: 25373788.20sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25373788.20sec, total: 25373788.20sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25373788.20sec, total: 25373788.20sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25373788.21sec, total: 25373788.21sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25373788.20sec, total: 25373788.21sec
  train.py:357:image_losses, cpu: 281us, accelerator: 25373788.20sec, total: 25373788.20sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 25373788.20sec, total: 25373788.20sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.84ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 423us, total: 1.68ms
      train.py:343:hfe, cpu: 554us, accelerator: 667us, total: 1.23ms
      train.py:344:hfe, cpu: 316us, accelerator: 749us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.19ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.19ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.28ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_181750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25338934.10sec, total: 25338934.10sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25338934.10sec, total: 25338934.10sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 85us, accelerator: 25338934.09sec, total: 25338934.09sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25338934.10sec, total: 25338934.10sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 25338934.10sec, total: 25338934.10sec
  train.py:357:image_losses, cpu: 281us, accelerator: 25338934.10sec, total: 25338934.10sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 25338934.10sec, total: 25338934.10sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.84ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.84ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 423us, total: 1.68ms
      train.py:343:hfe, cpu: 553us, accelerator: 667us, total: 1.23ms
      train.py:344:hfe, cpu: 316us, accelerator: 748us, total: 1.06ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.46ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.19ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.19ms, total: 7.63ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.28ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_182000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25304175.61sec, total: 25304175.62sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25304175.61sec, total: 25304175.61sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 25304175.61sec, total: 25304175.61sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25304175.62sec, total: 25304175.62sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 25304175.62sec, total: 25304175.62sec
  train.py:357:image_losses, cpu: 281us, accelerator: 25304175.61sec, total: 25304175.61sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 25304175.61sec, total: 25304175.61sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.84ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.84ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 423us, total: 1.67ms
      train.py:343:hfe, cpu: 553us, accelerator: 667us, total: 1.23ms
      train.py:344:hfe, cpu: 316us, accelerator: 747us, total: 1.06ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.46ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.18ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.18ms, total: 7.62ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.28ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_182250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25269512.36sec, total: 25269512.36sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25269512.36sec, total: 25269512.36sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 25269512.36sec, total: 25269512.36sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25269512.36sec, total: 25269512.37sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 25269512.36sec, total: 25269512.37sec
  train.py:357:image_losses, cpu: 281us, accelerator: 25269512.36sec, total: 25269512.36sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 25269512.36sec, total: 25269512.36sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.83ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 422us, total: 1.67ms
      train.py:343:hfe, cpu: 553us, accelerator: 667us, total: 1.22ms
      train.py:344:hfe, cpu: 316us, accelerator: 744us, total: 1.06ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.18ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 2.18ms, total: 7.62ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.29ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_182500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25234943.94sec, total: 25234943.94sec (25.00%)
top 2 operation type: Mean, cpu: 813us, accelerator: 25234943.94sec, total: 25234943.94sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 25234943.94sec, total: 25234943.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25234943.95sec, total: 25234943.95sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 25234943.95sec, total: 25234943.95sec
  train.py:357:image_losses, cpu: 281us, accelerator: 25234943.94sec, total: 25234943.94sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 25234943.94sec, total: 25234943.94sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.83ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 422us, total: 1.67ms
      train.py:343:hfe, cpu: 553us, accelerator: 666us, total: 1.22ms
      train.py:344:hfe, cpu: 316us, accelerator: 743us, total: 1.06ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.47ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.18ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 2.18ms, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.29ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_182750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25200469.98sec, total: 25200469.98sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25200469.98sec, total: 25200469.98sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 25200469.97sec, total: 25200469.97sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25200469.98sec, total: 25200469.98sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 25200469.98sec, total: 25200469.98sec
  train.py:357:image_losses, cpu: 281us, accelerator: 25200469.97sec, total: 25200469.97sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 25200469.97sec, total: 25200469.97sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.30ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.83ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 422us, total: 1.67ms
      train.py:343:hfe, cpu: 553us, accelerator: 665us, total: 1.22ms
      train.py:344:hfe, cpu: 316us, accelerator: 743us, total: 1.06ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.46ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.18ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.18ms, total: 7.60ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 2.29ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_183000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25166090.07sec, total: 25166090.07sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25166090.07sec, total: 25166090.07sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 25166090.07sec, total: 25166090.07sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25166090.08sec, total: 25166090.08sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 25166090.07sec, total: 25166090.08sec
  train.py:357:image_losses, cpu: 281us, accelerator: 25166090.07sec, total: 25166090.07sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 25166090.07sec, total: 25166090.07sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.29ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.83ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 421us, total: 1.67ms
      train.py:343:hfe, cpu: 553us, accelerator: 665us, total: 1.22ms
      train.py:344:hfe, cpu: 315us, accelerator: 741us, total: 1.06ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.46ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.18ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.18ms, total: 7.60ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.28ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_183250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25131803.84sec, total: 25131803.85sec (25.00%)
top 2 operation type: Mean, cpu: 811us, accelerator: 25131803.84sec, total: 25131803.85sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 25131803.84sec, total: 25131803.84sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25131803.85sec, total: 25131803.85sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 25131803.85sec, total: 25131803.85sec
  train.py:357:image_losses, cpu: 281us, accelerator: 25131803.84sec, total: 25131803.84sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 25131803.84sec, total: 25131803.84sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.82ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.82ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 421us, total: 1.67ms
      train.py:343:hfe, cpu: 553us, accelerator: 663us, total: 1.22ms
      train.py:344:hfe, cpu: 315us, accelerator: 741us, total: 1.06ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.46ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.18ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.18ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.28ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_183500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25097610.91sec, total: 25097610.92sec (25.00%)
top 2 operation type: Mean, cpu: 812us, accelerator: 25097610.91sec, total: 25097610.91sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 25097610.91sec, total: 25097610.91sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25097610.92sec, total: 25097610.92sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 25097610.92sec, total: 25097610.92sec
  train.py:357:image_losses, cpu: 281us, accelerator: 25097610.91sec, total: 25097610.91sec
    train.py:322:loss_fn, cpu: 261us, accelerator: 25097610.91sec, total: 25097610.91sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.29ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.82ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.82ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 420us, total: 1.67ms
      train.py:343:hfe, cpu: 552us, accelerator: 661us, total: 1.22ms
      train.py:344:hfe, cpu: 315us, accelerator: 741us, total: 1.06ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.45ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.17ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.17ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.28ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_183750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25063510.90sec, total: 25063510.90sec (25.00%)
top 2 operation type: Mean, cpu: 835us, accelerator: 25063510.90sec, total: 25063510.90sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 25063510.90sec, total: 25063510.90sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25063510.90sec, total: 25063510.91sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25063510.90sec, total: 25063510.91sec
  train.py:357:image_losses, cpu: 304us, accelerator: 25063510.90sec, total: 25063510.90sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 25063510.90sec, total: 25063510.90sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.82ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.82ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 419us, total: 1.67ms
      train.py:343:hfe, cpu: 551us, accelerator: 659us, total: 1.21ms
      train.py:344:hfe, cpu: 315us, accelerator: 739us, total: 1.06ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.44ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.17ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.17ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.28ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_184000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25029503.42sec, total: 25029503.42sec (25.00%)
top 2 operation type: Mean, cpu: 833us, accelerator: 25029503.42sec, total: 25029503.42sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 25029503.42sec, total: 25029503.42sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 25029503.43sec, total: 25029503.43sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 25029503.42sec, total: 25029503.43sec
  train.py:357:image_losses, cpu: 304us, accelerator: 25029503.42sec, total: 25029503.42sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 25029503.42sec, total: 25029503.42sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.31ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.82ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.82ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 419us, total: 1.66ms
      train.py:343:hfe, cpu: 550us, accelerator: 659us, total: 1.21ms
      train.py:344:hfe, cpu: 315us, accelerator: 739us, total: 1.06ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.44ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.16ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.16ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.28ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_184250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24995588.11sec, total: 24995588.11sec (25.00%)
top 2 operation type: Mean, cpu: 832us, accelerator: 24995588.11sec, total: 24995588.11sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 24995588.10sec, total: 24995588.10sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24995588.11sec, total: 24995588.11sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 24995588.11sec, total: 24995588.11sec
  train.py:357:image_losses, cpu: 303us, accelerator: 24995588.10sec, total: 24995588.11sec
    train.py:322:loss_fn, cpu: 283us, accelerator: 24995588.10sec, total: 24995588.11sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 419us, total: 1.66ms
      train.py:343:hfe, cpu: 549us, accelerator: 659us, total: 1.21ms
      train.py:344:hfe, cpu: 315us, accelerator: 737us, total: 1.05ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.43ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 2.16ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.16ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 2.27ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_184500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24961764.58sec, total: 24961764.58sec (25.00%)
top 2 operation type: Mean, cpu: 835us, accelerator: 24961764.58sec, total: 24961764.58sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 24961764.58sec, total: 24961764.58sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24961764.58sec, total: 24961764.58sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 24961764.58sec, total: 24961764.58sec
  train.py:357:image_losses, cpu: 306us, accelerator: 24961764.58sec, total: 24961764.58sec
    train.py:322:loss_fn, cpu: 286us, accelerator: 24961764.58sec, total: 24961764.58sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 419us, total: 1.66ms
      train.py:343:hfe, cpu: 548us, accelerator: 659us, total: 1.21ms
      train.py:344:hfe, cpu: 315us, accelerator: 736us, total: 1.05ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.42ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.15ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.15ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.27ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_184750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24928032.46sec, total: 24928032.46sec (25.00%)
top 2 operation type: Mean, cpu: 835us, accelerator: 24928032.46sec, total: 24928032.46sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 24928032.46sec, total: 24928032.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24928032.47sec, total: 24928032.47sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 24928032.46sec, total: 24928032.47sec
  train.py:357:image_losses, cpu: 306us, accelerator: 24928032.46sec, total: 24928032.46sec
    train.py:322:loss_fn, cpu: 286us, accelerator: 24928032.46sec, total: 24928032.46sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 417us, total: 1.66ms
      train.py:343:hfe, cpu: 548us, accelerator: 659us, total: 1.21ms
      train.py:344:hfe, cpu: 315us, accelerator: 736us, total: 1.05ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.42ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.15ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.15ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.27ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_185000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24894391.39sec, total: 24894391.39sec (25.00%)
top 2 operation type: Mean, cpu: 833us, accelerator: 24894391.39sec, total: 24894391.39sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 24894391.39sec, total: 24894391.39sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24894391.40sec, total: 24894391.40sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 24894391.40sec, total: 24894391.40sec
  train.py:357:image_losses, cpu: 305us, accelerator: 24894391.39sec, total: 24894391.39sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 24894391.39sec, total: 24894391.39sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.31ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.31ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 419us, total: 1.66ms
      train.py:343:hfe, cpu: 548us, accelerator: 657us, total: 1.21ms
      train.py:344:hfe, cpu: 314us, accelerator: 734us, total: 1.05ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.42ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.15ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.15ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.27ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_185250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24860841.00sec, total: 24860841.00sec (25.00%)
top 2 operation type: Mean, cpu: 834us, accelerator: 24860841.00sec, total: 24860841.00sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24860841.00sec, total: 24860841.00sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 24860841.00sec, total: 24860841.01sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 24860841.00sec, total: 24860841.01sec
  train.py:357:image_losses, cpu: 305us, accelerator: 24860841.00sec, total: 24860841.00sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 24860841.00sec, total: 24860841.00sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.82ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.82ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 419us, total: 1.66ms
      train.py:343:hfe, cpu: 548us, accelerator: 655us, total: 1.21ms
      train.py:344:hfe, cpu: 315us, accelerator: 748us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.41ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.15ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.15ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.27ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_185500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24827380.92sec, total: 24827380.92sec (25.00%)
top 2 operation type: Mean, cpu: 833us, accelerator: 24827380.92sec, total: 24827380.92sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24827380.92sec, total: 24827380.92sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24827380.92sec, total: 24827380.93sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 24827380.92sec, total: 24827380.93sec
  train.py:357:image_losses, cpu: 305us, accelerator: 24827380.92sec, total: 24827380.92sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 24827380.92sec, total: 24827380.92sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.85ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.82ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.82ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 419us, total: 1.66ms
      train.py:343:hfe, cpu: 548us, accelerator: 655us, total: 1.21ms
      train.py:344:hfe, cpu: 314us, accelerator: 747us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.41ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.15ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.15ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.26ms, total: 5.98ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_185750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24794010.78sec, total: 24794010.78sec (25.00%)
top 2 operation type: Mean, cpu: 844us, accelerator: 24794010.78sec, total: 24794010.78sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24794010.78sec, total: 24794010.78sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24794010.79sec, total: 24794010.79sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 24794010.78sec, total: 24794010.79sec
  train.py:357:image_losses, cpu: 305us, accelerator: 24794010.78sec, total: 24794010.78sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 24794010.78sec, total: 24794010.78sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.82ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.82ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 424us, total: 1.67ms
      train.py:343:hfe, cpu: 548us, accelerator: 655us, total: 1.21ms
      train.py:344:hfe, cpu: 325us, accelerator: 746us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.42ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 2.14ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.14ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.28ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2123.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_186000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24760730.23sec, total: 24760730.23sec (25.00%)
top 2 operation type: Mean, cpu: 844us, accelerator: 24760730.23sec, total: 24760730.23sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24760730.23sec, total: 24760730.23sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24760730.24sec, total: 24760730.24sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 24760730.23sec, total: 24760730.24sec
  train.py:357:image_losses, cpu: 305us, accelerator: 24760730.23sec, total: 24760730.23sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 24760730.23sec, total: 24760730.23sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 1.30ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.29ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.83ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.83ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 425us, total: 1.67ms
      train.py:343:hfe, cpu: 548us, accelerator: 655us, total: 1.21ms
      train.py:344:hfe, cpu: 325us, accelerator: 746us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.42ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.14ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.28ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_186250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24727538.90sec, total: 24727538.91sec (25.00%)
top 2 operation type: Mean, cpu: 844us, accelerator: 24727538.90sec, total: 24727538.90sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24727538.90sec, total: 24727538.90sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24727538.91sec, total: 24727538.91sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 24727538.91sec, total: 24727538.91sec
  train.py:357:image_losses, cpu: 305us, accelerator: 24727538.90sec, total: 24727538.90sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 24727538.90sec, total: 24727538.90sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.29ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.82ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.82ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 425us, total: 1.67ms
      train.py:343:hfe, cpu: 548us, accelerator: 655us, total: 1.21ms
      train.py:344:hfe, cpu: 325us, accelerator: 744us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.45ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.15ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.15ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.30ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_186500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24694436.44sec, total: 24694436.44sec (25.00%)
top 2 operation type: Mean, cpu: 842us, accelerator: 24694436.44sec, total: 24694436.44sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24694436.44sec, total: 24694436.44sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24694436.45sec, total: 24694436.45sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 24694436.44sec, total: 24694436.45sec
  train.py:357:image_losses, cpu: 305us, accelerator: 24694436.44sec, total: 24694436.44sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 24694436.44sec, total: 24694436.44sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.29ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.82ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.82ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 425us, total: 1.67ms
      train.py:343:hfe, cpu: 548us, accelerator: 653us, total: 1.21ms
      train.py:344:hfe, cpu: 325us, accelerator: 744us, total: 1.07ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.44ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 2.14ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.30ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_186750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24661422.49sec, total: 24661422.49sec (25.00%)
top 2 operation type: Mean, cpu: 842us, accelerator: 24661422.49sec, total: 24661422.49sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24661422.49sec, total: 24661422.49sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24661422.49sec, total: 24661422.50sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 24661422.49sec, total: 24661422.50sec
  train.py:357:image_losses, cpu: 305us, accelerator: 24661422.49sec, total: 24661422.49sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 24661422.49sec, total: 24661422.49sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.29ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.82ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.82ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 425us, total: 1.67ms
      train.py:343:hfe, cpu: 548us, accelerator: 653us, total: 1.21ms
      train.py:344:hfe, cpu: 325us, accelerator: 742us, total: 1.07ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.14ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.30ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_187000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24628496.69sec, total: 24628496.69sec (25.00%)
top 2 operation type: Mean, cpu: 839us, accelerator: 24628496.69sec, total: 24628496.69sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24628496.69sec, total: 24628496.69sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24628496.70sec, total: 24628496.70sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 24628496.69sec, total: 24628496.70sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24628496.69sec, total: 24628496.69sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24628496.69sec, total: 24628496.69sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.82ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.82ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 425us, total: 1.67ms
      train.py:343:hfe, cpu: 547us, accelerator: 652us, total: 1.20ms
      train.py:344:hfe, cpu: 324us, accelerator: 742us, total: 1.07ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.14ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.14ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.30ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_187250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24595658.70sec, total: 24595658.70sec (25.00%)
top 2 operation type: Mean, cpu: 839us, accelerator: 24595658.70sec, total: 24595658.70sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24595658.69sec, total: 24595658.69sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24595658.70sec, total: 24595658.70sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 24595658.70sec, total: 24595658.70sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24595658.70sec, total: 24595658.70sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24595658.70sec, total: 24595658.70sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.82ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.82ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 424us, total: 1.66ms
      train.py:343:hfe, cpu: 546us, accelerator: 651us, total: 1.20ms
      train.py:344:hfe, cpu: 324us, accelerator: 742us, total: 1.07ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.43ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.13ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.29ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_187500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24562908.15sec, total: 24562908.15sec (25.00%)
top 2 operation type: Mean, cpu: 839us, accelerator: 24562908.15sec, total: 24562908.15sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24562908.15sec, total: 24562908.15sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24562908.16sec, total: 24562908.16sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 24562908.15sec, total: 24562908.16sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24562908.15sec, total: 24562908.15sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24562908.15sec, total: 24562908.15sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.82ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.82ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 427us, total: 1.66ms
      train.py:343:hfe, cpu: 545us, accelerator: 651us, total: 1.20ms
      train.py:344:hfe, cpu: 324us, accelerator: 740us, total: 1.07ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.42ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.13ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.29ms, total: 5.99ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_187750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24530244.71sec, total: 24530244.71sec (25.00%)
top 2 operation type: Mean, cpu: 839us, accelerator: 24530244.71sec, total: 24530244.71sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24530244.71sec, total: 24530244.71sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24530244.71sec, total: 24530244.72sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 24530244.71sec, total: 24530244.72sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24530244.71sec, total: 24530244.71sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24530244.71sec, total: 24530244.71sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 426us, total: 1.66ms
      train.py:343:hfe, cpu: 545us, accelerator: 650us, total: 1.20ms
      train.py:344:hfe, cpu: 324us, accelerator: 738us, total: 1.07ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.42ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.13ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.29ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_188000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24497668.02sec, total: 24497668.03sec (25.00%)
top 2 operation type: Mean, cpu: 839us, accelerator: 24497668.02sec, total: 24497668.02sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24497668.02sec, total: 24497668.02sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 24497668.03sec, total: 24497668.03sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 24497668.03sec, total: 24497668.03sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24497668.02sec, total: 24497668.02sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24497668.02sec, total: 24497668.02sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 425us, total: 1.66ms
      train.py:343:hfe, cpu: 544us, accelerator: 649us, total: 1.20ms
      train.py:344:hfe, cpu: 323us, accelerator: 737us, total: 1.06ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.42ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.13ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.29ms, total: 5.98ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_188250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24465177.75sec, total: 24465177.75sec (25.00%)
top 2 operation type: Mean, cpu: 839us, accelerator: 24465177.75sec, total: 24465177.75sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 24465177.75sec, total: 24465177.75sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 24465177.75sec, total: 24465177.76sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 24465177.75sec, total: 24465177.76sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24465177.75sec, total: 24465177.75sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24465177.75sec, total: 24465177.75sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.81ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 426us, total: 1.66ms
      train.py:343:hfe, cpu: 543us, accelerator: 649us, total: 1.20ms
      train.py:344:hfe, cpu: 323us, accelerator: 736us, total: 1.06ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.42ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.13ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.29ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_188500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24432773.54sec, total: 24432773.54sec (25.00%)
top 2 operation type: Mean, cpu: 839us, accelerator: 24432773.54sec, total: 24432773.54sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24432773.54sec, total: 24432773.54sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 24432773.54sec, total: 24432773.55sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 24432773.54sec, total: 24432773.55sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24432773.54sec, total: 24432773.54sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24432773.54sec, total: 24432773.54sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.30ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.81ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.81ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 426us, total: 1.66ms
      train.py:343:hfe, cpu: 543us, accelerator: 648us, total: 1.20ms
      train.py:344:hfe, cpu: 322us, accelerator: 736us, total: 1.06ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.41ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.13ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.13ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.29ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_188750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24400455.06sec, total: 24400455.06sec (25.00%)
top 2 operation type: Mean, cpu: 839us, accelerator: 24400455.06sec, total: 24400455.06sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24400455.05sec, total: 24400455.05sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24400455.06sec, total: 24400455.06sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 24400455.06sec, total: 24400455.06sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24400455.05sec, total: 24400455.06sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24400455.05sec, total: 24400455.06sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.29ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.29ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 426us, total: 1.66ms
      train.py:343:hfe, cpu: 551us, accelerator: 648us, total: 1.20ms
      train.py:344:hfe, cpu: 324us, accelerator: 735us, total: 1.06ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.41ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.12ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.12ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.28ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_189000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24368221.96sec, total: 24368221.96sec (25.00%)
top 2 operation type: Mean, cpu: 838us, accelerator: 24368221.96sec, total: 24368221.96sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24368221.96sec, total: 24368221.96sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24368221.96sec, total: 24368221.97sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 24368221.96sec, total: 24368221.97sec
  train.py:357:image_losses, cpu: 303us, accelerator: 24368221.96sec, total: 24368221.96sec
    train.py:322:loss_fn, cpu: 283us, accelerator: 24368221.96sec, total: 24368221.96sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.29ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.29ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.15ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.82ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.82ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 426us, total: 1.66ms
      train.py:343:hfe, cpu: 550us, accelerator: 652us, total: 1.20ms
      train.py:344:hfe, cpu: 323us, accelerator: 738us, total: 1.07ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.41ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.12ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.12ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.29ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_189250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24336073.91sec, total: 24336073.91sec (25.00%)
top 2 operation type: Mean, cpu: 838us, accelerator: 24336073.91sec, total: 24336073.91sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24336073.91sec, total: 24336073.91sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24336073.91sec, total: 24336073.92sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 24336073.91sec, total: 24336073.92sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24336073.91sec, total: 24336073.91sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24336073.91sec, total: 24336073.91sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.29ms, total: 4.23ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.29ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.15ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 426us, total: 1.66ms
      train.py:343:hfe, cpu: 551us, accelerator: 648us, total: 1.20ms
      train.py:344:hfe, cpu: 324us, accelerator: 737us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.40ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.12ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 2.12ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.28ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_189500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24304010.57sec, total: 24304010.57sec (25.00%)
top 2 operation type: Mean, cpu: 838us, accelerator: 24304010.57sec, total: 24304010.57sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24304010.57sec, total: 24304010.57sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24304010.57sec, total: 24304010.58sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 24304010.57sec, total: 24304010.58sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24304010.57sec, total: 24304010.57sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24304010.57sec, total: 24304010.57sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.29ms, total: 4.23ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.29ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.15ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 426us, total: 1.65ms
      train.py:343:hfe, cpu: 550us, accelerator: 648us, total: 1.20ms
      train.py:344:hfe, cpu: 323us, accelerator: 737us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.11ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.11ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.28ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_189750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24272031.61sec, total: 24272031.61sec (25.00%)
top 2 operation type: Mean, cpu: 838us, accelerator: 24272031.61sec, total: 24272031.61sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24272031.61sec, total: 24272031.61sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24272031.61sec, total: 24272031.62sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 24272031.61sec, total: 24272031.62sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24272031.61sec, total: 24272031.61sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24272031.61sec, total: 24272031.61sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.29ms, total: 4.23ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.29ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.28ms, total: 4.15ms
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.81ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.81ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 424us, total: 1.65ms
      train.py:343:hfe, cpu: 550us, accelerator: 648us, total: 1.20ms
      train.py:344:hfe, cpu: 323us, accelerator: 736us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.11ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 2.11ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.28ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_190000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24240136.69sec, total: 24240136.69sec (25.00%)
top 2 operation type: Mean, cpu: 837us, accelerator: 24240136.69sec, total: 24240136.69sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24240136.69sec, total: 24240136.69sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 24240136.70sec, total: 24240136.70sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 24240136.69sec, total: 24240136.70sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24240136.69sec, total: 24240136.69sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24240136.69sec, total: 24240136.69sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.31ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.31ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.29ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.80ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.80ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 422us, total: 1.65ms
      train.py:343:hfe, cpu: 550us, accelerator: 647us, total: 1.20ms
      train.py:344:hfe, cpu: 323us, accelerator: 736us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.11ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.11ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.27ms, total: 5.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_190250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24208325.49sec, total: 24208325.49sec (25.00%)
top 2 operation type: Mean, cpu: 835us, accelerator: 24208325.49sec, total: 24208325.49sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24208325.49sec, total: 24208325.49sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24208325.49sec, total: 24208325.50sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 24208325.49sec, total: 24208325.50sec
  train.py:357:image_losses, cpu: 303us, accelerator: 24208325.49sec, total: 24208325.49sec
    train.py:322:loss_fn, cpu: 283us, accelerator: 24208325.49sec, total: 24208325.49sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.31ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 1.31ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.84ms, accelerator: 1.29ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.80ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.80ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 421us, total: 1.65ms
      train.py:343:hfe, cpu: 548us, accelerator: 645us, total: 1.20ms
      train.py:344:hfe, cpu: 322us, accelerator: 735us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.10ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.27ms, total: 5.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_190500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24176597.67sec, total: 24176597.67sec (25.00%)
top 2 operation type: Mean, cpu: 835us, accelerator: 24176597.67sec, total: 24176597.67sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24176597.67sec, total: 24176597.67sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24176597.67sec, total: 24176597.68sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 24176597.67sec, total: 24176597.68sec
  train.py:357:image_losses, cpu: 303us, accelerator: 24176597.67sec, total: 24176597.67sec
    train.py:322:loss_fn, cpu: 283us, accelerator: 24176597.67sec, total: 24176597.67sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.30ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.29ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.80ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.80ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 419us, total: 1.65ms
      train.py:343:hfe, cpu: 548us, accelerator: 644us, total: 1.20ms
      train.py:344:hfe, cpu: 321us, accelerator: 734us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.37ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.10ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.27ms, total: 5.98ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_190750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24144952.91sec, total: 24144952.91sec (25.00%)
top 2 operation type: Mean, cpu: 836us, accelerator: 24144952.91sec, total: 24144952.91sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24144952.91sec, total: 24144952.91sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24144952.91sec, total: 24144952.92sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 24144952.91sec, total: 24144952.92sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24144952.91sec, total: 24144952.91sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24144952.91sec, total: 24144952.91sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.30ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.29ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.80ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.80ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 419us, total: 1.65ms
      train.py:343:hfe, cpu: 547us, accelerator: 644us, total: 1.20ms
      train.py:344:hfe, cpu: 321us, accelerator: 733us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.37ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.10ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.27ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_191000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24113390.88sec, total: 24113390.88sec (25.00%)
top 2 operation type: Mean, cpu: 836us, accelerator: 24113390.88sec, total: 24113390.88sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24113390.88sec, total: 24113390.88sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 24113390.88sec, total: 24113390.89sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 24113390.88sec, total: 24113390.89sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24113390.88sec, total: 24113390.88sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24113390.88sec, total: 24113390.88sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.30ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.29ms, total: 4.16ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.79ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.79ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 419us, total: 1.65ms
      train.py:343:hfe, cpu: 569us, accelerator: 644us, total: 1.22ms
      train.py:344:hfe, cpu: 321us, accelerator: 732us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.36ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.10ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.27ms, total: 5.99ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_191250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24081911.26sec, total: 24081911.26sec (25.00%)
top 2 operation type: Mean, cpu: 836us, accelerator: 24081911.26sec, total: 24081911.26sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24081911.25sec, total: 24081911.25sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 24081911.26sec, total: 24081911.26sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 24081911.26sec, total: 24081911.26sec
  train.py:357:image_losses, cpu: 304us, accelerator: 24081911.26sec, total: 24081911.26sec
    train.py:322:loss_fn, cpu: 284us, accelerator: 24081911.26sec, total: 24081911.26sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.24ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.30ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.29ms, total: 4.15ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.79ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.79ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 419us, total: 1.65ms
      train.py:343:hfe, cpu: 569us, accelerator: 644us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 730us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.36ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.10ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.27ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_191500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24050513.72sec, total: 24050513.72sec (25.00%)
top 2 operation type: Mean, cpu: 837us, accelerator: 24050513.72sec, total: 24050513.72sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24050513.72sec, total: 24050513.72sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 24050513.72sec, total: 24050513.73sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 24050513.72sec, total: 24050513.73sec
  train.py:357:image_losses, cpu: 305us, accelerator: 24050513.72sec, total: 24050513.72sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 24050513.72sec, total: 24050513.72sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.23ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.30ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.29ms, total: 4.15ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.80ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.80ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 419us, total: 1.65ms
      train.py:343:hfe, cpu: 568us, accelerator: 645us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 737us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.39ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.13ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.13ms, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.26ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_191750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24019197.95sec, total: 24019197.95sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 24019197.95sec, total: 24019197.95sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 24019197.94sec, total: 24019197.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 24019197.95sec, total: 24019197.95sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 24019197.95sec, total: 24019197.95sec
  train.py:357:image_losses, cpu: 305us, accelerator: 24019197.94sec, total: 24019197.94sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 24019197.94sec, total: 24019197.94sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.23ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.30ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.29ms, total: 4.15ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.80ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.80ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 418us, total: 1.65ms
      train.py:343:hfe, cpu: 567us, accelerator: 644us, total: 1.22ms
      train.py:344:hfe, cpu: 323us, accelerator: 737us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.40ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.12ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.12ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.28ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_192000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23987963.62sec, total: 23987963.62sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 23987963.62sec, total: 23987963.62sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 23987963.62sec, total: 23987963.62sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23987963.62sec, total: 23987963.63sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23987963.62sec, total: 23987963.63sec
  train.py:357:image_losses, cpu: 305us, accelerator: 23987963.62sec, total: 23987963.62sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 23987963.62sec, total: 23987963.62sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.30ms, total: 4.23ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.30ms, total: 4.22ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.29ms, total: 4.15ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.80ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.80ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 418us, total: 1.65ms
      train.py:343:hfe, cpu: 570us, accelerator: 644us, total: 1.22ms
      train.py:344:hfe, cpu: 323us, accelerator: 737us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.40ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.12ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.12ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.28ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_192250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23956810.42sec, total: 23956810.42sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 23956810.42sec, total: 23956810.42sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 82us, accelerator: 23956810.42sec, total: 23956810.42sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23956810.42sec, total: 23956810.43sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23956810.42sec, total: 23956810.43sec
  train.py:357:image_losses, cpu: 305us, accelerator: 23956810.42sec, total: 23956810.42sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 23956810.42sec, total: 23956810.42sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.30ms, total: 4.23ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.30ms, total: 4.21ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.28ms, total: 4.15ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.80ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.80ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 417us, total: 1.64ms
      train.py:343:hfe, cpu: 570us, accelerator: 644us, total: 1.22ms
      train.py:344:hfe, cpu: 323us, accelerator: 736us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.39ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.12ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.12ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.27ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_192500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23925738.03sec, total: 23925738.03sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 23925738.03sec, total: 23925738.03sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23925738.03sec, total: 23925738.03sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23925738.04sec, total: 23925738.04sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23925738.03sec, total: 23925738.04sec
  train.py:357:image_losses, cpu: 305us, accelerator: 23925738.03sec, total: 23925738.03sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 23925738.03sec, total: 23925738.03sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.32ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.32ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.31ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.79ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.79ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 417us, total: 1.64ms
      train.py:343:hfe, cpu: 570us, accelerator: 641us, total: 1.22ms
      train.py:344:hfe, cpu: 323us, accelerator: 736us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.40ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 2.12ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.12ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.28ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_192750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23894746.14sec, total: 23894746.14sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 23894746.14sec, total: 23894746.14sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23894746.14sec, total: 23894746.14sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23894746.15sec, total: 23894746.15sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23894746.15sec, total: 23894746.15sec
  train.py:357:image_losses, cpu: 305us, accelerator: 23894746.14sec, total: 23894746.14sec
    train.py:322:loss_fn, cpu: 285us, accelerator: 23894746.14sec, total: 23894746.14sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.32ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.32ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.31ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.79ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.79ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 417us, total: 1.64ms
      train.py:343:hfe, cpu: 570us, accelerator: 641us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 736us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.39ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.12ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.12ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.28ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_193000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23863834.44sec, total: 23863834.44sec (25.00%)
top 2 operation type: Mean, cpu: 842us, accelerator: 23863834.44sec, total: 23863834.44sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23863834.44sec, total: 23863834.44sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23863834.44sec, total: 23863834.45sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23863834.44sec, total: 23863834.45sec
  train.py:357:image_losses, cpu: 306us, accelerator: 23863834.44sec, total: 23863834.44sec
    train.py:322:loss_fn, cpu: 286us, accelerator: 23863834.44sec, total: 23863834.44sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.32ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.32ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.30ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.79ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.79ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 417us, total: 1.64ms
      train.py:343:hfe, cpu: 570us, accelerator: 640us, total: 1.22ms
      train.py:344:hfe, cpu: 322us, accelerator: 733us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.39ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.11ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.11ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.28ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_193250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23833002.61sec, total: 23833002.61sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 23833002.61sec, total: 23833002.61sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23833002.61sec, total: 23833002.61sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23833002.62sec, total: 23833002.62sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23833002.62sec, total: 23833002.62sec
  train.py:357:image_losses, cpu: 307us, accelerator: 23833002.61sec, total: 23833002.61sec
    train.py:322:loss_fn, cpu: 287us, accelerator: 23833002.61sec, total: 23833002.61sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 1.32ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.32ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.30ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.79ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.79ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 417us, total: 1.64ms
      train.py:343:hfe, cpu: 570us, accelerator: 640us, total: 1.21ms
      train.py:344:hfe, cpu: 323us, accelerator: 732us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.11ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.11ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.27ms, total: 5.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_193500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23802250.35sec, total: 23802250.35sec (25.00%)
top 2 operation type: Mean, cpu: 842us, accelerator: 23802250.35sec, total: 23802250.35sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23802250.35sec, total: 23802250.35sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23802250.36sec, total: 23802250.36sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 23802250.35sec, total: 23802250.36sec
  train.py:357:image_losses, cpu: 307us, accelerator: 23802250.35sec, total: 23802250.35sec
    train.py:322:loss_fn, cpu: 287us, accelerator: 23802250.35sec, total: 23802250.35sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.33ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.33ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.32ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.79ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.79ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 416us, total: 1.64ms
      train.py:343:hfe, cpu: 570us, accelerator: 640us, total: 1.22ms
      train.py:344:hfe, cpu: 323us, accelerator: 731us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.11ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.11ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.27ms, total: 5.97ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_193750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23771577.35sec, total: 23771577.35sec (25.00%)
top 2 operation type: Mean, cpu: 842us, accelerator: 23771577.35sec, total: 23771577.35sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23771577.35sec, total: 23771577.35sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23771577.35sec, total: 23771577.36sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23771577.35sec, total: 23771577.36sec
  train.py:357:image_losses, cpu: 307us, accelerator: 23771577.35sec, total: 23771577.35sec
    train.py:322:loss_fn, cpu: 287us, accelerator: 23771577.35sec, total: 23771577.35sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.33ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.33ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.32ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.79ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.79ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 416us, total: 1.65ms
      train.py:343:hfe, cpu: 570us, accelerator: 640us, total: 1.21ms
      train.py:344:hfe, cpu: 322us, accelerator: 731us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.10ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.27ms, total: 5.98ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_194000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23740983.30sec, total: 23740983.30sec (25.00%)
top 2 operation type: Mean, cpu: 840us, accelerator: 23740983.30sec, total: 23740983.30sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23740983.30sec, total: 23740983.30sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23740983.30sec, total: 23740983.31sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23740983.30sec, total: 23740983.31sec
  train.py:357:image_losses, cpu: 306us, accelerator: 23740983.30sec, total: 23740983.30sec
    train.py:322:loss_fn, cpu: 286us, accelerator: 23740983.30sec, total: 23740983.30sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.33ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.33ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.32ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.78ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.78ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 415us, total: 1.64ms
      train.py:343:hfe, cpu: 569us, accelerator: 639us, total: 1.21ms
      train.py:344:hfe, cpu: 322us, accelerator: 729us, total: 1.05ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.37ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.10ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.27ms, total: 5.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_194250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23710467.89sec, total: 23710467.90sec (25.00%)
top 2 operation type: Mean, cpu: 839us, accelerator: 23710467.89sec, total: 23710467.90sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23710467.89sec, total: 23710467.89sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23710467.90sec, total: 23710467.90sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23710467.90sec, total: 23710467.90sec
  train.py:357:image_losses, cpu: 306us, accelerator: 23710467.89sec, total: 23710467.89sec
    train.py:322:loss_fn, cpu: 286us, accelerator: 23710467.89sec, total: 23710467.89sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.33ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.33ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.31ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.78ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.78ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 414us, total: 1.64ms
      train.py:343:hfe, cpu: 569us, accelerator: 637us, total: 1.21ms
      train.py:344:hfe, cpu: 322us, accelerator: 728us, total: 1.05ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.37ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.10ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.27ms, total: 5.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_194500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23680030.84sec, total: 23680030.84sec (25.00%)
top 2 operation type: Mean, cpu: 842us, accelerator: 23680030.84sec, total: 23680030.84sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23680030.84sec, total: 23680030.84sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23680030.84sec, total: 23680030.85sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23680030.84sec, total: 23680030.85sec
  train.py:357:image_losses, cpu: 307us, accelerator: 23680030.84sec, total: 23680030.84sec
    train.py:322:loss_fn, cpu: 287us, accelerator: 23680030.84sec, total: 23680030.84sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.33ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.33ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.31ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.78ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.78ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 416us, total: 1.65ms
      train.py:343:hfe, cpu: 569us, accelerator: 638us, total: 1.21ms
      train.py:344:hfe, cpu: 322us, accelerator: 728us, total: 1.05ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 2.10ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.28ms, total: 5.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_194750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23649671.82sec, total: 23649671.83sec (25.00%)
top 2 operation type: Mean, cpu: 842us, accelerator: 23649671.82sec, total: 23649671.82sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23649671.82sec, total: 23649671.82sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23649671.83sec, total: 23649671.83sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23649671.83sec, total: 23649671.83sec
  train.py:357:image_losses, cpu: 307us, accelerator: 23649671.82sec, total: 23649671.82sec
    train.py:322:loss_fn, cpu: 287us, accelerator: 23649671.82sec, total: 23649671.82sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.33ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.33ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.31ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.78ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.78ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 416us, total: 1.65ms
      train.py:343:hfe, cpu: 567us, accelerator: 637us, total: 1.21ms
      train.py:344:hfe, cpu: 322us, accelerator: 728us, total: 1.05ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 2.10ms, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.29ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_195000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23619390.55sec, total: 23619390.56sec (25.00%)
top 2 operation type: Mean, cpu: 841us, accelerator: 23619390.55sec, total: 23619390.55sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23619390.55sec, total: 23619390.55sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23619390.56sec, total: 23619390.56sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23619390.56sec, total: 23619390.56sec
  train.py:357:image_losses, cpu: 307us, accelerator: 23619390.55sec, total: 23619390.55sec
    train.py:322:loss_fn, cpu: 287us, accelerator: 23619390.55sec, total: 23619390.55sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.33ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.33ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.31ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.78ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.78ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 415us, total: 1.65ms
      train.py:343:hfe, cpu: 567us, accelerator: 637us, total: 1.21ms
      train.py:344:hfe, cpu: 322us, accelerator: 726us, total: 1.05ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.10ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.29ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_195250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23589186.73sec, total: 23589186.73sec (25.00%)
top 2 operation type: Mean, cpu: 840us, accelerator: 23589186.73sec, total: 23589186.73sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23589186.73sec, total: 23589186.73sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23589186.73sec, total: 23589186.74sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23589186.73sec, total: 23589186.74sec
  train.py:357:image_losses, cpu: 307us, accelerator: 23589186.73sec, total: 23589186.73sec
    train.py:322:loss_fn, cpu: 287us, accelerator: 23589186.73sec, total: 23589186.73sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.33ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.33ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.31ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.79ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.79ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 415us, total: 1.65ms
      train.py:343:hfe, cpu: 567us, accelerator: 637us, total: 1.21ms
      train.py:344:hfe, cpu: 322us, accelerator: 740us, total: 1.07ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.09ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.09ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.29ms, total: 5.99ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_195500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23559060.05sec, total: 23559060.06sec (25.00%)
top 2 operation type: Mean, cpu: 840us, accelerator: 23559060.05sec, total: 23559060.05sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23559060.05sec, total: 23559060.05sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23559060.06sec, total: 23559060.06sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23559060.06sec, total: 23559060.06sec
  train.py:357:image_losses, cpu: 307us, accelerator: 23559060.05sec, total: 23559060.05sec
    train.py:322:loss_fn, cpu: 287us, accelerator: 23559060.05sec, total: 23559060.05sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.33ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.33ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.31ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.79ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.79ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 415us, total: 1.65ms
      train.py:343:hfe, cpu: 567us, accelerator: 635us, total: 1.21ms
      train.py:344:hfe, cpu: 322us, accelerator: 739us, total: 1.07ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.09ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.09ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.28ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_195750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23529010.23sec, total: 23529010.23sec (25.00%)
top 2 operation type: Mean, cpu: 839us, accelerator: 23529010.23sec, total: 23529010.23sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23529010.23sec, total: 23529010.23sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23529010.24sec, total: 23529010.24sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23529010.23sec, total: 23529010.24sec
  train.py:357:image_losses, cpu: 307us, accelerator: 23529010.23sec, total: 23529010.23sec
    train.py:322:loss_fn, cpu: 287us, accelerator: 23529010.23sec, total: 23529010.23sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.32ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.32ms, total: 4.23ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.31ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.79ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.79ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 415us, total: 1.65ms
      train.py:343:hfe, cpu: 567us, accelerator: 633us, total: 1.21ms
      train.py:344:hfe, cpu: 322us, accelerator: 738us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.40ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.09ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 2.09ms, total: 7.55ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.31ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_196000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23499036.97sec, total: 23499036.97sec (25.00%)
top 2 operation type: Mean, cpu: 847us, accelerator: 23499036.97sec, total: 23499036.97sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 81us, accelerator: 23499036.97sec, total: 23499036.97sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23499036.97sec, total: 23499036.98sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 23499036.97sec, total: 23499036.98sec
  train.py:357:image_losses, cpu: 315us, accelerator: 23499036.97sec, total: 23499036.97sec
    train.py:322:loss_fn, cpu: 295us, accelerator: 23499036.97sec, total: 23499036.97sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.34ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.34ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.32ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.79ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.79ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 415us, total: 1.65ms
      train.py:343:hfe, cpu: 567us, accelerator: 633us, total: 1.20ms
      train.py:344:hfe, cpu: 321us, accelerator: 738us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.08ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.08ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.31ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_196250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23469139.98sec, total: 23469139.98sec (25.00%)
top 2 operation type: Mean, cpu: 845us, accelerator: 23469139.98sec, total: 23469139.98sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 23469139.98sec, total: 23469139.98sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23469139.98sec, total: 23469139.99sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 23469139.98sec, total: 23469139.99sec
  train.py:357:image_losses, cpu: 315us, accelerator: 23469139.98sec, total: 23469139.98sec
    train.py:322:loss_fn, cpu: 295us, accelerator: 23469139.98sec, total: 23469139.98sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.34ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.34ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.32ms, total: 4.18ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.78ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.78ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 415us, total: 1.65ms
      train.py:343:hfe, cpu: 567us, accelerator: 633us, total: 1.20ms
      train.py:344:hfe, cpu: 320us, accelerator: 736us, total: 1.06ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.08ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.08ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.31ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_196500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23439318.96sec, total: 23439318.96sec (25.00%)
top 2 operation type: Mean, cpu: 845us, accelerator: 23439318.96sec, total: 23439318.96sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 23439318.96sec, total: 23439318.96sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23439318.96sec, total: 23439318.97sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 23439318.96sec, total: 23439318.97sec
  train.py:357:image_losses, cpu: 315us, accelerator: 23439318.96sec, total: 23439318.96sec
    train.py:322:loss_fn, cpu: 295us, accelerator: 23439318.96sec, total: 23439318.96sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.34ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.34ms, total: 4.24ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.32ms, total: 4.17ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.78ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.78ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 414us, total: 1.65ms
      train.py:343:hfe, cpu: 567us, accelerator: 633us, total: 1.20ms
      train.py:344:hfe, cpu: 320us, accelerator: 736us, total: 1.06ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.08ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.08ms, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.31ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_196750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23409573.63sec, total: 23409573.63sec (25.00%)
top 2 operation type: Mean, cpu: 845us, accelerator: 23409573.63sec, total: 23409573.63sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 23409573.63sec, total: 23409573.63sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23409573.64sec, total: 23409573.64sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 23409573.63sec, total: 23409573.64sec
  train.py:357:image_losses, cpu: 315us, accelerator: 23409573.63sec, total: 23409573.63sec
    train.py:322:loss_fn, cpu: 295us, accelerator: 23409573.63sec, total: 23409573.63sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.35ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.35ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.33ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.78ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.78ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 412us, total: 1.66ms
      train.py:343:hfe, cpu: 568us, accelerator: 631us, total: 1.20ms
      train.py:344:hfe, cpu: 327us, accelerator: 736us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.39ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.08ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.08ms, total: 7.52ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 2.31ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_197000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23379903.70sec, total: 23379903.71sec (25.00%)
top 2 operation type: Mean, cpu: 844us, accelerator: 23379903.70sec, total: 23379903.70sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 80us, accelerator: 23379903.70sec, total: 23379903.70sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23379903.71sec, total: 23379903.71sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 23379903.71sec, total: 23379903.71sec
  train.py:357:image_losses, cpu: 314us, accelerator: 23379903.70sec, total: 23379903.70sec
    train.py:322:loss_fn, cpu: 294us, accelerator: 23379903.70sec, total: 23379903.70sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.35ms, total: 4.27ms
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 1.35ms, total: 4.25ms
      train.py:349:msssim, cpu: 2.83ms, accelerator: 1.33ms, total: 4.19ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.78ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.78ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 412us, total: 1.66ms
      train.py:343:hfe, cpu: 567us, accelerator: 631us, total: 1.20ms
      train.py:344:hfe, cpu: 327us, accelerator: 734us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.07ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 2.07ms, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.31ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_197250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23350308.89sec, total: 23350308.89sec (25.00%)
top 2 operation type: Mean, cpu: 844us, accelerator: 23350308.89sec, total: 23350308.89sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 23350308.89sec, total: 23350308.89sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23350308.89sec, total: 23350308.90sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 23350308.89sec, total: 23350308.90sec
  train.py:357:image_losses, cpu: 314us, accelerator: 23350308.89sec, total: 23350308.89sec
    train.py:322:loss_fn, cpu: 294us, accelerator: 23350308.89sec, total: 23350308.89sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.36ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.36ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.34ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.78ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.78ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 412us, total: 1.65ms
      train.py:343:hfe, cpu: 566us, accelerator: 633us, total: 1.20ms
      train.py:344:hfe, cpu: 327us, accelerator: 738us, total: 1.07ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.38ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.07ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 2.07ms, total: 7.50ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.31ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_197500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23320788.90sec, total: 23320788.90sec (25.00%)
top 2 operation type: Mean, cpu: 844us, accelerator: 23320788.90sec, total: 23320788.90sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 23320788.90sec, total: 23320788.90sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 23320788.91sec, total: 23320788.91sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 23320788.91sec, total: 23320788.91sec
  train.py:357:image_losses, cpu: 314us, accelerator: 23320788.90sec, total: 23320788.90sec
    train.py:322:loss_fn, cpu: 294us, accelerator: 23320788.90sec, total: 23320788.90sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.36ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.36ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.34ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.78ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.78ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 412us, total: 1.66ms
      train.py:343:hfe, cpu: 565us, accelerator: 632us, total: 1.20ms
      train.py:344:hfe, cpu: 327us, accelerator: 738us, total: 1.07ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.37ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.07ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.07ms, total: 7.50ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.31ms, total: 6.02ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_197750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23291343.46sec, total: 23291343.46sec (25.00%)
top 2 operation type: Mean, cpu: 844us, accelerator: 23291343.46sec, total: 23291343.46sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 23291343.46sec, total: 23291343.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 23291343.47sec, total: 23291343.47sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 23291343.46sec, total: 23291343.47sec
  train.py:357:image_losses, cpu: 314us, accelerator: 23291343.46sec, total: 23291343.46sec
    train.py:322:loss_fn, cpu: 294us, accelerator: 23291343.46sec, total: 23291343.46sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.36ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.36ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.34ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.78ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.78ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 412us, total: 1.66ms
      train.py:343:hfe, cpu: 563us, accelerator: 630us, total: 1.20ms
      train.py:344:hfe, cpu: 328us, accelerator: 737us, total: 1.07ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.37ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.07ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.07ms, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.30ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_198000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23261972.29sec, total: 23261972.29sec (25.00%)
top 2 operation type: Mean, cpu: 844us, accelerator: 23261972.28sec, total: 23261972.29sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 84us, accelerator: 23261972.28sec, total: 23261972.28sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 23261972.29sec, total: 23261972.29sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 23261972.29sec, total: 23261972.29sec
  train.py:357:image_losses, cpu: 314us, accelerator: 23261972.28sec, total: 23261972.28sec
    train.py:322:loss_fn, cpu: 294us, accelerator: 23261972.28sec, total: 23261972.28sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.35ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.34ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.79ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.79ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 412us, total: 1.65ms
      train.py:343:hfe, cpu: 563us, accelerator: 633us, total: 1.20ms
      train.py:344:hfe, cpu: 328us, accelerator: 743us, total: 1.07ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.37ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.07ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 2.07ms, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 2.30ms, total: 6.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_198250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23232675.09sec, total: 23232675.09sec (25.00%)
top 2 operation type: Mean, cpu: 844us, accelerator: 23232675.09sec, total: 23232675.09sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 23232675.09sec, total: 23232675.09sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 23232675.09sec, total: 23232675.10sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 23232675.09sec, total: 23232675.10sec
  train.py:357:image_losses, cpu: 314us, accelerator: 23232675.09sec, total: 23232675.09sec
    train.py:322:loss_fn, cpu: 294us, accelerator: 23232675.09sec, total: 23232675.09sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.35ms, total: 4.27ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.34ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.79ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.79ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 411us, total: 1.66ms
      train.py:343:hfe, cpu: 563us, accelerator: 636us, total: 1.20ms
      train.py:344:hfe, cpu: 327us, accelerator: 745us, total: 1.07ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.37ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.06ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.06ms, total: 7.48ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.30ms, total: 6.02ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_198500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23203451.60sec, total: 23203451.60sec (25.00%)
top 2 operation type: Mean, cpu: 843us, accelerator: 23203451.60sec, total: 23203451.60sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 23203451.60sec, total: 23203451.60sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 23203451.60sec, total: 23203451.61sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 23203451.60sec, total: 23203451.61sec
  train.py:357:image_losses, cpu: 313us, accelerator: 23203451.60sec, total: 23203451.60sec
    train.py:322:loss_fn, cpu: 293us, accelerator: 23203451.60sec, total: 23203451.60sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.35ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.34ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.80ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.80ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 411us, total: 1.66ms
      train.py:343:hfe, cpu: 563us, accelerator: 637us, total: 1.20ms
      train.py:344:hfe, cpu: 327us, accelerator: 750us, total: 1.08ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.36ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.06ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.06ms, total: 7.48ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.30ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_198750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23174301.54sec, total: 23174301.54sec (25.00%)
top 2 operation type: Mean, cpu: 843us, accelerator: 23174301.54sec, total: 23174301.54sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 23174301.53sec, total: 23174301.53sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 23174301.54sec, total: 23174301.54sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 23174301.54sec, total: 23174301.54sec
  train.py:357:image_losses, cpu: 312us, accelerator: 23174301.53sec, total: 23174301.53sec
    train.py:322:loss_fn, cpu: 292us, accelerator: 23174301.53sec, total: 23174301.53sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.35ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.33ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.80ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.80ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 411us, total: 1.65ms
      train.py:343:hfe, cpu: 563us, accelerator: 636us, total: 1.20ms
      train.py:344:hfe, cpu: 327us, accelerator: 749us, total: 1.08ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.36ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.06ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.06ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.30ms, total: 6.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF/timelines/t.json_199000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 23145224.62sec, total: 23145224.62sec (25.00%)
top 2 operation type: Mean, cpu: 843us, accelerator: 23145224.62sec, total: 23145224.62sec (25.00%)
top 3 operation type: model/lambda/add-1-TransposeNHWCToNCHW-LayoutOptimizer, cpu: 83us, accelerator: 23145224.62sec, total: 23145224.62sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 23145224.62sec, total: 23145224.63sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 23145224.62sec, total: 23145224.63sec
  train.py:357:image_losses, cpu: 312us, accelerator: 23145224.62sec, total: 23145224.62sec
    train.py:322:loss_fn, cpu: 292us, accelerator: 23145224.62sec, total: 23145224.62sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 1.35ms, total: 4.28ms
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 1.35ms, total: 4.26ms
      train.py:349:msssim, cpu: 2.82ms, accelerator: 1.33ms, total: 4.20ms
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.80ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.80ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 411us, total: 1.65ms
      train.py:343:hfe, cpu: 562us, accelerator: 636us, total: 1.20ms
      train.py:344:hfe, cpu: 326us, accelerator: 749us, total: 1.08ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 4.35ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 2.06ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 2.06ms, total: 7.47ms
  __init__.py:185:compute_gradients, cpu: 3.67ms, accelerator: 2.30ms, total: 6.01ms
-------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
-------------------------------------------------------
