/software/openmpi-3.1.2-el7-x86_64/bin/mpirun
/software/Anaconda3-5.3.0-el7-x86_64/bin/python
/software/cuda-9.0-el7-x86_64/bin/nvcc
Parsing Inputs...
Parsing Inputs...
Parsing Inputs...
Parsing Inputs...
midway2-gpu05:8986:9046 [0] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:8986:9046 [0] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu05:8988:9044 [2] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:8988:9044 [2] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu05:8986:9046 [0] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu05:8986:9046 [0] INFO Using internal Network IB
midway2-gpu05:8986:9046 [0] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu05:8986:9046 [0] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:8986:9046 [0] INFO NET/Socket : 1 interfaces found
NCCL version 2.2.13+cuda9.0
midway2-gpu05:8989:9045 [3] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:8989:9045 [3] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu05:8987:9047 [1] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:8987:9047 [1] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu05:8988:9044 [2] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu05:8988:9044 [2] INFO Using internal Network IB
midway2-gpu05:8988:9044 [2] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu05:8989:9045 [3] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu05:8989:9045 [3] INFO Using internal Network IB
midway2-gpu05:8989:9045 [3] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu05:8987:9047 [1] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu05:8987:9047 [1] INFO Using internal Network IB
midway2-gpu05:8987:9047 [1] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu05:8986:9046 [0] INFO comm 0x7ff484888760 rank 0 nranks 4
midway2-gpu05:8986:9046 [0] INFO CUDA Dev 0, IB Ports : mlx5_0/1(SOC) 
midway2-gpu05:8987:9047 [1] INFO comm 0x7f688c8709d0 rank 1 nranks 4
midway2-gpu05:8987:9047 [1] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:8987:9047 [1] INFO NET/Socket : 1 interfaces found
midway2-gpu05:8987:9047 [1] INFO CUDA Dev 1, IB Ports : mlx5_0/1(SOC) 
midway2-gpu05:8988:9044 [2] INFO comm 0x7f14c4870890 rank 2 nranks 4
midway2-gpu05:8988:9044 [2] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:8988:9044 [2] INFO NET/Socket : 1 interfaces found
midway2-gpu05:8988:9044 [2] INFO CUDA Dev 2, IB Ports : mlx5_0/1(PHB) 
midway2-gpu05:8989:9045 [3] INFO comm 0x7f564c870ae0 rank 3 nranks 4
midway2-gpu05:8989:9045 [3] INFO NET : Using interface ib0:172.25.221.195<0>
midway2-gpu05:8989:9045 [3] INFO NET/Socket : 1 interfaces found
midway2-gpu05:8989:9045 [3] INFO CUDA Dev 3, IB Ports : mlx5_0/1(PHB) 
midway2-gpu05:8986:9046 [0] INFO Using 128 threads
midway2-gpu05:8986:9046 [0] INFO Min Comp Cap 3
midway2-gpu05:8986:9046 [0] INFO NCCL_SINGLE_RING_THRESHOLD=131072
midway2-gpu05:8986:9046 [0] INFO Ring 00 :    0   1   2   3
midway2-gpu05:8986:9046 [0] INFO Ring 01 :    0   1   2   3
midway2-gpu05:8989:9045 [3] INFO 3[8989] -> 0[8986] via direct shared memory
midway2-gpu05:8987:9047 [1] INFO 1[8987] -> 2[8988] via direct shared memory
midway2-gpu05:8986:9046 [0] INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC
midway2-gpu05:8988:9044 [2] INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC
midway2-gpu05:8989:9045 [3] INFO 3[8989] -> 0[8986] via direct shared memory
midway2-gpu05:8987:9047 [1] INFO 1[8987] -> 2[8988] via direct shared memory
midway2-gpu05:8986:9046 [0] INFO Ring 01 : 0[0] -> 1[1] via P2P/IPC
midway2-gpu05:8988:9044 [2] INFO Ring 01 : 2[2] -> 3[3] via P2P/IPC
midway2-gpu05:8986:9046 [0] INFO Launch mode Parallel
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_0.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.47sec, accelerator: 0us, total: 8.47sec (90.92%)
top 2 operation type: ImageSummary, cpu: 396.14ms, accelerator: 0us, total: 396.14ms (4.25%)
top 3 operation type: HistogramSummary, cpu: 55.84ms, accelerator: 0us, total: 55.84ms (0.60%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 168.62ms, accelerator: 0us, total: 168.62ms
top 3 graph node: autoencoded, cpu: 147.16ms, accelerator: 0us, total: 147.16ms
train.py:511:<module>, cpu: 8.49sec, accelerator: 12.60ms, total: 8.50sec
  __init__.py:194:compute_gradients, cpu: 8.48sec, accelerator: 313us, total: 8.48sec
    __init__.py:83:allreduce, cpu: 8.47sec, accelerator: 0us, total: 8.47sec
    __init__.py:86:allreduce, cpu: 16.11ms, accelerator: 313us, total: 16.43ms
  __init__.py:185:compute_gradients, cpu: 6.78ms, accelerator: 12.29ms, total: 19.07ms
train.py:447:<module>, cpu: 168.62ms, accelerator: 0us, total: 168.62ms
train.py:448:<module>, cpu: 147.16ms, accelerator: 0us, total: 147.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.76
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.69sec, accelerator: 0us, total: 8.69sec (91.79%)
top 2 operation type: ImageSummary, cpu: 332.44ms, accelerator: 0us, total: 332.44ms (3.51%)
top 3 operation type: HistogramSummary, cpu: 75.83ms, accelerator: 0us, total: 75.83ms (0.80%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 142.53ms, accelerator: 0us, total: 142.53ms
top 3 graph node: autoencoded, cpu: 120.92ms, accelerator: 0us, total: 120.92ms
train.py:511:<module>, cpu: 8.70sec, accelerator: 25.47ms, total: 8.73sec
  __init__.py:194:compute_gradients, cpu: 8.70sec, accelerator: 16.24ms, total: 8.71sec
    __init__.py:83:allreduce, cpu: 8.69sec, accelerator: 0us, total: 8.69sec
    __init__.py:86:allreduce, cpu: 10.63ms, accelerator: 16.24ms, total: 26.88ms
  __init__.py:185:compute_gradients, cpu: 5.87ms, accelerator: 9.23ms, total: 15.12ms
train.py:447:<module>, cpu: 142.53ms, accelerator: 0us, total: 142.53ms
train.py:448:<module>, cpu: 120.92ms, accelerator: 0us, total: 120.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 9.49sec, accelerator: 0us, total: 9.49sec (93.17%)
top 2 operation type: ImageSummary, cpu: 321.71ms, accelerator: 0us, total: 321.71ms (3.16%)
top 3 operation type: HistogramSummary, cpu: 92.69ms, accelerator: 0us, total: 92.69ms (0.91%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 140.27ms, accelerator: 0us, total: 140.27ms
top 3 graph node: autoencoded, cpu: 104.89ms, accelerator: 0us, total: 104.89ms
train.py:511:<module>, cpu: 9.50sec, accelerator: 20.83ms, total: 9.52sec
  __init__.py:194:compute_gradients, cpu: 9.49sec, accelerator: 10.92ms, total: 9.50sec
    __init__.py:83:allreduce, cpu: 9.49sec, accelerator: 0us, total: 9.49sec
    __init__.py:86:allreduce, cpu: 7.83ms, accelerator: 10.92ms, total: 18.77ms
  __init__.py:185:compute_gradients, cpu: 4.53ms, accelerator: 9.90ms, total: 14.46ms
train.py:447:<module>, cpu: 140.27ms, accelerator: 0us, total: 140.27ms
train.py:448:<module>, cpu: 104.90ms, accelerator: 0us, total: 104.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 9.50sec, accelerator: 0us, total: 9.50sec (92.70%)
top 2 operation type: ImageSummary, cpu: 368.41ms, accelerator: 0us, total: 368.41ms (3.59%)
top 3 operation type: HistogramSummary, cpu: 101.34ms, accelerator: 0us, total: 101.34ms (0.99%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 161.12ms, accelerator: 0us, total: 161.12ms
top 3 graph node: autoencoded, cpu: 116.82ms, accelerator: 0us, total: 116.82ms
train.py:511:<module>, cpu: 9.51sec, accelerator: 18.55ms, total: 9.53sec
  __init__.py:194:compute_gradients, cpu: 9.51sec, accelerator: 8.27ms, total: 9.52sec
    __init__.py:83:allreduce, cpu: 9.50sec, accelerator: 0us, total: 9.50sec
    __init__.py:86:allreduce, cpu: 6.47ms, accelerator: 8.27ms, total: 14.76ms
  __init__.py:185:compute_gradients, cpu: 4.29ms, accelerator: 10.28ms, total: 14.60ms
train.py:447:<module>, cpu: 161.12ms, accelerator: 0us, total: 161.12ms
train.py:448:<module>, cpu: 116.83ms, accelerator: 0us, total: 116.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_1000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 9.57sec, accelerator: 0us, total: 9.57sec (93.07%)
top 2 operation type: ImageSummary, cpu: 363.67ms, accelerator: 0us, total: 363.67ms (3.54%)
top 3 operation type: HistogramSummary, cpu: 97.82ms, accelerator: 0us, total: 97.82ms (0.95%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 147.22ms, accelerator: 0us, total: 147.22ms
top 3 graph node: autoencoded, cpu: 123.16ms, accelerator: 0us, total: 123.16ms
train.py:511:<module>, cpu: 9.58sec, accelerator: 14.97ms, total: 9.60sec
  __init__.py:194:compute_gradients, cpu: 9.58sec, accelerator: 6.67ms, total: 9.59sec
    __init__.py:83:allreduce, cpu: 9.57sec, accelerator: 0us, total: 9.57sec
    __init__.py:86:allreduce, cpu: 5.66ms, accelerator: 6.67ms, total: 12.35ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 8.30ms, total: 12.10ms
train.py:447:<module>, cpu: 147.23ms, accelerator: 0us, total: 147.23ms
train.py:448:<module>, cpu: 123.17ms, accelerator: 0us, total: 123.17ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_1250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 9.29sec, accelerator: 0us, total: 9.29sec (92.87%)
top 2 operation type: ImageSummary, cpu: 377.56ms, accelerator: 0us, total: 377.56ms (3.77%)
top 3 operation type: HistogramSummary, cpu: 106.78ms, accelerator: 0us, total: 106.78ms (1.07%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 148.53ms, accelerator: 0us, total: 148.53ms
top 3 graph node: autoencoded, cpu: 134.22ms, accelerator: 0us, total: 134.22ms
train.py:511:<module>, cpu: 9.30sec, accelerator: 12.93ms, total: 9.32sec
  __init__.py:194:compute_gradients, cpu: 9.30sec, accelerator: 5.86ms, total: 9.30sec
    __init__.py:83:allreduce, cpu: 9.29sec, accelerator: 0us, total: 9.29sec
    __init__.py:86:allreduce, cpu: 5.07ms, accelerator: 5.86ms, total: 10.95ms
  __init__.py:185:compute_gradients, cpu: 3.64ms, accelerator: 7.08ms, total: 10.75ms
train.py:447:<module>, cpu: 148.54ms, accelerator: 0us, total: 148.54ms
train.py:448:<module>, cpu: 134.23ms, accelerator: 0us, total: 134.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_1500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 9.13sec, accelerator: 0us, total: 9.13sec (93.06%)
top 2 operation type: ImageSummary, cpu: 363.89ms, accelerator: 0us, total: 363.89ms (3.71%)
top 3 operation type: HistogramSummary, cpu: 100.98ms, accelerator: 0us, total: 100.98ms (1.03%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 137.41ms, accelerator: 0us, total: 137.41ms
top 3 graph node: autoencoded, cpu: 132.99ms, accelerator: 0us, total: 132.99ms
train.py:511:<module>, cpu: 9.14sec, accelerator: 12.01ms, total: 9.15sec
  __init__.py:194:compute_gradients, cpu: 9.13sec, accelerator: 5.39ms, total: 9.14sec
    __init__.py:83:allreduce, cpu: 9.13sec, accelerator: 0us, total: 9.13sec
    __init__.py:86:allreduce, cpu: 4.70ms, accelerator: 5.39ms, total: 10.10ms
  __init__.py:185:compute_gradients, cpu: 3.40ms, accelerator: 6.62ms, total: 10.05ms
train.py:447:<module>, cpu: 137.42ms, accelerator: 0us, total: 137.42ms
train.py:448:<module>, cpu: 133.00ms, accelerator: 0us, total: 133.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_1750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.91sec, accelerator: 0us, total: 8.91sec (93.15%)
top 2 operation type: ImageSummary, cpu: 354.70ms, accelerator: 0us, total: 354.70ms (3.71%)
top 3 operation type: HistogramSummary, cpu: 103.88ms, accelerator: 0us, total: 103.88ms (1.09%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 131.91ms, accelerator: 0us, total: 131.91ms
top 3 graph node: original, cpu: 126.84ms, accelerator: 0us, total: 126.84ms
train.py:511:<module>, cpu: 8.92sec, accelerator: 11.02ms, total: 8.93sec
  __init__.py:194:compute_gradients, cpu: 8.92sec, accelerator: 4.74ms, total: 8.92sec
    __init__.py:83:allreduce, cpu: 8.91sec, accelerator: 0us, total: 8.91sec
    __init__.py:86:allreduce, cpu: 4.35ms, accelerator: 4.74ms, total: 9.12ms
  __init__.py:185:compute_gradients, cpu: 3.18ms, accelerator: 6.28ms, total: 9.49ms
train.py:448:<module>, cpu: 131.92ms, accelerator: 0us, total: 131.92ms
train.py:447:<module>, cpu: 126.84ms, accelerator: 0us, total: 126.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_2000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.75sec, accelerator: 0us, total: 8.75sec (93.28%)
top 2 operation type: ImageSummary, cpu: 343.22ms, accelerator: 0us, total: 343.22ms (3.66%)
top 3 operation type: HistogramSummary, cpu: 99.83ms, accelerator: 0us, total: 99.83ms (1.06%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 128.14ms, accelerator: 0us, total: 128.14ms
top 3 graph node: original, cpu: 119.73ms, accelerator: 0us, total: 119.73ms
train.py:511:<module>, cpu: 8.76sec, accelerator: 9.87ms, total: 8.77sec
  __init__.py:194:compute_gradients, cpu: 8.76sec, accelerator: 4.25ms, total: 8.76sec
    __init__.py:83:allreduce, cpu: 8.75sec, accelerator: 0us, total: 8.75sec
    __init__.py:86:allreduce, cpu: 4.37ms, accelerator: 4.25ms, total: 8.64ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 5.62ms, total: 9.35ms
train.py:448:<module>, cpu: 128.15ms, accelerator: 0us, total: 128.15ms
train.py:447:<module>, cpu: 119.74ms, accelerator: 0us, total: 119.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_2250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.67sec, accelerator: 0us, total: 8.67sec (93.39%)
top 2 operation type: ImageSummary, cpu: 341.85ms, accelerator: 0us, total: 341.85ms (3.68%)
top 3 operation type: HistogramSummary, cpu: 96.79ms, accelerator: 0us, total: 96.79ms (1.04%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 131.85ms, accelerator: 0us, total: 131.85ms
top 3 graph node: original, cpu: 113.97ms, accelerator: 0us, total: 113.97ms
train.py:511:<module>, cpu: 8.67sec, accelerator: 8.95ms, total: 8.68sec
  __init__.py:194:compute_gradients, cpu: 8.67sec, accelerator: 3.85ms, total: 8.67sec
    __init__.py:83:allreduce, cpu: 8.67sec, accelerator: 0us, total: 8.67sec
    __init__.py:86:allreduce, cpu: 4.08ms, accelerator: 3.85ms, total: 7.96ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 5.10ms, total: 8.64ms
train.py:448:<module>, cpu: 131.86ms, accelerator: 0us, total: 131.86ms
train.py:447:<module>, cpu: 113.97ms, accelerator: 0us, total: 113.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_2500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.55sec, accelerator: 0us, total: 8.55sec (93.33%)
top 2 operation type: ImageSummary, cpu: 348.45ms, accelerator: 0us, total: 348.45ms (3.80%)
top 3 operation type: HistogramSummary, cpu: 98.01ms, accelerator: 0us, total: 98.01ms (1.07%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 134.57ms, accelerator: 0us, total: 134.57ms
top 3 graph node: original, cpu: 114.75ms, accelerator: 0us, total: 114.75ms
train.py:511:<module>, cpu: 8.56sec, accelerator: 8.29ms, total: 8.57sec
  __init__.py:194:compute_gradients, cpu: 8.55sec, accelerator: 3.53ms, total: 8.56sec
    __init__.py:83:allreduce, cpu: 8.55sec, accelerator: 0us, total: 8.55sec
    __init__.py:86:allreduce, cpu: 3.89ms, accelerator: 3.53ms, total: 7.44ms
  __init__.py:185:compute_gradients, cpu: 3.41ms, accelerator: 4.76ms, total: 8.21ms
train.py:448:<module>, cpu: 134.58ms, accelerator: 0us, total: 134.58ms
train.py:447:<module>, cpu: 114.76ms, accelerator: 0us, total: 114.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_2750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.66sec, accelerator: 0us, total: 8.66sec (93.52%)
top 2 operation type: ImageSummary, cpu: 348.72ms, accelerator: 0us, total: 348.72ms (3.77%)
top 3 operation type: HistogramSummary, cpu: 97.06ms, accelerator: 0us, total: 97.06ms (1.05%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 134.68ms, accelerator: 0us, total: 134.68ms
top 3 graph node: original, cpu: 114.93ms, accelerator: 0us, total: 114.93ms
train.py:511:<module>, cpu: 8.66sec, accelerator: 7.66ms, total: 8.67sec
  __init__.py:194:compute_gradients, cpu: 8.66sec, accelerator: 3.26ms, total: 8.66sec
    __init__.py:83:allreduce, cpu: 8.66sec, accelerator: 0us, total: 8.66sec
    __init__.py:86:allreduce, cpu: 3.69ms, accelerator: 3.26ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 3.30ms, accelerator: 4.40ms, total: 7.75ms
train.py:448:<module>, cpu: 134.69ms, accelerator: 0us, total: 134.69ms
train.py:447:<module>, cpu: 114.93ms, accelerator: 0us, total: 114.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_3000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.60sec, accelerator: 0us, total: 8.60sec (93.49%)
top 2 operation type: ImageSummary, cpu: 349.45ms, accelerator: 0us, total: 349.45ms (3.80%)
top 3 operation type: HistogramSummary, cpu: 100.44ms, accelerator: 0us, total: 100.44ms (1.09%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 133.11ms, accelerator: 0us, total: 133.11ms
top 3 graph node: original, cpu: 115.12ms, accelerator: 0us, total: 115.12ms
train.py:511:<module>, cpu: 8.61sec, accelerator: 7.14ms, total: 8.62sec
  __init__.py:194:compute_gradients, cpu: 8.61sec, accelerator: 3.03ms, total: 8.61sec
    __init__.py:83:allreduce, cpu: 8.60sec, accelerator: 0us, total: 8.60sec
    __init__.py:86:allreduce, cpu: 3.51ms, accelerator: 3.03ms, total: 6.57ms
  __init__.py:185:compute_gradients, cpu: 3.21ms, accelerator: 4.11ms, total: 7.36ms
train.py:448:<module>, cpu: 133.12ms, accelerator: 0us, total: 133.12ms
train.py:447:<module>, cpu: 115.12ms, accelerator: 0us, total: 115.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_3250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.53sec, accelerator: 0us, total: 8.53sec (93.24%)
top 2 operation type: ImageSummary, cpu: 351.15ms, accelerator: 0us, total: 351.15ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 108.02ms, accelerator: 0us, total: 108.02ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 134.86ms, accelerator: 0us, total: 134.86ms
top 3 graph node: original, cpu: 116.24ms, accelerator: 0us, total: 116.24ms
train.py:511:<module>, cpu: 8.54sec, accelerator: 7.68ms, total: 8.54sec
  __init__.py:194:compute_gradients, cpu: 8.53sec, accelerator: 3.51ms, total: 8.54sec
    __init__.py:83:allreduce, cpu: 8.53sec, accelerator: 0us, total: 8.53sec
    __init__.py:86:allreduce, cpu: 4.07ms, accelerator: 3.51ms, total: 7.60ms
  __init__.py:185:compute_gradients, cpu: 3.28ms, accelerator: 4.17ms, total: 7.49ms
train.py:448:<module>, cpu: 134.87ms, accelerator: 0us, total: 134.87ms
train.py:447:<module>, cpu: 116.25ms, accelerator: 0us, total: 116.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_3500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.54sec, accelerator: 0us, total: 8.54sec (93.34%)
top 2 operation type: ImageSummary, cpu: 348.18ms, accelerator: 0us, total: 348.18ms (3.81%)
top 3 operation type: HistogramSummary, cpu: 106.54ms, accelerator: 0us, total: 106.54ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 132.11ms, accelerator: 0us, total: 132.11ms
top 3 graph node: original, cpu: 114.92ms, accelerator: 0us, total: 114.92ms
train.py:511:<module>, cpu: 8.55sec, accelerator: 7.22ms, total: 8.55sec
  __init__.py:194:compute_gradients, cpu: 8.54sec, accelerator: 3.29ms, total: 8.55sec
    __init__.py:83:allreduce, cpu: 8.54sec, accelerator: 0us, total: 8.54sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 3.29ms, total: 8.80ms
  __init__.py:185:compute_gradients, cpu: 3.19ms, accelerator: 3.93ms, total: 7.16ms
train.py:448:<module>, cpu: 132.12ms, accelerator: 0us, total: 132.12ms
train.py:447:<module>, cpu: 114.92ms, accelerator: 0us, total: 114.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_3750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.55sec, accelerator: 0us, total: 8.55sec (93.50%)
top 2 operation type: ImageSummary, cpu: 341.79ms, accelerator: 0us, total: 341.79ms (3.74%)
top 3 operation type: HistogramSummary, cpu: 104.99ms, accelerator: 0us, total: 104.99ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 129.61ms, accelerator: 0us, total: 129.61ms
top 3 graph node: original, cpu: 111.50ms, accelerator: 0us, total: 111.50ms
train.py:511:<module>, cpu: 8.56sec, accelerator: 7.04ms, total: 8.57sec
  __init__.py:194:compute_gradients, cpu: 8.56sec, accelerator: 3.11ms, total: 8.56sec
    __init__.py:83:allreduce, cpu: 8.55sec, accelerator: 0us, total: 8.55sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 3.11ms, total: 8.53ms
  __init__.py:185:compute_gradients, cpu: 3.13ms, accelerator: 3.93ms, total: 7.10ms
train.py:448:<module>, cpu: 129.62ms, accelerator: 0us, total: 129.62ms
train.py:447:<module>, cpu: 111.50ms, accelerator: 0us, total: 111.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_4000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.60sec, accelerator: 0us, total: 8.60sec (93.55%)
top 2 operation type: ImageSummary, cpu: 341.44ms, accelerator: 0us, total: 341.44ms (3.71%)
top 3 operation type: HistogramSummary, cpu: 104.24ms, accelerator: 0us, total: 104.24ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 131.62ms, accelerator: 0us, total: 131.62ms
top 3 graph node: original, cpu: 111.08ms, accelerator: 0us, total: 111.08ms
train.py:511:<module>, cpu: 8.61sec, accelerator: 6.66ms, total: 8.62sec
  __init__.py:194:compute_gradients, cpu: 8.61sec, accelerator: 2.94ms, total: 8.61sec
    __init__.py:83:allreduce, cpu: 8.60sec, accelerator: 0us, total: 8.60sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 2.94ms, total: 8.19ms
  __init__.py:185:compute_gradients, cpu: 4.35ms, accelerator: 3.71ms, total: 8.12ms
train.py:448:<module>, cpu: 131.62ms, accelerator: 0us, total: 131.62ms
train.py:447:<module>, cpu: 111.09ms, accelerator: 0us, total: 111.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_4250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.68sec, accelerator: 0us, total: 8.68sec (93.60%)
top 2 operation type: ImageSummary, cpu: 342.28ms, accelerator: 0us, total: 342.28ms (3.69%)
top 3 operation type: HistogramSummary, cpu: 106.40ms, accelerator: 0us, total: 106.40ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 134.00ms, accelerator: 0us, total: 134.00ms
top 3 graph node: original, cpu: 109.38ms, accelerator: 0us, total: 109.38ms
train.py:511:<module>, cpu: 8.69sec, accelerator: 6.62ms, total: 8.70sec
  __init__.py:194:compute_gradients, cpu: 8.69sec, accelerator: 2.91ms, total: 8.69sec
    __init__.py:83:allreduce, cpu: 8.68sec, accelerator: 0us, total: 8.68sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 2.91ms, total: 8.12ms
  __init__.py:185:compute_gradients, cpu: 4.22ms, accelerator: 3.71ms, total: 7.97ms
train.py:448:<module>, cpu: 134.00ms, accelerator: 0us, total: 134.00ms
train.py:447:<module>, cpu: 109.39ms, accelerator: 0us, total: 109.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_4500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.62sec, accelerator: 0us, total: 8.62sec (93.59%)
top 2 operation type: ImageSummary, cpu: 342.09ms, accelerator: 0us, total: 342.09ms (3.71%)
top 3 operation type: HistogramSummary, cpu: 105.59ms, accelerator: 0us, total: 105.59ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 132.87ms, accelerator: 0us, total: 132.87ms
top 3 graph node: original, cpu: 110.20ms, accelerator: 0us, total: 110.20ms
train.py:511:<module>, cpu: 8.63sec, accelerator: 6.33ms, total: 8.64sec
  __init__.py:194:compute_gradients, cpu: 8.63sec, accelerator: 2.77ms, total: 8.63sec
    __init__.py:83:allreduce, cpu: 8.62sec, accelerator: 0us, total: 8.62sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 2.77ms, total: 8.13ms
  __init__.py:185:compute_gradients, cpu: 4.29ms, accelerator: 3.55ms, total: 7.89ms
train.py:448:<module>, cpu: 132.88ms, accelerator: 0us, total: 132.88ms
train.py:447:<module>, cpu: 110.21ms, accelerator: 0us, total: 110.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_4750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.62sec, accelerator: 0us, total: 8.62sec (93.60%)
top 2 operation type: ImageSummary, cpu: 342.79ms, accelerator: 0us, total: 342.79ms (3.72%)
top 3 operation type: HistogramSummary, cpu: 105.96ms, accelerator: 0us, total: 105.96ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 133.91ms, accelerator: 0us, total: 133.91ms
top 3 graph node: original, cpu: 109.56ms, accelerator: 0us, total: 109.56ms
train.py:511:<module>, cpu: 8.63sec, accelerator: 6.06ms, total: 8.64sec
  __init__.py:194:compute_gradients, cpu: 8.63sec, accelerator: 2.66ms, total: 8.63sec
    __init__.py:83:allreduce, cpu: 8.62sec, accelerator: 0us, total: 8.62sec
    __init__.py:86:allreduce, cpu: 5.54ms, accelerator: 2.66ms, total: 8.22ms
  __init__.py:185:compute_gradients, cpu: 4.17ms, accelerator: 3.40ms, total: 7.61ms
train.py:448:<module>, cpu: 133.91ms, accelerator: 0us, total: 133.91ms
train.py:447:<module>, cpu: 109.57ms, accelerator: 0us, total: 109.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_5000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.65sec, accelerator: 0us, total: 8.65sec (93.64%)
top 2 operation type: ImageSummary, cpu: 344.74ms, accelerator: 0us, total: 344.74ms (3.73%)
top 3 operation type: HistogramSummary, cpu: 105.52ms, accelerator: 0us, total: 105.52ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 135.19ms, accelerator: 0us, total: 135.19ms
top 3 graph node: original, cpu: 109.75ms, accelerator: 0us, total: 109.75ms
train.py:511:<module>, cpu: 8.66sec, accelerator: 6.27ms, total: 8.67sec
  __init__.py:194:compute_gradients, cpu: 8.66sec, accelerator: 2.55ms, total: 8.66sec
    __init__.py:83:allreduce, cpu: 8.65sec, accelerator: 0us, total: 8.65sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 2.55ms, total: 7.92ms
  __init__.py:185:compute_gradients, cpu: 4.05ms, accelerator: 3.72ms, total: 7.81ms
train.py:448:<module>, cpu: 135.19ms, accelerator: 0us, total: 135.19ms
train.py:447:<module>, cpu: 109.76ms, accelerator: 0us, total: 109.76ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_5250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.60sec, accelerator: 0us, total: 8.60sec (93.65%)
top 2 operation type: ImageSummary, cpu: 346.01ms, accelerator: 0us, total: 346.01ms (3.77%)
top 3 operation type: HistogramSummary, cpu: 103.56ms, accelerator: 0us, total: 103.56ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 135.88ms, accelerator: 0us, total: 135.88ms
top 3 graph node: original, cpu: 110.97ms, accelerator: 0us, total: 110.97ms
train.py:511:<module>, cpu: 8.61sec, accelerator: 6.05ms, total: 8.62sec
  __init__.py:194:compute_gradients, cpu: 8.61sec, accelerator: 2.45ms, total: 8.61sec
    __init__.py:83:allreduce, cpu: 8.60sec, accelerator: 0us, total: 8.60sec
    __init__.py:86:allreduce, cpu: 5.48ms, accelerator: 2.45ms, total: 7.95ms
  __init__.py:185:compute_gradients, cpu: 3.94ms, accelerator: 3.61ms, total: 7.60ms
train.py:448:<module>, cpu: 135.88ms, accelerator: 0us, total: 135.88ms
train.py:447:<module>, cpu: 110.98ms, accelerator: 0us, total: 110.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_5500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.58sec, accelerator: 0us, total: 8.58sec (93.68%)
top 2 operation type: ImageSummary, cpu: 345.17ms, accelerator: 0us, total: 345.17ms (3.77%)
top 3 operation type: HistogramSummary, cpu: 103.18ms, accelerator: 0us, total: 103.18ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 135.64ms, accelerator: 0us, total: 135.64ms
top 3 graph node: original, cpu: 111.25ms, accelerator: 0us, total: 111.25ms
train.py:511:<module>, cpu: 8.59sec, accelerator: 5.82ms, total: 8.60sec
  __init__.py:194:compute_gradients, cpu: 8.59sec, accelerator: 2.35ms, total: 8.59sec
    __init__.py:83:allreduce, cpu: 8.58sec, accelerator: 0us, total: 8.58sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 2.35ms, total: 7.70ms
  __init__.py:185:compute_gradients, cpu: 3.86ms, accelerator: 3.47ms, total: 7.37ms
train.py:448:<module>, cpu: 135.65ms, accelerator: 0us, total: 135.65ms
train.py:447:<module>, cpu: 111.26ms, accelerator: 0us, total: 111.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_5750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.53sec, accelerator: 0us, total: 8.53sec (93.69%)
top 2 operation type: ImageSummary, cpu: 343.82ms, accelerator: 0us, total: 343.82ms (3.78%)
top 3 operation type: HistogramSummary, cpu: 102.49ms, accelerator: 0us, total: 102.49ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 134.91ms, accelerator: 0us, total: 134.91ms
top 3 graph node: original, cpu: 110.05ms, accelerator: 0us, total: 110.05ms
train.py:511:<module>, cpu: 8.54sec, accelerator: 5.61ms, total: 8.55sec
  __init__.py:194:compute_gradients, cpu: 8.54sec, accelerator: 2.27ms, total: 8.54sec
    __init__.py:83:allreduce, cpu: 8.53sec, accelerator: 0us, total: 8.53sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 2.27ms, total: 7.68ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 3.34ms, total: 7.16ms
train.py:448:<module>, cpu: 134.91ms, accelerator: 0us, total: 134.91ms
train.py:447:<module>, cpu: 110.05ms, accelerator: 0us, total: 110.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_6000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.50sec, accelerator: 0us, total: 8.50sec (93.64%)
top 2 operation type: ImageSummary, cpu: 345.14ms, accelerator: 0us, total: 345.14ms (3.80%)
top 3 operation type: HistogramSummary, cpu: 102.90ms, accelerator: 0us, total: 102.90ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 136.38ms, accelerator: 0us, total: 136.38ms
top 3 graph node: original, cpu: 108.25ms, accelerator: 0us, total: 108.25ms
train.py:511:<module>, cpu: 8.51sec, accelerator: 6.15ms, total: 8.51sec
  __init__.py:194:compute_gradients, cpu: 8.50sec, accelerator: 2.37ms, total: 8.51sec
    __init__.py:83:allreduce, cpu: 8.50sec, accelerator: 0us, total: 8.50sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 2.37ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.70ms, accelerator: 3.77ms, total: 7.51ms
train.py:448:<module>, cpu: 136.39ms, accelerator: 0us, total: 136.39ms
train.py:447:<module>, cpu: 108.26ms, accelerator: 0us, total: 108.26ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_6250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.44sec, accelerator: 0us, total: 8.44sec (93.56%)
top 2 operation type: ImageSummary, cpu: 348.75ms, accelerator: 0us, total: 348.75ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 103.58ms, accelerator: 0us, total: 103.58ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 137.54ms, accelerator: 0us, total: 137.54ms
top 3 graph node: original, cpu: 109.76ms, accelerator: 0us, total: 109.76ms
train.py:511:<module>, cpu: 8.45sec, accelerator: 5.94ms, total: 8.46sec
  __init__.py:194:compute_gradients, cpu: 8.45sec, accelerator: 2.29ms, total: 8.45sec
    __init__.py:83:allreduce, cpu: 8.44sec, accelerator: 0us, total: 8.44sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 2.29ms, total: 7.79ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 3.65ms, total: 7.37ms
train.py:448:<module>, cpu: 137.55ms, accelerator: 0us, total: 137.55ms
train.py:447:<module>, cpu: 109.77ms, accelerator: 0us, total: 109.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_6500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.49sec, accelerator: 0us, total: 8.49sec (93.56%)
top 2 operation type: ImageSummary, cpu: 352.39ms, accelerator: 0us, total: 352.39ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 102.95ms, accelerator: 0us, total: 102.95ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.36ms, accelerator: 0us, total: 139.36ms
top 3 graph node: original, cpu: 110.50ms, accelerator: 0us, total: 110.50ms
train.py:511:<module>, cpu: 8.50sec, accelerator: 5.74ms, total: 8.51sec
  __init__.py:194:compute_gradients, cpu: 8.50sec, accelerator: 2.21ms, total: 8.50sec
    __init__.py:83:allreduce, cpu: 8.49sec, accelerator: 0us, total: 8.49sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 2.21ms, total: 7.57ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 3.53ms, total: 7.17ms
train.py:448:<module>, cpu: 139.37ms, accelerator: 0us, total: 139.37ms
train.py:447:<module>, cpu: 110.51ms, accelerator: 0us, total: 110.51ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_6750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.48sec, accelerator: 0us, total: 8.48sec (93.57%)
top 2 operation type: ImageSummary, cpu: 351.92ms, accelerator: 0us, total: 351.92ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 104.14ms, accelerator: 0us, total: 104.14ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.14ms, accelerator: 0us, total: 140.14ms
top 3 graph node: original, cpu: 108.81ms, accelerator: 0us, total: 108.81ms
train.py:511:<module>, cpu: 8.49sec, accelerator: 5.59ms, total: 8.50sec
  __init__.py:194:compute_gradients, cpu: 8.49sec, accelerator: 2.17ms, total: 8.49sec
    __init__.py:83:allreduce, cpu: 8.48sec, accelerator: 0us, total: 8.48sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 2.17ms, total: 7.40ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 3.42ms, total: 7.00ms
train.py:448:<module>, cpu: 140.15ms, accelerator: 0us, total: 140.15ms
train.py:447:<module>, cpu: 108.81ms, accelerator: 0us, total: 108.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_7000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.54sec, accelerator: 0us, total: 8.54sec (93.66%)
top 2 operation type: ImageSummary, cpu: 350.11ms, accelerator: 0us, total: 350.11ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 103.46ms, accelerator: 0us, total: 103.46ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.45ms, accelerator: 0us, total: 140.45ms
top 3 graph node: original, cpu: 108.08ms, accelerator: 0us, total: 108.08ms
train.py:511:<module>, cpu: 8.54sec, accelerator: 5.45ms, total: 8.55sec
  __init__.py:194:compute_gradients, cpu: 8.54sec, accelerator: 2.10ms, total: 8.54sec
    __init__.py:83:allreduce, cpu: 8.54sec, accelerator: 0us, total: 8.54sec
    __init__.py:86:allreduce, cpu: 5.09ms, accelerator: 2.10ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 3.35ms, total: 6.95ms
train.py:448:<module>, cpu: 140.46ms, accelerator: 0us, total: 140.46ms
train.py:447:<module>, cpu: 108.09ms, accelerator: 0us, total: 108.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_7250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.52sec, accelerator: 0us, total: 8.52sec (93.67%)
top 2 operation type: ImageSummary, cpu: 348.78ms, accelerator: 0us, total: 348.78ms (3.83%)
top 3 operation type: HistogramSummary, cpu: 103.40ms, accelerator: 0us, total: 103.40ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.34ms, accelerator: 0us, total: 139.34ms
top 3 graph node: original, cpu: 106.93ms, accelerator: 0us, total: 106.93ms
train.py:511:<module>, cpu: 8.53sec, accelerator: 5.29ms, total: 8.54sec
  __init__.py:194:compute_gradients, cpu: 8.53sec, accelerator: 2.04ms, total: 8.53sec
    __init__.py:83:allreduce, cpu: 8.52sec, accelerator: 0us, total: 8.52sec
    __init__.py:86:allreduce, cpu: 5.51ms, accelerator: 2.04ms, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 3.25ms, total: 6.94ms
train.py:448:<module>, cpu: 139.34ms, accelerator: 0us, total: 139.34ms
train.py:447:<module>, cpu: 106.94ms, accelerator: 0us, total: 106.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_7500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.53sec, accelerator: 0us, total: 8.53sec (93.64%)
top 2 operation type: ImageSummary, cpu: 353.41ms, accelerator: 0us, total: 353.41ms (3.88%)
top 3 operation type: HistogramSummary, cpu: 103.26ms, accelerator: 0us, total: 103.26ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.97ms, accelerator: 0us, total: 140.97ms
top 3 graph node: original, cpu: 109.03ms, accelerator: 0us, total: 109.03ms
train.py:511:<module>, cpu: 8.54sec, accelerator: 5.15ms, total: 8.54sec
  __init__.py:194:compute_gradients, cpu: 8.53sec, accelerator: 1.99ms, total: 8.54sec
    __init__.py:83:allreduce, cpu: 8.53sec, accelerator: 0us, total: 8.53sec
    __init__.py:86:allreduce, cpu: 5.68ms, accelerator: 1.99ms, total: 7.70ms
  __init__.py:185:compute_gradients, cpu: 3.86ms, accelerator: 3.16ms, total: 7.07ms
train.py:448:<module>, cpu: 140.97ms, accelerator: 0us, total: 140.97ms
train.py:447:<module>, cpu: 109.04ms, accelerator: 0us, total: 109.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_7750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.45sec, accelerator: 0us, total: 8.45sec (93.62%)
top 2 operation type: ImageSummary, cpu: 352.24ms, accelerator: 0us, total: 352.24ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 102.43ms, accelerator: 0us, total: 102.43ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.68ms, accelerator: 0us, total: 140.68ms
top 3 graph node: original, cpu: 108.40ms, accelerator: 0us, total: 108.40ms
train.py:511:<module>, cpu: 8.46sec, accelerator: 5.02ms, total: 8.46sec
  __init__.py:194:compute_gradients, cpu: 8.46sec, accelerator: 1.94ms, total: 8.46sec
    __init__.py:83:allreduce, cpu: 8.45sec, accelerator: 0us, total: 8.45sec
    __init__.py:86:allreduce, cpu: 6.01ms, accelerator: 1.94ms, total: 7.98ms
  __init__.py:185:compute_gradients, cpu: 3.80ms, accelerator: 3.08ms, total: 6.92ms
train.py:448:<module>, cpu: 140.68ms, accelerator: 0us, total: 140.68ms
train.py:447:<module>, cpu: 108.41ms, accelerator: 0us, total: 108.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_8000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.45sec, accelerator: 0us, total: 8.45sec (93.60%)
top 2 operation type: ImageSummary, cpu: 353.27ms, accelerator: 0us, total: 353.27ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 103.14ms, accelerator: 0us, total: 103.14ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.80ms, accelerator: 0us, total: 140.80ms
top 3 graph node: original, cpu: 108.87ms, accelerator: 0us, total: 108.87ms
train.py:511:<module>, cpu: 8.46sec, accelerator: 4.89ms, total: 8.47sec
  __init__.py:194:compute_gradients, cpu: 8.46sec, accelerator: 1.89ms, total: 8.46sec
    __init__.py:83:allreduce, cpu: 8.45sec, accelerator: 0us, total: 8.45sec
    __init__.py:86:allreduce, cpu: 5.91ms, accelerator: 1.89ms, total: 7.82ms
  __init__.py:185:compute_gradients, cpu: 4.37ms, accelerator: 3.00ms, total: 7.41ms
train.py:448:<module>, cpu: 140.80ms, accelerator: 0us, total: 140.80ms
train.py:447:<module>, cpu: 108.88ms, accelerator: 0us, total: 108.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_8250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.39sec, accelerator: 0us, total: 8.39sec (93.57%)
top 2 operation type: ImageSummary, cpu: 352.47ms, accelerator: 0us, total: 352.47ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 102.27ms, accelerator: 0us, total: 102.27ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.25ms, accelerator: 0us, total: 141.25ms
top 3 graph node: original, cpu: 107.83ms, accelerator: 0us, total: 107.83ms
train.py:511:<module>, cpu: 8.40sec, accelerator: 5.50ms, total: 8.41sec
  __init__.py:194:compute_gradients, cpu: 8.40sec, accelerator: 2.56ms, total: 8.40sec
    __init__.py:83:allreduce, cpu: 8.39sec, accelerator: 0us, total: 8.39sec
    __init__.py:86:allreduce, cpu: 5.82ms, accelerator: 2.56ms, total: 8.40ms
  __init__.py:185:compute_gradients, cpu: 4.29ms, accelerator: 2.94ms, total: 7.27ms
train.py:448:<module>, cpu: 141.25ms, accelerator: 0us, total: 141.25ms
train.py:447:<module>, cpu: 107.83ms, accelerator: 0us, total: 107.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_8500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.36sec, accelerator: 0us, total: 8.36sec (93.56%)
top 2 operation type: ImageSummary, cpu: 351.31ms, accelerator: 0us, total: 351.31ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 102.01ms, accelerator: 0us, total: 102.01ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.70ms, accelerator: 0us, total: 141.70ms
top 3 graph node: original, cpu: 106.65ms, accelerator: 0us, total: 106.65ms
train.py:511:<module>, cpu: 8.37sec, accelerator: 5.72ms, total: 8.37sec
  __init__.py:194:compute_gradients, cpu: 8.36sec, accelerator: 2.50ms, total: 8.37sec
    __init__.py:83:allreduce, cpu: 8.36sec, accelerator: 0us, total: 8.36sec
    __init__.py:86:allreduce, cpu: 5.71ms, accelerator: 2.50ms, total: 8.24ms
  __init__.py:185:compute_gradients, cpu: 4.23ms, accelerator: 3.23ms, total: 7.50ms
train.py:448:<module>, cpu: 141.71ms, accelerator: 0us, total: 141.71ms
train.py:447:<module>, cpu: 106.65ms, accelerator: 0us, total: 106.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_8750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.36sec, accelerator: 0us, total: 8.36sec (93.59%)
top 2 operation type: ImageSummary, cpu: 350.20ms, accelerator: 0us, total: 350.20ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.06ms, accelerator: 0us, total: 101.06ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.17ms, accelerator: 0us, total: 141.17ms
top 3 graph node: original, cpu: 106.30ms, accelerator: 0us, total: 106.30ms
train.py:511:<module>, cpu: 8.37sec, accelerator: 6.12ms, total: 8.38sec
  __init__.py:194:compute_gradients, cpu: 8.37sec, accelerator: 2.44ms, total: 8.37sec
    __init__.py:83:allreduce, cpu: 8.36sec, accelerator: 0us, total: 8.36sec
    __init__.py:86:allreduce, cpu: 6.36ms, accelerator: 2.44ms, total: 8.82ms
  __init__.py:185:compute_gradients, cpu: 4.17ms, accelerator: 3.67ms, total: 7.88ms
train.py:448:<module>, cpu: 141.17ms, accelerator: 0us, total: 141.17ms
train.py:447:<module>, cpu: 106.31ms, accelerator: 0us, total: 106.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_9000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.33sec, accelerator: 0us, total: 8.33sec (93.61%)
top 2 operation type: ImageSummary, cpu: 348.46ms, accelerator: 0us, total: 348.46ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 99.97ms, accelerator: 0us, total: 99.97ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.30ms, accelerator: 0us, total: 141.30ms
top 3 graph node: original, cpu: 105.30ms, accelerator: 0us, total: 105.30ms
train.py:511:<module>, cpu: 8.34sec, accelerator: 6.13ms, total: 8.35sec
  __init__.py:194:compute_gradients, cpu: 8.34sec, accelerator: 2.52ms, total: 8.34sec
    __init__.py:83:allreduce, cpu: 8.33sec, accelerator: 0us, total: 8.33sec
    __init__.py:86:allreduce, cpu: 6.63ms, accelerator: 2.52ms, total: 9.18ms
  __init__.py:185:compute_gradients, cpu: 4.10ms, accelerator: 3.61ms, total: 7.75ms
train.py:448:<module>, cpu: 141.30ms, accelerator: 0us, total: 141.30ms
train.py:447:<module>, cpu: 105.30ms, accelerator: 0us, total: 105.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_9250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.31sec, accelerator: 0us, total: 8.31sec (93.61%)
top 2 operation type: ImageSummary, cpu: 350.39ms, accelerator: 0us, total: 350.39ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 98.98ms, accelerator: 0us, total: 98.98ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.76ms, accelerator: 0us, total: 141.76ms
top 3 graph node: original, cpu: 106.51ms, accelerator: 0us, total: 106.51ms
train.py:511:<module>, cpu: 8.32sec, accelerator: 6.02ms, total: 8.33sec
  __init__.py:194:compute_gradients, cpu: 8.32sec, accelerator: 2.46ms, total: 8.32sec
    __init__.py:83:allreduce, cpu: 8.31sec, accelerator: 0us, total: 8.31sec
    __init__.py:86:allreduce, cpu: 6.53ms, accelerator: 2.46ms, total: 9.02ms
  __init__.py:185:compute_gradients, cpu: 4.04ms, accelerator: 3.55ms, total: 7.63ms
train.py:448:<module>, cpu: 141.77ms, accelerator: 0us, total: 141.77ms
train.py:447:<module>, cpu: 106.52ms, accelerator: 0us, total: 106.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_9500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec (93.61%)
top 2 operation type: ImageSummary, cpu: 349.46ms, accelerator: 0us, total: 349.46ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 98.74ms, accelerator: 0us, total: 98.74ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.42ms, accelerator: 0us, total: 142.42ms
top 3 graph node: original, cpu: 105.31ms, accelerator: 0us, total: 105.31ms
train.py:511:<module>, cpu: 8.29sec, accelerator: 5.89ms, total: 8.29sec
  __init__.py:194:compute_gradients, cpu: 8.28sec, accelerator: 2.41ms, total: 8.29sec
    __init__.py:83:allreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec
    __init__.py:86:allreduce, cpu: 6.54ms, accelerator: 2.41ms, total: 8.97ms
  __init__.py:185:compute_gradients, cpu: 4.06ms, accelerator: 3.48ms, total: 7.58ms
train.py:448:<module>, cpu: 142.43ms, accelerator: 0us, total: 142.43ms
train.py:447:<module>, cpu: 105.31ms, accelerator: 0us, total: 105.31ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_9750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec (93.63%)
top 2 operation type: ImageSummary, cpu: 347.83ms, accelerator: 0us, total: 347.83ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 98.55ms, accelerator: 0us, total: 98.55ms (1.11%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.44ms, accelerator: 0us, total: 142.44ms
top 3 graph node: original, cpu: 104.25ms, accelerator: 0us, total: 104.25ms
train.py:511:<module>, cpu: 8.29sec, accelerator: 6.02ms, total: 8.29sec
  __init__.py:194:compute_gradients, cpu: 8.28sec, accelerator: 2.35ms, total: 8.29sec
    __init__.py:83:allreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec
    __init__.py:86:allreduce, cpu: 6.41ms, accelerator: 2.35ms, total: 8.79ms
  __init__.py:185:compute_gradients, cpu: 4.01ms, accelerator: 3.66ms, total: 7.71ms
train.py:448:<module>, cpu: 142.45ms, accelerator: 0us, total: 142.45ms
train.py:447:<module>, cpu: 104.26ms, accelerator: 0us, total: 104.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_10000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.24sec, accelerator: 0us, total: 8.24sec (93.62%)
top 2 operation type: ImageSummary, cpu: 347.31ms, accelerator: 0us, total: 347.31ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 99.09ms, accelerator: 0us, total: 99.09ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.72ms, accelerator: 0us, total: 142.72ms
top 3 graph node: original, cpu: 104.08ms, accelerator: 0us, total: 104.08ms
train.py:511:<module>, cpu: 8.25sec, accelerator: 6.17ms, total: 8.25sec
  __init__.py:194:compute_gradients, cpu: 8.24sec, accelerator: 2.31ms, total: 8.24sec
    __init__.py:83:allreduce, cpu: 8.24sec, accelerator: 0us, total: 8.24sec
    __init__.py:86:allreduce, cpu: 6.29ms, accelerator: 2.31ms, total: 8.62ms
  __init__.py:185:compute_gradients, cpu: 3.96ms, accelerator: 3.86ms, total: 7.85ms
train.py:448:<module>, cpu: 142.73ms, accelerator: 0us, total: 142.73ms
train.py:447:<module>, cpu: 104.08ms, accelerator: 0us, total: 104.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_10250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.23sec, accelerator: 0us, total: 8.23sec (93.63%)
top 2 operation type: ImageSummary, cpu: 346.94ms, accelerator: 0us, total: 346.94ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 99.10ms, accelerator: 0us, total: 99.10ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.00ms, accelerator: 0us, total: 143.00ms
top 3 graph node: original, cpu: 104.33ms, accelerator: 0us, total: 104.33ms
train.py:511:<module>, cpu: 8.24sec, accelerator: 6.04ms, total: 8.25sec
  __init__.py:194:compute_gradients, cpu: 8.24sec, accelerator: 2.26ms, total: 8.24sec
    __init__.py:83:allreduce, cpu: 8.23sec, accelerator: 0us, total: 8.23sec
    __init__.py:86:allreduce, cpu: 6.39ms, accelerator: 2.26ms, total: 8.67ms
  __init__.py:185:compute_gradients, cpu: 3.90ms, accelerator: 3.78ms, total: 7.72ms
train.py:448:<module>, cpu: 143.00ms, accelerator: 0us, total: 143.00ms
train.py:447:<module>, cpu: 104.34ms, accelerator: 0us, total: 104.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_10500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.24sec, accelerator: 0us, total: 8.24sec (93.60%)
top 2 operation type: ImageSummary, cpu: 347.62ms, accelerator: 0us, total: 347.62ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 98.99ms, accelerator: 0us, total: 98.99ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.33ms, accelerator: 0us, total: 143.33ms
top 3 graph node: original, cpu: 104.81ms, accelerator: 0us, total: 104.81ms
train.py:511:<module>, cpu: 8.25sec, accelerator: 6.32ms, total: 8.26sec
  __init__.py:194:compute_gradients, cpu: 8.25sec, accelerator: 2.21ms, total: 8.25sec
    __init__.py:83:allreduce, cpu: 8.24sec, accelerator: 0us, total: 8.24sec
    __init__.py:86:allreduce, cpu: 6.28ms, accelerator: 2.21ms, total: 8.51ms
  __init__.py:185:compute_gradients, cpu: 4.17ms, accelerator: 4.11ms, total: 8.31ms
train.py:448:<module>, cpu: 143.34ms, accelerator: 0us, total: 143.34ms
train.py:447:<module>, cpu: 104.81ms, accelerator: 0us, total: 104.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_10750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec (93.58%)
top 2 operation type: ImageSummary, cpu: 349.91ms, accelerator: 0us, total: 349.91ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 98.61ms, accelerator: 0us, total: 98.61ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.20ms, accelerator: 0us, total: 144.20ms
top 3 graph node: original, cpu: 105.04ms, accelerator: 0us, total: 105.04ms
train.py:511:<module>, cpu: 8.23sec, accelerator: 6.19ms, total: 8.24sec
  __init__.py:194:compute_gradients, cpu: 8.23sec, accelerator: 2.17ms, total: 8.23sec
    __init__.py:83:allreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec
    __init__.py:86:allreduce, cpu: 6.25ms, accelerator: 2.17ms, total: 8.45ms
  __init__.py:185:compute_gradients, cpu: 4.12ms, accelerator: 4.03ms, total: 8.18ms
train.py:448:<module>, cpu: 144.20ms, accelerator: 0us, total: 144.20ms
train.py:447:<module>, cpu: 105.05ms, accelerator: 0us, total: 105.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_11000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec (93.59%)
top 2 operation type: ImageSummary, cpu: 349.70ms, accelerator: 0us, total: 349.70ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 98.37ms, accelerator: 0us, total: 98.37ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.46ms, accelerator: 0us, total: 144.46ms
top 3 graph node: original, cpu: 105.21ms, accelerator: 0us, total: 105.21ms
train.py:511:<module>, cpu: 8.22sec, accelerator: 6.06ms, total: 8.23sec
  __init__.py:194:compute_gradients, cpu: 8.22sec, accelerator: 2.12ms, total: 8.22sec
    __init__.py:83:allreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec
    __init__.py:86:allreduce, cpu: 6.18ms, accelerator: 2.12ms, total: 8.33ms
  __init__.py:185:compute_gradients, cpu: 4.12ms, accelerator: 3.94ms, total: 8.09ms
train.py:448:<module>, cpu: 144.46ms, accelerator: 0us, total: 144.46ms
train.py:447:<module>, cpu: 105.22ms, accelerator: 0us, total: 105.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_11250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec (93.60%)
top 2 operation type: ImageSummary, cpu: 351.39ms, accelerator: 0us, total: 351.39ms (4.00%)
top 3 operation type: HistogramSummary, cpu: 97.74ms, accelerator: 0us, total: 97.74ms (1.11%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.42ms, accelerator: 0us, total: 144.42ms
top 3 graph node: original, cpu: 106.04ms, accelerator: 0us, total: 106.04ms
train.py:511:<module>, cpu: 8.23sec, accelerator: 6.15ms, total: 8.24sec
  __init__.py:194:compute_gradients, cpu: 8.23sec, accelerator: 2.09ms, total: 8.23sec
    __init__.py:83:allreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec
    __init__.py:86:allreduce, cpu: 6.42ms, accelerator: 2.09ms, total: 8.53ms
  __init__.py:185:compute_gradients, cpu: 4.06ms, accelerator: 4.06ms, total: 8.15ms
train.py:448:<module>, cpu: 144.42ms, accelerator: 0us, total: 144.42ms
train.py:447:<module>, cpu: 106.05ms, accelerator: 0us, total: 106.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_11500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec (93.62%)
top 2 operation type: ImageSummary, cpu: 349.22ms, accelerator: 0us, total: 349.22ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 97.61ms, accelerator: 0us, total: 97.61ms (1.11%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.30ms, accelerator: 0us, total: 144.30ms
top 3 graph node: original, cpu: 104.91ms, accelerator: 0us, total: 104.91ms
train.py:511:<module>, cpu: 8.22sec, accelerator: 6.34ms, total: 8.22sec
  __init__.py:194:compute_gradients, cpu: 8.21sec, accelerator: 2.04ms, total: 8.21sec
    __init__.py:83:allreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec
    __init__.py:86:allreduce, cpu: 6.33ms, accelerator: 2.04ms, total: 8.40ms
  __init__.py:185:compute_gradients, cpu: 4.12ms, accelerator: 4.29ms, total: 8.45ms
train.py:448:<module>, cpu: 144.30ms, accelerator: 0us, total: 144.30ms
train.py:447:<module>, cpu: 104.91ms, accelerator: 0us, total: 104.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_11750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec (93.63%)
top 2 operation type: ImageSummary, cpu: 349.50ms, accelerator: 0us, total: 349.50ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 97.21ms, accelerator: 0us, total: 97.21ms (1.11%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.70ms, accelerator: 0us, total: 144.70ms
top 3 graph node: original, cpu: 105.26ms, accelerator: 0us, total: 105.26ms
train.py:511:<module>, cpu: 8.22sec, accelerator: 6.24ms, total: 8.23sec
  __init__.py:194:compute_gradients, cpu: 8.22sec, accelerator: 2.01ms, total: 8.22sec
    __init__.py:83:allreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec
    __init__.py:86:allreduce, cpu: 6.22ms, accelerator: 2.01ms, total: 8.27ms
  __init__.py:185:compute_gradients, cpu: 4.08ms, accelerator: 4.23ms, total: 8.36ms
train.py:448:<module>, cpu: 144.71ms, accelerator: 0us, total: 144.71ms
train.py:447:<module>, cpu: 105.27ms, accelerator: 0us, total: 105.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_12000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec (93.65%)
top 2 operation type: ImageSummary, cpu: 348.63ms, accelerator: 0us, total: 348.63ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 97.28ms, accelerator: 0us, total: 97.28ms (1.11%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.33ms, accelerator: 0us, total: 144.33ms
top 3 graph node: original, cpu: 104.88ms, accelerator: 0us, total: 104.88ms
train.py:511:<module>, cpu: 8.22sec, accelerator: 6.14ms, total: 8.23sec
  __init__.py:194:compute_gradients, cpu: 8.22sec, accelerator: 1.98ms, total: 8.22sec
    __init__.py:83:allreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec
    __init__.py:86:allreduce, cpu: 6.16ms, accelerator: 1.98ms, total: 8.16ms
  __init__.py:185:compute_gradients, cpu: 4.04ms, accelerator: 4.16ms, total: 8.23ms
train.py:448:<module>, cpu: 144.34ms, accelerator: 0us, total: 144.34ms
train.py:447:<module>, cpu: 104.88ms, accelerator: 0us, total: 104.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_12250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec (93.65%)
top 2 operation type: ImageSummary, cpu: 348.49ms, accelerator: 0us, total: 348.49ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 97.90ms, accelerator: 0us, total: 97.90ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.06ms, accelerator: 0us, total: 144.06ms
top 3 graph node: original, cpu: 104.33ms, accelerator: 0us, total: 104.33ms
train.py:511:<module>, cpu: 8.23sec, accelerator: 6.02ms, total: 8.23sec
  __init__.py:194:compute_gradients, cpu: 8.22sec, accelerator: 1.94ms, total: 8.22sec
    __init__.py:83:allreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec
    __init__.py:86:allreduce, cpu: 6.10ms, accelerator: 1.94ms, total: 8.06ms
  __init__.py:185:compute_gradients, cpu: 3.99ms, accelerator: 4.08ms, total: 8.11ms
train.py:448:<module>, cpu: 144.07ms, accelerator: 0us, total: 144.07ms
train.py:447:<module>, cpu: 104.33ms, accelerator: 0us, total: 104.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2020.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_12500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.25sec, accelerator: 0us, total: 8.25sec (93.70%)
top 2 operation type: ImageSummary, cpu: 347.45ms, accelerator: 0us, total: 347.45ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 97.35ms, accelerator: 0us, total: 97.35ms (1.11%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.41ms, accelerator: 0us, total: 143.41ms
top 3 graph node: original, cpu: 103.81ms, accelerator: 0us, total: 103.81ms
train.py:511:<module>, cpu: 8.26sec, accelerator: 5.92ms, total: 8.26sec
  __init__.py:194:compute_gradients, cpu: 8.25sec, accelerator: 1.91ms, total: 8.25sec
    __init__.py:83:allreduce, cpu: 8.25sec, accelerator: 0us, total: 8.25sec
    __init__.py:86:allreduce, cpu: 6.03ms, accelerator: 1.91ms, total: 7.97ms
  __init__.py:185:compute_gradients, cpu: 3.95ms, accelerator: 4.01ms, total: 8.00ms
train.py:448:<module>, cpu: 143.41ms, accelerator: 0us, total: 143.41ms
train.py:447:<module>, cpu: 103.81ms, accelerator: 0us, total: 103.81ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_12750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec (93.70%)
top 2 operation type: ImageSummary, cpu: 347.10ms, accelerator: 0us, total: 347.10ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 97.78ms, accelerator: 0us, total: 97.78ms (1.11%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.80ms, accelerator: 0us, total: 143.80ms
top 3 graph node: original, cpu: 103.54ms, accelerator: 0us, total: 103.54ms
train.py:511:<module>, cpu: 8.23sec, accelerator: 5.81ms, total: 8.24sec
  __init__.py:194:compute_gradients, cpu: 8.23sec, accelerator: 1.87ms, total: 8.23sec
    __init__.py:83:allreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec
    __init__.py:86:allreduce, cpu: 6.10ms, accelerator: 1.87ms, total: 8.01ms
  __init__.py:185:compute_gradients, cpu: 3.91ms, accelerator: 3.94ms, total: 7.88ms
train.py:448:<module>, cpu: 143.81ms, accelerator: 0us, total: 143.81ms
train.py:447:<module>, cpu: 103.55ms, accelerator: 0us, total: 103.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2038.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_13000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec (93.69%)
top 2 operation type: ImageSummary, cpu: 347.18ms, accelerator: 0us, total: 347.18ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 98.46ms, accelerator: 0us, total: 98.46ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.11ms, accelerator: 0us, total: 144.11ms
top 3 graph node: original, cpu: 102.74ms, accelerator: 0us, total: 102.74ms
train.py:511:<module>, cpu: 8.22sec, accelerator: 5.72ms, total: 8.22sec
  __init__.py:194:compute_gradients, cpu: 8.21sec, accelerator: 1.85ms, total: 8.22sec
    __init__.py:83:allreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec
    __init__.py:86:allreduce, cpu: 6.14ms, accelerator: 1.85ms, total: 8.01ms
  __init__.py:185:compute_gradients, cpu: 3.87ms, accelerator: 3.88ms, total: 7.79ms
train.py:448:<module>, cpu: 144.12ms, accelerator: 0us, total: 144.12ms
train.py:447:<module>, cpu: 102.74ms, accelerator: 0us, total: 102.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_13250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec (93.72%)
top 2 operation type: ImageSummary, cpu: 346.88ms, accelerator: 0us, total: 346.88ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 98.17ms, accelerator: 0us, total: 98.17ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.00ms, accelerator: 0us, total: 144.00ms
top 3 graph node: original, cpu: 101.83ms, accelerator: 0us, total: 101.83ms
train.py:511:<module>, cpu: 8.23sec, accelerator: 5.67ms, total: 8.23sec
  __init__.py:194:compute_gradients, cpu: 8.22sec, accelerator: 1.82ms, total: 8.23sec
    __init__.py:83:allreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec
    __init__.py:86:allreduce, cpu: 6.15ms, accelerator: 1.82ms, total: 8.00ms
  __init__.py:185:compute_gradients, cpu: 3.83ms, accelerator: 3.85ms, total: 7.71ms
train.py:448:<module>, cpu: 144.00ms, accelerator: 0us, total: 144.00ms
train.py:447:<module>, cpu: 101.84ms, accelerator: 0us, total: 101.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_13500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.18sec, accelerator: 0us, total: 8.18sec (93.69%)
top 2 operation type: ImageSummary, cpu: 347.09ms, accelerator: 0us, total: 347.09ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 98.56ms, accelerator: 0us, total: 98.56ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.38ms, accelerator: 0us, total: 143.38ms
top 3 graph node: original, cpu: 101.96ms, accelerator: 0us, total: 101.96ms
train.py:511:<module>, cpu: 8.19sec, accelerator: 5.58ms, total: 8.19sec
  __init__.py:194:compute_gradients, cpu: 8.19sec, accelerator: 1.79ms, total: 8.19sec
    __init__.py:83:allreduce, cpu: 8.18sec, accelerator: 0us, total: 8.18sec
    __init__.py:86:allreduce, cpu: 6.08ms, accelerator: 1.79ms, total: 7.89ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 3.79ms, total: 7.63ms
train.py:448:<module>, cpu: 143.38ms, accelerator: 0us, total: 143.38ms
train.py:447:<module>, cpu: 101.96ms, accelerator: 0us, total: 101.96ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_13750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec (93.68%)
top 2 operation type: ImageSummary, cpu: 345.51ms, accelerator: 0us, total: 345.51ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 98.46ms, accelerator: 0us, total: 98.46ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.45ms, accelerator: 0us, total: 142.45ms
top 3 graph node: original, cpu: 101.62ms, accelerator: 0us, total: 101.62ms
train.py:511:<module>, cpu: 8.16sec, accelerator: 5.49ms, total: 8.16sec
  __init__.py:194:compute_gradients, cpu: 8.15sec, accelerator: 1.76ms, total: 8.15sec
    __init__.py:83:allreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec
    __init__.py:86:allreduce, cpu: 6.00ms, accelerator: 1.76ms, total: 7.79ms
  __init__.py:185:compute_gradients, cpu: 3.78ms, accelerator: 3.73ms, total: 7.54ms
train.py:448:<module>, cpu: 142.46ms, accelerator: 0us, total: 142.46ms
train.py:447:<module>, cpu: 101.63ms, accelerator: 0us, total: 101.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_14000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec (93.69%)
top 2 operation type: ImageSummary, cpu: 344.86ms, accelerator: 0us, total: 344.86ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 98.42ms, accelerator: 0us, total: 98.42ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.63ms, accelerator: 0us, total: 142.63ms
top 3 graph node: original, cpu: 101.58ms, accelerator: 0us, total: 101.58ms
train.py:511:<module>, cpu: 8.15sec, accelerator: 5.40ms, total: 8.15sec
  __init__.py:194:compute_gradients, cpu: 8.14sec, accelerator: 1.74ms, total: 8.14sec
    __init__.py:83:allreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec
    __init__.py:86:allreduce, cpu: 5.92ms, accelerator: 1.74ms, total: 7.69ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 3.67ms, total: 7.46ms
train.py:448:<module>, cpu: 142.64ms, accelerator: 0us, total: 142.64ms
train.py:447:<module>, cpu: 101.59ms, accelerator: 0us, total: 101.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_14250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.16sec, accelerator: 0us, total: 8.16sec (93.71%)
top 2 operation type: ImageSummary, cpu: 344.75ms, accelerator: 0us, total: 344.75ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 98.58ms, accelerator: 0us, total: 98.58ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.00ms, accelerator: 0us, total: 142.00ms
top 3 graph node: original, cpu: 101.82ms, accelerator: 0us, total: 101.82ms
train.py:511:<module>, cpu: 8.17sec, accelerator: 5.33ms, total: 8.17sec
  __init__.py:194:compute_gradients, cpu: 8.16sec, accelerator: 1.71ms, total: 8.17sec
    __init__.py:83:allreduce, cpu: 8.16sec, accelerator: 0us, total: 8.16sec
    __init__.py:86:allreduce, cpu: 5.96ms, accelerator: 1.71ms, total: 7.70ms
  __init__.py:185:compute_gradients, cpu: 3.85ms, accelerator: 3.62ms, total: 7.50ms
train.py:448:<module>, cpu: 142.01ms, accelerator: 0us, total: 142.01ms
train.py:447:<module>, cpu: 101.82ms, accelerator: 0us, total: 101.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_14500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec (93.73%)
top 2 operation type: ImageSummary, cpu: 344.06ms, accelerator: 0us, total: 344.06ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 97.80ms, accelerator: 0us, total: 97.80ms (1.12%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.83ms, accelerator: 0us, total: 141.83ms
top 3 graph node: difference, cpu: 101.12ms, accelerator: 0us, total: 101.12ms
train.py:511:<module>, cpu: 8.16sec, accelerator: 5.25ms, total: 8.17sec
  __init__.py:194:compute_gradients, cpu: 8.16sec, accelerator: 1.69ms, total: 8.16sec
    __init__.py:83:allreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec
    __init__.py:86:allreduce, cpu: 5.93ms, accelerator: 1.69ms, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 3.56ms, total: 7.41ms
train.py:448:<module>, cpu: 141.84ms, accelerator: 0us, total: 141.84ms
train.py:449:<module>, cpu: 101.16ms, accelerator: 41us, total: 101.20ms
  summary.py:146:image, cpu: 101.13ms, accelerator: 0us, total: 101.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_14750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.16sec, accelerator: 0us, total: 8.16sec (93.71%)
top 2 operation type: ImageSummary, cpu: 344.35ms, accelerator: 0us, total: 344.35ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 98.81ms, accelerator: 0us, total: 98.81ms (1.13%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.52ms, accelerator: 0us, total: 141.52ms
top 3 graph node: difference, cpu: 101.82ms, accelerator: 0us, total: 101.82ms
train.py:511:<module>, cpu: 8.17sec, accelerator: 5.27ms, total: 8.17sec
  __init__.py:194:compute_gradients, cpu: 8.16sec, accelerator: 1.72ms, total: 8.17sec
    __init__.py:83:allreduce, cpu: 8.16sec, accelerator: 0us, total: 8.16sec
    __init__.py:86:allreduce, cpu: 5.90ms, accelerator: 1.72ms, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.82ms, accelerator: 3.55ms, total: 7.41ms
train.py:448:<module>, cpu: 141.53ms, accelerator: 0us, total: 141.53ms
train.py:449:<module>, cpu: 101.85ms, accelerator: 41us, total: 101.89ms
  summary.py:146:image, cpu: 101.82ms, accelerator: 0us, total: 101.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_15000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec (93.67%)
top 2 operation type: ImageSummary, cpu: 346.91ms, accelerator: 0us, total: 346.91ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 99.48ms, accelerator: 0us, total: 99.48ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.48ms, accelerator: 0us, total: 142.48ms
top 3 graph node: difference, cpu: 102.90ms, accelerator: 0us, total: 102.90ms
train.py:511:<module>, cpu: 8.15sec, accelerator: 5.35ms, total: 8.15sec
  __init__.py:194:compute_gradients, cpu: 8.14sec, accelerator: 1.70ms, total: 8.15sec
    __init__.py:83:allreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec
    __init__.py:86:allreduce, cpu: 5.82ms, accelerator: 1.70ms, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.99ms, accelerator: 3.65ms, total: 7.68ms
train.py:448:<module>, cpu: 142.48ms, accelerator: 0us, total: 142.48ms
train.py:449:<module>, cpu: 102.94ms, accelerator: 40us, total: 102.98ms
  summary.py:146:image, cpu: 102.91ms, accelerator: 0us, total: 102.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2032.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_15250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec (93.67%)
top 2 operation type: ImageSummary, cpu: 346.05ms, accelerator: 0us, total: 346.05ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 100.00ms, accelerator: 0us, total: 100.00ms (1.15%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.07ms, accelerator: 0us, total: 142.07ms
top 3 graph node: difference, cpu: 103.02ms, accelerator: 0us, total: 103.02ms
train.py:511:<module>, cpu: 8.14sec, accelerator: 5.28ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.13sec, accelerator: 1.68ms, total: 8.14sec
    __init__.py:83:allreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec
    __init__.py:86:allreduce, cpu: 5.76ms, accelerator: 1.68ms, total: 7.46ms
  __init__.py:185:compute_gradients, cpu: 3.95ms, accelerator: 3.60ms, total: 7.59ms
train.py:448:<module>, cpu: 142.07ms, accelerator: 0us, total: 142.07ms
train.py:449:<module>, cpu: 103.06ms, accelerator: 40us, total: 103.10ms
  summary.py:146:image, cpu: 103.03ms, accelerator: 0us, total: 103.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_15500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec (93.68%)
top 2 operation type: ImageSummary, cpu: 346.18ms, accelerator: 0us, total: 346.18ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 99.23ms, accelerator: 0us, total: 99.23ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.27ms, accelerator: 0us, total: 142.27ms
top 3 graph node: difference, cpu: 103.21ms, accelerator: 0us, total: 103.21ms
train.py:511:<module>, cpu: 8.14sec, accelerator: 5.22ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.13sec, accelerator: 1.65ms, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec
    __init__.py:86:allreduce, cpu: 5.73ms, accelerator: 1.65ms, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 3.91ms, accelerator: 3.57ms, total: 7.52ms
train.py:448:<module>, cpu: 142.27ms, accelerator: 0us, total: 142.27ms
train.py:449:<module>, cpu: 103.25ms, accelerator: 39us, total: 103.29ms
  summary.py:146:image, cpu: 103.22ms, accelerator: 0us, total: 103.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_15750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (93.68%)
top 2 operation type: ImageSummary, cpu: 346.32ms, accelerator: 0us, total: 346.32ms (4.00%)
top 3 operation type: HistogramSummary, cpu: 99.10ms, accelerator: 0us, total: 99.10ms (1.14%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.49ms, accelerator: 0us, total: 142.49ms
top 3 graph node: difference, cpu: 103.31ms, accelerator: 0us, total: 103.31ms
train.py:511:<module>, cpu: 8.13sec, accelerator: 5.14ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 1.63ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 5.69ms, accelerator: 1.63ms, total: 7.34ms
  __init__.py:185:compute_gradients, cpu: 4.08ms, accelerator: 3.52ms, total: 7.63ms
train.py:448:<module>, cpu: 142.50ms, accelerator: 0us, total: 142.50ms
train.py:449:<module>, cpu: 103.34ms, accelerator: 39us, total: 103.38ms
  summary.py:146:image, cpu: 103.31ms, accelerator: 0us, total: 103.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_16000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (93.62%)
top 2 operation type: ImageSummary, cpu: 347.99ms, accelerator: 0us, total: 347.99ms (4.02%)
top 3 operation type: HistogramSummary, cpu: 100.65ms, accelerator: 0us, total: 100.65ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.38ms, accelerator: 0us, total: 143.38ms
top 3 graph node: difference, cpu: 104.11ms, accelerator: 0us, total: 104.11ms
train.py:511:<module>, cpu: 8.12sec, accelerator: 5.32ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 1.62ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 5.83ms, accelerator: 1.62ms, total: 7.48ms
  __init__.py:185:compute_gradients, cpu: 4.24ms, accelerator: 3.70ms, total: 7.97ms
train.py:448:<module>, cpu: 143.38ms, accelerator: 0us, total: 143.38ms
train.py:449:<module>, cpu: 104.14ms, accelerator: 38us, total: 104.18ms
  summary.py:146:image, cpu: 104.11ms, accelerator: 0us, total: 104.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_16250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (93.63%)
top 2 operation type: ImageSummary, cpu: 346.46ms, accelerator: 0us, total: 346.46ms (4.01%)
top 3 operation type: HistogramSummary, cpu: 100.60ms, accelerator: 0us, total: 100.60ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.88ms, accelerator: 0us, total: 142.88ms
top 3 graph node: difference, cpu: 103.54ms, accelerator: 0us, total: 103.54ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 5.26ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.60ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.77ms, accelerator: 1.60ms, total: 7.40ms
  __init__.py:185:compute_gradients, cpu: 4.19ms, accelerator: 3.66ms, total: 7.89ms
train.py:448:<module>, cpu: 142.89ms, accelerator: 0us, total: 142.89ms
train.py:449:<module>, cpu: 103.58ms, accelerator: 38us, total: 103.61ms
  summary.py:146:image, cpu: 103.55ms, accelerator: 0us, total: 103.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_16500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.61%)
top 2 operation type: ImageSummary, cpu: 345.89ms, accelerator: 0us, total: 345.89ms (4.01%)
top 3 operation type: HistogramSummary, cpu: 101.16ms, accelerator: 0us, total: 101.16ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.12ms, accelerator: 0us, total: 143.12ms
top 3 graph node: difference, cpu: 102.95ms, accelerator: 0us, total: 102.95ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.20ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.58ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.72ms, accelerator: 1.58ms, total: 7.32ms
  __init__.py:185:compute_gradients, cpu: 4.16ms, accelerator: 3.62ms, total: 7.81ms
train.py:448:<module>, cpu: 143.13ms, accelerator: 0us, total: 143.13ms
train.py:449:<module>, cpu: 102.98ms, accelerator: 37us, total: 103.02ms
  summary.py:146:image, cpu: 102.95ms, accelerator: 0us, total: 102.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_16750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.61%)
top 2 operation type: ImageSummary, cpu: 346.34ms, accelerator: 0us, total: 346.34ms (4.02%)
top 3 operation type: HistogramSummary, cpu: 101.06ms, accelerator: 0us, total: 101.06ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.56ms, accelerator: 0us, total: 143.56ms
top 3 graph node: difference, cpu: 103.26ms, accelerator: 0us, total: 103.26ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.29ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.56ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.65ms, accelerator: 1.56ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 4.13ms, accelerator: 3.73ms, total: 7.90ms
train.py:448:<module>, cpu: 143.57ms, accelerator: 0us, total: 143.57ms
train.py:449:<module>, cpu: 103.30ms, accelerator: 37us, total: 103.34ms
  summary.py:146:image, cpu: 103.27ms, accelerator: 0us, total: 103.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_17000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.62%)
top 2 operation type: ImageSummary, cpu: 345.91ms, accelerator: 0us, total: 345.91ms (4.01%)
top 3 operation type: HistogramSummary, cpu: 101.05ms, accelerator: 0us, total: 101.05ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.45ms, accelerator: 0us, total: 143.45ms
top 3 graph node: difference, cpu: 102.87ms, accelerator: 0us, total: 102.87ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.32ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.64ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 1.64ms, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 4.09ms, accelerator: 3.68ms, total: 7.82ms
train.py:448:<module>, cpu: 143.46ms, accelerator: 0us, total: 143.46ms
train.py:449:<module>, cpu: 102.91ms, accelerator: 36us, total: 102.94ms
  summary.py:146:image, cpu: 102.87ms, accelerator: 0us, total: 102.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_17250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.63%)
top 2 operation type: ImageSummary, cpu: 345.74ms, accelerator: 0us, total: 345.74ms (4.01%)
top 3 operation type: HistogramSummary, cpu: 100.67ms, accelerator: 0us, total: 100.67ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.61ms, accelerator: 0us, total: 143.61ms
top 3 graph node: difference, cpu: 102.94ms, accelerator: 0us, total: 102.94ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.25ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.61ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.53ms, accelerator: 1.61ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 4.06ms, accelerator: 3.64ms, total: 7.74ms
train.py:448:<module>, cpu: 143.61ms, accelerator: 0us, total: 143.61ms
train.py:449:<module>, cpu: 102.98ms, accelerator: 36us, total: 103.01ms
  summary.py:146:image, cpu: 102.94ms, accelerator: 0us, total: 102.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2032.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_17500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.65%)
top 2 operation type: ImageSummary, cpu: 344.62ms, accelerator: 0us, total: 344.62ms (4.00%)
top 3 operation type: HistogramSummary, cpu: 100.22ms, accelerator: 0us, total: 100.22ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.32ms, accelerator: 0us, total: 143.32ms
top 3 graph node: difference, cpu: 102.51ms, accelerator: 0us, total: 102.51ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.19ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.59ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.55ms, accelerator: 1.59ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 4.03ms, accelerator: 3.60ms, total: 7.67ms
train.py:448:<module>, cpu: 143.33ms, accelerator: 0us, total: 143.33ms
train.py:449:<module>, cpu: 102.55ms, accelerator: 35us, total: 102.58ms
  summary.py:146:image, cpu: 102.52ms, accelerator: 0us, total: 102.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_17750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.65%)
top 2 operation type: ImageSummary, cpu: 344.06ms, accelerator: 0us, total: 344.06ms (4.01%)
top 3 operation type: HistogramSummary, cpu: 99.87ms, accelerator: 0us, total: 99.87ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.88ms, accelerator: 0us, total: 142.88ms
top 3 graph node: difference, cpu: 102.59ms, accelerator: 0us, total: 102.59ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.22ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.58ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 1.58ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 4.00ms, accelerator: 3.65ms, total: 7.68ms
train.py:448:<module>, cpu: 142.89ms, accelerator: 0us, total: 142.89ms
train.py:449:<module>, cpu: 102.63ms, accelerator: 35us, total: 102.66ms
  summary.py:146:image, cpu: 102.59ms, accelerator: 0us, total: 102.59ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_18000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.62%)
top 2 operation type: ImageSummary, cpu: 345.07ms, accelerator: 0us, total: 345.07ms (4.02%)
top 3 operation type: HistogramSummary, cpu: 100.53ms, accelerator: 0us, total: 100.53ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.87ms, accelerator: 0us, total: 142.87ms
top 3 graph node: difference, cpu: 102.99ms, accelerator: 0us, total: 102.99ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.37ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.77ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 1.77ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.97ms, accelerator: 3.60ms, total: 7.62ms
train.py:448:<module>, cpu: 142.88ms, accelerator: 0us, total: 142.88ms
train.py:449:<module>, cpu: 103.03ms, accelerator: 34us, total: 103.06ms
  summary.py:146:image, cpu: 102.99ms, accelerator: 0us, total: 102.99ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_18250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.62%)
top 2 operation type: ImageSummary, cpu: 344.45ms, accelerator: 0us, total: 344.45ms (4.02%)
top 3 operation type: HistogramSummary, cpu: 101.41ms, accelerator: 0us, total: 101.41ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.90ms, accelerator: 0us, total: 142.90ms
top 3 graph node: difference, cpu: 102.71ms, accelerator: 0us, total: 102.71ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.32ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.75ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 1.75ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.94ms, accelerator: 3.57ms, total: 7.54ms
train.py:448:<module>, cpu: 142.91ms, accelerator: 0us, total: 142.91ms
train.py:449:<module>, cpu: 102.75ms, accelerator: 34us, total: 102.78ms
  summary.py:146:image, cpu: 102.71ms, accelerator: 0us, total: 102.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_18500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.99sec, accelerator: 0us, total: 7.99sec (93.57%)
top 2 operation type: ImageSummary, cpu: 345.64ms, accelerator: 0us, total: 345.64ms (4.05%)
top 3 operation type: HistogramSummary, cpu: 101.22ms, accelerator: 0us, total: 101.22ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.42ms, accelerator: 0us, total: 143.42ms
top 3 graph node: difference, cpu: 102.88ms, accelerator: 0us, total: 102.88ms
train.py:511:<module>, cpu: 8.00sec, accelerator: 5.42ms, total: 8.01sec
  __init__.py:194:compute_gradients, cpu: 8.00sec, accelerator: 1.76ms, total: 8.00sec
    __init__.py:83:allreduce, cpu: 7.99sec, accelerator: 0us, total: 7.99sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 1.76ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.91ms, accelerator: 3.66ms, total: 7.61ms
train.py:448:<module>, cpu: 143.43ms, accelerator: 0us, total: 143.43ms
train.py:449:<module>, cpu: 102.91ms, accelerator: 34us, total: 102.95ms
  summary.py:146:image, cpu: 102.88ms, accelerator: 0us, total: 102.88ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_18750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec (93.53%)
top 2 operation type: ImageSummary, cpu: 345.21ms, accelerator: 0us, total: 345.21ms (4.04%)
top 3 operation type: HistogramSummary, cpu: 101.44ms, accelerator: 0us, total: 101.44ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.74ms, accelerator: 0us, total: 143.74ms
top 3 graph node: difference, cpu: 102.49ms, accelerator: 0us, total: 102.49ms
train.py:511:<module>, cpu: 7.99sec, accelerator: 5.53ms, total: 8.00sec
  __init__.py:194:compute_gradients, cpu: 7.99sec, accelerator: 1.81ms, total: 7.99sec
    __init__.py:83:allreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec
    __init__.py:86:allreduce, cpu: 5.52ms, accelerator: 1.81ms, total: 7.34ms
  __init__.py:185:compute_gradients, cpu: 3.90ms, accelerator: 3.72ms, total: 7.65ms
train.py:448:<module>, cpu: 143.74ms, accelerator: 0us, total: 143.74ms
train.py:449:<module>, cpu: 102.53ms, accelerator: 34us, total: 102.56ms
  summary.py:146:image, cpu: 102.49ms, accelerator: 0us, total: 102.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_19000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.53%)
top 2 operation type: ImageSummary, cpu: 344.18ms, accelerator: 0us, total: 344.18ms (4.04%)
top 3 operation type: HistogramSummary, cpu: 101.54ms, accelerator: 0us, total: 101.54ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.34ms, accelerator: 0us, total: 143.34ms
top 3 graph node: difference, cpu: 102.17ms, accelerator: 0us, total: 102.17ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 5.46ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.79ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 1.79ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.88ms, accelerator: 3.67ms, total: 7.60ms
train.py:448:<module>, cpu: 143.34ms, accelerator: 0us, total: 143.34ms
train.py:449:<module>, cpu: 102.21ms, accelerator: 33us, total: 102.24ms
  summary.py:146:image, cpu: 102.18ms, accelerator: 0us, total: 102.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_19250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.52%)
top 2 operation type: ImageSummary, cpu: 344.29ms, accelerator: 0us, total: 344.29ms (4.05%)
top 3 operation type: HistogramSummary, cpu: 102.16ms, accelerator: 0us, total: 102.16ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.29ms, accelerator: 0us, total: 143.29ms
top 3 graph node: difference, cpu: 102.24ms, accelerator: 0us, total: 102.24ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 5.47ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.84ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.50ms, accelerator: 1.84ms, total: 7.36ms
  __init__.py:185:compute_gradients, cpu: 3.86ms, accelerator: 3.63ms, total: 7.54ms
train.py:448:<module>, cpu: 143.29ms, accelerator: 0us, total: 143.29ms
train.py:449:<module>, cpu: 102.28ms, accelerator: 33us, total: 102.31ms
  summary.py:146:image, cpu: 102.25ms, accelerator: 0us, total: 102.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2038.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_19500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec (93.53%)
top 2 operation type: ImageSummary, cpu: 344.85ms, accelerator: 0us, total: 344.85ms (4.03%)
top 3 operation type: HistogramSummary, cpu: 102.72ms, accelerator: 0us, total: 102.72ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.66ms, accelerator: 0us, total: 143.66ms
top 3 graph node: difference, cpu: 102.43ms, accelerator: 0us, total: 102.43ms
train.py:511:<module>, cpu: 8.01sec, accelerator: 5.43ms, total: 8.01sec
  __init__.py:194:compute_gradients, cpu: 8.00sec, accelerator: 1.82ms, total: 8.00sec
    __init__.py:83:allreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 1.82ms, total: 7.30ms
  __init__.py:185:compute_gradients, cpu: 3.85ms, accelerator: 3.61ms, total: 7.49ms
train.py:448:<module>, cpu: 143.67ms, accelerator: 0us, total: 143.67ms
train.py:449:<module>, cpu: 102.46ms, accelerator: 33us, total: 102.50ms
  summary.py:146:image, cpu: 102.43ms, accelerator: 0us, total: 102.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_19750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec (93.54%)
top 2 operation type: ImageSummary, cpu: 344.57ms, accelerator: 0us, total: 344.57ms (4.04%)
top 3 operation type: HistogramSummary, cpu: 102.25ms, accelerator: 0us, total: 102.25ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.64ms, accelerator: 0us, total: 143.64ms
top 3 graph node: difference, cpu: 102.31ms, accelerator: 0us, total: 102.31ms
train.py:511:<module>, cpu: 7.99sec, accelerator: 5.49ms, total: 8.00sec
  __init__.py:194:compute_gradients, cpu: 7.99sec, accelerator: 1.80ms, total: 7.99sec
    __init__.py:83:allreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 1.80ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.92ms, accelerator: 3.68ms, total: 7.66ms
train.py:448:<module>, cpu: 143.65ms, accelerator: 0us, total: 143.65ms
train.py:449:<module>, cpu: 102.34ms, accelerator: 32us, total: 102.38ms
  summary.py:146:image, cpu: 102.31ms, accelerator: 0us, total: 102.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_20000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.58%)
top 2 operation type: ImageSummary, cpu: 343.32ms, accelerator: 0us, total: 343.32ms (4.01%)
top 3 operation type: HistogramSummary, cpu: 101.94ms, accelerator: 0us, total: 101.94ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.26ms, accelerator: 0us, total: 143.26ms
top 3 graph node: difference, cpu: 102.01ms, accelerator: 0us, total: 102.01ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 5.76ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.79ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 1.79ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.92ms, accelerator: 3.97ms, total: 7.92ms
train.py:448:<module>, cpu: 143.27ms, accelerator: 0us, total: 143.27ms
train.py:449:<module>, cpu: 102.05ms, accelerator: 32us, total: 102.08ms
  summary.py:146:image, cpu: 102.02ms, accelerator: 0us, total: 102.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2038.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_20250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.61%)
top 2 operation type: ImageSummary, cpu: 342.29ms, accelerator: 0us, total: 342.29ms (4.00%)
top 3 operation type: HistogramSummary, cpu: 101.34ms, accelerator: 0us, total: 101.34ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.05ms, accelerator: 0us, total: 143.05ms
top 3 graph node: difference, cpu: 101.68ms, accelerator: 0us, total: 101.68ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.70ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.77ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.48ms, accelerator: 1.77ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 3.89ms, accelerator: 3.93ms, total: 7.86ms
train.py:448:<module>, cpu: 143.06ms, accelerator: 0us, total: 143.06ms
train.py:449:<module>, cpu: 101.72ms, accelerator: 32us, total: 101.75ms
  summary.py:146:image, cpu: 101.69ms, accelerator: 0us, total: 101.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_20500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.62%)
top 2 operation type: ImageSummary, cpu: 341.63ms, accelerator: 0us, total: 341.63ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 100.82ms, accelerator: 0us, total: 100.82ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.82ms, accelerator: 0us, total: 142.82ms
top 3 graph node: difference, cpu: 101.70ms, accelerator: 0us, total: 101.70ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 5.64ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.76ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 1.76ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 3.87ms, accelerator: 3.88ms, total: 7.80ms
train.py:448:<module>, cpu: 142.83ms, accelerator: 0us, total: 142.83ms
train.py:449:<module>, cpu: 101.73ms, accelerator: 31us, total: 101.77ms
  summary.py:146:image, cpu: 101.70ms, accelerator: 0us, total: 101.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_20750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.61%)
top 2 operation type: ImageSummary, cpu: 341.64ms, accelerator: 0us, total: 341.64ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 101.23ms, accelerator: 0us, total: 101.23ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.72ms, accelerator: 0us, total: 142.72ms
top 3 graph node: difference, cpu: 101.45ms, accelerator: 0us, total: 101.45ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.73ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.76ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 1.76ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 3.84ms, accelerator: 3.97ms, total: 7.86ms
train.py:448:<module>, cpu: 142.72ms, accelerator: 0us, total: 142.72ms
train.py:449:<module>, cpu: 101.48ms, accelerator: 54us, total: 101.54ms
  summary.py:146:image, cpu: 101.45ms, accelerator: 0us, total: 101.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_21000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.61%)
top 2 operation type: ImageSummary, cpu: 342.71ms, accelerator: 0us, total: 342.71ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 101.47ms, accelerator: 0us, total: 101.47ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.77ms, accelerator: 0us, total: 142.77ms
top 3 graph node: difference, cpu: 101.85ms, accelerator: 0us, total: 101.85ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.91ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.74ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 1.74ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.87ms, accelerator: 4.17ms, total: 8.08ms
train.py:448:<module>, cpu: 142.78ms, accelerator: 0us, total: 142.78ms
train.py:449:<module>, cpu: 101.88ms, accelerator: 53us, total: 101.94ms
  summary.py:146:image, cpu: 101.85ms, accelerator: 0us, total: 101.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_21250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.62%)
top 2 operation type: ImageSummary, cpu: 342.46ms, accelerator: 0us, total: 342.46ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 101.17ms, accelerator: 0us, total: 101.17ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.10ms, accelerator: 0us, total: 143.10ms
top 3 graph node: difference, cpu: 101.53ms, accelerator: 0us, total: 101.53ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.84ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.72ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.72ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.85ms, accelerator: 4.12ms, total: 8.02ms
train.py:448:<module>, cpu: 143.10ms, accelerator: 0us, total: 143.10ms
train.py:449:<module>, cpu: 101.57ms, accelerator: 53us, total: 101.62ms
  summary.py:146:image, cpu: 101.54ms, accelerator: 0us, total: 101.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2026.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_21500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.62%)
top 2 operation type: ImageSummary, cpu: 342.48ms, accelerator: 0us, total: 342.48ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 102.17ms, accelerator: 0us, total: 102.17ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.44ms, accelerator: 0us, total: 143.44ms
top 3 graph node: difference, cpu: 101.84ms, accelerator: 0us, total: 101.84ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.79ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.71ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.71ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 3.83ms, accelerator: 4.08ms, total: 7.96ms
train.py:448:<module>, cpu: 143.44ms, accelerator: 0us, total: 143.44ms
train.py:449:<module>, cpu: 101.87ms, accelerator: 52us, total: 101.93ms
  summary.py:146:image, cpu: 101.84ms, accelerator: 0us, total: 101.84ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_21750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.62%)
top 2 operation type: ImageSummary, cpu: 342.33ms, accelerator: 0us, total: 342.33ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 102.55ms, accelerator: 0us, total: 102.55ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.27ms, accelerator: 0us, total: 143.27ms
top 3 graph node: difference, cpu: 101.71ms, accelerator: 0us, total: 101.71ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.74ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.69ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.69ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 3.81ms, accelerator: 4.04ms, total: 7.90ms
train.py:448:<module>, cpu: 143.27ms, accelerator: 0us, total: 143.27ms
train.py:449:<module>, cpu: 101.74ms, accelerator: 52us, total: 101.80ms
  summary.py:146:image, cpu: 101.71ms, accelerator: 0us, total: 101.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_22000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.63%)
top 2 operation type: ImageSummary, cpu: 341.64ms, accelerator: 0us, total: 341.64ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.47ms, accelerator: 0us, total: 102.47ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.83ms, accelerator: 0us, total: 142.83ms
top 3 graph node: difference, cpu: 101.33ms, accelerator: 0us, total: 101.33ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.75ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.68ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.30ms, accelerator: 1.68ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 4.08ms, total: 7.91ms
train.py:448:<module>, cpu: 142.84ms, accelerator: 0us, total: 142.84ms
train.py:449:<module>, cpu: 101.36ms, accelerator: 51us, total: 101.42ms
  summary.py:146:image, cpu: 101.33ms, accelerator: 0us, total: 101.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_22250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.64%)
top 2 operation type: ImageSummary, cpu: 341.82ms, accelerator: 0us, total: 341.82ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.79ms, accelerator: 0us, total: 102.79ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.30ms, accelerator: 0us, total: 143.30ms
top 3 graph node: difference, cpu: 101.40ms, accelerator: 0us, total: 101.40ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.70ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.66ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.26ms, accelerator: 1.66ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 4.04ms, total: 7.86ms
train.py:448:<module>, cpu: 143.31ms, accelerator: 0us, total: 143.31ms
train.py:449:<module>, cpu: 101.44ms, accelerator: 51us, total: 101.49ms
  summary.py:146:image, cpu: 101.41ms, accelerator: 0us, total: 101.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_22500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.65%)
top 2 operation type: ImageSummary, cpu: 342.70ms, accelerator: 0us, total: 342.70ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.57ms, accelerator: 0us, total: 102.57ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.84ms, accelerator: 0us, total: 143.84ms
top 3 graph node: difference, cpu: 101.85ms, accelerator: 0us, total: 101.85ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.77ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.65ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 1.65ms, total: 6.90ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 4.12ms, total: 7.92ms
train.py:448:<module>, cpu: 143.85ms, accelerator: 0us, total: 143.85ms
train.py:449:<module>, cpu: 101.88ms, accelerator: 50us, total: 101.94ms
  summary.py:146:image, cpu: 101.85ms, accelerator: 0us, total: 101.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_22750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.62%)
top 2 operation type: ImageSummary, cpu: 343.81ms, accelerator: 0us, total: 343.81ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 102.71ms, accelerator: 0us, total: 102.71ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.12ms, accelerator: 0us, total: 144.12ms
top 3 graph node: difference, cpu: 102.25ms, accelerator: 0us, total: 102.25ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 6.05ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.64ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 1.64ms, total: 7.11ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 4.42ms, total: 8.19ms
train.py:448:<module>, cpu: 144.12ms, accelerator: 0us, total: 144.12ms
train.py:449:<module>, cpu: 102.29ms, accelerator: 50us, total: 102.34ms
  summary.py:146:image, cpu: 102.26ms, accelerator: 0us, total: 102.26ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_23000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.62%)
top 2 operation type: ImageSummary, cpu: 343.86ms, accelerator: 0us, total: 343.86ms (4.00%)
top 3 operation type: HistogramSummary, cpu: 102.36ms, accelerator: 0us, total: 102.36ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.41ms, accelerator: 0us, total: 144.41ms
top 3 graph node: difference, cpu: 101.97ms, accelerator: 0us, total: 101.97ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.99ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.62ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 1.62ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 4.37ms, total: 8.19ms
train.py:448:<module>, cpu: 144.41ms, accelerator: 0us, total: 144.41ms
train.py:449:<module>, cpu: 102.00ms, accelerator: 49us, total: 102.05ms
  summary.py:146:image, cpu: 101.97ms, accelerator: 0us, total: 101.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_23250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.62%)
top 2 operation type: ImageSummary, cpu: 343.90ms, accelerator: 0us, total: 343.90ms (4.00%)
top 3 operation type: HistogramSummary, cpu: 102.35ms, accelerator: 0us, total: 102.35ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.31ms, accelerator: 0us, total: 144.31ms
top 3 graph node: difference, cpu: 101.88ms, accelerator: 0us, total: 101.88ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.94ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.60ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 1.60ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 3.75ms, accelerator: 4.34ms, total: 8.12ms
train.py:448:<module>, cpu: 144.32ms, accelerator: 0us, total: 144.32ms
train.py:449:<module>, cpu: 101.92ms, accelerator: 49us, total: 101.97ms
  summary.py:146:image, cpu: 101.89ms, accelerator: 0us, total: 101.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_23500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.63%)
top 2 operation type: ImageSummary, cpu: 343.48ms, accelerator: 0us, total: 343.48ms (4.00%)
top 3 operation type: HistogramSummary, cpu: 102.16ms, accelerator: 0us, total: 102.16ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 144.42ms, accelerator: 0us, total: 144.42ms
top 3 graph node: difference, cpu: 101.71ms, accelerator: 0us, total: 101.71ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.88ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.59ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.59ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 3.79ms, accelerator: 4.29ms, total: 8.12ms
train.py:448:<module>, cpu: 144.43ms, accelerator: 0us, total: 144.43ms
train.py:449:<module>, cpu: 101.74ms, accelerator: 48us, total: 101.79ms
  summary.py:146:image, cpu: 101.71ms, accelerator: 0us, total: 101.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_23750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.66%)
top 2 operation type: ImageSummary, cpu: 342.43ms, accelerator: 0us, total: 342.43ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.15ms, accelerator: 0us, total: 102.15ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.90ms, accelerator: 0us, total: 143.90ms
top 3 graph node: difference, cpu: 101.49ms, accelerator: 0us, total: 101.49ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.85ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.59ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.30ms, accelerator: 1.59ms, total: 6.91ms
  __init__.py:185:compute_gradients, cpu: 3.77ms, accelerator: 4.27ms, total: 8.08ms
train.py:448:<module>, cpu: 143.90ms, accelerator: 0us, total: 143.90ms
train.py:449:<module>, cpu: 101.53ms, accelerator: 48us, total: 101.58ms
  summary.py:146:image, cpu: 101.50ms, accelerator: 0us, total: 101.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_24000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.67%)
top 2 operation type: ImageSummary, cpu: 341.84ms, accelerator: 0us, total: 341.84ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 101.81ms, accelerator: 0us, total: 101.81ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.97ms, accelerator: 0us, total: 143.97ms
top 3 graph node: difference, cpu: 101.12ms, accelerator: 0us, total: 101.12ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.80ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.57ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.26ms, accelerator: 1.57ms, total: 6.86ms
  __init__.py:185:compute_gradients, cpu: 3.74ms, accelerator: 4.23ms, total: 8.01ms
train.py:448:<module>, cpu: 143.97ms, accelerator: 0us, total: 143.97ms
train.py:449:<module>, cpu: 101.15ms, accelerator: 47us, total: 101.20ms
  summary.py:146:image, cpu: 101.12ms, accelerator: 0us, total: 101.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_24250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.67%)
top 2 operation type: ImageSummary, cpu: 341.69ms, accelerator: 0us, total: 341.69ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 101.74ms, accelerator: 0us, total: 101.74ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.78ms, accelerator: 0us, total: 143.78ms
top 3 graph node: difference, cpu: 101.44ms, accelerator: 0us, total: 101.44ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.76ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.56ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 1.56ms, total: 6.81ms
  __init__.py:185:compute_gradients, cpu: 3.73ms, accelerator: 4.20ms, total: 7.97ms
train.py:448:<module>, cpu: 143.78ms, accelerator: 0us, total: 143.78ms
train.py:449:<module>, cpu: 101.48ms, accelerator: 47us, total: 101.53ms
  summary.py:146:image, cpu: 101.44ms, accelerator: 0us, total: 101.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_24500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.68%)
top 2 operation type: ImageSummary, cpu: 341.30ms, accelerator: 0us, total: 341.30ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 102.17ms, accelerator: 0us, total: 102.17ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.57ms, accelerator: 0us, total: 143.57ms
top 3 graph node: difference, cpu: 101.49ms, accelerator: 0us, total: 101.49ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.71ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.55ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 1.55ms, total: 6.82ms
  __init__.py:185:compute_gradients, cpu: 3.71ms, accelerator: 4.16ms, total: 7.91ms
train.py:448:<module>, cpu: 143.58ms, accelerator: 0us, total: 143.58ms
train.py:449:<module>, cpu: 101.53ms, accelerator: 46us, total: 101.57ms
  summary.py:146:image, cpu: 101.49ms, accelerator: 0us, total: 101.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_24750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.69%)
top 2 operation type: ImageSummary, cpu: 340.51ms, accelerator: 0us, total: 340.51ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 102.03ms, accelerator: 0us, total: 102.03ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.26ms, accelerator: 0us, total: 143.26ms
top 3 graph node: difference, cpu: 101.25ms, accelerator: 0us, total: 101.25ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.66ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.54ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.80ms, accelerator: 1.54ms, total: 7.36ms
  __init__.py:185:compute_gradients, cpu: 3.69ms, accelerator: 4.12ms, total: 7.86ms
train.py:448:<module>, cpu: 143.26ms, accelerator: 0us, total: 143.26ms
train.py:449:<module>, cpu: 101.29ms, accelerator: 46us, total: 101.33ms
  summary.py:146:image, cpu: 101.26ms, accelerator: 0us, total: 101.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_25000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.69%)
top 2 operation type: ImageSummary, cpu: 339.94ms, accelerator: 0us, total: 339.94ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 101.58ms, accelerator: 0us, total: 101.58ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.29ms, accelerator: 0us, total: 143.29ms
top 3 graph node: difference, cpu: 100.83ms, accelerator: 0us, total: 100.83ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.62ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.53ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.77ms, accelerator: 1.53ms, total: 7.32ms
  __init__.py:185:compute_gradients, cpu: 3.68ms, accelerator: 4.09ms, total: 7.82ms
train.py:448:<module>, cpu: 143.29ms, accelerator: 0us, total: 143.29ms
train.py:449:<module>, cpu: 100.87ms, accelerator: 46us, total: 100.92ms
  summary.py:146:image, cpu: 100.84ms, accelerator: 0us, total: 100.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_25250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.70%)
top 2 operation type: ImageSummary, cpu: 339.25ms, accelerator: 0us, total: 339.25ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 101.48ms, accelerator: 0us, total: 101.48ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.07ms, accelerator: 0us, total: 143.07ms
top 3 graph node: difference, cpu: 100.67ms, accelerator: 0us, total: 100.67ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.58ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.52ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.82ms, accelerator: 1.52ms, total: 7.35ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 4.06ms, total: 7.77ms
train.py:448:<module>, cpu: 143.08ms, accelerator: 0us, total: 143.08ms
train.py:449:<module>, cpu: 100.71ms, accelerator: 45us, total: 100.75ms
  summary.py:146:image, cpu: 100.67ms, accelerator: 0us, total: 100.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_25500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.68%)
top 2 operation type: ImageSummary, cpu: 340.02ms, accelerator: 0us, total: 340.02ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 101.49ms, accelerator: 0us, total: 101.49ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.39ms, accelerator: 0us, total: 143.39ms
top 3 graph node: difference, cpu: 101.00ms, accelerator: 0us, total: 101.00ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.81ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.54ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.81ms, accelerator: 1.54ms, total: 7.37ms
  __init__.py:185:compute_gradients, cpu: 3.66ms, accelerator: 4.27ms, total: 7.97ms
train.py:448:<module>, cpu: 143.39ms, accelerator: 0us, total: 143.39ms
train.py:449:<module>, cpu: 101.04ms, accelerator: 45us, total: 101.09ms
  summary.py:146:image, cpu: 101.01ms, accelerator: 0us, total: 101.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_25750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.70%)
top 2 operation type: ImageSummary, cpu: 339.53ms, accelerator: 0us, total: 339.53ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 101.17ms, accelerator: 0us, total: 101.17ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.47ms, accelerator: 0us, total: 143.47ms
top 3 graph node: difference, cpu: 100.53ms, accelerator: 0us, total: 100.53ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.76ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.53ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.77ms, accelerator: 1.53ms, total: 7.33ms
  __init__.py:185:compute_gradients, cpu: 3.65ms, accelerator: 4.23ms, total: 7.91ms
train.py:448:<module>, cpu: 143.47ms, accelerator: 0us, total: 143.47ms
train.py:449:<module>, cpu: 100.56ms, accelerator: 44us, total: 100.61ms
  summary.py:146:image, cpu: 100.53ms, accelerator: 0us, total: 100.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_26000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.70%)
top 2 operation type: ImageSummary, cpu: 339.60ms, accelerator: 0us, total: 339.60ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 100.80ms, accelerator: 0us, total: 100.80ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.51ms, accelerator: 0us, total: 143.51ms
top 3 graph node: difference, cpu: 100.65ms, accelerator: 0us, total: 100.65ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.89ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.52ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.83ms, accelerator: 1.52ms, total: 7.38ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 4.37ms, total: 8.03ms
train.py:448:<module>, cpu: 143.52ms, accelerator: 0us, total: 143.52ms
train.py:449:<module>, cpu: 100.68ms, accelerator: 44us, total: 100.73ms
  summary.py:146:image, cpu: 100.65ms, accelerator: 0us, total: 100.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_26250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.69%)
top 2 operation type: ImageSummary, cpu: 340.25ms, accelerator: 0us, total: 340.25ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 100.90ms, accelerator: 0us, total: 100.90ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.62ms, accelerator: 0us, total: 143.62ms
top 3 graph node: difference, cpu: 100.53ms, accelerator: 0us, total: 100.53ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.84ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.50ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.80ms, accelerator: 1.50ms, total: 7.33ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 4.33ms, total: 7.99ms
train.py:448:<module>, cpu: 143.62ms, accelerator: 0us, total: 143.62ms
train.py:449:<module>, cpu: 100.57ms, accelerator: 44us, total: 100.61ms
  summary.py:146:image, cpu: 100.53ms, accelerator: 0us, total: 100.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_26500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.69%)
top 2 operation type: ImageSummary, cpu: 340.43ms, accelerator: 0us, total: 340.43ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 100.57ms, accelerator: 0us, total: 100.57ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.70ms, accelerator: 0us, total: 143.70ms
top 3 graph node: difference, cpu: 100.45ms, accelerator: 0us, total: 100.45ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 5.79ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.49ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.79ms, accelerator: 1.49ms, total: 7.31ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 4.30ms, total: 7.94ms
train.py:448:<module>, cpu: 143.70ms, accelerator: 0us, total: 143.70ms
train.py:449:<module>, cpu: 100.49ms, accelerator: 43us, total: 100.54ms
  summary.py:146:image, cpu: 100.46ms, accelerator: 0us, total: 100.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_26750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.69%)
top 2 operation type: ImageSummary, cpu: 340.39ms, accelerator: 0us, total: 340.39ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 100.46ms, accelerator: 0us, total: 100.46ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.61ms, accelerator: 0us, total: 143.61ms
top 3 graph node: difference, cpu: 100.31ms, accelerator: 0us, total: 100.31ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.74ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.48ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.78ms, accelerator: 1.48ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 4.26ms, total: 7.89ms
train.py:448:<module>, cpu: 143.61ms, accelerator: 0us, total: 143.61ms
train.py:449:<module>, cpu: 100.35ms, accelerator: 43us, total: 100.39ms
  summary.py:146:image, cpu: 100.31ms, accelerator: 0us, total: 100.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_27000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.70%)
top 2 operation type: ImageSummary, cpu: 340.35ms, accelerator: 0us, total: 340.35ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 100.38ms, accelerator: 0us, total: 100.38ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.73ms, accelerator: 0us, total: 143.73ms
top 3 graph node: difference, cpu: 100.09ms, accelerator: 0us, total: 100.09ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.69ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.47ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.75ms, accelerator: 1.47ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 4.22ms, total: 7.84ms
train.py:448:<module>, cpu: 143.74ms, accelerator: 0us, total: 143.74ms
train.py:449:<module>, cpu: 100.13ms, accelerator: 43us, total: 100.17ms
  summary.py:146:image, cpu: 100.10ms, accelerator: 0us, total: 100.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_27250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.72%)
top 2 operation type: ImageSummary, cpu: 339.46ms, accelerator: 0us, total: 339.46ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 100.39ms, accelerator: 0us, total: 100.39ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.62ms, accelerator: 0us, total: 143.62ms
top 3 graph node: difference, cpu: 99.72ms, accelerator: 0us, total: 99.72ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.75ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.46ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.71ms, accelerator: 1.46ms, total: 7.19ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.29ms, total: 7.88ms
train.py:448:<module>, cpu: 143.63ms, accelerator: 0us, total: 143.63ms
train.py:449:<module>, cpu: 99.75ms, accelerator: 42us, total: 99.80ms
  summary.py:146:image, cpu: 99.72ms, accelerator: 0us, total: 99.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_27500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.73%)
top 2 operation type: ImageSummary, cpu: 339.64ms, accelerator: 0us, total: 339.64ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 100.29ms, accelerator: 0us, total: 100.29ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.56ms, accelerator: 0us, total: 143.56ms
top 3 graph node: difference, cpu: 100.07ms, accelerator: 0us, total: 100.07ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.70ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.45ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.69ms, accelerator: 1.45ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 4.25ms, total: 7.83ms
train.py:448:<module>, cpu: 143.56ms, accelerator: 0us, total: 143.56ms
train.py:449:<module>, cpu: 100.10ms, accelerator: 42us, total: 100.15ms
  summary.py:146:image, cpu: 100.07ms, accelerator: 0us, total: 100.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2014.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_27750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (93.76%)
top 2 operation type: ImageSummary, cpu: 338.82ms, accelerator: 0us, total: 338.82ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 100.11ms, accelerator: 0us, total: 100.11ms (1.16%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.14ms, accelerator: 0us, total: 143.14ms
top 3 graph node: difference, cpu: 100.02ms, accelerator: 0us, total: 100.02ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 5.66ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.44ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.66ms, accelerator: 1.44ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 4.22ms, total: 7.79ms
train.py:448:<module>, cpu: 143.15ms, accelerator: 0us, total: 143.15ms
train.py:449:<module>, cpu: 100.06ms, accelerator: 41us, total: 100.10ms
  summary.py:146:image, cpu: 100.02ms, accelerator: 0us, total: 100.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2034.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_28000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.75%)
top 2 operation type: ImageSummary, cpu: 338.42ms, accelerator: 0us, total: 338.42ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 100.40ms, accelerator: 0us, total: 100.40ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.02ms, accelerator: 0us, total: 143.02ms
top 3 graph node: difference, cpu: 100.03ms, accelerator: 0us, total: 100.03ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.62ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.43ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.43ms, total: 7.09ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.19ms, total: 7.74ms
train.py:448:<module>, cpu: 143.02ms, accelerator: 0us, total: 143.02ms
train.py:449:<module>, cpu: 100.06ms, accelerator: 41us, total: 100.11ms
  summary.py:146:image, cpu: 100.03ms, accelerator: 0us, total: 100.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_28250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.76%)
top 2 operation type: ImageSummary, cpu: 337.90ms, accelerator: 0us, total: 337.90ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 100.70ms, accelerator: 0us, total: 100.70ms (1.17%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.78ms, accelerator: 0us, total: 142.78ms
top 3 graph node: difference, cpu: 99.65ms, accelerator: 0us, total: 99.65ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.58ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.43ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.43ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 4.15ms, total: 7.69ms
train.py:448:<module>, cpu: 142.78ms, accelerator: 0us, total: 142.78ms
train.py:449:<module>, cpu: 99.68ms, accelerator: 41us, total: 99.72ms
  summary.py:146:image, cpu: 99.65ms, accelerator: 0us, total: 99.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_28500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.75%)
top 2 operation type: ImageSummary, cpu: 337.68ms, accelerator: 0us, total: 337.68ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 100.92ms, accelerator: 0us, total: 100.92ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.72ms, accelerator: 0us, total: 142.72ms
top 3 graph node: difference, cpu: 99.72ms, accelerator: 0us, total: 99.72ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.53ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.41ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.60ms, accelerator: 1.41ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 4.12ms, total: 7.65ms
train.py:448:<module>, cpu: 142.73ms, accelerator: 0us, total: 142.73ms
train.py:449:<module>, cpu: 99.76ms, accelerator: 40us, total: 99.80ms
  summary.py:146:image, cpu: 99.72ms, accelerator: 0us, total: 99.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_28750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.74%)
top 2 operation type: ImageSummary, cpu: 337.69ms, accelerator: 0us, total: 337.69ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 101.92ms, accelerator: 0us, total: 101.92ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.94ms, accelerator: 0us, total: 142.94ms
top 3 graph node: difference, cpu: 99.56ms, accelerator: 0us, total: 99.56ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.62ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.44ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.62ms, accelerator: 1.44ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 4.18ms, total: 7.69ms
train.py:448:<module>, cpu: 142.94ms, accelerator: 0us, total: 142.94ms
train.py:449:<module>, cpu: 99.59ms, accelerator: 40us, total: 99.64ms
  summary.py:146:image, cpu: 99.56ms, accelerator: 0us, total: 99.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_29000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (93.75%)
top 2 operation type: ImageSummary, cpu: 337.49ms, accelerator: 0us, total: 337.49ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.92ms, accelerator: 0us, total: 101.92ms (1.18%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.99ms, accelerator: 0us, total: 142.99ms
top 3 graph node: difference, cpu: 99.29ms, accelerator: 0us, total: 99.29ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 5.58ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.43ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.58ms, accelerator: 1.43ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 4.15ms, total: 7.65ms
train.py:448:<module>, cpu: 142.99ms, accelerator: 0us, total: 142.99ms
train.py:449:<module>, cpu: 99.32ms, accelerator: 40us, total: 99.36ms
  summary.py:146:image, cpu: 99.29ms, accelerator: 0us, total: 99.29ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_29250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.72%)
top 2 operation type: ImageSummary, cpu: 338.36ms, accelerator: 0us, total: 338.36ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 102.39ms, accelerator: 0us, total: 102.39ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.30ms, accelerator: 0us, total: 143.30ms
top 3 graph node: difference, cpu: 99.64ms, accelerator: 0us, total: 99.64ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.79ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.44ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.55ms, accelerator: 1.44ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 4.34ms, total: 7.85ms
train.py:448:<module>, cpu: 143.31ms, accelerator: 0us, total: 143.31ms
train.py:449:<module>, cpu: 99.67ms, accelerator: 40us, total: 99.71ms
  summary.py:146:image, cpu: 99.64ms, accelerator: 0us, total: 99.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_29500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (93.72%)
top 2 operation type: ImageSummary, cpu: 338.27ms, accelerator: 0us, total: 338.27ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 102.41ms, accelerator: 0us, total: 102.41ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.20ms, accelerator: 0us, total: 143.20ms
top 3 graph node: difference, cpu: 99.76ms, accelerator: 0us, total: 99.76ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 5.75ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.43ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.52ms, accelerator: 1.43ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 4.31ms, total: 7.81ms
train.py:448:<module>, cpu: 143.20ms, accelerator: 0us, total: 143.20ms
train.py:449:<module>, cpu: 99.80ms, accelerator: 39us, total: 99.84ms
  summary.py:146:image, cpu: 99.77ms, accelerator: 0us, total: 99.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2028.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_29750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (93.71%)
top 2 operation type: ImageSummary, cpu: 338.85ms, accelerator: 0us, total: 338.85ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 102.26ms, accelerator: 0us, total: 102.26ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.50ms, accelerator: 0us, total: 143.50ms
top 3 graph node: difference, cpu: 99.78ms, accelerator: 0us, total: 99.78ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.71ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.42ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 1.42ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 3.45ms, accelerator: 4.28ms, total: 7.77ms
train.py:448:<module>, cpu: 143.51ms, accelerator: 0us, total: 143.51ms
train.py:449:<module>, cpu: 99.82ms, accelerator: 39us, total: 99.86ms
  summary.py:146:image, cpu: 99.78ms, accelerator: 0us, total: 99.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_30000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (93.71%)
top 2 operation type: ImageSummary, cpu: 338.70ms, accelerator: 0us, total: 338.70ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 102.49ms, accelerator: 0us, total: 102.49ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.47ms, accelerator: 0us, total: 143.47ms
top 3 graph node: difference, cpu: 99.93ms, accelerator: 0us, total: 99.93ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 5.66ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.41ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.52ms, accelerator: 1.41ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 4.25ms, total: 7.72ms
train.py:448:<module>, cpu: 143.47ms, accelerator: 0us, total: 143.47ms
train.py:449:<module>, cpu: 99.97ms, accelerator: 39us, total: 100.01ms
  summary.py:146:image, cpu: 99.94ms, accelerator: 0us, total: 99.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_30250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (93.71%)
top 2 operation type: ImageSummary, cpu: 338.21ms, accelerator: 0us, total: 338.21ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 102.35ms, accelerator: 0us, total: 102.35ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.28ms, accelerator: 0us, total: 143.28ms
top 3 graph node: difference, cpu: 99.60ms, accelerator: 0us, total: 99.60ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 5.73ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.41ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.50ms, accelerator: 1.41ms, total: 6.92ms
  __init__.py:185:compute_gradients, cpu: 3.42ms, accelerator: 4.32ms, total: 7.79ms
train.py:448:<module>, cpu: 143.29ms, accelerator: 0us, total: 143.29ms
train.py:449:<module>, cpu: 99.64ms, accelerator: 38us, total: 99.67ms
  summary.py:146:image, cpu: 99.60ms, accelerator: 0us, total: 99.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_30500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.71%)
top 2 operation type: ImageSummary, cpu: 337.98ms, accelerator: 0us, total: 337.98ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 102.54ms, accelerator: 0us, total: 102.54ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.22ms, accelerator: 0us, total: 143.22ms
top 3 graph node: difference, cpu: 99.64ms, accelerator: 0us, total: 99.64ms
train.py:511:<module>, cpu: 8.01sec, accelerator: 5.72ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 1.41ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 1.41ms, total: 6.91ms
  __init__.py:185:compute_gradients, cpu: 3.42ms, accelerator: 4.31ms, total: 7.76ms
train.py:448:<module>, cpu: 143.22ms, accelerator: 0us, total: 143.22ms
train.py:449:<module>, cpu: 99.67ms, accelerator: 38us, total: 99.71ms
  summary.py:146:image, cpu: 99.64ms, accelerator: 0us, total: 99.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_30750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec (93.70%)
top 2 operation type: ImageSummary, cpu: 338.51ms, accelerator: 0us, total: 338.51ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 102.62ms, accelerator: 0us, total: 102.62ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.29ms, accelerator: 0us, total: 143.29ms
top 3 graph node: difference, cpu: 99.51ms, accelerator: 0us, total: 99.51ms
train.py:511:<module>, cpu: 8.01sec, accelerator: 5.69ms, total: 8.01sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 1.40ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 1.40ms, total: 6.88ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 4.29ms, total: 7.78ms
train.py:448:<module>, cpu: 143.29ms, accelerator: 0us, total: 143.29ms
train.py:449:<module>, cpu: 99.55ms, accelerator: 38us, total: 99.59ms
  summary.py:146:image, cpu: 99.52ms, accelerator: 0us, total: 99.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_31000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (93.72%)
top 2 operation type: ImageSummary, cpu: 337.87ms, accelerator: 0us, total: 337.87ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 102.41ms, accelerator: 0us, total: 102.41ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.05ms, accelerator: 0us, total: 143.05ms
top 3 graph node: difference, cpu: 99.31ms, accelerator: 0us, total: 99.31ms
train.py:511:<module>, cpu: 8.02sec, accelerator: 5.69ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 1.43ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 1.43ms, total: 6.88ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 4.26ms, total: 7.74ms
train.py:448:<module>, cpu: 143.06ms, accelerator: 0us, total: 143.06ms
train.py:449:<module>, cpu: 99.34ms, accelerator: 37us, total: 99.38ms
  summary.py:146:image, cpu: 99.31ms, accelerator: 0us, total: 99.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_31250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec (93.70%)
top 2 operation type: ImageSummary, cpu: 338.39ms, accelerator: 0us, total: 338.39ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 102.72ms, accelerator: 0us, total: 102.72ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.33ms, accelerator: 0us, total: 143.33ms
top 3 graph node: difference, cpu: 99.58ms, accelerator: 0us, total: 99.58ms
train.py:511:<module>, cpu: 8.01sec, accelerator: 5.65ms, total: 8.01sec
  __init__.py:194:compute_gradients, cpu: 8.00sec, accelerator: 1.42ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 1.42ms, total: 6.87ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 4.24ms, total: 7.88ms
train.py:448:<module>, cpu: 143.34ms, accelerator: 0us, total: 143.34ms
train.py:449:<module>, cpu: 99.62ms, accelerator: 37us, total: 99.66ms
  summary.py:146:image, cpu: 99.59ms, accelerator: 0us, total: 99.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_31500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec (93.70%)
top 2 operation type: ImageSummary, cpu: 338.33ms, accelerator: 0us, total: 338.33ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 102.84ms, accelerator: 0us, total: 102.84ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.39ms, accelerator: 0us, total: 143.39ms
top 3 graph node: difference, cpu: 99.45ms, accelerator: 0us, total: 99.45ms
train.py:511:<module>, cpu: 8.00sec, accelerator: 5.65ms, total: 8.01sec
  __init__.py:194:compute_gradients, cpu: 8.00sec, accelerator: 1.41ms, total: 8.00sec
    __init__.py:83:allreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 1.41ms, total: 6.83ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 4.24ms, total: 7.88ms
train.py:448:<module>, cpu: 143.39ms, accelerator: 0us, total: 143.39ms
train.py:449:<module>, cpu: 99.48ms, accelerator: 37us, total: 99.52ms
  summary.py:146:image, cpu: 99.45ms, accelerator: 0us, total: 99.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_31750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.99sec, accelerator: 0us, total: 7.99sec (93.70%)
top 2 operation type: ImageSummary, cpu: 338.29ms, accelerator: 0us, total: 338.29ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.66ms, accelerator: 0us, total: 102.66ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.28ms, accelerator: 0us, total: 143.28ms
top 3 graph node: difference, cpu: 99.52ms, accelerator: 0us, total: 99.52ms
train.py:511:<module>, cpu: 8.00sec, accelerator: 5.62ms, total: 8.00sec
  __init__.py:194:compute_gradients, cpu: 8.00sec, accelerator: 1.40ms, total: 8.00sec
    __init__.py:83:allreduce, cpu: 7.99sec, accelerator: 0us, total: 7.99sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.40ms, total: 6.80ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 4.22ms, total: 7.84ms
train.py:448:<module>, cpu: 143.29ms, accelerator: 0us, total: 143.29ms
train.py:449:<module>, cpu: 99.56ms, accelerator: 37us, total: 99.60ms
  summary.py:146:image, cpu: 99.53ms, accelerator: 0us, total: 99.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_32000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec (93.69%)
top 2 operation type: ImageSummary, cpu: 338.34ms, accelerator: 0us, total: 338.34ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.54ms, accelerator: 0us, total: 102.54ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.59ms, accelerator: 0us, total: 143.59ms
top 3 graph node: difference, cpu: 99.25ms, accelerator: 0us, total: 99.25ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 5.62ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.39ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.39ms, total: 6.78ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.23ms, total: 7.83ms
train.py:448:<module>, cpu: 143.60ms, accelerator: 0us, total: 143.60ms
train.py:449:<module>, cpu: 99.29ms, accelerator: 36us, total: 99.32ms
  summary.py:146:image, cpu: 99.26ms, accelerator: 0us, total: 99.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2030.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_32250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.68%)
top 2 operation type: ImageSummary, cpu: 338.16ms, accelerator: 0us, total: 338.16ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.39ms, accelerator: 0us, total: 102.39ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.61ms, accelerator: 0us, total: 143.61ms
top 3 graph node: difference, cpu: 99.05ms, accelerator: 0us, total: 99.05ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 5.76ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.39ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 1.39ms, total: 6.76ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.37ms, total: 7.96ms
train.py:448:<module>, cpu: 143.61ms, accelerator: 0us, total: 143.61ms
train.py:449:<module>, cpu: 99.08ms, accelerator: 36us, total: 99.12ms
  summary.py:146:image, cpu: 99.05ms, accelerator: 0us, total: 99.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_32500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.68%)
top 2 operation type: ImageSummary, cpu: 337.58ms, accelerator: 0us, total: 337.58ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.46ms, accelerator: 0us, total: 102.46ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.22ms, accelerator: 0us, total: 143.22ms
top 3 graph node: difference, cpu: 98.97ms, accelerator: 0us, total: 98.97ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 5.72ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.39ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 1.39ms, total: 6.74ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.34ms, total: 7.92ms
train.py:448:<module>, cpu: 143.23ms, accelerator: 0us, total: 143.23ms
train.py:449:<module>, cpu: 99.00ms, accelerator: 36us, total: 99.04ms
  summary.py:146:image, cpu: 98.97ms, accelerator: 0us, total: 98.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_32750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.69%)
top 2 operation type: ImageSummary, cpu: 337.63ms, accelerator: 0us, total: 337.63ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.17ms, accelerator: 0us, total: 102.17ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.07ms, accelerator: 0us, total: 143.07ms
top 3 graph node: difference, cpu: 99.33ms, accelerator: 0us, total: 99.33ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 5.68ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.37ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 1.37ms, total: 6.83ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.31ms, total: 7.89ms
train.py:448:<module>, cpu: 143.08ms, accelerator: 0us, total: 143.08ms
train.py:449:<module>, cpu: 99.37ms, accelerator: 36us, total: 99.41ms
  summary.py:146:image, cpu: 99.34ms, accelerator: 0us, total: 99.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_33000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (93.67%)
top 2 operation type: ImageSummary, cpu: 338.26ms, accelerator: 0us, total: 338.26ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.64ms, accelerator: 0us, total: 102.64ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.20ms, accelerator: 0us, total: 143.20ms
top 3 graph node: difference, cpu: 99.53ms, accelerator: 0us, total: 99.53ms
train.py:511:<module>, cpu: 7.96sec, accelerator: 5.64ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.36ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 1.36ms, total: 6.80ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 4.28ms, total: 7.92ms
train.py:448:<module>, cpu: 143.21ms, accelerator: 0us, total: 143.21ms
train.py:449:<module>, cpu: 99.56ms, accelerator: 35us, total: 99.60ms
  summary.py:146:image, cpu: 99.53ms, accelerator: 0us, total: 99.53ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_33250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.68%)
top 2 operation type: ImageSummary, cpu: 337.76ms, accelerator: 0us, total: 337.76ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.53ms, accelerator: 0us, total: 102.53ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.01ms, accelerator: 0us, total: 143.01ms
top 3 graph node: difference, cpu: 99.44ms, accelerator: 0us, total: 99.44ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 5.68ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.36ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 1.36ms, total: 6.78ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 4.32ms, total: 7.93ms
train.py:448:<module>, cpu: 143.02ms, accelerator: 0us, total: 143.02ms
train.py:449:<module>, cpu: 99.47ms, accelerator: 35us, total: 99.51ms
  summary.py:146:image, cpu: 99.44ms, accelerator: 0us, total: 99.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_33500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.68%)
top 2 operation type: ImageSummary, cpu: 337.72ms, accelerator: 0us, total: 337.72ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.57ms, accelerator: 0us, total: 102.57ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.94ms, accelerator: 0us, total: 142.94ms
top 3 graph node: difference, cpu: 99.31ms, accelerator: 0us, total: 99.31ms
train.py:511:<module>, cpu: 7.96sec, accelerator: 5.72ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.36ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 1.36ms, total: 6.78ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 4.36ms, total: 7.97ms
train.py:448:<module>, cpu: 142.94ms, accelerator: 0us, total: 142.94ms
train.py:449:<module>, cpu: 99.34ms, accelerator: 35us, total: 99.38ms
  summary.py:146:image, cpu: 99.31ms, accelerator: 0us, total: 99.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_33750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (93.68%)
top 2 operation type: ImageSummary, cpu: 337.83ms, accelerator: 0us, total: 337.83ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.51ms, accelerator: 0us, total: 102.51ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 143.02ms, accelerator: 0us, total: 143.02ms
top 3 graph node: difference, cpu: 99.20ms, accelerator: 0us, total: 99.20ms
train.py:511:<module>, cpu: 7.96sec, accelerator: 5.78ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.36ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.36ms, total: 6.75ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.42ms, total: 8.02ms
train.py:448:<module>, cpu: 143.03ms, accelerator: 0us, total: 143.03ms
train.py:449:<module>, cpu: 99.24ms, accelerator: 35us, total: 99.28ms
  summary.py:146:image, cpu: 99.21ms, accelerator: 0us, total: 99.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_34000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.68%)
top 2 operation type: ImageSummary, cpu: 337.08ms, accelerator: 0us, total: 337.08ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.58ms, accelerator: 0us, total: 102.58ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.72ms, accelerator: 0us, total: 142.72ms
top 3 graph node: difference, cpu: 98.91ms, accelerator: 0us, total: 98.91ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 5.74ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.35ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.35ms, total: 6.74ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 4.39ms, total: 7.98ms
train.py:448:<module>, cpu: 142.72ms, accelerator: 0us, total: 142.72ms
train.py:449:<module>, cpu: 98.94ms, accelerator: 34us, total: 98.98ms
  summary.py:146:image, cpu: 98.91ms, accelerator: 0us, total: 98.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_34250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.68%)
top 2 operation type: ImageSummary, cpu: 336.93ms, accelerator: 0us, total: 336.93ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.46ms, accelerator: 0us, total: 102.46ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.62ms, accelerator: 0us, total: 142.62ms
top 3 graph node: difference, cpu: 98.97ms, accelerator: 0us, total: 98.97ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 5.72ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.35ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.35ms, total: 6.72ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 4.37ms, total: 7.95ms
train.py:448:<module>, cpu: 142.63ms, accelerator: 0us, total: 142.63ms
train.py:449:<module>, cpu: 99.00ms, accelerator: 34us, total: 99.03ms
  summary.py:146:image, cpu: 98.97ms, accelerator: 0us, total: 98.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_34500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.69%)
top 2 operation type: ImageSummary, cpu: 336.57ms, accelerator: 0us, total: 336.57ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.42ms, accelerator: 0us, total: 102.42ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.47ms, accelerator: 0us, total: 142.47ms
top 3 graph node: difference, cpu: 99.10ms, accelerator: 0us, total: 99.10ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 5.68ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.34ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 1.34ms, total: 6.69ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.34ms, total: 7.91ms
train.py:448:<module>, cpu: 142.48ms, accelerator: 0us, total: 142.48ms
train.py:449:<module>, cpu: 99.13ms, accelerator: 34us, total: 99.17ms
  summary.py:146:image, cpu: 99.10ms, accelerator: 0us, total: 99.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_34750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (93.68%)
top 2 operation type: ImageSummary, cpu: 336.13ms, accelerator: 0us, total: 336.13ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.69ms, accelerator: 0us, total: 102.69ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.54ms, accelerator: 0us, total: 142.54ms
top 3 graph node: difference, cpu: 98.93ms, accelerator: 0us, total: 98.93ms
train.py:511:<module>, cpu: 7.93sec, accelerator: 5.65ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.33ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 1.33ms, total: 6.66ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 4.31ms, total: 7.87ms
train.py:448:<module>, cpu: 142.54ms, accelerator: 0us, total: 142.54ms
train.py:449:<module>, cpu: 98.96ms, accelerator: 34us, total: 99.00ms
  summary.py:146:image, cpu: 98.93ms, accelerator: 0us, total: 98.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_35000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (93.69%)
top 2 operation type: ImageSummary, cpu: 335.75ms, accelerator: 0us, total: 335.75ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.60ms, accelerator: 0us, total: 102.60ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.27ms, accelerator: 0us, total: 142.27ms
top 3 graph node: difference, cpu: 98.74ms, accelerator: 0us, total: 98.74ms
train.py:511:<module>, cpu: 7.92sec, accelerator: 5.62ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.32ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 1.32ms, total: 6.63ms
  __init__.py:185:compute_gradients, cpu: 3.53ms, accelerator: 4.30ms, total: 7.87ms
train.py:448:<module>, cpu: 142.27ms, accelerator: 0us, total: 142.27ms
train.py:449:<module>, cpu: 98.77ms, accelerator: 33us, total: 98.81ms
  summary.py:146:image, cpu: 98.74ms, accelerator: 0us, total: 98.74ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_35250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec (93.68%)
top 2 operation type: ImageSummary, cpu: 335.19ms, accelerator: 0us, total: 335.19ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.70ms, accelerator: 0us, total: 102.70ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.07ms, accelerator: 0us, total: 142.07ms
top 3 graph node: difference, cpu: 98.50ms, accelerator: 0us, total: 98.50ms
train.py:511:<module>, cpu: 7.91sec, accelerator: 5.61ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.32ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 1.32ms, total: 6.66ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.29ms, total: 7.85ms
train.py:448:<module>, cpu: 142.08ms, accelerator: 0us, total: 142.08ms
train.py:449:<module>, cpu: 98.53ms, accelerator: 33us, total: 98.57ms
  summary.py:146:image, cpu: 98.50ms, accelerator: 0us, total: 98.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_35500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (93.68%)
top 2 operation type: ImageSummary, cpu: 334.87ms, accelerator: 0us, total: 334.87ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.72ms, accelerator: 0us, total: 102.72ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.09ms, accelerator: 0us, total: 142.09ms
top 3 graph node: difference, cpu: 98.32ms, accelerator: 0us, total: 98.32ms
train.py:511:<module>, cpu: 7.91sec, accelerator: 5.64ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.32ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.32ms, total: 6.68ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 4.33ms, total: 7.88ms
train.py:448:<module>, cpu: 142.09ms, accelerator: 0us, total: 142.09ms
train.py:449:<module>, cpu: 98.35ms, accelerator: 33us, total: 98.38ms
  summary.py:146:image, cpu: 98.32ms, accelerator: 0us, total: 98.32ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_35750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec (93.67%)
top 2 operation type: ImageSummary, cpu: 335.41ms, accelerator: 0us, total: 335.41ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.73ms, accelerator: 0us, total: 102.73ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.47ms, accelerator: 0us, total: 142.47ms
top 3 graph node: difference, cpu: 98.69ms, accelerator: 0us, total: 98.69ms
train.py:511:<module>, cpu: 7.91sec, accelerator: 5.75ms, total: 7.91sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.31ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 1.31ms, total: 6.67ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 4.44ms, total: 7.99ms
train.py:448:<module>, cpu: 142.48ms, accelerator: 0us, total: 142.48ms
train.py:449:<module>, cpu: 98.73ms, accelerator: 33us, total: 98.76ms
  summary.py:146:image, cpu: 98.70ms, accelerator: 0us, total: 98.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_36000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.89sec, accelerator: 0us, total: 7.89sec (93.66%)
top 2 operation type: ImageSummary, cpu: 335.24ms, accelerator: 0us, total: 335.24ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 103.27ms, accelerator: 0us, total: 103.27ms (1.23%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.63ms, accelerator: 0us, total: 142.63ms
top 3 graph node: difference, cpu: 98.56ms, accelerator: 0us, total: 98.56ms
train.py:511:<module>, cpu: 7.90sec, accelerator: 5.91ms, total: 7.91sec
  __init__.py:194:compute_gradients, cpu: 7.90sec, accelerator: 1.30ms, total: 7.90sec
    __init__.py:83:allreduce, cpu: 7.89sec, accelerator: 0us, total: 7.89sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 1.30ms, total: 6.64ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 4.61ms, total: 8.18ms
train.py:448:<module>, cpu: 142.63ms, accelerator: 0us, total: 142.63ms
train.py:449:<module>, cpu: 98.59ms, accelerator: 33us, total: 98.62ms
  summary.py:146:image, cpu: 98.56ms, accelerator: 0us, total: 98.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_36250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.88sec, accelerator: 0us, total: 7.88sec (93.65%)
top 2 operation type: ImageSummary, cpu: 335.42ms, accelerator: 0us, total: 335.42ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 103.29ms, accelerator: 0us, total: 103.29ms (1.23%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.82ms, accelerator: 0us, total: 142.82ms
top 3 graph node: difference, cpu: 98.59ms, accelerator: 0us, total: 98.59ms
train.py:511:<module>, cpu: 7.89sec, accelerator: 5.91ms, total: 7.90sec
  __init__.py:194:compute_gradients, cpu: 7.89sec, accelerator: 1.33ms, total: 7.89sec
    __init__.py:83:allreduce, cpu: 7.88sec, accelerator: 0us, total: 7.88sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 1.33ms, total: 6.64ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.58ms, total: 8.14ms
train.py:448:<module>, cpu: 142.82ms, accelerator: 0us, total: 142.82ms
train.py:449:<module>, cpu: 98.63ms, accelerator: 33us, total: 98.66ms
  summary.py:146:image, cpu: 98.60ms, accelerator: 0us, total: 98.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_36500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.89sec, accelerator: 0us, total: 7.89sec (93.65%)
top 2 operation type: ImageSummary, cpu: 335.69ms, accelerator: 0us, total: 335.69ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 103.33ms, accelerator: 0us, total: 103.33ms (1.23%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.66ms, accelerator: 0us, total: 142.66ms
top 3 graph node: difference, cpu: 98.60ms, accelerator: 0us, total: 98.60ms
train.py:511:<module>, cpu: 7.90sec, accelerator: 5.87ms, total: 7.90sec
  __init__.py:194:compute_gradients, cpu: 7.89sec, accelerator: 1.32ms, total: 7.89sec
    __init__.py:83:allreduce, cpu: 7.89sec, accelerator: 0us, total: 7.89sec
    __init__.py:86:allreduce, cpu: 5.28ms, accelerator: 1.32ms, total: 6.63ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 4.55ms, total: 8.11ms
train.py:448:<module>, cpu: 142.66ms, accelerator: 0us, total: 142.66ms
train.py:449:<module>, cpu: 98.64ms, accelerator: 32us, total: 98.67ms
  summary.py:146:image, cpu: 98.61ms, accelerator: 0us, total: 98.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_36750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.89sec, accelerator: 0us, total: 7.89sec (93.65%)
top 2 operation type: ImageSummary, cpu: 335.72ms, accelerator: 0us, total: 335.72ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 103.10ms, accelerator: 0us, total: 103.10ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.70ms, accelerator: 0us, total: 142.70ms
top 3 graph node: difference, cpu: 98.66ms, accelerator: 0us, total: 98.66ms
train.py:511:<module>, cpu: 7.90sec, accelerator: 5.84ms, total: 7.90sec
  __init__.py:194:compute_gradients, cpu: 7.89sec, accelerator: 1.32ms, total: 7.89sec
    __init__.py:83:allreduce, cpu: 7.89sec, accelerator: 0us, total: 7.89sec
    __init__.py:86:allreduce, cpu: 5.27ms, accelerator: 1.32ms, total: 6.61ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 4.52ms, total: 8.07ms
train.py:448:<module>, cpu: 142.71ms, accelerator: 0us, total: 142.71ms
train.py:449:<module>, cpu: 98.69ms, accelerator: 32us, total: 98.73ms
  summary.py:146:image, cpu: 98.66ms, accelerator: 0us, total: 98.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_37000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.88sec, accelerator: 0us, total: 7.88sec (93.65%)
top 2 operation type: ImageSummary, cpu: 335.31ms, accelerator: 0us, total: 335.31ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 102.97ms, accelerator: 0us, total: 102.97ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.54ms, accelerator: 0us, total: 142.54ms
top 3 graph node: difference, cpu: 98.44ms, accelerator: 0us, total: 98.44ms
train.py:511:<module>, cpu: 7.89sec, accelerator: 5.86ms, total: 7.89sec
  __init__.py:194:compute_gradients, cpu: 7.88sec, accelerator: 1.32ms, total: 7.89sec
    __init__.py:83:allreduce, cpu: 7.88sec, accelerator: 0us, total: 7.88sec
    __init__.py:86:allreduce, cpu: 5.26ms, accelerator: 1.32ms, total: 6.60ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 4.54ms, total: 8.08ms
train.py:448:<module>, cpu: 142.54ms, accelerator: 0us, total: 142.54ms
train.py:449:<module>, cpu: 98.47ms, accelerator: 32us, total: 98.50ms
  summary.py:146:image, cpu: 98.44ms, accelerator: 0us, total: 98.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_37250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.88sec, accelerator: 0us, total: 7.88sec (93.66%)
top 2 operation type: ImageSummary, cpu: 335.04ms, accelerator: 0us, total: 335.04ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 103.15ms, accelerator: 0us, total: 103.15ms (1.23%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.31ms, accelerator: 0us, total: 142.31ms
top 3 graph node: difference, cpu: 98.28ms, accelerator: 0us, total: 98.28ms
train.py:511:<module>, cpu: 7.89sec, accelerator: 5.83ms, total: 7.90sec
  __init__.py:194:compute_gradients, cpu: 7.89sec, accelerator: 1.31ms, total: 7.89sec
    __init__.py:83:allreduce, cpu: 7.88sec, accelerator: 0us, total: 7.88sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 1.31ms, total: 6.59ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 4.51ms, total: 8.04ms
train.py:448:<module>, cpu: 142.32ms, accelerator: 0us, total: 142.32ms
train.py:449:<module>, cpu: 98.32ms, accelerator: 32us, total: 98.35ms
  summary.py:146:image, cpu: 98.28ms, accelerator: 0us, total: 98.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_37500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.88sec, accelerator: 0us, total: 7.88sec (93.65%)
top 2 operation type: ImageSummary, cpu: 335.33ms, accelerator: 0us, total: 335.33ms (3.99%)
top 3 operation type: HistogramSummary, cpu: 103.11ms, accelerator: 0us, total: 103.11ms (1.23%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.49ms, accelerator: 0us, total: 142.49ms
top 3 graph node: difference, cpu: 98.53ms, accelerator: 0us, total: 98.53ms
train.py:511:<module>, cpu: 7.89sec, accelerator: 5.82ms, total: 7.89sec
  __init__.py:194:compute_gradients, cpu: 7.88sec, accelerator: 1.32ms, total: 7.89sec
    __init__.py:83:allreduce, cpu: 7.88sec, accelerator: 0us, total: 7.88sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 1.32ms, total: 6.58ms
  __init__.py:185:compute_gradients, cpu: 3.48ms, accelerator: 4.50ms, total: 8.02ms
train.py:448:<module>, cpu: 142.50ms, accelerator: 0us, total: 142.50ms
train.py:449:<module>, cpu: 98.56ms, accelerator: 32us, total: 98.59ms
  summary.py:146:image, cpu: 98.53ms, accelerator: 0us, total: 98.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_37750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.88sec, accelerator: 0us, total: 7.88sec (93.67%)
top 2 operation type: ImageSummary, cpu: 334.71ms, accelerator: 0us, total: 334.71ms (3.98%)
top 3 operation type: HistogramSummary, cpu: 102.80ms, accelerator: 0us, total: 102.80ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.27ms, accelerator: 0us, total: 142.27ms
top 3 graph node: difference, cpu: 98.18ms, accelerator: 0us, total: 98.18ms
train.py:511:<module>, cpu: 7.89sec, accelerator: 5.87ms, total: 7.90sec
  __init__.py:194:compute_gradients, cpu: 7.89sec, accelerator: 1.31ms, total: 7.89sec
    __init__.py:83:allreduce, cpu: 7.88sec, accelerator: 0us, total: 7.88sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 1.31ms, total: 6.55ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 4.56ms, total: 8.06ms
train.py:448:<module>, cpu: 142.28ms, accelerator: 0us, total: 142.28ms
train.py:449:<module>, cpu: 98.21ms, accelerator: 31us, total: 98.24ms
  summary.py:146:image, cpu: 98.18ms, accelerator: 0us, total: 98.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_38000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.89sec, accelerator: 0us, total: 7.89sec (93.68%)
top 2 operation type: ImageSummary, cpu: 334.17ms, accelerator: 0us, total: 334.17ms (3.97%)
top 3 operation type: HistogramSummary, cpu: 102.62ms, accelerator: 0us, total: 102.62ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.25ms, accelerator: 0us, total: 142.25ms
top 3 graph node: difference, cpu: 97.96ms, accelerator: 0us, total: 97.96ms
train.py:511:<module>, cpu: 7.90sec, accelerator: 5.88ms, total: 7.91sec
  __init__.py:194:compute_gradients, cpu: 7.90sec, accelerator: 1.30ms, total: 7.90sec
    __init__.py:83:allreduce, cpu: 7.89sec, accelerator: 0us, total: 7.89sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 1.30ms, total: 6.52ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 4.58ms, total: 8.07ms
train.py:448:<module>, cpu: 142.25ms, accelerator: 0us, total: 142.25ms
train.py:449:<module>, cpu: 98.00ms, accelerator: 31us, total: 98.03ms
  summary.py:146:image, cpu: 97.97ms, accelerator: 0us, total: 97.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_38250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (93.71%)
top 2 operation type: ImageSummary, cpu: 333.91ms, accelerator: 0us, total: 333.91ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 102.42ms, accelerator: 0us, total: 102.42ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.22ms, accelerator: 0us, total: 142.22ms
top 3 graph node: difference, cpu: 97.69ms, accelerator: 0us, total: 97.69ms
train.py:511:<module>, cpu: 7.92sec, accelerator: 5.85ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.30ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 1.30ms, total: 6.50ms
  __init__.py:185:compute_gradients, cpu: 3.45ms, accelerator: 4.55ms, total: 8.04ms
train.py:448:<module>, cpu: 142.22ms, accelerator: 0us, total: 142.22ms
train.py:449:<module>, cpu: 97.73ms, accelerator: 31us, total: 97.76ms
  summary.py:146:image, cpu: 97.69ms, accelerator: 0us, total: 97.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_38500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec (93.69%)
top 2 operation type: ImageSummary, cpu: 334.04ms, accelerator: 0us, total: 334.04ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 102.42ms, accelerator: 0us, total: 102.42ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 142.02ms, accelerator: 0us, total: 142.02ms
top 3 graph node: difference, cpu: 97.93ms, accelerator: 0us, total: 97.93ms
train.py:511:<module>, cpu: 7.91sec, accelerator: 5.84ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.29ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 1.29ms, total: 6.49ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 4.54ms, total: 8.05ms
train.py:448:<module>, cpu: 142.03ms, accelerator: 0us, total: 142.03ms
train.py:449:<module>, cpu: 97.97ms, accelerator: 31us, total: 98.00ms
  summary.py:146:image, cpu: 97.94ms, accelerator: 0us, total: 97.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_38750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec (93.70%)
top 2 operation type: ImageSummary, cpu: 333.72ms, accelerator: 0us, total: 333.72ms (3.96%)
top 3 operation type: HistogramSummary, cpu: 102.13ms, accelerator: 0us, total: 102.13ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.74ms, accelerator: 0us, total: 141.74ms
top 3 graph node: difference, cpu: 97.79ms, accelerator: 0us, total: 97.79ms
train.py:511:<module>, cpu: 7.91sec, accelerator: 5.84ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.29ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.29ms, total: 6.46ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 4.55ms, total: 8.05ms
train.py:448:<module>, cpu: 141.74ms, accelerator: 0us, total: 141.74ms
train.py:449:<module>, cpu: 97.82ms, accelerator: 31us, total: 97.85ms
  summary.py:146:image, cpu: 97.79ms, accelerator: 0us, total: 97.79ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_39000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (93.70%)
top 2 operation type: ImageSummary, cpu: 333.55ms, accelerator: 0us, total: 333.55ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 102.27ms, accelerator: 0us, total: 102.27ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.80ms, accelerator: 0us, total: 141.80ms
top 3 graph node: difference, cpu: 97.51ms, accelerator: 0us, total: 97.51ms
train.py:511:<module>, cpu: 7.92sec, accelerator: 5.82ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.29ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.13ms, accelerator: 1.29ms, total: 6.44ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 4.53ms, total: 8.02ms
train.py:448:<module>, cpu: 141.80ms, accelerator: 0us, total: 141.80ms
train.py:449:<module>, cpu: 97.55ms, accelerator: 30us, total: 97.58ms
  summary.py:146:image, cpu: 97.52ms, accelerator: 0us, total: 97.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_39250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (93.72%)
top 2 operation type: ImageSummary, cpu: 333.01ms, accelerator: 0us, total: 333.01ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 102.24ms, accelerator: 0us, total: 102.24ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.72ms, accelerator: 0us, total: 141.72ms
top 3 graph node: difference, cpu: 97.36ms, accelerator: 0us, total: 97.36ms
train.py:511:<module>, cpu: 7.93sec, accelerator: 5.85ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.28ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 1.28ms, total: 6.47ms
  __init__.py:185:compute_gradients, cpu: 3.45ms, accelerator: 4.56ms, total: 8.04ms
train.py:448:<module>, cpu: 141.72ms, accelerator: 0us, total: 141.72ms
train.py:449:<module>, cpu: 97.40ms, accelerator: 30us, total: 97.43ms
  summary.py:146:image, cpu: 97.36ms, accelerator: 0us, total: 97.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_39500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (93.71%)
top 2 operation type: ImageSummary, cpu: 332.92ms, accelerator: 0us, total: 332.92ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 102.51ms, accelerator: 0us, total: 102.51ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.65ms, accelerator: 0us, total: 141.65ms
top 3 graph node: difference, cpu: 97.32ms, accelerator: 0us, total: 97.32ms
train.py:511:<module>, cpu: 7.92sec, accelerator: 5.81ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.28ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.28ms, total: 6.44ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 4.54ms, total: 8.01ms
train.py:448:<module>, cpu: 141.65ms, accelerator: 0us, total: 141.65ms
train.py:449:<module>, cpu: 97.36ms, accelerator: 30us, total: 97.39ms
  summary.py:146:image, cpu: 97.32ms, accelerator: 0us, total: 97.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_39750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (93.72%)
top 2 operation type: ImageSummary, cpu: 332.77ms, accelerator: 0us, total: 332.77ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 102.53ms, accelerator: 0us, total: 102.53ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.51ms, accelerator: 0us, total: 141.51ms
top 3 graph node: difference, cpu: 97.27ms, accelerator: 0us, total: 97.27ms
train.py:511:<module>, cpu: 7.93sec, accelerator: 5.87ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.31ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.12ms, accelerator: 1.31ms, total: 6.45ms
  __init__.py:185:compute_gradients, cpu: 3.43ms, accelerator: 4.56ms, total: 8.02ms
train.py:448:<module>, cpu: 141.52ms, accelerator: 0us, total: 141.52ms
train.py:449:<module>, cpu: 97.31ms, accelerator: 30us, total: 97.34ms
  summary.py:146:image, cpu: 97.27ms, accelerator: 0us, total: 97.27ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_40000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (93.70%)
top 2 operation type: ImageSummary, cpu: 333.20ms, accelerator: 0us, total: 333.20ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 102.51ms, accelerator: 0us, total: 102.51ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.70ms, accelerator: 0us, total: 141.70ms
top 3 graph node: difference, cpu: 97.59ms, accelerator: 0us, total: 97.59ms
train.py:511:<module>, cpu: 7.92sec, accelerator: 5.97ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.30ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 1.30ms, total: 6.47ms
  __init__.py:185:compute_gradients, cpu: 3.42ms, accelerator: 4.67ms, total: 8.13ms
train.py:448:<module>, cpu: 141.71ms, accelerator: 0us, total: 141.71ms
train.py:449:<module>, cpu: 97.63ms, accelerator: 30us, total: 97.66ms
  summary.py:146:image, cpu: 97.60ms, accelerator: 0us, total: 97.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_40250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (93.70%)
top 2 operation type: ImageSummary, cpu: 332.95ms, accelerator: 0us, total: 332.95ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 102.46ms, accelerator: 0us, total: 102.46ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.61ms, accelerator: 0us, total: 141.61ms
top 3 graph node: difference, cpu: 97.34ms, accelerator: 0us, total: 97.34ms
train.py:511:<module>, cpu: 7.92sec, accelerator: 5.98ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.29ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 1.29ms, total: 6.53ms
  __init__.py:185:compute_gradients, cpu: 3.41ms, accelerator: 4.69ms, total: 8.14ms
train.py:448:<module>, cpu: 141.62ms, accelerator: 0us, total: 141.62ms
train.py:449:<module>, cpu: 97.37ms, accelerator: 30us, total: 97.40ms
  summary.py:146:image, cpu: 97.34ms, accelerator: 0us, total: 97.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_40500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec (93.69%)
top 2 operation type: ImageSummary, cpu: 333.07ms, accelerator: 0us, total: 333.07ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 102.65ms, accelerator: 0us, total: 102.65ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.53ms, accelerator: 0us, total: 141.53ms
top 3 graph node: difference, cpu: 97.46ms, accelerator: 0us, total: 97.46ms
train.py:511:<module>, cpu: 7.90sec, accelerator: 5.95ms, total: 7.91sec
  __init__.py:194:compute_gradients, cpu: 7.90sec, accelerator: 1.29ms, total: 7.90sec
    __init__.py:83:allreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.29ms, total: 6.51ms
  __init__.py:185:compute_gradients, cpu: 3.40ms, accelerator: 4.67ms, total: 8.11ms
train.py:448:<module>, cpu: 141.53ms, accelerator: 0us, total: 141.53ms
train.py:449:<module>, cpu: 97.50ms, accelerator: 31us, total: 97.53ms
  summary.py:146:image, cpu: 97.46ms, accelerator: 0us, total: 97.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2043.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_40750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec (93.70%)
top 2 operation type: ImageSummary, cpu: 332.79ms, accelerator: 0us, total: 332.79ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 102.46ms, accelerator: 0us, total: 102.46ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.40ms, accelerator: 0us, total: 141.40ms
top 3 graph node: difference, cpu: 97.48ms, accelerator: 0us, total: 97.48ms
train.py:511:<module>, cpu: 7.91sec, accelerator: 5.93ms, total: 7.91sec
  __init__.py:194:compute_gradients, cpu: 7.90sec, accelerator: 1.28ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 1.28ms, total: 6.51ms
  __init__.py:185:compute_gradients, cpu: 3.39ms, accelerator: 4.66ms, total: 8.08ms
train.py:448:<module>, cpu: 141.41ms, accelerator: 0us, total: 141.41ms
train.py:449:<module>, cpu: 97.52ms, accelerator: 31us, total: 97.55ms
  summary.py:146:image, cpu: 97.48ms, accelerator: 0us, total: 97.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_41000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec (93.70%)
top 2 operation type: ImageSummary, cpu: 332.69ms, accelerator: 0us, total: 332.69ms (3.95%)
top 3 operation type: HistogramSummary, cpu: 102.30ms, accelerator: 0us, total: 102.30ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.27ms, accelerator: 0us, total: 141.27ms
top 3 graph node: difference, cpu: 97.41ms, accelerator: 0us, total: 97.41ms
train.py:511:<module>, cpu: 7.91sec, accelerator: 5.94ms, total: 7.91sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.30ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 1.30ms, total: 6.51ms
  __init__.py:185:compute_gradients, cpu: 3.38ms, accelerator: 4.64ms, total: 8.06ms
train.py:448:<module>, cpu: 141.28ms, accelerator: 0us, total: 141.28ms
train.py:449:<module>, cpu: 97.45ms, accelerator: 30us, total: 97.48ms
  summary.py:146:image, cpu: 97.42ms, accelerator: 0us, total: 97.42ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_41250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (93.71%)
top 2 operation type: ImageSummary, cpu: 332.35ms, accelerator: 0us, total: 332.35ms (3.94%)
top 3 operation type: HistogramSummary, cpu: 102.20ms, accelerator: 0us, total: 102.20ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.12ms, accelerator: 0us, total: 141.12ms
top 3 graph node: difference, cpu: 97.17ms, accelerator: 0us, total: 97.17ms
train.py:511:<module>, cpu: 7.92sec, accelerator: 5.93ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.29ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 1.29ms, total: 6.49ms
  __init__.py:185:compute_gradients, cpu: 3.38ms, accelerator: 4.63ms, total: 8.05ms
train.py:448:<module>, cpu: 141.13ms, accelerator: 0us, total: 141.13ms
train.py:449:<module>, cpu: 97.21ms, accelerator: 30us, total: 97.24ms
  summary.py:146:image, cpu: 97.18ms, accelerator: 0us, total: 97.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_41500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (93.73%)
top 2 operation type: ImageSummary, cpu: 331.75ms, accelerator: 0us, total: 331.75ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 102.19ms, accelerator: 0us, total: 102.19ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.88ms, accelerator: 0us, total: 140.88ms
top 3 graph node: difference, cpu: 96.98ms, accelerator: 0us, total: 96.98ms
train.py:511:<module>, cpu: 7.93sec, accelerator: 5.94ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.30ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.30ms, total: 6.47ms
  __init__.py:185:compute_gradients, cpu: 3.37ms, accelerator: 4.64ms, total: 8.04ms
train.py:448:<module>, cpu: 140.88ms, accelerator: 0us, total: 140.88ms
train.py:449:<module>, cpu: 97.02ms, accelerator: 30us, total: 97.05ms
  summary.py:146:image, cpu: 96.99ms, accelerator: 0us, total: 96.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2043.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_41750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.74%)
top 2 operation type: ImageSummary, cpu: 331.21ms, accelerator: 0us, total: 331.21ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 102.10ms, accelerator: 0us, total: 102.10ms (1.21%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.64ms, accelerator: 0us, total: 140.64ms
top 3 graph node: difference, cpu: 96.88ms, accelerator: 0us, total: 96.88ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 5.93ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.29ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.12ms, accelerator: 1.29ms, total: 6.44ms
  __init__.py:185:compute_gradients, cpu: 3.35ms, accelerator: 4.63ms, total: 8.03ms
train.py:448:<module>, cpu: 140.65ms, accelerator: 0us, total: 140.65ms
train.py:449:<module>, cpu: 96.91ms, accelerator: 30us, total: 96.94ms
  summary.py:146:image, cpu: 96.88ms, accelerator: 0us, total: 96.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_42000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.74%)
top 2 operation type: ImageSummary, cpu: 331.30ms, accelerator: 0us, total: 331.30ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 102.05ms, accelerator: 0us, total: 102.05ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.76ms, accelerator: 0us, total: 140.76ms
top 3 graph node: difference, cpu: 96.71ms, accelerator: 0us, total: 96.71ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 5.96ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.30ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.30ms, total: 6.54ms
  __init__.py:185:compute_gradients, cpu: 3.41ms, accelerator: 4.66ms, total: 8.11ms
train.py:448:<module>, cpu: 140.77ms, accelerator: 0us, total: 140.77ms
train.py:449:<module>, cpu: 96.75ms, accelerator: 30us, total: 96.78ms
  summary.py:146:image, cpu: 96.72ms, accelerator: 0us, total: 96.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_42250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.74%)
top 2 operation type: ImageSummary, cpu: 331.23ms, accelerator: 0us, total: 331.23ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.96ms, accelerator: 0us, total: 101.96ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.81ms, accelerator: 0us, total: 140.81ms
top 3 graph node: difference, cpu: 96.76ms, accelerator: 0us, total: 96.76ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 5.99ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.30ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.30ms, total: 6.52ms
  __init__.py:185:compute_gradients, cpu: 3.40ms, accelerator: 4.70ms, total: 8.14ms
train.py:448:<module>, cpu: 140.82ms, accelerator: 0us, total: 140.82ms
train.py:449:<module>, cpu: 96.80ms, accelerator: 30us, total: 96.83ms
  summary.py:146:image, cpu: 96.77ms, accelerator: 0us, total: 96.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_42500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.75%)
top 2 operation type: ImageSummary, cpu: 330.76ms, accelerator: 0us, total: 330.76ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.87ms, accelerator: 0us, total: 101.87ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.63ms, accelerator: 0us, total: 140.63ms
top 3 graph node: difference, cpu: 96.71ms, accelerator: 0us, total: 96.71ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.01ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.29ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 1.29ms, total: 6.54ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 4.72ms, total: 8.22ms
train.py:448:<module>, cpu: 140.64ms, accelerator: 0us, total: 140.64ms
train.py:449:<module>, cpu: 96.74ms, accelerator: 30us, total: 96.77ms
  summary.py:146:image, cpu: 96.71ms, accelerator: 0us, total: 96.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2035.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_42750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.75%)
top 2 operation type: ImageSummary, cpu: 330.78ms, accelerator: 0us, total: 330.78ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.73ms, accelerator: 0us, total: 101.73ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.80ms, accelerator: 0us, total: 140.80ms
top 3 graph node: difference, cpu: 96.67ms, accelerator: 0us, total: 96.67ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.06ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.29ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.29ms, total: 6.51ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 4.77ms, total: 8.31ms
train.py:448:<module>, cpu: 140.80ms, accelerator: 0us, total: 140.80ms
train.py:449:<module>, cpu: 96.70ms, accelerator: 29us, total: 96.73ms
  summary.py:146:image, cpu: 96.67ms, accelerator: 0us, total: 96.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2032.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_43000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.74%)
top 2 operation type: ImageSummary, cpu: 330.78ms, accelerator: 0us, total: 330.78ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.83ms, accelerator: 0us, total: 101.83ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.75ms, accelerator: 0us, total: 140.75ms
top 3 graph node: difference, cpu: 96.60ms, accelerator: 0us, total: 96.60ms
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.04ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.28ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 1.28ms, total: 6.48ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 4.76ms, total: 8.29ms
train.py:448:<module>, cpu: 140.75ms, accelerator: 0us, total: 140.75ms
train.py:449:<module>, cpu: 96.64ms, accelerator: 29us, total: 96.67ms
  summary.py:146:image, cpu: 96.60ms, accelerator: 0us, total: 96.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_43250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.74%)
top 2 operation type: ImageSummary, cpu: 331.36ms, accelerator: 0us, total: 331.36ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.60ms, accelerator: 0us, total: 101.60ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.04ms, accelerator: 0us, total: 141.04ms
top 3 graph node: difference, cpu: 96.69ms, accelerator: 0us, total: 96.69ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.07ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.27ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.27ms, total: 6.50ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.80ms, total: 8.36ms
train.py:448:<module>, cpu: 141.05ms, accelerator: 0us, total: 141.05ms
train.py:449:<module>, cpu: 96.73ms, accelerator: 29us, total: 96.76ms
  summary.py:146:image, cpu: 96.69ms, accelerator: 0us, total: 96.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_43500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.74%)
top 2 operation type: ImageSummary, cpu: 331.39ms, accelerator: 0us, total: 331.39ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.86ms, accelerator: 0us, total: 101.86ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.95ms, accelerator: 0us, total: 140.95ms
top 3 graph node: difference, cpu: 96.70ms, accelerator: 0us, total: 96.70ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.09ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.31ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 1.31ms, total: 6.52ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.78ms, total: 8.33ms
train.py:448:<module>, cpu: 140.96ms, accelerator: 0us, total: 140.96ms
train.py:449:<module>, cpu: 96.73ms, accelerator: 29us, total: 96.76ms
  summary.py:146:image, cpu: 96.70ms, accelerator: 0us, total: 96.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_43750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (93.73%)
top 2 operation type: ImageSummary, cpu: 331.70ms, accelerator: 0us, total: 331.70ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.87ms, accelerator: 0us, total: 101.87ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.90ms, accelerator: 0us, total: 140.90ms
top 3 graph node: difference, cpu: 96.76ms, accelerator: 0us, total: 96.76ms
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.06ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.30ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 1.30ms, total: 6.55ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 4.76ms, total: 8.30ms
train.py:448:<module>, cpu: 140.90ms, accelerator: 0us, total: 140.90ms
train.py:449:<module>, cpu: 96.80ms, accelerator: 29us, total: 96.83ms
  summary.py:146:image, cpu: 96.77ms, accelerator: 0us, total: 96.77ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_44000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.73%)
top 2 operation type: ImageSummary, cpu: 331.65ms, accelerator: 0us, total: 331.65ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.70ms, accelerator: 0us, total: 101.70ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.78ms, accelerator: 0us, total: 140.78ms
top 3 graph node: difference, cpu: 96.99ms, accelerator: 0us, total: 96.99ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.07ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.30ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.30ms, total: 6.52ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 4.76ms, total: 8.31ms
train.py:448:<module>, cpu: 140.79ms, accelerator: 0us, total: 140.79ms
train.py:449:<module>, cpu: 97.02ms, accelerator: 29us, total: 97.05ms
  summary.py:146:image, cpu: 96.99ms, accelerator: 0us, total: 96.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_44250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.74%)
top 2 operation type: ImageSummary, cpu: 331.56ms, accelerator: 0us, total: 331.56ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.56ms, accelerator: 0us, total: 101.56ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.84ms, accelerator: 0us, total: 140.84ms
top 3 graph node: difference, cpu: 96.91ms, accelerator: 0us, total: 96.91ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.14ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.30ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 1.30ms, total: 6.50ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 4.84ms, total: 8.38ms
train.py:448:<module>, cpu: 140.84ms, accelerator: 0us, total: 140.84ms
train.py:449:<module>, cpu: 96.94ms, accelerator: 29us, total: 96.97ms
  summary.py:146:image, cpu: 96.91ms, accelerator: 0us, total: 96.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_44500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.74%)
top 2 operation type: ImageSummary, cpu: 331.57ms, accelerator: 0us, total: 331.57ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.33ms, accelerator: 0us, total: 101.33ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.95ms, accelerator: 0us, total: 140.95ms
top 3 graph node: difference, cpu: 96.89ms, accelerator: 0us, total: 96.89ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.11ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.29ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 1.29ms, total: 6.49ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 4.82ms, total: 8.35ms
train.py:448:<module>, cpu: 140.95ms, accelerator: 0us, total: 140.95ms
train.py:449:<module>, cpu: 96.92ms, accelerator: 29us, total: 96.95ms
  summary.py:146:image, cpu: 96.89ms, accelerator: 0us, total: 96.89ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2026.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_44750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.73%)
top 2 operation type: ImageSummary, cpu: 331.50ms, accelerator: 0us, total: 331.50ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.19ms, accelerator: 0us, total: 101.19ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.84ms, accelerator: 0us, total: 140.84ms
top 3 graph node: difference, cpu: 96.81ms, accelerator: 0us, total: 96.81ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.12ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.31ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.31ms, total: 6.53ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 4.81ms, total: 8.34ms
train.py:448:<module>, cpu: 140.84ms, accelerator: 0us, total: 140.84ms
train.py:449:<module>, cpu: 96.85ms, accelerator: 28us, total: 96.88ms
  summary.py:146:image, cpu: 96.81ms, accelerator: 0us, total: 96.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_45000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.73%)
top 2 operation type: ImageSummary, cpu: 331.71ms, accelerator: 0us, total: 331.71ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.47ms, accelerator: 0us, total: 101.47ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.00ms, accelerator: 0us, total: 141.00ms
top 3 graph node: difference, cpu: 96.96ms, accelerator: 0us, total: 96.96ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.22ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.33ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 1.33ms, total: 6.59ms
  __init__.py:185:compute_gradients, cpu: 3.48ms, accelerator: 4.89ms, total: 8.41ms
train.py:448:<module>, cpu: 141.01ms, accelerator: 0us, total: 141.01ms
train.py:449:<module>, cpu: 97.00ms, accelerator: 28us, total: 97.02ms
  summary.py:146:image, cpu: 96.96ms, accelerator: 0us, total: 96.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_45250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (93.72%)
top 2 operation type: ImageSummary, cpu: 331.71ms, accelerator: 0us, total: 331.71ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 101.42ms, accelerator: 0us, total: 101.42ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.01ms, accelerator: 0us, total: 141.01ms
top 3 graph node: difference, cpu: 96.92ms, accelerator: 0us, total: 96.92ms
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.26ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.40ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 1.40ms, total: 6.64ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 4.86ms, total: 8.38ms
train.py:448:<module>, cpu: 141.01ms, accelerator: 0us, total: 141.01ms
train.py:449:<module>, cpu: 96.96ms, accelerator: 28us, total: 96.98ms
  summary.py:146:image, cpu: 96.92ms, accelerator: 0us, total: 96.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2035.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_45500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (93.72%)
top 2 operation type: ImageSummary, cpu: 331.72ms, accelerator: 0us, total: 331.72ms (3.93%)
top 3 operation type: HistogramSummary, cpu: 101.29ms, accelerator: 0us, total: 101.29ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.24ms, accelerator: 0us, total: 141.24ms
top 3 graph node: difference, cpu: 96.80ms, accelerator: 0us, total: 96.80ms
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.30ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.39ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.39ms, total: 6.62ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 4.92ms, total: 8.42ms
train.py:448:<module>, cpu: 141.24ms, accelerator: 0us, total: 141.24ms
train.py:449:<module>, cpu: 96.83ms, accelerator: 28us, total: 96.86ms
  summary.py:146:image, cpu: 96.80ms, accelerator: 0us, total: 96.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_45750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.73%)
top 2 operation type: ImageSummary, cpu: 331.56ms, accelerator: 0us, total: 331.56ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.39ms, accelerator: 0us, total: 101.39ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.16ms, accelerator: 0us, total: 141.16ms
top 3 graph node: difference, cpu: 96.88ms, accelerator: 0us, total: 96.88ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.32ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.40ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 1.40ms, total: 6.61ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.92ms, total: 8.53ms
train.py:448:<module>, cpu: 141.17ms, accelerator: 0us, total: 141.17ms
train.py:449:<module>, cpu: 96.92ms, accelerator: 28us, total: 96.95ms
  summary.py:146:image, cpu: 96.89ms, accelerator: 0us, total: 96.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_46000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.73%)
top 2 operation type: ImageSummary, cpu: 331.84ms, accelerator: 0us, total: 331.84ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.21ms, accelerator: 0us, total: 101.21ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.33ms, accelerator: 0us, total: 141.33ms
top 3 graph node: difference, cpu: 96.87ms, accelerator: 0us, total: 96.87ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.40ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.42ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 1.42ms, total: 6.61ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.98ms, total: 8.58ms
train.py:448:<module>, cpu: 141.34ms, accelerator: 0us, total: 141.34ms
train.py:449:<module>, cpu: 96.91ms, accelerator: 28us, total: 96.94ms
  summary.py:146:image, cpu: 96.87ms, accelerator: 0us, total: 96.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_46250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.73%)
top 2 operation type: ImageSummary, cpu: 332.17ms, accelerator: 0us, total: 332.17ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.34ms, accelerator: 0us, total: 101.34ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.38ms, accelerator: 0us, total: 141.38ms
top 3 graph node: difference, cpu: 97.04ms, accelerator: 0us, total: 97.04ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.45ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.48ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 1.48ms, total: 6.65ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.97ms, total: 8.57ms
train.py:448:<module>, cpu: 141.38ms, accelerator: 0us, total: 141.38ms
train.py:449:<module>, cpu: 97.08ms, accelerator: 28us, total: 97.11ms
  summary.py:146:image, cpu: 97.05ms, accelerator: 0us, total: 97.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_46500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.73%)
top 2 operation type: ImageSummary, cpu: 331.96ms, accelerator: 0us, total: 331.96ms (3.92%)
top 3 operation type: HistogramSummary, cpu: 101.18ms, accelerator: 0us, total: 101.18ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.11ms, accelerator: 0us, total: 141.11ms
top 3 graph node: difference, cpu: 97.14ms, accelerator: 0us, total: 97.14ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.49ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.47ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.47ms, total: 6.64ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 5.02ms, total: 8.60ms
train.py:448:<module>, cpu: 141.11ms, accelerator: 0us, total: 141.11ms
train.py:449:<module>, cpu: 97.18ms, accelerator: 27us, total: 97.21ms
  summary.py:146:image, cpu: 97.15ms, accelerator: 0us, total: 97.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_46750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (93.74%)
top 2 operation type: ImageSummary, cpu: 331.83ms, accelerator: 0us, total: 331.83ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.24ms, accelerator: 0us, total: 101.24ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.22ms, accelerator: 0us, total: 141.22ms
top 3 graph node: difference, cpu: 97.07ms, accelerator: 0us, total: 97.07ms
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.49ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.46ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.46ms, total: 6.63ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 5.02ms, total: 8.60ms
train.py:448:<module>, cpu: 141.23ms, accelerator: 0us, total: 141.23ms
train.py:449:<module>, cpu: 97.11ms, accelerator: 27us, total: 97.14ms
  summary.py:146:image, cpu: 97.08ms, accelerator: 0us, total: 97.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2032.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_47000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.21ms, accelerator: 0us, total: 331.21ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 100.97ms, accelerator: 0us, total: 100.97ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.99ms, accelerator: 0us, total: 140.99ms
top 3 graph node: difference, cpu: 96.85ms, accelerator: 0us, total: 96.85ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.46ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.46ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.46ms, total: 6.68ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 5.00ms, total: 8.59ms
train.py:448:<module>, cpu: 141.00ms, accelerator: 0us, total: 141.00ms
train.py:449:<module>, cpu: 96.89ms, accelerator: 27us, total: 96.92ms
  summary.py:146:image, cpu: 96.86ms, accelerator: 0us, total: 96.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_47250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.37ms, accelerator: 0us, total: 331.37ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 100.79ms, accelerator: 0us, total: 100.79ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.06ms, accelerator: 0us, total: 141.06ms
top 3 graph node: difference, cpu: 97.05ms, accelerator: 0us, total: 97.05ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.52ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.45ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 1.45ms, total: 6.65ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 5.07ms, total: 8.65ms
train.py:448:<module>, cpu: 141.07ms, accelerator: 0us, total: 141.07ms
train.py:449:<module>, cpu: 97.08ms, accelerator: 27us, total: 97.11ms
  summary.py:146:image, cpu: 97.05ms, accelerator: 0us, total: 97.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_47500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.50ms, accelerator: 0us, total: 331.50ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 100.83ms, accelerator: 0us, total: 100.83ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.18ms, accelerator: 0us, total: 141.18ms
top 3 graph node: difference, cpu: 97.05ms, accelerator: 0us, total: 97.05ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.49ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.44ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 1.44ms, total: 6.64ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 5.05ms, total: 8.62ms
train.py:448:<module>, cpu: 141.18ms, accelerator: 0us, total: 141.18ms
train.py:449:<module>, cpu: 97.10ms, accelerator: 27us, total: 97.12ms
  summary.py:146:image, cpu: 97.06ms, accelerator: 0us, total: 97.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_47750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.27ms, accelerator: 0us, total: 331.27ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 100.83ms, accelerator: 0us, total: 100.83ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.03ms, accelerator: 0us, total: 141.03ms
top 3 graph node: difference, cpu: 97.20ms, accelerator: 0us, total: 97.20ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.46ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.44ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 1.44ms, total: 6.65ms
  __init__.py:185:compute_gradients, cpu: 3.53ms, accelerator: 5.03ms, total: 8.60ms
train.py:448:<module>, cpu: 141.03ms, accelerator: 0us, total: 141.03ms
train.py:449:<module>, cpu: 97.25ms, accelerator: 27us, total: 97.28ms
  summary.py:146:image, cpu: 97.21ms, accelerator: 0us, total: 97.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_48000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.27ms, accelerator: 0us, total: 331.27ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 100.89ms, accelerator: 0us, total: 100.89ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.09ms, accelerator: 0us, total: 141.09ms
top 3 graph node: difference, cpu: 97.27ms, accelerator: 0us, total: 97.27ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.53ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.43ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 1.43ms, total: 6.63ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 5.10ms, total: 8.66ms
train.py:448:<module>, cpu: 141.09ms, accelerator: 0us, total: 141.09ms
train.py:449:<module>, cpu: 97.31ms, accelerator: 27us, total: 97.34ms
  summary.py:146:image, cpu: 97.27ms, accelerator: 0us, total: 97.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_48250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.20ms, accelerator: 0us, total: 331.20ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.24ms, accelerator: 0us, total: 101.24ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.16ms, accelerator: 0us, total: 141.16ms
top 3 graph node: difference, cpu: 97.27ms, accelerator: 0us, total: 97.27ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.50ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.43ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 1.43ms, total: 6.61ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 5.08ms, total: 8.63ms
train.py:448:<module>, cpu: 141.17ms, accelerator: 0us, total: 141.17ms
train.py:449:<module>, cpu: 97.31ms, accelerator: 27us, total: 97.34ms
  summary.py:146:image, cpu: 97.27ms, accelerator: 0us, total: 97.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_48500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.29ms, accelerator: 0us, total: 331.29ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.20ms, accelerator: 0us, total: 101.20ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.22ms, accelerator: 0us, total: 141.22ms
top 3 graph node: difference, cpu: 97.38ms, accelerator: 0us, total: 97.38ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.48ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.43ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 1.43ms, total: 6.63ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 5.05ms, total: 8.59ms
train.py:448:<module>, cpu: 141.22ms, accelerator: 0us, total: 141.22ms
train.py:449:<module>, cpu: 97.42ms, accelerator: 26us, total: 97.45ms
  summary.py:146:image, cpu: 97.38ms, accelerator: 0us, total: 97.38ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_48750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.75%)
top 2 operation type: ImageSummary, cpu: 331.78ms, accelerator: 0us, total: 331.78ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.37ms, accelerator: 0us, total: 101.37ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.33ms, accelerator: 0us, total: 141.33ms
top 3 graph node: difference, cpu: 97.44ms, accelerator: 0us, total: 97.44ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.62ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.44ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 1.44ms, total: 6.68ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 5.18ms, total: 8.71ms
train.py:448:<module>, cpu: 141.34ms, accelerator: 0us, total: 141.34ms
train.py:449:<module>, cpu: 97.49ms, accelerator: 26us, total: 97.51ms
  summary.py:146:image, cpu: 97.44ms, accelerator: 0us, total: 97.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_49000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.76ms, accelerator: 0us, total: 331.76ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.25ms, accelerator: 0us, total: 101.25ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.35ms, accelerator: 0us, total: 141.35ms
top 3 graph node: difference, cpu: 97.39ms, accelerator: 0us, total: 97.39ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.59ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.43ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 1.43ms, total: 6.66ms
  __init__.py:185:compute_gradients, cpu: 3.48ms, accelerator: 5.15ms, total: 8.68ms
train.py:448:<module>, cpu: 141.35ms, accelerator: 0us, total: 141.35ms
train.py:449:<module>, cpu: 97.44ms, accelerator: 26us, total: 97.47ms
  summary.py:146:image, cpu: 97.40ms, accelerator: 0us, total: 97.40ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_49250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec (93.75%)
top 2 operation type: ImageSummary, cpu: 332.27ms, accelerator: 0us, total: 332.27ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.26ms, accelerator: 0us, total: 101.26ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.46ms, accelerator: 0us, total: 141.46ms
top 3 graph node: difference, cpu: 97.59ms, accelerator: 0us, total: 97.59ms
train.py:511:<module>, cpu: 7.99sec, accelerator: 6.60ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.44ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 1.44ms, total: 6.93ms
  __init__.py:185:compute_gradients, cpu: 3.48ms, accelerator: 5.16ms, total: 8.68ms
train.py:448:<module>, cpu: 141.47ms, accelerator: 0us, total: 141.47ms
train.py:449:<module>, cpu: 97.63ms, accelerator: 26us, total: 97.66ms
  summary.py:146:image, cpu: 97.59ms, accelerator: 0us, total: 97.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_49500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.75%)
top 2 operation type: ImageSummary, cpu: 332.39ms, accelerator: 0us, total: 332.39ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.35ms, accelerator: 0us, total: 101.35ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.57ms, accelerator: 0us, total: 141.57ms
top 3 graph node: difference, cpu: 97.75ms, accelerator: 0us, total: 97.75ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.57ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.44ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 1.44ms, total: 6.91ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 5.14ms, total: 8.64ms
train.py:448:<module>, cpu: 141.58ms, accelerator: 0us, total: 141.58ms
train.py:449:<module>, cpu: 97.79ms, accelerator: 26us, total: 97.82ms
  summary.py:146:image, cpu: 97.75ms, accelerator: 0us, total: 97.75ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_49750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.74%)
top 2 operation type: ImageSummary, cpu: 332.30ms, accelerator: 0us, total: 332.30ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.25ms, accelerator: 0us, total: 101.25ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.59ms, accelerator: 0us, total: 141.59ms
top 3 graph node: difference, cpu: 97.82ms, accelerator: 0us, total: 97.82ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.59ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.43ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 1.43ms, total: 6.89ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 5.16ms, total: 8.67ms
train.py:448:<module>, cpu: 141.59ms, accelerator: 0us, total: 141.59ms
train.py:449:<module>, cpu: 97.86ms, accelerator: 26us, total: 97.89ms
  summary.py:146:image, cpu: 97.82ms, accelerator: 0us, total: 97.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_50000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.87ms, accelerator: 0us, total: 331.87ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.33ms, accelerator: 0us, total: 101.33ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.47ms, accelerator: 0us, total: 141.47ms
top 3 graph node: difference, cpu: 97.71ms, accelerator: 0us, total: 97.71ms
train.py:511:<module>, cpu: 7.99sec, accelerator: 6.61ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.45ms, total: 7.99sec
    __init__.py:83:allreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 1.45ms, total: 6.90ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 5.16ms, total: 8.72ms
train.py:448:<module>, cpu: 141.48ms, accelerator: 0us, total: 141.48ms
train.py:449:<module>, cpu: 97.76ms, accelerator: 26us, total: 97.78ms
  summary.py:146:image, cpu: 97.72ms, accelerator: 0us, total: 97.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_50250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.50ms, accelerator: 0us, total: 331.50ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.23ms, accelerator: 0us, total: 101.23ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.28ms, accelerator: 0us, total: 141.28ms
top 3 graph node: difference, cpu: 97.56ms, accelerator: 0us, total: 97.56ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.58ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.45ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 1.45ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 5.14ms, total: 8.69ms
train.py:448:<module>, cpu: 141.28ms, accelerator: 0us, total: 141.28ms
train.py:449:<module>, cpu: 97.61ms, accelerator: 28us, total: 97.64ms
  summary.py:146:image, cpu: 97.57ms, accelerator: 0us, total: 97.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_50500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.53ms, accelerator: 0us, total: 331.53ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.09ms, accelerator: 0us, total: 101.09ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.31ms, accelerator: 0us, total: 141.31ms
top 3 graph node: difference, cpu: 97.53ms, accelerator: 0us, total: 97.53ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.55ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.44ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec
    __init__.py:86:allreduce, cpu: 5.48ms, accelerator: 1.44ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 5.11ms, total: 8.66ms
train.py:448:<module>, cpu: 141.31ms, accelerator: 0us, total: 141.31ms
train.py:449:<module>, cpu: 97.58ms, accelerator: 28us, total: 97.60ms
  summary.py:146:image, cpu: 97.53ms, accelerator: 0us, total: 97.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_50750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.53ms, accelerator: 0us, total: 331.53ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.16ms, accelerator: 0us, total: 101.16ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.38ms, accelerator: 0us, total: 141.38ms
top 3 graph node: difference, cpu: 97.52ms, accelerator: 0us, total: 97.52ms
train.py:511:<module>, cpu: 7.99sec, accelerator: 6.53ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.43ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.98sec, accelerator: 0us, total: 7.98sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 1.43ms, total: 6.92ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 5.09ms, total: 8.65ms
train.py:448:<module>, cpu: 141.39ms, accelerator: 0us, total: 141.39ms
train.py:449:<module>, cpu: 97.57ms, accelerator: 28us, total: 97.60ms
  summary.py:146:image, cpu: 97.53ms, accelerator: 0us, total: 97.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_51000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.95ms, accelerator: 0us, total: 331.95ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.36ms, accelerator: 0us, total: 101.36ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.62ms, accelerator: 0us, total: 141.62ms
top 3 graph node: difference, cpu: 97.79ms, accelerator: 0us, total: 97.79ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.56ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.43ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 1.43ms, total: 6.90ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 5.13ms, total: 8.68ms
train.py:448:<module>, cpu: 141.62ms, accelerator: 0us, total: 141.62ms
train.py:449:<module>, cpu: 97.83ms, accelerator: 28us, total: 97.86ms
  summary.py:146:image, cpu: 97.80ms, accelerator: 0us, total: 97.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_51250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.75%)
top 2 operation type: ImageSummary, cpu: 332.57ms, accelerator: 0us, total: 332.57ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.14ms, accelerator: 0us, total: 101.14ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.80ms, accelerator: 0us, total: 141.80ms
top 3 graph node: difference, cpu: 97.94ms, accelerator: 0us, total: 97.94ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.60ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.42ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 1.42ms, total: 6.88ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 5.17ms, total: 8.71ms
train.py:448:<module>, cpu: 141.81ms, accelerator: 0us, total: 141.81ms
train.py:449:<module>, cpu: 97.99ms, accelerator: 28us, total: 98.02ms
  summary.py:146:image, cpu: 97.95ms, accelerator: 0us, total: 97.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_51500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.75%)
top 2 operation type: ImageSummary, cpu: 332.32ms, accelerator: 0us, total: 332.32ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.21ms, accelerator: 0us, total: 101.21ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.61ms, accelerator: 0us, total: 141.61ms
top 3 graph node: difference, cpu: 98.06ms, accelerator: 0us, total: 98.06ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.63ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.42ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 1.42ms, total: 6.86ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 5.21ms, total: 8.75ms
train.py:448:<module>, cpu: 141.62ms, accelerator: 0us, total: 141.62ms
train.py:449:<module>, cpu: 98.11ms, accelerator: 28us, total: 98.13ms
  summary.py:146:image, cpu: 98.07ms, accelerator: 0us, total: 98.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_51750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.84ms, accelerator: 0us, total: 331.84ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.07ms, accelerator: 0us, total: 101.07ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.47ms, accelerator: 0us, total: 141.47ms
top 3 graph node: difference, cpu: 97.90ms, accelerator: 0us, total: 97.90ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.63ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.41ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 1.41ms, total: 6.84ms
  __init__.py:185:compute_gradients, cpu: 3.48ms, accelerator: 5.22ms, total: 8.74ms
train.py:448:<module>, cpu: 141.48ms, accelerator: 0us, total: 141.48ms
train.py:449:<module>, cpu: 97.95ms, accelerator: 28us, total: 97.98ms
  summary.py:146:image, cpu: 97.91ms, accelerator: 0us, total: 97.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_52000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.98ms, accelerator: 0us, total: 331.98ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 100.98ms, accelerator: 0us, total: 100.98ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.57ms, accelerator: 0us, total: 141.57ms
top 3 graph node: difference, cpu: 97.80ms, accelerator: 0us, total: 97.80ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.61ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.41ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 1.41ms, total: 6.83ms
  __init__.py:185:compute_gradients, cpu: 3.48ms, accelerator: 5.20ms, total: 8.71ms
train.py:448:<module>, cpu: 141.58ms, accelerator: 0us, total: 141.58ms
train.py:449:<module>, cpu: 97.84ms, accelerator: 27us, total: 97.87ms
  summary.py:146:image, cpu: 97.80ms, accelerator: 0us, total: 97.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2043.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_52250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.77%)
top 2 operation type: ImageSummary, cpu: 331.77ms, accelerator: 0us, total: 331.77ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 100.91ms, accelerator: 0us, total: 100.91ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.60ms, accelerator: 0us, total: 141.60ms
top 3 graph node: difference, cpu: 97.64ms, accelerator: 0us, total: 97.64ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.60ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.42ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 1.42ms, total: 6.82ms
  __init__.py:185:compute_gradients, cpu: 3.47ms, accelerator: 5.18ms, total: 8.68ms
train.py:448:<module>, cpu: 141.60ms, accelerator: 0us, total: 141.60ms
train.py:449:<module>, cpu: 97.68ms, accelerator: 27us, total: 97.71ms
  summary.py:146:image, cpu: 97.64ms, accelerator: 0us, total: 97.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_52500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (93.77%)
top 2 operation type: ImageSummary, cpu: 331.69ms, accelerator: 0us, total: 331.69ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 100.89ms, accelerator: 0us, total: 100.89ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.56ms, accelerator: 0us, total: 141.56ms
top 3 graph node: difference, cpu: 97.65ms, accelerator: 0us, total: 97.65ms
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.57ms, total: 7.99sec
  __init__.py:194:compute_gradients, cpu: 7.98sec, accelerator: 1.42ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.42ms, total: 6.80ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 5.16ms, total: 8.66ms
train.py:448:<module>, cpu: 141.56ms, accelerator: 0us, total: 141.56ms
train.py:449:<module>, cpu: 97.69ms, accelerator: 27us, total: 97.72ms
  summary.py:146:image, cpu: 97.66ms, accelerator: 0us, total: 97.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_52750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (93.77%)
top 2 operation type: ImageSummary, cpu: 331.45ms, accelerator: 0us, total: 331.45ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.19ms, accelerator: 0us, total: 101.19ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.56ms, accelerator: 0us, total: 141.56ms
top 3 graph node: difference, cpu: 97.59ms, accelerator: 0us, total: 97.59ms
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.54ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.41ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 1.41ms, total: 6.79ms
  __init__.py:185:compute_gradients, cpu: 3.45ms, accelerator: 5.13ms, total: 8.63ms
train.py:448:<module>, cpu: 141.57ms, accelerator: 0us, total: 141.57ms
train.py:449:<module>, cpu: 97.63ms, accelerator: 27us, total: 97.66ms
  summary.py:146:image, cpu: 97.59ms, accelerator: 0us, total: 97.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_53000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.38ms, accelerator: 0us, total: 331.38ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.47ms, accelerator: 0us, total: 101.47ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.47ms, accelerator: 0us, total: 141.47ms
top 3 graph node: difference, cpu: 97.53ms, accelerator: 0us, total: 97.53ms
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.56ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.44ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.44ms, total: 6.80ms
  __init__.py:185:compute_gradients, cpu: 3.45ms, accelerator: 5.12ms, total: 8.61ms
train.py:448:<module>, cpu: 141.48ms, accelerator: 0us, total: 141.48ms
train.py:449:<module>, cpu: 97.58ms, accelerator: 27us, total: 97.61ms
  summary.py:146:image, cpu: 97.54ms, accelerator: 0us, total: 97.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_53250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (93.76%)
top 2 operation type: ImageSummary, cpu: 331.11ms, accelerator: 0us, total: 331.11ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.33ms, accelerator: 0us, total: 101.33ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.30ms, accelerator: 0us, total: 141.30ms
top 3 graph node: difference, cpu: 97.42ms, accelerator: 0us, total: 97.42ms
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.54ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.43ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.43ms, total: 6.80ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 5.11ms, total: 8.58ms
train.py:448:<module>, cpu: 141.30ms, accelerator: 0us, total: 141.30ms
train.py:449:<module>, cpu: 97.46ms, accelerator: 27us, total: 97.49ms
  summary.py:146:image, cpu: 97.42ms, accelerator: 0us, total: 97.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_53500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (93.76%)
top 2 operation type: ImageSummary, cpu: 330.84ms, accelerator: 0us, total: 330.84ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.33ms, accelerator: 0us, total: 101.33ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.13ms, accelerator: 0us, total: 141.13ms
top 3 graph node: difference, cpu: 97.27ms, accelerator: 0us, total: 97.27ms
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.51ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.43ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 1.43ms, total: 6.77ms
  __init__.py:185:compute_gradients, cpu: 3.43ms, accelerator: 5.08ms, total: 8.56ms
train.py:448:<module>, cpu: 141.14ms, accelerator: 0us, total: 141.14ms
train.py:449:<module>, cpu: 97.31ms, accelerator: 27us, total: 97.34ms
  summary.py:146:image, cpu: 97.28ms, accelerator: 0us, total: 97.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_53750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.76%)
top 2 operation type: ImageSummary, cpu: 330.52ms, accelerator: 0us, total: 330.52ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.32ms, accelerator: 0us, total: 101.32ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.08ms, accelerator: 0us, total: 141.08ms
top 3 graph node: difference, cpu: 97.08ms, accelerator: 0us, total: 97.08ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.49ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.42ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.42ms, total: 6.81ms
  __init__.py:185:compute_gradients, cpu: 3.44ms, accelerator: 5.07ms, total: 8.55ms
train.py:448:<module>, cpu: 141.09ms, accelerator: 0us, total: 141.09ms
train.py:449:<module>, cpu: 97.13ms, accelerator: 27us, total: 97.16ms
  summary.py:146:image, cpu: 97.09ms, accelerator: 0us, total: 97.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2043.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_54000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.76%)
top 2 operation type: ImageSummary, cpu: 330.69ms, accelerator: 0us, total: 330.69ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.30ms, accelerator: 0us, total: 101.30ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.08ms, accelerator: 0us, total: 141.08ms
top 3 graph node: difference, cpu: 97.16ms, accelerator: 0us, total: 97.16ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.46ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.42ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 1.42ms, total: 6.79ms
  __init__.py:185:compute_gradients, cpu: 3.43ms, accelerator: 5.05ms, total: 8.52ms
train.py:448:<module>, cpu: 141.09ms, accelerator: 0us, total: 141.09ms
train.py:449:<module>, cpu: 97.21ms, accelerator: 27us, total: 97.23ms
  summary.py:146:image, cpu: 97.17ms, accelerator: 0us, total: 97.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_54250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (93.76%)
top 2 operation type: ImageSummary, cpu: 330.46ms, accelerator: 0us, total: 330.46ms (3.91%)
top 3 operation type: HistogramSummary, cpu: 101.09ms, accelerator: 0us, total: 101.09ms (1.19%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.11ms, accelerator: 0us, total: 141.11ms
top 3 graph node: difference, cpu: 97.09ms, accelerator: 0us, total: 97.09ms
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.46ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.41ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.41ms, total: 6.77ms
  __init__.py:185:compute_gradients, cpu: 3.43ms, accelerator: 5.05ms, total: 8.51ms
train.py:448:<module>, cpu: 141.12ms, accelerator: 0us, total: 141.12ms
train.py:449:<module>, cpu: 97.14ms, accelerator: 26us, total: 97.17ms
  summary.py:146:image, cpu: 97.10ms, accelerator: 0us, total: 97.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_54500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (93.77%)
top 2 operation type: ImageSummary, cpu: 330.35ms, accelerator: 0us, total: 330.35ms (3.90%)
top 3 operation type: HistogramSummary, cpu: 101.68ms, accelerator: 0us, total: 101.68ms (1.20%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.12ms, accelerator: 0us, total: 141.12ms
top 3 graph node: difference, cpu: 97.10ms, accelerator: 0us, total: 97.10ms
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.44ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.40ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 1.40ms, total: 6.75ms
  __init__.py:185:compute_gradients, cpu: 3.42ms, accelerator: 5.03ms, total: 8.50ms
train.py:448:<module>, cpu: 141.12ms, accelerator: 0us, total: 141.12ms
train.py:449:<module>, cpu: 97.15ms, accelerator: 26us, total: 97.17ms
  summary.py:146:image, cpu: 97.11ms, accelerator: 0us, total: 97.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_54750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 83848836.46sec, total: 83848836.46sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.06ms, accelerator: 0us, total: 330.06ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.03ms, accelerator: 0us, total: 141.03ms
top 3 graph node: difference, cpu: 96.97ms, accelerator: 0us, total: 96.97ms
train.py:441:<module> (gradient), cpu: 4.03ms, accelerator: 83848836.47sec, total: 83848836.47sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.45ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.40ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.30ms, accelerator: 1.40ms, total: 6.72ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 5.05ms, total: 8.55ms
train.py:448:<module>, cpu: 141.04ms, accelerator: 0us, total: 141.04ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_55000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 83469429.96sec, total: 83469429.96sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.00ms, accelerator: 0us, total: 330.00ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.02ms, accelerator: 0us, total: 141.02ms
top 3 graph node: difference, cpu: 97.08ms, accelerator: 0us, total: 97.08ms
train.py:441:<module> (gradient), cpu: 4.03ms, accelerator: 83469429.97sec, total: 83469429.97sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.43ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.40ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 1.40ms, total: 6.77ms
  __init__.py:185:compute_gradients, cpu: 3.46ms, accelerator: 5.03ms, total: 8.53ms
train.py:448:<module>, cpu: 141.02ms, accelerator: 0us, total: 141.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_55250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 83093441.54sec, total: 83093441.54sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 3 operation type: ImageSummary, cpu: 329.83ms, accelerator: 0us, total: 329.83ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.95ms, accelerator: 0us, total: 140.95ms
top 3 graph node: difference, cpu: 96.90ms, accelerator: 0us, total: 96.90ms
train.py:441:<module> (gradient), cpu: 4.02ms, accelerator: 83093441.54sec, total: 83093441.55sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.41ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.39ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.39ms, total: 6.75ms
  __init__.py:185:compute_gradients, cpu: 3.45ms, accelerator: 5.01ms, total: 8.50ms
train.py:448:<module>, cpu: 140.96ms, accelerator: 0us, total: 140.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_55500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 82720825.21sec, total: 82720825.21sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 3 operation type: ImageSummary, cpu: 329.89ms, accelerator: 0us, total: 329.89ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.06ms, accelerator: 0us, total: 141.06ms
top 3 graph node: difference, cpu: 97.05ms, accelerator: 0us, total: 97.05ms
train.py:441:<module> (gradient), cpu: 4.02ms, accelerator: 82720825.21sec, total: 82720825.22sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.44ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.39ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 1.39ms, total: 6.74ms
  __init__.py:185:compute_gradients, cpu: 3.53ms, accelerator: 5.05ms, total: 8.62ms
train.py:448:<module>, cpu: 141.06ms, accelerator: 0us, total: 141.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_55750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 82351535.81sec, total: 82351535.81sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.08ms, accelerator: 0us, total: 330.08ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.97ms, accelerator: 0us, total: 140.97ms
top 3 graph node: difference, cpu: 97.13ms, accelerator: 0us, total: 97.13ms
train.py:441:<module> (gradient), cpu: 4.02ms, accelerator: 82351535.82sec, total: 82351535.82sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.41ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.38ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.38ms, total: 6.75ms
  __init__.py:185:compute_gradients, cpu: 3.53ms, accelerator: 5.03ms, total: 8.59ms
train.py:448:<module>, cpu: 140.98ms, accelerator: 0us, total: 140.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_56000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 81985528.98sec, total: 81985528.99sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.69ms, accelerator: 0us, total: 330.69ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.08ms, accelerator: 0us, total: 141.08ms
top 3 graph node: difference, cpu: 97.26ms, accelerator: 0us, total: 97.26ms
train.py:441:<module> (gradient), cpu: 4.02ms, accelerator: 81985528.99sec, total: 81985528.99sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.54ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.50ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 1.50ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 5.04ms, total: 8.60ms
train.py:448:<module>, cpu: 141.09ms, accelerator: 0us, total: 141.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_56250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 81622761.16sec, total: 81622761.16sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.68ms, accelerator: 0us, total: 330.68ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.92ms, accelerator: 0us, total: 140.92ms
top 3 graph node: difference, cpu: 97.32ms, accelerator: 0us, total: 97.32ms
train.py:441:<module> (gradient), cpu: 4.02ms, accelerator: 81622761.16sec, total: 81622761.17sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.53ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.50ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 1.50ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 5.03ms, total: 8.57ms
train.py:448:<module>, cpu: 140.93ms, accelerator: 0us, total: 140.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_56500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 81263189.52sec, total: 81263189.52sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.69ms, accelerator: 0us, total: 330.69ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.06ms, accelerator: 0us, total: 141.06ms
top 3 graph node: difference, cpu: 97.15ms, accelerator: 0us, total: 97.15ms
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 81263189.53sec, total: 81263189.53sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.50ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.50ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 1.50ms, total: 6.92ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 5.01ms, total: 8.55ms
train.py:448:<module>, cpu: 141.06ms, accelerator: 0us, total: 141.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_56750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 80906772.02sec, total: 80906772.03sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.36ms, accelerator: 0us, total: 330.36ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.89ms, accelerator: 0us, total: 140.89ms
top 3 graph node: difference, cpu: 97.06ms, accelerator: 0us, total: 97.06ms
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 80906772.03sec, total: 80906772.03sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.48ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.49ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 1.49ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 4.99ms, total: 8.52ms
train.py:448:<module>, cpu: 140.90ms, accelerator: 0us, total: 140.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_57000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 80553467.34sec, total: 80553467.34sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.35ms, accelerator: 0us, total: 330.35ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.94ms, accelerator: 0us, total: 140.94ms
top 3 graph node: difference, cpu: 96.97ms, accelerator: 0us, total: 96.97ms
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 80553467.35sec, total: 80553467.35sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.45ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.48ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 1.48ms, total: 6.92ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 4.97ms, total: 8.50ms
train.py:448:<module>, cpu: 140.94ms, accelerator: 0us, total: 140.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_57250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 80203234.88sec, total: 80203234.88sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.45ms, accelerator: 0us, total: 330.45ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.91ms, accelerator: 0us, total: 140.91ms
top 3 graph node: difference, cpu: 96.93ms, accelerator: 0us, total: 96.93ms
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 80203234.88sec, total: 80203234.89sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.42ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.48ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 1.48ms, total: 6.90ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 4.95ms, total: 8.47ms
train.py:448:<module>, cpu: 140.91ms, accelerator: 0us, total: 140.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_57500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 79856034.73sec, total: 79856034.73sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.33ms, accelerator: 0us, total: 330.33ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.92ms, accelerator: 0us, total: 140.92ms
top 3 graph node: difference, cpu: 96.89ms, accelerator: 0us, total: 96.89ms
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 79856034.73sec, total: 79856034.73sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.43ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.48ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 1.48ms, total: 6.88ms
  __init__.py:185:compute_gradients, cpu: 3.48ms, accelerator: 4.95ms, total: 8.47ms
train.py:448:<module>, cpu: 140.93ms, accelerator: 0us, total: 140.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_57750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 79511827.68sec, total: 79511827.68sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.07ms, accelerator: 0us, total: 330.07ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.85ms, accelerator: 0us, total: 140.85ms
top 3 graph node: difference, cpu: 96.82ms, accelerator: 0us, total: 96.82ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 79511827.68sec, total: 79511827.69sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.44ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.47ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.47ms, total: 6.87ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.97ms, total: 8.53ms
train.py:448:<module>, cpu: 140.85ms, accelerator: 0us, total: 140.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_58000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 79170575.20sec, total: 79170575.20sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.29ms, accelerator: 0us, total: 330.29ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.99ms, accelerator: 0us, total: 140.99ms
top 3 graph node: difference, cpu: 96.91ms, accelerator: 0us, total: 96.91ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 79170575.20sec, total: 79170575.21sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.42ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.47ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 1.47ms, total: 6.91ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 4.95ms, total: 8.50ms
train.py:448:<module>, cpu: 141.00ms, accelerator: 0us, total: 141.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_58250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 78832239.41sec, total: 78832239.41sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.18ms, accelerator: 0us, total: 330.18ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.10ms, accelerator: 0us, total: 141.10ms
top 3 graph node: difference, cpu: 96.79ms, accelerator: 0us, total: 96.79ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 78832239.41sec, total: 78832239.42sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.41ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.46ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 1.46ms, total: 6.89ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 4.95ms, total: 8.48ms
train.py:448:<module>, cpu: 141.11ms, accelerator: 0us, total: 141.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_58500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 78496783.07sec, total: 78496783.07sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.32ms, accelerator: 0us, total: 330.32ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.01ms, accelerator: 0us, total: 141.01ms
top 3 graph node: difference, cpu: 96.91ms, accelerator: 0us, total: 96.91ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 78496783.08sec, total: 78496783.08sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.41ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.46ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 1.46ms, total: 6.88ms
  __init__.py:185:compute_gradients, cpu: 3.53ms, accelerator: 4.95ms, total: 8.52ms
train.py:448:<module>, cpu: 141.02ms, accelerator: 0us, total: 141.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_58750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 78164169.58sec, total: 78164169.58sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.02ms, accelerator: 0us, total: 330.02ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.81ms, accelerator: 0us, total: 140.81ms
top 3 graph node: difference, cpu: 96.95ms, accelerator: 0us, total: 96.95ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 78164169.59sec, total: 78164169.59sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.44ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.45ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 1.45ms, total: 6.86ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.99ms, total: 8.54ms
train.py:448:<module>, cpu: 140.82ms, accelerator: 0us, total: 140.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_59000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 77834362.96sec, total: 77834362.96sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.05ms, accelerator: 0us, total: 330.05ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.88ms, accelerator: 0us, total: 140.88ms
top 3 graph node: difference, cpu: 96.90ms, accelerator: 0us, total: 96.90ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 77834362.96sec, total: 77834362.97sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.41ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.45ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.45ms, total: 6.84ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 4.97ms, total: 8.52ms
train.py:448:<module>, cpu: 140.89ms, accelerator: 0us, total: 140.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_59250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 77507327.82sec, total: 77507327.82sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.60ms, accelerator: 0us, total: 330.60ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.01ms, accelerator: 0us, total: 141.01ms
top 3 graph node: difference, cpu: 97.06ms, accelerator: 0us, total: 97.06ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 77507327.83sec, total: 77507327.83sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.53ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.44ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 1.44ms, total: 6.83ms
  __init__.py:185:compute_gradients, cpu: 3.51ms, accelerator: 5.09ms, total: 8.63ms
train.py:448:<module>, cpu: 141.02ms, accelerator: 0us, total: 141.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2040.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_59500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 77183029.38sec, total: 77183029.38sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.84ms, accelerator: 0us, total: 330.84ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.07ms, accelerator: 0us, total: 141.07ms
top 3 graph node: difference, cpu: 96.98ms, accelerator: 0us, total: 96.98ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 77183029.38sec, total: 77183029.39sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.51ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.44ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 1.44ms, total: 6.81ms
  __init__.py:185:compute_gradients, cpu: 3.50ms, accelerator: 5.08ms, total: 8.62ms
train.py:448:<module>, cpu: 141.08ms, accelerator: 0us, total: 141.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_59750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 76861433.42sec, total: 76861433.43sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.92ms, accelerator: 0us, total: 330.92ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.15ms, accelerator: 0us, total: 141.15ms
top 3 graph node: difference, cpu: 96.96ms, accelerator: 0us, total: 96.96ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 76861433.43sec, total: 76861433.43sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.49ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.43ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.43ms, total: 6.80ms
  __init__.py:185:compute_gradients, cpu: 3.49ms, accelerator: 5.06ms, total: 8.60ms
train.py:448:<module>, cpu: 141.16ms, accelerator: 0us, total: 141.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_60000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 76542506.31sec, total: 76542506.32sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 3 operation type: ImageSummary, cpu: 331.28ms, accelerator: 0us, total: 331.28ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.28ms, accelerator: 0us, total: 141.28ms
top 3 graph node: difference, cpu: 97.09ms, accelerator: 0us, total: 97.09ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 76542506.32sec, total: 76542506.32sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.48ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.43ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 1.43ms, total: 6.79ms
  __init__.py:185:compute_gradients, cpu: 3.53ms, accelerator: 5.06ms, total: 8.63ms
train.py:448:<module>, cpu: 141.29ms, accelerator: 0us, total: 141.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_60250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 76226214.97sec, total: 76226214.97sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 3 operation type: ImageSummary, cpu: 331.85ms, accelerator: 0us, total: 331.85ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.51ms, accelerator: 0us, total: 141.51ms
top 3 graph node: difference, cpu: 97.29ms, accelerator: 0us, total: 97.29ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 76226214.97sec, total: 76226214.97sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.46ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.42ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 1.42ms, total: 6.77ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 5.04ms, total: 8.61ms
train.py:448:<module>, cpu: 141.52ms, accelerator: 0us, total: 141.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_60500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 75912526.84sec, total: 75912526.84sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 3 operation type: ImageSummary, cpu: 331.66ms, accelerator: 0us, total: 331.66ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.55ms, accelerator: 0us, total: 141.55ms
top 3 graph node: difference, cpu: 97.16ms, accelerator: 0us, total: 97.16ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 75912526.84sec, total: 75912526.85sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.53ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.42ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.30ms, accelerator: 1.42ms, total: 6.75ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 5.11ms, total: 8.66ms
train.py:448:<module>, cpu: 141.55ms, accelerator: 0us, total: 141.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_60750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 75601409.92sec, total: 75601409.93sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 3 operation type: ImageSummary, cpu: 331.92ms, accelerator: 0us, total: 331.92ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.53ms, accelerator: 0us, total: 141.53ms
top 3 graph node: difference, cpu: 97.26ms, accelerator: 0us, total: 97.26ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 75601409.93sec, total: 75601409.93sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.52ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.42ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 1.42ms, total: 6.76ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 5.11ms, total: 8.66ms
train.py:448:<module>, cpu: 141.54ms, accelerator: 0us, total: 141.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_61000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 75292832.74sec, total: 75292832.74sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 332.11ms, accelerator: 0us, total: 332.11ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.51ms, accelerator: 0us, total: 141.51ms
top 3 graph node: difference, cpu: 97.31ms, accelerator: 0us, total: 97.31ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 75292832.75sec, total: 75292832.75sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.50ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.41ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.30ms, accelerator: 1.41ms, total: 6.74ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 5.09ms, total: 8.71ms
train.py:448:<module>, cpu: 141.52ms, accelerator: 0us, total: 141.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2032.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_61250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 74986764.32sec, total: 74986764.32sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 332.12ms, accelerator: 0us, total: 332.12ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.38ms, accelerator: 0us, total: 141.38ms
top 3 graph node: difference, cpu: 97.28ms, accelerator: 0us, total: 97.28ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 74986764.32sec, total: 74986764.32sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.52ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.40ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 1.40ms, total: 6.72ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.12ms, total: 8.77ms
train.py:448:<module>, cpu: 141.38ms, accelerator: 0us, total: 141.38ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_61500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 74683174.18sec, total: 74683174.18sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 331.99ms, accelerator: 0us, total: 331.99ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.43ms, accelerator: 0us, total: 141.43ms
top 3 graph node: difference, cpu: 97.19ms, accelerator: 0us, total: 97.19ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 74683174.18sec, total: 74683174.19sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.55ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.42ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 1.42ms, total: 6.74ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.13ms, total: 8.77ms
train.py:448:<module>, cpu: 141.43ms, accelerator: 0us, total: 141.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_61750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 74382032.34sec, total: 74382032.35sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 332.06ms, accelerator: 0us, total: 332.06ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.50ms, accelerator: 0us, total: 141.50ms
top 3 graph node: difference, cpu: 97.09ms, accelerator: 0us, total: 97.09ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 74382032.35sec, total: 74382032.35sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.57ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.42ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.28ms, accelerator: 1.42ms, total: 6.72ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.15ms, total: 8.80ms
train.py:448:<module>, cpu: 141.50ms, accelerator: 0us, total: 141.50ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_62000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 74083309.32sec, total: 74083309.33sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 331.88ms, accelerator: 0us, total: 331.88ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.53ms, accelerator: 0us, total: 141.53ms
top 3 graph node: difference, cpu: 97.01ms, accelerator: 0us, total: 97.01ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 74083309.33sec, total: 74083309.33sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.57ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.42ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.27ms, accelerator: 1.42ms, total: 6.71ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 5.15ms, total: 8.78ms
train.py:448:<module>, cpu: 141.53ms, accelerator: 0us, total: 141.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_62250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 73786976.09sec, total: 73786976.09sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 331.43ms, accelerator: 0us, total: 331.43ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.33ms, accelerator: 0us, total: 141.33ms
top 3 graph node: difference, cpu: 96.88ms, accelerator: 0us, total: 96.88ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 73786976.09sec, total: 73786976.09sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.53ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.41ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 1.41ms, total: 6.69ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 5.12ms, total: 8.75ms
train.py:448:<module>, cpu: 141.34ms, accelerator: 0us, total: 141.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2026.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_62500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 73493004.07sec, total: 73493004.07sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 331.19ms, accelerator: 0us, total: 331.19ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.29ms, accelerator: 0us, total: 141.29ms
top 3 graph node: difference, cpu: 96.82ms, accelerator: 0us, total: 96.82ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 73493004.07sec, total: 73493004.08sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.53ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.41ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.27ms, accelerator: 1.41ms, total: 6.70ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 5.12ms, total: 8.74ms
train.py:448:<module>, cpu: 141.29ms, accelerator: 0us, total: 141.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_62750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 73201365.16sec, total: 73201365.17sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.90ms, accelerator: 0us, total: 330.90ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.17ms, accelerator: 0us, total: 141.17ms
top 3 graph node: difference, cpu: 96.78ms, accelerator: 0us, total: 96.78ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 73201365.17sec, total: 73201365.17sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.55ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.41ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 1.41ms, total: 6.69ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 5.15ms, total: 8.77ms
train.py:448:<module>, cpu: 141.17ms, accelerator: 0us, total: 141.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_63000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 72912031.71sec, total: 72912031.71sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.74ms, accelerator: 0us, total: 330.74ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.01ms, accelerator: 0us, total: 141.01ms
top 3 graph node: difference, cpu: 96.84ms, accelerator: 0us, total: 96.84ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 72912031.71sec, total: 72912031.71sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.54ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.40ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.24ms, accelerator: 1.40ms, total: 6.66ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 5.13ms, total: 8.75ms
train.py:448:<module>, cpu: 141.02ms, accelerator: 0us, total: 141.02ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2019.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_63250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 72624976.46sec, total: 72624976.46sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.58ms, accelerator: 0us, total: 330.58ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.02ms, accelerator: 0us, total: 141.02ms
top 3 graph node: difference, cpu: 96.81ms, accelerator: 0us, total: 96.81ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 72624976.47sec, total: 72624976.47sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.52ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.40ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 1.40ms, total: 6.65ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 5.12ms, total: 8.72ms
train.py:448:<module>, cpu: 141.03ms, accelerator: 0us, total: 141.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2031.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_63500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 72340172.63sec, total: 72340172.64sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.45ms, accelerator: 0us, total: 330.45ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.94ms, accelerator: 0us, total: 140.94ms
top 3 graph node: difference, cpu: 96.81ms, accelerator: 0us, total: 96.81ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 72340172.64sec, total: 72340172.64sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.50ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.40ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 1.40ms, total: 6.63ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 5.11ms, total: 8.71ms
train.py:448:<module>, cpu: 140.95ms, accelerator: 0us, total: 140.95ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_63750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 72057593.83sec, total: 72057593.84sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 3 operation type: ImageSummary, cpu: 330.13ms, accelerator: 0us, total: 330.13ms (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.82ms, accelerator: 0us, total: 140.82ms
top 3 graph node: difference, cpu: 96.69ms, accelerator: 0us, total: 96.69ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 72057593.84sec, total: 72057593.84sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.48ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.39ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 1.39ms, total: 6.64ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 5.09ms, total: 8.69ms
train.py:448:<module>, cpu: 140.83ms, accelerator: 0us, total: 140.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_64000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 71777214.09sec, total: 71777214.09sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.43ms, accelerator: 71777214.09sec, total: 71777214.09sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.83ms, accelerator: 0us, total: 140.83ms
top 3 graph node: difference, cpu: 96.60ms, accelerator: 0us, total: 96.60ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 143554428.19sec, total: 143554428.19sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.51ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.39ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 1.39ms, total: 6.63ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 5.12ms, total: 8.71ms
train.py:448:<module>, cpu: 140.83ms, accelerator: 0us, total: 140.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_64250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 71499007.84sec, total: 71499007.84sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.43ms, accelerator: 71499007.84sec, total: 71499007.84sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.97ms, accelerator: 0us, total: 140.97ms
top 3 graph node: difference, cpu: 96.45ms, accelerator: 0us, total: 96.45ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 142998015.67sec, total: 142998015.68sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.48ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.38ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.38ms, total: 6.61ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 5.11ms, total: 8.69ms
train.py:448:<module>, cpu: 140.98ms, accelerator: 0us, total: 140.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_64500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 71222949.89sec, total: 71222949.89sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.43ms, accelerator: 71222949.89sec, total: 71222949.89sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.99ms, accelerator: 0us, total: 140.99ms
top 3 graph node: difference, cpu: 96.46ms, accelerator: 0us, total: 96.46ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 142445899.78sec, total: 142445899.79sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.51ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.37ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 1.37ms, total: 6.63ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 5.13ms, total: 8.71ms
train.py:448:<module>, cpu: 140.99ms, accelerator: 0us, total: 140.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_64750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 70949015.47sec, total: 70949015.47sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.42ms, accelerator: 70949015.47sec, total: 70949015.47sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.89ms, accelerator: 0us, total: 140.89ms
top 3 graph node: difference, cpu: 96.54ms, accelerator: 0us, total: 96.54ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 141898030.94sec, total: 141898030.94sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.57ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.37ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 1.37ms, total: 6.64ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 5.20ms, total: 8.81ms
train.py:448:<module>, cpu: 140.90ms, accelerator: 0us, total: 140.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_65000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 70677180.16sec, total: 70677180.16sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.42ms, accelerator: 70677180.16sec, total: 70677180.16sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.96ms, accelerator: 0us, total: 140.96ms
top 3 graph node: difference, cpu: 96.44ms, accelerator: 0us, total: 96.44ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 141354360.32sec, total: 141354360.32sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.54ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.37ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 1.37ms, total: 6.62ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 5.18ms, total: 8.79ms
train.py:448:<module>, cpu: 140.97ms, accelerator: 0us, total: 140.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_65250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 70407419.93sec, total: 70407419.93sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.42ms, accelerator: 70407419.93sec, total: 70407419.93sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.94ms, accelerator: 0us, total: 140.94ms
top 3 graph node: difference, cpu: 96.44ms, accelerator: 0us, total: 96.44ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 140814839.86sec, total: 140814839.87sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.55ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.36ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.27ms, accelerator: 1.36ms, total: 6.66ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 5.19ms, total: 8.79ms
train.py:448:<module>, cpu: 140.95ms, accelerator: 0us, total: 140.95ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_65500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 70139711.11sec, total: 70139711.11sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.42ms, accelerator: 70139711.11sec, total: 70139711.11sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.92ms, accelerator: 0us, total: 140.92ms
top 3 graph node: difference, cpu: 96.46ms, accelerator: 0us, total: 96.46ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 140279422.22sec, total: 140279422.22sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.54ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.36ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.26ms, accelerator: 1.36ms, total: 6.64ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 5.18ms, total: 8.78ms
train.py:448:<module>, cpu: 140.93ms, accelerator: 0us, total: 140.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_65750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 69874030.38sec, total: 69874030.39sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.42ms, accelerator: 69874030.39sec, total: 69874030.39sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.02ms, accelerator: 0us, total: 141.02ms
top 3 graph node: difference, cpu: 96.60ms, accelerator: 0us, total: 96.60ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 139748060.77sec, total: 139748060.78sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.53ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.36ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.29ms, accelerator: 1.36ms, total: 6.67ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 5.18ms, total: 8.77ms
train.py:448:<module>, cpu: 141.02ms, accelerator: 0us, total: 141.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_66000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 69610354.80sec, total: 69610354.80sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.42ms, accelerator: 69610354.80sec, total: 69610354.80sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.90ms, accelerator: 0us, total: 140.90ms
top 3 graph node: difference, cpu: 96.72ms, accelerator: 0us, total: 96.72ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 139220709.60sec, total: 139220709.60sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.50ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.35ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.27ms, accelerator: 1.35ms, total: 6.65ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 5.15ms, total: 8.83ms
train.py:448:<module>, cpu: 140.91ms, accelerator: 0us, total: 140.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_66250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 69348661.74sec, total: 69348661.74sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.42ms, accelerator: 69348661.74sec, total: 69348661.74sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 141.06ms, accelerator: 0us, total: 141.06ms
top 3 graph node: difference, cpu: 96.70ms, accelerator: 0us, total: 96.70ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 138697323.47sec, total: 138697323.48sec
train.py:511:<module>, cpu: 7.91sec, accelerator: 6.55ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.35ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.90sec, accelerator: 0us, total: 7.90sec
    __init__.py:86:allreduce, cpu: 5.26ms, accelerator: 1.35ms, total: 6.64ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.20ms, total: 8.86ms
train.py:448:<module>, cpu: 141.07ms, accelerator: 0us, total: 141.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_66500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 69088928.92sec, total: 69088928.92sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.41ms, accelerator: 69088928.92sec, total: 69088928.92sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.94ms, accelerator: 0us, total: 140.94ms
top 3 graph node: difference, cpu: 96.56ms, accelerator: 0us, total: 96.56ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 138177857.84sec, total: 138177857.85sec
train.py:511:<module>, cpu: 7.91sec, accelerator: 6.54ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.35ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 1.35ms, total: 6.62ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.19ms, total: 8.85ms
train.py:448:<module>, cpu: 140.95ms, accelerator: 0us, total: 140.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_66750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 68831134.41sec, total: 68831134.41sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.42ms, accelerator: 68831134.41sec, total: 68831134.41sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.89ms, accelerator: 0us, total: 140.89ms
top 3 graph node: difference, cpu: 96.65ms, accelerator: 0us, total: 96.65ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 137662268.82sec, total: 137662268.82sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.67ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.42ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 1.42ms, total: 6.68ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.25ms, total: 8.91ms
train.py:448:<module>, cpu: 140.90ms, accelerator: 0us, total: 140.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_67000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 68575256.59sec, total: 68575256.59sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.42ms, accelerator: 68575256.59sec, total: 68575256.59sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.76ms, accelerator: 0us, total: 140.76ms
top 3 graph node: difference, cpu: 96.55ms, accelerator: 0us, total: 96.55ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 137150513.17sec, total: 137150513.18sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.64ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.42ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.25ms, accelerator: 1.42ms, total: 6.68ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.23ms, total: 8.89ms
train.py:448:<module>, cpu: 140.76ms, accelerator: 0us, total: 140.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_67250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 68321274.15sec, total: 68321274.16sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.42ms, accelerator: 68321274.15sec, total: 68321274.16sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.64ms, accelerator: 0us, total: 140.64ms
top 3 graph node: difference, cpu: 96.42ms, accelerator: 0us, total: 96.42ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 136642548.31sec, total: 136642548.31sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.62ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.41ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.24ms, accelerator: 1.41ms, total: 6.67ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.21ms, total: 8.86ms
train.py:448:<module>, cpu: 140.65ms, accelerator: 0us, total: 140.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_67500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.41ms, accelerator: 68069166.13sec, total: 68069166.13sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 68069166.13sec, total: 68069166.13sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.66ms, accelerator: 0us, total: 140.66ms
top 3 graph node: difference, cpu: 96.36ms, accelerator: 0us, total: 96.36ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 136138332.26sec, total: 136138332.27sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.65ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.41ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.23ms, accelerator: 1.41ms, total: 6.67ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.24ms, total: 8.90ms
train.py:448:<module>, cpu: 140.67ms, accelerator: 0us, total: 140.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_67750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.41ms, accelerator: 67818911.84sec, total: 67818911.85sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 67818911.84sec, total: 67818911.85sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.61ms, accelerator: 0us, total: 140.61ms
top 3 graph node: difference, cpu: 96.33ms, accelerator: 0us, total: 96.33ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 135637823.69sec, total: 135637823.69sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.67ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.41ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 1.41ms, total: 6.66ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.26ms, total: 8.91ms
train.py:448:<module>, cpu: 140.61ms, accelerator: 0us, total: 140.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_68000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.41ms, accelerator: 67570490.92sec, total: 67570490.92sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 67570490.92sec, total: 67570490.92sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.61ms, accelerator: 0us, total: 140.61ms
top 3 graph node: difference, cpu: 96.53ms, accelerator: 0us, total: 96.53ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 135140981.85sec, total: 135140981.85sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.66ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.40ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.22ms, accelerator: 1.40ms, total: 6.64ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.25ms, total: 8.89ms
train.py:448:<module>, cpu: 140.62ms, accelerator: 0us, total: 140.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_68250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.41ms, accelerator: 67323883.29sec, total: 67323883.29sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 67323883.29sec, total: 67323883.29sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.71ms, accelerator: 0us, total: 140.71ms
top 3 graph node: difference, cpu: 96.46ms, accelerator: 0us, total: 96.46ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 134647766.58sec, total: 134647766.59sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.70ms, total: 7.92sec
  __init__.py:194:compute_gradients, cpu: 7.91sec, accelerator: 1.40ms, total: 7.91sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.20ms, accelerator: 1.40ms, total: 6.62ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.30ms, total: 8.96ms
train.py:448:<module>, cpu: 140.71ms, accelerator: 0us, total: 140.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_68500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.41ms, accelerator: 67079069.17sec, total: 67079069.17sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 67079069.17sec, total: 67079069.17sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.82ms, accelerator: 0us, total: 140.82ms
top 3 graph node: difference, cpu: 96.57ms, accelerator: 0us, total: 96.57ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 134158138.34sec, total: 134158138.35sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.68ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.40ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 1.40ms, total: 6.61ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.28ms, total: 8.93ms
train.py:448:<module>, cpu: 140.82ms, accelerator: 0us, total: 140.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_68750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.41ms, accelerator: 66836029.06sec, total: 66836029.07sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 66836029.06sec, total: 66836029.07sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.74ms, accelerator: 0us, total: 140.74ms
top 3 graph node: difference, cpu: 96.57ms, accelerator: 0us, total: 96.57ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 133672058.13sec, total: 133672058.13sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.65ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.39ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 1.39ms, total: 6.59ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.26ms, total: 8.92ms
train.py:448:<module>, cpu: 140.74ms, accelerator: 0us, total: 140.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_69000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.41ms, accelerator: 66594743.76sec, total: 66594743.76sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 66594743.76sec, total: 66594743.76sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.75ms, accelerator: 0us, total: 140.75ms
top 3 graph node: difference, cpu: 96.50ms, accelerator: 0us, total: 96.50ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 133189487.52sec, total: 133189487.53sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.68ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.39ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 1.39ms, total: 6.61ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.29ms, total: 8.94ms
train.py:448:<module>, cpu: 140.76ms, accelerator: 0us, total: 140.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_69250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.40ms, accelerator: 66355194.32sec, total: 66355194.32sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 66355194.32sec, total: 66355194.32sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.79ms, accelerator: 0us, total: 140.79ms
top 3 graph node: difference, cpu: 96.45ms, accelerator: 0us, total: 96.45ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 132710388.65sec, total: 132710388.65sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.66ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.38ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 1.38ms, total: 6.59ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.28ms, total: 8.92ms
train.py:448:<module>, cpu: 140.80ms, accelerator: 0us, total: 140.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_69500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.40ms, accelerator: 66117362.09sec, total: 66117362.09sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 66117362.08sec, total: 66117362.09sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.72ms, accelerator: 0us, total: 140.72ms
top 3 graph node: difference, cpu: 96.33ms, accelerator: 0us, total: 96.33ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 132234724.17sec, total: 132234724.18sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.68ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.38ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 1.38ms, total: 6.58ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.30ms, total: 8.97ms
train.py:448:<module>, cpu: 140.72ms, accelerator: 0us, total: 140.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_69750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.40ms, accelerator: 65881228.65sec, total: 65881228.65sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 65881228.65sec, total: 65881228.65sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.75ms, accelerator: 0us, total: 140.75ms
top 3 graph node: difference, cpu: 96.33ms, accelerator: 0us, total: 96.33ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 131762457.30sec, total: 131762457.30sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.66ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.38ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 1.38ms, total: 6.61ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.29ms, total: 8.95ms
train.py:448:<module>, cpu: 140.76ms, accelerator: 0us, total: 140.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_70000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.40ms, accelerator: 65646775.88sec, total: 65646775.88sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 65646775.88sec, total: 65646775.88sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.70ms, accelerator: 0us, total: 140.70ms
top 3 graph node: difference, cpu: 96.19ms, accelerator: 0us, total: 96.19ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 131293551.76sec, total: 131293551.76sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.67ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.37ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 1.37ms, total: 6.61ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.30ms, total: 8.96ms
train.py:448:<module>, cpu: 140.70ms, accelerator: 0us, total: 140.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2038.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_70250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.40ms, accelerator: 65413985.89sec, total: 65413985.89sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 65413985.89sec, total: 65413985.89sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.57ms, accelerator: 0us, total: 140.57ms
top 3 graph node: difference, cpu: 96.15ms, accelerator: 0us, total: 96.15ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 130827971.79sec, total: 130827971.79sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.66ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.37ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 1.37ms, total: 6.59ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.29ms, total: 8.94ms
train.py:448:<module>, cpu: 140.58ms, accelerator: 0us, total: 140.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_70500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.40ms, accelerator: 65182841.07sec, total: 65182841.07sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 65182841.07sec, total: 65182841.07sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.64ms, accelerator: 0us, total: 140.64ms
top 3 graph node: difference, cpu: 96.02ms, accelerator: 0us, total: 96.02ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 130365682.13sec, total: 130365682.14sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.66ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.36ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.21ms, accelerator: 1.36ms, total: 6.60ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.29ms, total: 8.94ms
train.py:448:<module>, cpu: 140.65ms, accelerator: 0us, total: 140.65ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_70750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.40ms, accelerator: 64953324.02sec, total: 64953324.02sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 64953324.02sec, total: 64953324.02sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.48ms, accelerator: 0us, total: 140.48ms
top 3 graph node: difference, cpu: 95.84ms, accelerator: 0us, total: 95.84ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 129906648.04sec, total: 129906648.05sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.64ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.36ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 1.36ms, total: 6.58ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.29ms, total: 8.92ms
train.py:448:<module>, cpu: 140.49ms, accelerator: 0us, total: 140.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_71000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.40ms, accelerator: 64725417.62sec, total: 64725417.62sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 64725417.62sec, total: 64725417.62sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.37ms, accelerator: 0us, total: 140.37ms
top 3 graph node: difference, cpu: 95.83ms, accelerator: 0us, total: 95.83ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 129450835.24sec, total: 129450835.25sec
train.py:511:<module>, cpu: 7.92sec, accelerator: 6.63ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.36ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.91sec, accelerator: 0us, total: 7.91sec
    __init__.py:86:allreduce, cpu: 5.19ms, accelerator: 1.36ms, total: 6.57ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.27ms, total: 8.91ms
train.py:448:<module>, cpu: 140.38ms, accelerator: 0us, total: 140.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_71250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.39ms, accelerator: 64499104.97sec, total: 64499104.97sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 64499104.97sec, total: 64499104.97sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.35ms, accelerator: 0us, total: 140.35ms
top 3 graph node: difference, cpu: 95.78ms, accelerator: 0us, total: 95.78ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 128998209.94sec, total: 128998209.95sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.62ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.36ms, total: 7.92sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.18ms, accelerator: 1.36ms, total: 6.56ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 5.26ms, total: 8.93ms
train.py:448:<module>, cpu: 140.35ms, accelerator: 0us, total: 140.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_71500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.39ms, accelerator: 64274369.41sec, total: 64274369.42sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 64274369.41sec, total: 64274369.42sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.29ms, accelerator: 0us, total: 140.29ms
top 3 graph node: difference, cpu: 95.82ms, accelerator: 0us, total: 95.82ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 128548738.83sec, total: 128548738.83sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.61ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.35ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 1.35ms, total: 6.54ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.25ms, total: 8.91ms
train.py:448:<module>, cpu: 140.29ms, accelerator: 0us, total: 140.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_71750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.39ms, accelerator: 64051194.52sec, total: 64051194.52sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 64051194.52sec, total: 64051194.52sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.15ms, accelerator: 0us, total: 140.15ms
top 3 graph node: difference, cpu: 95.76ms, accelerator: 0us, total: 95.76ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 128102389.04sec, total: 128102389.05sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.59ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.35ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 1.35ms, total: 6.53ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.24ms, total: 8.89ms
train.py:448:<module>, cpu: 140.16ms, accelerator: 0us, total: 140.16ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_72000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.39ms, accelerator: 63829564.09sec, total: 63829564.09sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 63829564.09sec, total: 63829564.09sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.05ms, accelerator: 0us, total: 140.05ms
top 3 graph node: difference, cpu: 95.69ms, accelerator: 0us, total: 95.69ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 127659128.18sec, total: 127659128.18sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.57ms, total: 7.93sec
  __init__.py:194:compute_gradients, cpu: 7.92sec, accelerator: 1.35ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 1.35ms, total: 6.52ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.22ms, total: 8.87ms
train.py:448:<module>, cpu: 140.06ms, accelerator: 0us, total: 140.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_72250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.39ms, accelerator: 63609462.14sec, total: 63609462.15sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 63609462.14sec, total: 63609462.15sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.09ms, accelerator: 0us, total: 140.09ms
top 3 graph node: difference, cpu: 95.61ms, accelerator: 0us, total: 95.61ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 127218924.29sec, total: 127218924.29sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.54ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.34ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.17ms, accelerator: 1.34ms, total: 6.54ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.20ms, total: 8.85ms
train.py:448:<module>, cpu: 140.10ms, accelerator: 0us, total: 140.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_72500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.39ms, accelerator: 63390872.93sec, total: 63390872.93sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 63390872.93sec, total: 63390872.93sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.16ms, accelerator: 0us, total: 140.16ms
top 3 graph node: difference, cpu: 95.69ms, accelerator: 0us, total: 95.69ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 126781745.86sec, total: 126781745.86sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.53ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.34ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 1.34ms, total: 6.52ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.19ms, total: 8.83ms
train.py:448:<module>, cpu: 140.16ms, accelerator: 0us, total: 140.16ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_72750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.39ms, accelerator: 63173780.90sec, total: 63173780.90sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 63173780.90sec, total: 63173780.90sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 140.02ms, accelerator: 0us, total: 140.02ms
top 3 graph node: difference, cpu: 95.69ms, accelerator: 0us, total: 95.69ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 126347561.79sec, total: 126347561.80sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.51ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.34ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.34ms, total: 6.51ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.17ms, total: 8.83ms
train.py:448:<module>, cpu: 140.02ms, accelerator: 0us, total: 140.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_73000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.39ms, accelerator: 62958170.72sec, total: 62958170.72sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 62958170.72sec, total: 62958170.72sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.98ms, accelerator: 0us, total: 139.98ms
top 3 graph node: difference, cpu: 95.61ms, accelerator: 0us, total: 95.61ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 125916341.45sec, total: 125916341.45sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.56ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.35ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 1.35ms, total: 6.52ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.20ms, total: 8.86ms
train.py:448:<module>, cpu: 139.98ms, accelerator: 0us, total: 139.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_73250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.39ms, accelerator: 62744027.29sec, total: 62744027.29sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 62744027.28sec, total: 62744027.29sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.96ms, accelerator: 0us, total: 139.96ms
top 3 graph node: difference, cpu: 95.52ms, accelerator: 0us, total: 95.52ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 125488054.57sec, total: 125488054.58sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.56ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.36ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.36ms, total: 6.53ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 5.20ms, total: 8.87ms
train.py:448:<module>, cpu: 139.96ms, accelerator: 0us, total: 139.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_73500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.39ms, accelerator: 62531335.67sec, total: 62531335.67sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 62531335.67sec, total: 62531335.67sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.88ms, accelerator: 0us, total: 139.88ms
top 3 graph node: difference, cpu: 95.55ms, accelerator: 0us, total: 95.55ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 125062671.34sec, total: 125062671.34sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.54ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.35ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.13ms, accelerator: 1.35ms, total: 6.51ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.19ms, total: 8.85ms
train.py:448:<module>, cpu: 139.89ms, accelerator: 0us, total: 139.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_73750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 62320081.15sec, total: 62320081.16sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 62320081.15sec, total: 62320081.16sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.88ms, accelerator: 0us, total: 139.88ms
top 3 graph node: difference, cpu: 95.40ms, accelerator: 0us, total: 95.40ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 124640162.31sec, total: 124640162.31sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.52ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.35ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.12ms, accelerator: 1.35ms, total: 6.50ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.17ms, total: 8.82ms
train.py:448:<module>, cpu: 139.88ms, accelerator: 0us, total: 139.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_74000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 62110249.23sec, total: 62110249.23sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 62110249.23sec, total: 62110249.23sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.97ms, accelerator: 0us, total: 139.97ms
top 3 graph node: difference, cpu: 95.35ms, accelerator: 0us, total: 95.35ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 124220498.46sec, total: 124220498.47sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.50ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.35ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.16ms, accelerator: 1.35ms, total: 6.54ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.16ms, total: 8.82ms
train.py:448:<module>, cpu: 139.98ms, accelerator: 0us, total: 139.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_74250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 61901825.58sec, total: 61901825.58sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 61901825.58sec, total: 61901825.58sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.87ms, accelerator: 0us, total: 139.87ms
top 3 graph node: difference, cpu: 95.28ms, accelerator: 0us, total: 95.28ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 123803651.15sec, total: 123803651.16sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.49ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.34ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 1.34ms, total: 6.52ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.14ms, total: 8.81ms
train.py:448:<module>, cpu: 139.88ms, accelerator: 0us, total: 139.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_74500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 61694796.06sec, total: 61694796.06sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 61694796.06sec, total: 61694796.06sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.92ms, accelerator: 0us, total: 139.92ms
top 3 graph node: difference, cpu: 95.34ms, accelerator: 0us, total: 95.34ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 123389592.12sec, total: 123389592.12sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.47ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.34ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.34ms, total: 6.50ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.13ms, total: 8.79ms
train.py:448:<module>, cpu: 139.92ms, accelerator: 0us, total: 139.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_74750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 61489146.74sec, total: 61489146.74sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 61489146.74sec, total: 61489146.74sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.96ms, accelerator: 0us, total: 139.96ms
top 3 graph node: difference, cpu: 95.27ms, accelerator: 0us, total: 95.27ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 122978293.48sec, total: 122978293.48sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.45ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.34ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.15ms, accelerator: 1.34ms, total: 6.51ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.12ms, total: 8.77ms
train.py:448:<module>, cpu: 139.97ms, accelerator: 0us, total: 139.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_75000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 61284863.86sec, total: 61284863.86sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 61284863.86sec, total: 61284863.86sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.84ms, accelerator: 0us, total: 139.84ms
top 3 graph node: difference, cpu: 95.28ms, accelerator: 0us, total: 95.28ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 122569727.72sec, total: 122569727.72sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.43ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.34ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.34ms, total: 6.50ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.10ms, total: 8.75ms
train.py:448:<module>, cpu: 139.85ms, accelerator: 0us, total: 139.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_75250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 61081933.85sec, total: 61081933.85sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 61081933.85sec, total: 61081933.85sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.77ms, accelerator: 0us, total: 139.77ms
top 3 graph node: difference, cpu: 95.19ms, accelerator: 0us, total: 95.19ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 122163867.70sec, total: 122163867.70sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.42ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.34ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 5.13ms, accelerator: 1.34ms, total: 6.49ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.09ms, total: 8.73ms
train.py:448:<module>, cpu: 139.78ms, accelerator: 0us, total: 139.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2040.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_75500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 60880343.31sec, total: 60880343.31sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 60880343.31sec, total: 60880343.31sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.67ms, accelerator: 0us, total: 139.67ms
top 3 graph node: difference, cpu: 95.25ms, accelerator: 0us, total: 95.25ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 121760686.61sec, total: 121760686.62sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.46ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.33ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.33ms, total: 6.50ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.13ms, total: 8.77ms
train.py:448:<module>, cpu: 139.67ms, accelerator: 0us, total: 139.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_75750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 60680079.02sec, total: 60680079.02sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 60680079.02sec, total: 60680079.02sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.59ms, accelerator: 0us, total: 139.59ms
top 3 graph node: difference, cpu: 95.24ms, accelerator: 0us, total: 95.24ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 121360158.04sec, total: 121360158.04sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.50ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.38ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.14ms, accelerator: 1.38ms, total: 6.55ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.12ms, total: 8.76ms
train.py:448:<module>, cpu: 139.60ms, accelerator: 0us, total: 139.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_76000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 60481127.94sec, total: 60481127.94sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 60481127.94sec, total: 60481127.94sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.53ms, accelerator: 0us, total: 139.53ms
top 3 graph node: difference, cpu: 95.23ms, accelerator: 0us, total: 95.23ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 120962255.88sec, total: 120962255.89sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.56ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.37ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.13ms, accelerator: 1.37ms, total: 6.53ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.19ms, total: 8.82ms
train.py:448:<module>, cpu: 139.54ms, accelerator: 0us, total: 139.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_76250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 60283477.20sec, total: 60283477.20sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 60283477.19sec, total: 60283477.20sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.51ms, accelerator: 0us, total: 139.51ms
top 3 graph node: difference, cpu: 95.29ms, accelerator: 0us, total: 95.29ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 120566954.39sec, total: 120566954.40sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.54ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.37ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.12ms, accelerator: 1.37ms, total: 6.52ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 5.18ms, total: 8.79ms
train.py:448:<module>, cpu: 139.52ms, accelerator: 0us, total: 139.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2034.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_76500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 60087114.08sec, total: 60087114.08sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 60087114.08sec, total: 60087114.08sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.45ms, accelerator: 0us, total: 139.45ms
top 3 graph node: difference, cpu: 95.17ms, accelerator: 0us, total: 95.17ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 120174228.16sec, total: 120174228.16sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.52ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.36ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.12ms, accelerator: 1.36ms, total: 6.50ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 5.16ms, total: 8.78ms
train.py:448:<module>, cpu: 139.45ms, accelerator: 0us, total: 139.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_76750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 59892026.05sec, total: 59892026.05sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 59892026.04sec, total: 59892026.05sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.30ms, accelerator: 0us, total: 139.30ms
top 3 graph node: difference, cpu: 95.18ms, accelerator: 0us, total: 95.18ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 119784052.09sec, total: 119784052.09sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.50ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.36ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.10ms, accelerator: 1.36ms, total: 6.49ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.14ms, total: 8.78ms
train.py:448:<module>, cpu: 139.31ms, accelerator: 0us, total: 139.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_77000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 59698200.72sec, total: 59698200.72sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 59698200.72sec, total: 59698200.72sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.18ms, accelerator: 0us, total: 139.18ms
top 3 graph node: difference, cpu: 95.22ms, accelerator: 0us, total: 95.22ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 119396401.44sec, total: 119396401.44sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.49ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.36ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.09ms, accelerator: 1.36ms, total: 6.47ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 5.13ms, total: 8.76ms
train.py:448:<module>, cpu: 139.19ms, accelerator: 0us, total: 139.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_77250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 59505625.88sec, total: 59505625.88sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 59505625.88sec, total: 59505625.88sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.04ms, accelerator: 0us, total: 139.04ms
top 3 graph node: difference, cpu: 95.10ms, accelerator: 0us, total: 95.10ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 119011251.75sec, total: 119011251.76sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.46ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.35ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.08ms, accelerator: 1.35ms, total: 6.46ms
  __init__.py:185:compute_gradients, cpu: 3.59ms, accelerator: 5.11ms, total: 8.74ms
train.py:448:<module>, cpu: 139.04ms, accelerator: 0us, total: 139.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_77500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 59314289.46sec, total: 59314289.46sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 59314289.46sec, total: 59314289.46sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.06ms, accelerator: 0us, total: 139.06ms
top 3 graph node: difference, cpu: 95.02ms, accelerator: 0us, total: 95.02ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 118628578.92sec, total: 118628578.92sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.45ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.35ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.09ms, accelerator: 1.35ms, total: 6.46ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 5.10ms, total: 8.72ms
train.py:448:<module>, cpu: 139.06ms, accelerator: 0us, total: 139.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_77750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 59124179.56sec, total: 59124179.56sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 59124179.56sec, total: 59124179.56sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.08ms, accelerator: 0us, total: 139.08ms
top 3 graph node: difference, cpu: 95.00ms, accelerator: 0us, total: 95.00ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 118248359.12sec, total: 118248359.12sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.43ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.35ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.08ms, accelerator: 1.35ms, total: 6.46ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 5.09ms, total: 8.71ms
train.py:448:<module>, cpu: 139.09ms, accelerator: 0us, total: 139.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_78000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 58935284.41sec, total: 58935284.42sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 58935284.41sec, total: 58935284.42sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 139.03ms, accelerator: 0us, total: 139.03ms
top 3 graph node: difference, cpu: 94.97ms, accelerator: 0us, total: 94.97ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 117870568.83sec, total: 117870568.83sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.42ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.34ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.07ms, accelerator: 1.34ms, total: 6.43ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 5.08ms, total: 8.69ms
train.py:448:<module>, cpu: 139.03ms, accelerator: 0us, total: 139.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_78250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 58747592.43sec, total: 58747592.43sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 58747592.43sec, total: 58747592.43sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.93ms, accelerator: 0us, total: 138.93ms
top 3 graph node: difference, cpu: 95.02ms, accelerator: 0us, total: 95.02ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 117495184.85sec, total: 117495184.86sec
train.py:511:<module>, cpu: 7.93sec, accelerator: 6.40ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.34ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.92sec, accelerator: 0us, total: 7.92sec
    __init__.py:86:allreduce, cpu: 5.06ms, accelerator: 1.34ms, total: 6.43ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 5.06ms, total: 8.67ms
train.py:448:<module>, cpu: 138.94ms, accelerator: 0us, total: 138.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2029.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_78500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 58561092.13sec, total: 58561092.13sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 58561092.13sec, total: 58561092.13sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.82ms, accelerator: 0us, total: 138.82ms
top 3 graph node: difference, cpu: 94.94ms, accelerator: 0us, total: 94.94ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 117122184.27sec, total: 117122184.27sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.38ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.33ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 1.33ms, total: 6.41ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 5.05ms, total: 8.66ms
train.py:448:<module>, cpu: 138.82ms, accelerator: 0us, total: 138.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_78750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 58375772.22sec, total: 58375772.22sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 58375772.22sec, total: 58375772.22sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.83ms, accelerator: 0us, total: 138.83ms
top 3 graph node: difference, cpu: 94.88ms, accelerator: 0us, total: 94.88ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 116751544.44sec, total: 116751544.45sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.36ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.33ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.04ms, accelerator: 1.33ms, total: 6.40ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 5.03ms, total: 8.64ms
train.py:448:<module>, cpu: 138.84ms, accelerator: 0us, total: 138.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_79000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 58191621.52sec, total: 58191621.52sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 58191621.52sec, total: 58191621.52sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.75ms, accelerator: 0us, total: 138.75ms
top 3 graph node: difference, cpu: 94.82ms, accelerator: 0us, total: 94.82ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 116383243.04sec, total: 116383243.05sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.35ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.33ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.03ms, accelerator: 1.33ms, total: 6.38ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 5.02ms, total: 8.62ms
train.py:448:<module>, cpu: 138.76ms, accelerator: 0us, total: 138.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2032.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_79250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 58008629.00sec, total: 58008629.00sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 58008629.00sec, total: 58008629.00sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.70ms, accelerator: 0us, total: 138.70ms
top 3 graph node: difference, cpu: 94.77ms, accelerator: 0us, total: 94.77ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 116017258.00sec, total: 116017258.00sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.33ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.33ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.03ms, accelerator: 1.33ms, total: 6.38ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 5.01ms, total: 8.60ms
train.py:448:<module>, cpu: 138.71ms, accelerator: 0us, total: 138.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_79500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 57826783.77sec, total: 57826783.77sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 57826783.77sec, total: 57826783.77sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.72ms, accelerator: 0us, total: 138.72ms
top 3 graph node: difference, cpu: 94.62ms, accelerator: 0us, total: 94.62ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 115653567.54sec, total: 115653567.54sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.31ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.32ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.02ms, accelerator: 1.32ms, total: 6.37ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.99ms, total: 8.59ms
train.py:448:<module>, cpu: 138.73ms, accelerator: 0us, total: 138.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_79750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 57646075.07sec, total: 57646075.07sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 57646075.07sec, total: 57646075.07sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.67ms, accelerator: 0us, total: 138.67ms
top 3 graph node: difference, cpu: 94.52ms, accelerator: 0us, total: 94.52ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 115292150.14sec, total: 115292150.14sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.31ms, total: 7.94sec
  __init__.py:194:compute_gradients, cpu: 7.93sec, accelerator: 1.32ms, total: 7.93sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 1.32ms, total: 6.36ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.99ms, total: 8.59ms
train.py:448:<module>, cpu: 138.67ms, accelerator: 0us, total: 138.67ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2038.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_80000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 57466492.28sec, total: 57466492.28sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 57466492.28sec, total: 57466492.28sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.63ms, accelerator: 0us, total: 138.63ms
top 3 graph node: difference, cpu: 94.37ms, accelerator: 0us, total: 94.37ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 114932984.56sec, total: 114932984.57sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.29ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.32ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 1.32ms, total: 6.34ms
  __init__.py:185:compute_gradients, cpu: 3.58ms, accelerator: 4.98ms, total: 8.59ms
train.py:448:<module>, cpu: 138.64ms, accelerator: 0us, total: 138.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_80250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 57288024.91sec, total: 57288024.91sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 57288024.91sec, total: 57288024.91sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.64ms, accelerator: 0us, total: 138.64ms
top 3 graph node: difference, cpu: 94.36ms, accelerator: 0us, total: 94.36ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 114576049.83sec, total: 114576049.83sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.28ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.31ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.93sec, accelerator: 0us, total: 7.93sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 1.31ms, total: 6.33ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 4.96ms, total: 8.57ms
train.py:448:<module>, cpu: 138.65ms, accelerator: 0us, total: 138.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_80500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 57110662.61sec, total: 57110662.61sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 57110662.61sec, total: 57110662.61sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.57ms, accelerator: 0us, total: 138.57ms
top 3 graph node: difference, cpu: 94.34ms, accelerator: 0us, total: 94.34ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 114221325.21sec, total: 114221325.22sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.30ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.31ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 1.31ms, total: 6.33ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 4.98ms, total: 8.59ms
train.py:448:<module>, cpu: 138.57ms, accelerator: 0us, total: 138.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_80750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 56934395.13sec, total: 56934395.13sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 56934395.13sec, total: 56934395.13sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.57ms, accelerator: 0us, total: 138.57ms
top 3 graph node: difference, cpu: 94.33ms, accelerator: 0us, total: 94.33ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 113868790.26sec, total: 113868790.26sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.32ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.31ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 1.31ms, total: 6.35ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 5.00ms, total: 8.61ms
train.py:448:<module>, cpu: 138.58ms, accelerator: 0us, total: 138.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_81000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 56759212.38sec, total: 56759212.38sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 56759212.37sec, total: 56759212.38sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.59ms, accelerator: 0us, total: 138.59ms
top 3 graph node: difference, cpu: 94.27ms, accelerator: 0us, total: 94.27ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 113518424.75sec, total: 113518424.76sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.35ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.31ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 1.31ms, total: 6.33ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 5.04ms, total: 8.63ms
train.py:448:<module>, cpu: 138.59ms, accelerator: 0us, total: 138.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_81250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 56585104.36sec, total: 56585104.36sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 56585104.36sec, total: 56585104.36sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.68ms, accelerator: 0us, total: 138.68ms
top 3 graph node: difference, cpu: 94.29ms, accelerator: 0us, total: 94.29ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 113170208.72sec, total: 113170208.73sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.33ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.31ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 1.31ms, total: 6.32ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 5.02ms, total: 8.62ms
train.py:448:<module>, cpu: 138.69ms, accelerator: 0us, total: 138.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_81500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 56412061.23sec, total: 56412061.23sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 56412061.23sec, total: 56412061.23sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.58ms, accelerator: 0us, total: 138.58ms
top 3 graph node: difference, cpu: 94.21ms, accelerator: 0us, total: 94.21ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 112824122.46sec, total: 112824122.46sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.31ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.31ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 1.31ms, total: 6.31ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 5.00ms, total: 8.60ms
train.py:448:<module>, cpu: 138.58ms, accelerator: 0us, total: 138.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_81750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 56240073.24sec, total: 56240073.24sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 56240073.24sec, total: 56240073.24sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.52ms, accelerator: 0us, total: 138.52ms
top 3 graph node: difference, cpu: 94.25ms, accelerator: 0us, total: 94.25ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 112480146.48sec, total: 112480146.48sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.30ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.30ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.97ms, accelerator: 1.30ms, total: 6.30ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.99ms, total: 8.60ms
train.py:448:<module>, cpu: 138.53ms, accelerator: 0us, total: 138.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_82000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 56069130.77sec, total: 56069130.77sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 56069130.76sec, total: 56069130.77sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.40ms, accelerator: 0us, total: 138.40ms
top 3 graph node: difference, cpu: 94.28ms, accelerator: 0us, total: 94.28ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 112138261.53sec, total: 112138261.54sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.28ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.30ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.97ms, accelerator: 1.30ms, total: 6.30ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.98ms, total: 8.58ms
train.py:448:<module>, cpu: 138.41ms, accelerator: 0us, total: 138.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_82250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 55899224.31sec, total: 55899224.31sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 55899224.31sec, total: 55899224.31sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.32ms, accelerator: 0us, total: 138.32ms
top 3 graph node: difference, cpu: 94.16ms, accelerator: 0us, total: 94.16ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 111798448.62sec, total: 111798448.62sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.26ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.29ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 1.29ms, total: 6.31ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.97ms, total: 8.56ms
train.py:448:<module>, cpu: 138.33ms, accelerator: 0us, total: 138.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_82500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 55730344.48sec, total: 55730344.48sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 55730344.48sec, total: 55730344.48sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.21ms, accelerator: 0us, total: 138.21ms
top 3 graph node: difference, cpu: 94.09ms, accelerator: 0us, total: 94.09ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 111460688.96sec, total: 111460688.96sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.25ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.29ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 1.29ms, total: 6.30ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.96ms, total: 8.55ms
train.py:448:<module>, cpu: 138.21ms, accelerator: 0us, total: 138.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_82750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 55562481.99sec, total: 55562482.00sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 55562481.99sec, total: 55562481.99sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.28ms, accelerator: 0us, total: 138.28ms
top 3 graph node: difference, cpu: 94.02ms, accelerator: 0us, total: 94.02ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 111124963.99sec, total: 111124963.99sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.23ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.29ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.97ms, accelerator: 1.29ms, total: 6.28ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.94ms, total: 8.53ms
train.py:448:<module>, cpu: 138.29ms, accelerator: 0us, total: 138.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_83000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 55395627.69sec, total: 55395627.69sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 55395627.69sec, total: 55395627.69sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.23ms, accelerator: 0us, total: 138.23ms
top 3 graph node: difference, cpu: 93.92ms, accelerator: 0us, total: 93.92ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 110791255.39sec, total: 110791255.39sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.30ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.28ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 1.28ms, total: 6.28ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 5.01ms, total: 8.59ms
train.py:448:<module>, cpu: 138.24ms, accelerator: 0us, total: 138.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_83250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 55229772.52sec, total: 55229772.52sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 55229772.52sec, total: 55229772.52sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.19ms, accelerator: 0us, total: 138.19ms
top 3 graph node: difference, cpu: 93.92ms, accelerator: 0us, total: 93.92ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 110459545.04sec, total: 110459545.05sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.28ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.28ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 1.28ms, total: 6.27ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 5.00ms, total: 8.58ms
train.py:448:<module>, cpu: 138.19ms, accelerator: 0us, total: 138.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_83500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 55064907.53sec, total: 55064907.53sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 55064907.53sec, total: 55064907.53sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.31ms, accelerator: 0us, total: 138.31ms
top 3 graph node: difference, cpu: 94.03ms, accelerator: 0us, total: 94.03ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 110129815.06sec, total: 110129815.06sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.27ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.28ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 1.28ms, total: 6.26ms
  __init__.py:185:compute_gradients, cpu: 3.53ms, accelerator: 4.99ms, total: 8.56ms
train.py:448:<module>, cpu: 138.31ms, accelerator: 0us, total: 138.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_83750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 54901023.87sec, total: 54901023.88sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 54901023.87sec, total: 54901023.88sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.38ms, accelerator: 0us, total: 138.38ms
top 3 graph node: difference, cpu: 94.11ms, accelerator: 0us, total: 94.11ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 109802047.75sec, total: 109802047.75sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.26ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.28ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 1.28ms, total: 6.27ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.98ms, total: 8.56ms
train.py:448:<module>, cpu: 138.39ms, accelerator: 0us, total: 138.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_84000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 54738112.82sec, total: 54738112.83sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 54738112.82sec, total: 54738112.83sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.47ms, accelerator: 0us, total: 138.47ms
top 3 graph node: difference, cpu: 94.19ms, accelerator: 0us, total: 94.19ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 109476225.65sec, total: 109476225.65sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.24ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.27ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.96ms, accelerator: 1.27ms, total: 6.26ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.97ms, total: 8.56ms
train.py:448:<module>, cpu: 138.47ms, accelerator: 0us, total: 138.47ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2034.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_84250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 54576165.75sec, total: 54576165.75sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 54576165.74sec, total: 54576165.75sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.54ms, accelerator: 0us, total: 138.54ms
top 3 graph node: difference, cpu: 94.27ms, accelerator: 0us, total: 94.27ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 109152331.49sec, total: 109152331.50sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.22ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.27ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.95ms, accelerator: 1.27ms, total: 6.24ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.95ms, total: 8.54ms
train.py:448:<module>, cpu: 138.55ms, accelerator: 0us, total: 138.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_84500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 54415174.11sec, total: 54415174.11sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 54415174.11sec, total: 54415174.11sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.53ms, accelerator: 0us, total: 138.53ms
top 3 graph node: difference, cpu: 94.15ms, accelerator: 0us, total: 94.15ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 108830348.21sec, total: 108830348.22sec
train.py:511:<module>, cpu: 7.94sec, accelerator: 6.30ms, total: 7.95sec
  __init__.py:194:compute_gradients, cpu: 7.94sec, accelerator: 1.28ms, total: 7.94sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 1.28ms, total: 6.25ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 5.01ms, total: 8.60ms
train.py:448:<module>, cpu: 138.54ms, accelerator: 0us, total: 138.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_84750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 54255129.48sec, total: 54255129.48sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 54255129.48sec, total: 54255129.48sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.44ms, accelerator: 0us, total: 138.44ms
top 3 graph node: difference, cpu: 94.06ms, accelerator: 0us, total: 94.06ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 108510258.95sec, total: 108510258.96sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.29ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.28ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 1.28ms, total: 6.24ms
  __init__.py:185:compute_gradients, cpu: 3.57ms, accelerator: 5.00ms, total: 8.61ms
train.py:448:<module>, cpu: 138.45ms, accelerator: 0us, total: 138.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_85000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 54096023.52sec, total: 54096023.53sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 54096023.52sec, total: 54096023.53sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.46ms, accelerator: 0us, total: 138.46ms
top 3 graph node: difference, cpu: 94.10ms, accelerator: 0us, total: 94.10ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 108192047.05sec, total: 108192047.05sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.27ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.28ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.94sec, accelerator: 0us, total: 7.94sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 1.28ms, total: 6.24ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.99ms, total: 8.59ms
train.py:448:<module>, cpu: 138.47ms, accelerator: 0us, total: 138.47ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2023.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_85250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 53937848.02sec, total: 53937848.02sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 53937848.02sec, total: 53937848.02sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.55ms, accelerator: 0us, total: 138.55ms
top 3 graph node: difference, cpu: 94.09ms, accelerator: 0us, total: 94.09ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 107875696.04sec, total: 107875696.04sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.26ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.28ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 1.28ms, total: 6.24ms
  __init__.py:185:compute_gradients, cpu: 3.56ms, accelerator: 4.99ms, total: 8.57ms
train.py:448:<module>, cpu: 138.56ms, accelerator: 0us, total: 138.56ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_85500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 53780594.82sec, total: 53780594.82sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 53780594.82sec, total: 53780594.82sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.45ms, accelerator: 0us, total: 138.45ms
top 3 graph node: difference, cpu: 94.13ms, accelerator: 0us, total: 94.13ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 107561189.63sec, total: 107561189.64sec
train.py:511:<module>, cpu: 7.95sec, accelerator: 6.24ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.27ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.94ms, accelerator: 1.27ms, total: 6.24ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.97ms, total: 8.56ms
train.py:448:<module>, cpu: 138.46ms, accelerator: 0us, total: 138.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_85750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 53624255.88sec, total: 53624255.88sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 53624255.88sec, total: 53624255.88sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.37ms, accelerator: 0us, total: 138.37ms
top 3 graph node: difference, cpu: 94.24ms, accelerator: 0us, total: 94.24ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 107248511.76sec, total: 107248511.76sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.22ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.27ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 1.27ms, total: 6.23ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.95ms, total: 8.54ms
train.py:448:<module>, cpu: 138.37ms, accelerator: 0us, total: 138.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_86000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 53468823.25sec, total: 53468823.25sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 53468823.25sec, total: 53468823.25sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.48ms, accelerator: 0us, total: 138.48ms
top 3 graph node: difference, cpu: 94.29ms, accelerator: 0us, total: 94.29ms
train.py:441:<module> (gradient), cpu: 3.94ms, accelerator: 106937646.50sec, total: 106937646.51sec
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.27ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.27ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 1.27ms, total: 6.23ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 5.00ms, total: 8.58ms
train.py:448:<module>, cpu: 138.48ms, accelerator: 0us, total: 138.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_86250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 53314289.08sec, total: 53314289.08sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 53314289.08sec, total: 53314289.08sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.37ms, accelerator: 0us, total: 138.37ms
top 3 graph node: difference, cpu: 94.29ms, accelerator: 0us, total: 94.29ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 106628578.16sec, total: 106628578.17sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.26ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.27ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 1.27ms, total: 6.23ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 4.99ms, total: 8.56ms
train.py:448:<module>, cpu: 138.37ms, accelerator: 0us, total: 138.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2043.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_86500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 53160645.60sec, total: 53160645.60sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 53160645.60sec, total: 53160645.60sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.43ms, accelerator: 0us, total: 138.43ms
top 3 graph node: difference, cpu: 94.30ms, accelerator: 0us, total: 94.30ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 106321291.19sec, total: 106321291.20sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.25ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.27ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 1.27ms, total: 6.22ms
  __init__.py:185:compute_gradients, cpu: 3.54ms, accelerator: 4.98ms, total: 8.55ms
train.py:448:<module>, cpu: 138.44ms, accelerator: 0us, total: 138.44ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_86750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 53007885.12sec, total: 53007885.12sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 53007885.12sec, total: 53007885.12sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.42ms, accelerator: 0us, total: 138.42ms
top 3 graph node: difference, cpu: 94.34ms, accelerator: 0us, total: 94.34ms
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 106015770.24sec, total: 106015770.25sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.22ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.26ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 1.26ms, total: 6.20ms
  __init__.py:185:compute_gradients, cpu: 3.53ms, accelerator: 4.96ms, total: 8.53ms
train.py:448:<module>, cpu: 138.43ms, accelerator: 0us, total: 138.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_87000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 52856000.06sec, total: 52856000.06sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 52856000.06sec, total: 52856000.06sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.47ms, accelerator: 0us, total: 138.47ms
top 3 graph node: difference, cpu: 94.25ms, accelerator: 0us, total: 94.25ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 105712000.13sec, total: 105712000.13sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.21ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.26ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.91ms, accelerator: 1.26ms, total: 6.19ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.95ms, total: 8.51ms
train.py:448:<module>, cpu: 138.47ms, accelerator: 0us, total: 138.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_87250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 52704982.92sec, total: 52704982.92sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 52704982.92sec, total: 52704982.92sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.39ms, accelerator: 0us, total: 138.39ms
top 3 graph node: difference, cpu: 94.21ms, accelerator: 0us, total: 94.21ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 105409965.84sec, total: 105409965.84sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.23ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.26ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.90ms, accelerator: 1.26ms, total: 6.18ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.97ms, total: 8.54ms
train.py:448:<module>, cpu: 138.40ms, accelerator: 0us, total: 138.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_87500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 52554826.27sec, total: 52554826.27sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 52554826.27sec, total: 52554826.27sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.30ms, accelerator: 0us, total: 138.30ms
top 3 graph node: difference, cpu: 94.12ms, accelerator: 0us, total: 94.12ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 105109652.55sec, total: 105109652.55sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.25ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.27ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.89ms, accelerator: 1.27ms, total: 6.19ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.98ms, total: 8.55ms
train.py:448:<module>, cpu: 138.30ms, accelerator: 0us, total: 138.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_87750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 52405522.79sec, total: 52405522.79sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 52405522.79sec, total: 52405522.79sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.36ms, accelerator: 0us, total: 138.36ms
top 3 graph node: difference, cpu: 94.20ms, accelerator: 0us, total: 94.20ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 104811045.58sec, total: 104811045.58sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.24ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.26ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.88ms, accelerator: 1.26ms, total: 6.18ms
  __init__.py:185:compute_gradients, cpu: 3.52ms, accelerator: 4.97ms, total: 8.53ms
train.py:448:<module>, cpu: 138.37ms, accelerator: 0us, total: 138.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_88000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 52257065.22sec, total: 52257065.22sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 52257065.22sec, total: 52257065.22sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.45ms, accelerator: 0us, total: 138.45ms
top 3 graph node: difference, cpu: 94.22ms, accelerator: 0us, total: 94.22ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 104514130.44sec, total: 104514130.44sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.23ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.27ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 1.27ms, total: 6.22ms
  __init__.py:185:compute_gradients, cpu: 3.63ms, accelerator: 4.96ms, total: 8.63ms
train.py:448:<module>, cpu: 138.45ms, accelerator: 0us, total: 138.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_88250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 52109446.39sec, total: 52109446.39sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 52109446.39sec, total: 52109446.39sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.44ms, accelerator: 0us, total: 138.44ms
top 3 graph node: difference, cpu: 94.23ms, accelerator: 0us, total: 94.23ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 104218892.78sec, total: 104218892.78sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.26ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.26ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 1.26ms, total: 6.21ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.00ms, total: 8.66ms
train.py:448:<module>, cpu: 138.45ms, accelerator: 0us, total: 138.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_88500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.38ms, accelerator: 51962659.22sec, total: 51962659.22sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 51962659.22sec, total: 51962659.22sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.48ms, accelerator: 0us, total: 138.48ms
top 3 graph node: difference, cpu: 94.25ms, accelerator: 0us, total: 94.25ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 103925318.43sec, total: 103925318.44sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.30ms, total: 7.96sec
  __init__.py:194:compute_gradients, cpu: 7.95sec, accelerator: 1.27ms, total: 7.95sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.92ms, accelerator: 1.27ms, total: 6.22ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.03ms, total: 8.70ms
train.py:448:<module>, cpu: 138.49ms, accelerator: 0us, total: 138.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_88750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 51816696.69sec, total: 51816696.69sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 51816696.69sec, total: 51816696.69sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.57ms, accelerator: 0us, total: 138.57ms
top 3 graph node: difference, cpu: 94.28ms, accelerator: 0us, total: 94.28ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 103633393.38sec, total: 103633393.39sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.29ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.27ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.93ms, accelerator: 1.27ms, total: 6.22ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.02ms, total: 8.68ms
train.py:448:<module>, cpu: 138.58ms, accelerator: 0us, total: 138.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_89000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 51671551.88sec, total: 51671551.88sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 51671551.88sec, total: 51671551.88sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.54ms, accelerator: 0us, total: 138.54ms
top 3 graph node: difference, cpu: 94.18ms, accelerator: 0us, total: 94.18ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 103343103.77sec, total: 103343103.77sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.28ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.26ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 4.97ms, accelerator: 1.26ms, total: 6.25ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.01ms, total: 8.68ms
train.py:448:<module>, cpu: 138.55ms, accelerator: 0us, total: 138.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2025.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_89250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 51527217.94sec, total: 51527217.94sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 51527217.94sec, total: 51527217.94sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.60ms, accelerator: 0us, total: 138.60ms
top 3 graph node: difference, cpu: 94.10ms, accelerator: 0us, total: 94.10ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 103054435.88sec, total: 103054435.88sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.31ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.26ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.95sec, accelerator: 0us, total: 7.95sec
    __init__.py:86:allreduce, cpu: 4.98ms, accelerator: 1.26ms, total: 6.26ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.05ms, total: 8.71ms
train.py:448:<module>, cpu: 138.60ms, accelerator: 0us, total: 138.60ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_89500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 51383688.08sec, total: 51383688.08sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 51383688.08sec, total: 51383688.08sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.76ms, accelerator: 0us, total: 138.76ms
top 3 graph node: difference, cpu: 94.12ms, accelerator: 0us, total: 94.12ms
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 102767376.17sec, total: 102767376.17sec
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.30ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.26ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.01ms, accelerator: 1.26ms, total: 6.30ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.04ms, total: 8.70ms
train.py:448:<module>, cpu: 138.76ms, accelerator: 0us, total: 138.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_89750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 51240955.62sec, total: 51240955.62sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 51240955.62sec, total: 51240955.62sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.80ms, accelerator: 0us, total: 138.80ms
top 3 graph node: difference, cpu: 94.18ms, accelerator: 0us, total: 94.18ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 102481911.23sec, total: 102481911.24sec
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.34ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.25ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 1.25ms, total: 6.29ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.09ms, total: 8.75ms
train.py:448:<module>, cpu: 138.80ms, accelerator: 0us, total: 138.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_90000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 51099013.91sec, total: 51099013.91sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 51099013.91sec, total: 51099013.91sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.83ms, accelerator: 0us, total: 138.83ms
top 3 graph node: difference, cpu: 94.21ms, accelerator: 0us, total: 94.21ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 102198027.82sec, total: 102198027.83sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.34ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.25ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 4.99ms, accelerator: 1.25ms, total: 6.27ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.09ms, total: 8.74ms
train.py:448:<module>, cpu: 138.84ms, accelerator: 0us, total: 138.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_90250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 50957856.41sec, total: 50957856.42sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 50957856.41sec, total: 50957856.42sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.76ms, accelerator: 0us, total: 138.76ms
top 3 graph node: difference, cpu: 94.23ms, accelerator: 0us, total: 94.23ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 101915712.83sec, total: 101915712.83sec
train.py:511:<module>, cpu: 7.96sec, accelerator: 6.42ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.25ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.02ms, accelerator: 1.25ms, total: 6.29ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.17ms, total: 8.83ms
train.py:448:<module>, cpu: 138.76ms, accelerator: 0us, total: 138.76ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_90500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 50817476.64sec, total: 50817476.65sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 50817476.64sec, total: 50817476.65sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.68ms, accelerator: 0us, total: 138.68ms
top 3 graph node: difference, cpu: 94.24ms, accelerator: 0us, total: 94.24ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 101634953.29sec, total: 101634953.29sec
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.40ms, total: 7.97sec
  __init__.py:194:compute_gradients, cpu: 7.96sec, accelerator: 1.25ms, total: 7.96sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.00ms, accelerator: 1.25ms, total: 6.28ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.15ms, total: 8.81ms
train.py:448:<module>, cpu: 138.68ms, accelerator: 0us, total: 138.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_90750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 50677868.19sec, total: 50677868.19sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 50677868.19sec, total: 50677868.19sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.59ms, accelerator: 0us, total: 138.59ms
top 3 graph node: difference, cpu: 94.13ms, accelerator: 0us, total: 94.13ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 101355736.39sec, total: 101355736.39sec
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.47ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.26ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.04ms, accelerator: 1.26ms, total: 6.33ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.21ms, total: 8.87ms
train.py:448:<module>, cpu: 138.59ms, accelerator: 0us, total: 138.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_91000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 50539024.72sec, total: 50539024.72sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 50539024.72sec, total: 50539024.72sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.49ms, accelerator: 0us, total: 138.49ms
top 3 graph node: difference, cpu: 94.17ms, accelerator: 0us, total: 94.17ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 101078049.44sec, total: 101078049.44sec
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.46ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.25ms, total: 7.98sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.04ms, accelerator: 1.25ms, total: 6.32ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.20ms, total: 8.85ms
train.py:448:<module>, cpu: 138.50ms, accelerator: 0us, total: 138.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2020.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_91250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 50400939.95sec, total: 50400939.95sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 50400939.95sec, total: 50400939.95sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.51ms, accelerator: 0us, total: 138.51ms
top 3 graph node: difference, cpu: 94.10ms, accelerator: 0us, total: 94.10ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 100801879.90sec, total: 100801879.91sec
train.py:511:<module>, cpu: 7.98sec, accelerator: 6.45ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.25ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.97sec, accelerator: 0us, total: 7.97sec
    __init__.py:86:allreduce, cpu: 5.05ms, accelerator: 1.25ms, total: 6.33ms
  __init__.py:185:compute_gradients, cpu: 3.60ms, accelerator: 5.19ms, total: 8.84ms
train.py:448:<module>, cpu: 138.52ms, accelerator: 0us, total: 138.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_91500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 50263607.69sec, total: 50263607.69sec (50.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 50263607.69sec, total: 50263607.69sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 138.41ms, accelerator: 0us, total: 138.41ms
top 3 graph node: difference, cpu: 94.11ms, accelerator: 0us, total: 94.11ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 100527215.38sec, total: 100527215.38sec
train.py:511:<module>, cpu: 7.97sec, accelerator: 6.43ms, total: 7.98sec
  __init__.py:194:compute_gradients, cpu: 7.97sec, accelerator: 1.25ms, total: 7.97sec
    __init__.py:83:allreduce, cpu: 7.96sec, accelerator: 0us, total: 7.96sec
    __init__.py:86:allreduce, cpu: 5.04ms, accelerator: 1.25ms, total: 6.32ms
  __init__.py:185:compute_gradients, cpu: 3.62ms, accelerator: 5.18ms, total: 8.83ms
train.py:448:<module>, cpu: 138.42ms, accelerator: 0us, total: 138.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_91750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 50127021.80sec, total: 50127021.80sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 50127021.80sec, total: 50127021.80sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 50127021.80sec, total: 50127021.80sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.44ms, accelerator: 0us, total: 138.44ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 100254043.60sec, total: 100254043.60sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 50127021.80sec, total: 50127021.81sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 50127021.80sec, total: 50127021.80sec
  train.py:359:image_losses (gradient), cpu: 789us, accelerator: 551us, total: 1.35ms
train.py:436:<module>, cpu: 5.08ms, accelerator: 50127021.78sec, total: 50127021.79sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_92000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 49991176.21sec, total: 49991176.21sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 49991176.21sec, total: 49991176.21sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 49991176.21sec, total: 49991176.21sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.51ms, accelerator: 0us, total: 138.51ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 99982352.42sec, total: 99982352.43sec
train.py:442:<module> (gradient), cpu: 3.74ms, accelerator: 49991176.21sec, total: 49991176.22sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 49991176.21sec, total: 49991176.22sec
  train.py:359:image_losses (gradient), cpu: 791us, accelerator: 552us, total: 1.35ms
train.py:436:<module>, cpu: 5.08ms, accelerator: 49991176.20sec, total: 49991176.20sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_92250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 49856064.92sec, total: 49856064.93sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 49856064.92sec, total: 49856064.93sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 49856064.92sec, total: 49856064.92sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.47ms, accelerator: 0us, total: 138.47ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 99712129.85sec, total: 99712129.85sec
train.py:442:<module> (gradient), cpu: 3.74ms, accelerator: 49856064.93sec, total: 49856064.93sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 49856064.93sec, total: 49856064.93sec
  train.py:359:image_losses (gradient), cpu: 791us, accelerator: 551us, total: 1.35ms
train.py:436:<module>, cpu: 5.09ms, accelerator: 49856064.91sec, total: 49856064.91sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_92500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 49721682.00sec, total: 49721682.00sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 49721682.00sec, total: 49721682.00sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 49721682.00sec, total: 49721682.00sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.50ms, accelerator: 0us, total: 138.50ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 99443364.00sec, total: 99443364.00sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 49721682.00sec, total: 49721682.01sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 49721682.00sec, total: 49721682.00sec
  train.py:359:image_losses (gradient), cpu: 791us, accelerator: 550us, total: 1.35ms
train.py:436:<module>, cpu: 5.10ms, accelerator: 49721681.99sec, total: 49721681.99sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_92750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 49588021.56sec, total: 49588021.57sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 49588021.56sec, total: 49588021.57sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 49588021.56sec, total: 49588021.56sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.55ms, accelerator: 0us, total: 138.55ms
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 99176043.13sec, total: 99176043.13sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 49588021.57sec, total: 49588021.57sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 49588021.57sec, total: 49588021.57sec
  train.py:359:image_losses (gradient), cpu: 789us, accelerator: 548us, total: 1.35ms
train.py:436:<module>, cpu: 5.10ms, accelerator: 49588021.55sec, total: 49588021.55sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_93000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 49455077.81sec, total: 49455077.81sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 49455077.81sec, total: 49455077.81sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 49455077.81sec, total: 49455077.81sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.50ms, accelerator: 0us, total: 138.50ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 98910155.61sec, total: 98910155.62sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 49455077.81sec, total: 49455077.81sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 49455077.81sec, total: 49455077.81sec
  train.py:359:image_losses (gradient), cpu: 788us, accelerator: 547us, total: 1.34ms
train.py:436:<module>, cpu: 5.09ms, accelerator: 49455077.79sec, total: 49455077.80sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_93250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 49322844.98sec, total: 49322844.98sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 49322844.98sec, total: 49322844.98sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 49322844.98sec, total: 49322844.98sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.46ms, accelerator: 0us, total: 138.46ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 98645689.96sec, total: 98645689.96sec
train.py:442:<module> (gradient), cpu: 3.75ms, accelerator: 49322844.98sec, total: 49322844.98sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 49322844.98sec, total: 49322844.98sec
  train.py:359:image_losses (gradient), cpu: 808us, accelerator: 547us, total: 1.36ms
train.py:436:<module>, cpu: 5.10ms, accelerator: 49322844.96sec, total: 49322844.97sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2038.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_93500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 49191317.39sec, total: 49191317.39sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 49191317.39sec, total: 49191317.39sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 49191317.39sec, total: 49191317.39sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.51ms, accelerator: 0us, total: 138.51ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 98382634.78sec, total: 98382634.79sec
train.py:442:<module> (gradient), cpu: 3.75ms, accelerator: 49191317.39sec, total: 49191317.40sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 49191317.39sec, total: 49191317.40sec
  train.py:359:image_losses (gradient), cpu: 806us, accelerator: 547us, total: 1.36ms
train.py:436:<module>, cpu: 5.10ms, accelerator: 49191317.38sec, total: 49191317.38sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_93750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 49060489.42sec, total: 49060489.42sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 49060489.42sec, total: 49060489.42sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 49060489.42sec, total: 49060489.42sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.44ms, accelerator: 0us, total: 138.44ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 98120978.84sec, total: 98120978.85sec
train.py:442:<module> (gradient), cpu: 3.75ms, accelerator: 49060489.42sec, total: 49060489.43sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 49060489.42sec, total: 49060489.42sec
  train.py:359:image_losses (gradient), cpu: 808us, accelerator: 547us, total: 1.36ms
train.py:436:<module>, cpu: 5.10ms, accelerator: 49060489.41sec, total: 49060489.41sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_94000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 48930355.50sec, total: 48930355.50sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 48930355.50sec, total: 48930355.50sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 48930355.49sec, total: 48930355.49sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.42ms, accelerator: 0us, total: 138.42ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 97860710.99sec, total: 97860711.00sec
train.py:442:<module> (gradient), cpu: 3.75ms, accelerator: 48930355.50sec, total: 48930355.50sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 48930355.50sec, total: 48930355.50sec
  train.py:359:image_losses (gradient), cpu: 809us, accelerator: 543us, total: 1.36ms
train.py:436:<module>, cpu: 5.11ms, accelerator: 48930355.48sec, total: 48930355.49sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_94250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 48800910.11sec, total: 48800910.11sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 48800910.11sec, total: 48800910.11sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 48800910.11sec, total: 48800910.11sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.37ms, accelerator: 0us, total: 138.37ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 97601820.22sec, total: 97601820.23sec
train.py:442:<module> (gradient), cpu: 3.75ms, accelerator: 48800910.11sec, total: 48800910.12sec
  train.py:360:image_losses (gradient), cpu: 2.72ms, accelerator: 48800910.11sec, total: 48800910.12sec
  train.py:359:image_losses (gradient), cpu: 809us, accelerator: 542us, total: 1.36ms
train.py:436:<module>, cpu: 5.11ms, accelerator: 48800910.10sec, total: 48800910.10sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2030.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_94500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 48672147.82sec, total: 48672147.82sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 48672147.81sec, total: 48672147.82sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 48672147.81sec, total: 48672147.81sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.31ms, accelerator: 0us, total: 138.31ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 97344295.63sec, total: 97344295.64sec
train.py:442:<module> (gradient), cpu: 3.74ms, accelerator: 48672147.82sec, total: 48672147.82sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 48672147.82sec, total: 48672147.82sec
  train.py:359:image_losses (gradient), cpu: 805us, accelerator: 541us, total: 1.35ms
train.py:436:<module>, cpu: 5.10ms, accelerator: 48672147.80sec, total: 48672147.81sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_94750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 48544063.22sec, total: 48544063.22sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 48544063.22sec, total: 48544063.22sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 48544063.21sec, total: 48544063.21sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.22ms, accelerator: 0us, total: 138.22ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 97088126.43sec, total: 97088126.44sec
train.py:442:<module> (gradient), cpu: 3.74ms, accelerator: 48544063.22sec, total: 48544063.22sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 48544063.22sec, total: 48544063.22sec
  train.py:359:image_losses (gradient), cpu: 805us, accelerator: 541us, total: 1.35ms
train.py:436:<module>, cpu: 5.09ms, accelerator: 48544063.20sec, total: 48544063.21sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_95000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 48416650.98sec, total: 48416650.98sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 48416650.98sec, total: 48416650.98sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 48416650.97sec, total: 48416650.98sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.30ms, accelerator: 0us, total: 138.30ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 96833301.95sec, total: 96833301.96sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 48416650.98sec, total: 48416650.98sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 48416650.98sec, total: 48416650.98sec
  train.py:359:image_losses (gradient), cpu: 803us, accelerator: 538us, total: 1.35ms
train.py:436:<module>, cpu: 5.09ms, accelerator: 48416650.96sec, total: 48416650.97sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_95250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 48289905.82sec, total: 48289905.82sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 48289905.82sec, total: 48289905.82sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 48289905.82sec, total: 48289905.82sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.26ms, accelerator: 0us, total: 138.26ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 96579811.63sec, total: 96579811.64sec
train.py:442:<module> (gradient), cpu: 3.74ms, accelerator: 48289905.82sec, total: 48289905.82sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 48289905.82sec, total: 48289905.82sec
  train.py:359:image_losses (gradient), cpu: 802us, accelerator: 537us, total: 1.35ms
train.py:436:<module>, cpu: 5.08ms, accelerator: 48289905.80sec, total: 48289905.81sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_95500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 48163822.51sec, total: 48163822.51sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 48163822.51sec, total: 48163822.51sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 48163822.51sec, total: 48163822.51sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.23ms, accelerator: 0us, total: 138.23ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 96327645.02sec, total: 96327645.03sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 48163822.51sec, total: 48163822.52sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 48163822.51sec, total: 48163822.52sec
  train.py:359:image_losses (gradient), cpu: 802us, accelerator: 538us, total: 1.35ms
train.py:436:<module>, cpu: 5.08ms, accelerator: 48163822.50sec, total: 48163822.50sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_95750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 48038395.89sec, total: 48038395.89sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 48038395.89sec, total: 48038395.89sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 48038395.89sec, total: 48038395.89sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.16ms, accelerator: 0us, total: 138.16ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 96076791.78sec, total: 96076791.79sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 48038395.89sec, total: 48038395.90sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 48038395.89sec, total: 48038395.90sec
  train.py:359:image_losses (gradient), cpu: 802us, accelerator: 538us, total: 1.35ms
train.py:436:<module>, cpu: 5.07ms, accelerator: 48038395.88sec, total: 48038395.88sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_96000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 47913620.84sec, total: 47913620.84sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 47913620.84sec, total: 47913620.84sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 47913620.83sec, total: 47913620.84sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.05ms, accelerator: 0us, total: 138.05ms
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 95827241.67sec, total: 95827241.68sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 47913620.84sec, total: 47913620.84sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 47913620.84sec, total: 47913620.84sec
  train.py:359:image_losses (gradient), cpu: 800us, accelerator: 537us, total: 1.34ms
train.py:436:<module>, cpu: 5.07ms, accelerator: 47913620.82sec, total: 47913620.83sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_96250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 47789492.29sec, total: 47789492.29sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 47789492.28sec, total: 47789492.29sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 47789492.28sec, total: 47789492.28sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.09ms, accelerator: 0us, total: 138.09ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 95578984.57sec, total: 95578984.57sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 47789492.29sec, total: 47789492.29sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 47789492.29sec, total: 47789492.29sec
  train.py:359:image_losses (gradient), cpu: 803us, accelerator: 536us, total: 1.35ms
train.py:436:<module>, cpu: 5.06ms, accelerator: 47789492.27sec, total: 47789492.28sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2040.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_96500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 47666005.22sec, total: 47666005.23sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 47666005.22sec, total: 47666005.23sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 47666005.22sec, total: 47666005.22sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 95332010.45sec, total: 95332010.45sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 47666005.23sec, total: 47666005.23sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 47666005.23sec, total: 47666005.23sec
  train.py:359:image_losses (gradient), cpu: 802us, accelerator: 536us, total: 1.34ms
train.py:436:<module>, cpu: 5.07ms, accelerator: 47666005.21sec, total: 47666005.22sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2023.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_96750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 47543154.70sec, total: 47543154.70sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 47543154.70sec, total: 47543154.70sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 47543154.69sec, total: 47543154.69sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.04ms, accelerator: 0us, total: 138.04ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 95086309.39sec, total: 95086309.40sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 47543154.70sec, total: 47543154.70sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 47543154.70sec, total: 47543154.70sec
  train.py:359:image_losses (gradient), cpu: 801us, accelerator: 535us, total: 1.34ms
train.py:436:<module>, cpu: 5.06ms, accelerator: 47543154.68sec, total: 47543154.69sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_97000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 47420935.79sec, total: 47420935.79sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 47420935.79sec, total: 47420935.79sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 47420935.79sec, total: 47420935.79sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.11ms, accelerator: 0us, total: 138.11ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 94841871.58sec, total: 94841871.58sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 47420935.79sec, total: 47420935.80sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 47420935.79sec, total: 47420935.79sec
  train.py:359:image_losses (gradient), cpu: 801us, accelerator: 533us, total: 1.34ms
train.py:436:<module>, cpu: 5.06ms, accelerator: 47420935.77sec, total: 47420935.78sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_97250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 47299343.65sec, total: 47299343.65sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 47299343.65sec, total: 47299343.65sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 47299343.64sec, total: 47299343.64sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.15ms, accelerator: 0us, total: 138.15ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 94598687.29sec, total: 94598687.30sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 47299343.65sec, total: 47299343.65sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 47299343.65sec, total: 47299343.65sec
  train.py:359:image_losses (gradient), cpu: 800us, accelerator: 531us, total: 1.34ms
train.py:436:<module>, cpu: 5.05ms, accelerator: 47299343.63sec, total: 47299343.64sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_97500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 47178373.46sec, total: 47178373.46sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 47178373.46sec, total: 47178373.46sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 47178373.46sec, total: 47178373.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.07ms, accelerator: 0us, total: 138.07ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 94356746.92sec, total: 94356746.92sec
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 47178373.46sec, total: 47178373.46sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 47178373.46sec, total: 47178373.46sec
  train.py:359:image_losses (gradient), cpu: 800us, accelerator: 531us, total: 1.34ms
train.py:436:<module>, cpu: 5.04ms, accelerator: 47178373.44sec, total: 47178373.45sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_97750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 47058020.46sec, total: 47058020.47sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 47058020.46sec, total: 47058020.47sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 47058020.46sec, total: 47058020.46sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.28ms, accelerator: 0us, total: 138.28ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 94116040.93sec, total: 94116040.93sec
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 47058020.47sec, total: 47058020.47sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 47058020.47sec, total: 47058020.47sec
  train.py:359:image_losses (gradient), cpu: 799us, accelerator: 529us, total: 1.33ms
train.py:436:<module>, cpu: 5.04ms, accelerator: 47058020.45sec, total: 47058020.46sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_98000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 46938279.95sec, total: 46938279.96sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 46938279.95sec, total: 46938279.96sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 46938279.95sec, total: 46938279.95sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.33ms, accelerator: 0us, total: 138.33ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 93876559.91sec, total: 93876559.91sec
train.py:442:<module> (gradient), cpu: 3.74ms, accelerator: 46938279.96sec, total: 46938279.96sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 46938279.96sec, total: 46938279.96sec
  train.py:359:image_losses (gradient), cpu: 819us, accelerator: 527us, total: 1.35ms
train.py:436:<module>, cpu: 5.03ms, accelerator: 46938279.94sec, total: 46938279.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_98250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 46819147.26sec, total: 46819147.27sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 46819147.26sec, total: 46819147.27sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 46819147.26sec, total: 46819147.26sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.26ms, accelerator: 0us, total: 138.26ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 93638294.53sec, total: 93638294.53sec
train.py:442:<module> (gradient), cpu: 3.74ms, accelerator: 46819147.27sec, total: 46819147.27sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 46819147.27sec, total: 46819147.27sec
  train.py:359:image_losses (gradient), cpu: 816us, accelerator: 526us, total: 1.35ms
train.py:436:<module>, cpu: 5.03ms, accelerator: 46819147.25sec, total: 46819147.26sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_98500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 46700617.78sec, total: 46700617.78sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 46700617.78sec, total: 46700617.78sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 46700617.78sec, total: 46700617.78sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.18ms, accelerator: 0us, total: 138.18ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 93401235.56sec, total: 93401235.56sec
train.py:442:<module> (gradient), cpu: 3.74ms, accelerator: 46700617.78sec, total: 46700617.78sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 46700617.78sec, total: 46700617.78sec
  train.py:359:image_losses (gradient), cpu: 816us, accelerator: 524us, total: 1.35ms
train.py:436:<module>, cpu: 5.03ms, accelerator: 46700617.76sec, total: 46700617.77sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_98750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 46582686.92sec, total: 46582686.93sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 46582686.92sec, total: 46582686.93sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 46582686.92sec, total: 46582686.92sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.16ms, accelerator: 0us, total: 138.16ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 93165373.85sec, total: 93165373.85sec
train.py:442:<module> (gradient), cpu: 3.74ms, accelerator: 46582686.93sec, total: 46582686.93sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 46582686.93sec, total: 46582686.93sec
  train.py:359:image_losses (gradient), cpu: 816us, accelerator: 526us, total: 1.35ms
train.py:436:<module>, cpu: 5.02ms, accelerator: 46582686.91sec, total: 46582686.92sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_99000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 46465350.18sec, total: 46465350.18sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 46465350.18sec, total: 46465350.18sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 46465350.18sec, total: 46465350.18sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.20ms, accelerator: 0us, total: 138.20ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 92930700.36sec, total: 92930700.37sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 46465350.18sec, total: 46465350.19sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 46465350.18sec, total: 46465350.19sec
  train.py:359:image_losses (gradient), cpu: 812us, accelerator: 523us, total: 1.34ms
train.py:436:<module>, cpu: 5.02ms, accelerator: 46465350.17sec, total: 46465350.17sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_99250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 46348603.07sec, total: 46348603.07sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 46348603.07sec, total: 46348603.07sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 46348603.07sec, total: 46348603.07sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.32ms, accelerator: 0us, total: 138.32ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 92697206.14sec, total: 92697206.15sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 46348603.07sec, total: 46348603.08sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 46348603.07sec, total: 46348603.07sec
  train.py:359:image_losses (gradient), cpu: 811us, accelerator: 523us, total: 1.34ms
train.py:436:<module>, cpu: 5.01ms, accelerator: 46348603.06sec, total: 46348603.06sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2030.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_99500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 46232441.16sec, total: 46232441.16sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 46232441.16sec, total: 46232441.16sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 46232441.16sec, total: 46232441.16sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.28ms, accelerator: 0us, total: 138.28ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 92464882.32sec, total: 92464882.32sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 46232441.16sec, total: 46232441.16sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 46232441.16sec, total: 46232441.16sec
  train.py:359:image_losses (gradient), cpu: 808us, accelerator: 522us, total: 1.34ms
train.py:436:<module>, cpu: 5.00ms, accelerator: 46232441.14sec, total: 46232441.15sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_99750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 46116860.06sec, total: 46116860.06sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 46116860.05sec, total: 46116860.06sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 46116860.05sec, total: 46116860.05sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.34ms, accelerator: 0us, total: 138.34ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 92233720.11sec, total: 92233720.11sec
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 46116860.06sec, total: 46116860.06sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 46116860.06sec, total: 46116860.06sec
  train.py:359:image_losses (gradient), cpu: 806us, accelerator: 521us, total: 1.34ms
train.py:436:<module>, cpu: 5.04ms, accelerator: 46116860.04sec, total: 46116860.05sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2034.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_100000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 46001855.42sec, total: 46001855.42sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 46001855.42sec, total: 46001855.42sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 46001855.41sec, total: 46001855.42sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.39ms, accelerator: 0us, total: 138.39ms
train.py:441:<module> (gradient), cpu: 3.96ms, accelerator: 92003710.83sec, total: 92003710.84sec
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 46001855.42sec, total: 46001855.42sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 46001855.42sec, total: 46001855.42sec
  train.py:359:image_losses (gradient), cpu: 807us, accelerator: 521us, total: 1.34ms
train.py:436:<module>, cpu: 5.03ms, accelerator: 46001855.40sec, total: 46001855.41sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_100250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 45887422.94sec, total: 45887422.94sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 45887422.94sec, total: 45887422.94sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 45887422.94sec, total: 45887422.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.46ms, accelerator: 0us, total: 138.46ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 91774845.88sec, total: 91774845.89sec
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 45887422.94sec, total: 45887422.95sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 45887422.94sec, total: 45887422.94sec
  train.py:359:image_losses (gradient), cpu: 807us, accelerator: 520us, total: 1.33ms
train.py:436:<module>, cpu: 5.05ms, accelerator: 45887422.93sec, total: 45887422.93sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_100500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 45773558.37sec, total: 45773558.37sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 45773558.37sec, total: 45773558.37sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 45773558.37sec, total: 45773558.37sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.53ms, accelerator: 0us, total: 138.53ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 91547116.74sec, total: 91547116.74sec
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 45773558.37sec, total: 45773558.37sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 45773558.37sec, total: 45773558.37sec
  train.py:359:image_losses (gradient), cpu: 806us, accelerator: 519us, total: 1.33ms
train.py:436:<module>, cpu: 5.06ms, accelerator: 45773558.35sec, total: 45773558.36sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_100750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 45660257.48sec, total: 45660257.48sec (25.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 45660257.48sec, total: 45660257.48sec (25.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 45660257.48sec, total: 45660257.48sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.52ms, accelerator: 0us, total: 138.52ms
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 91320514.96sec, total: 91320514.97sec
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 45660257.48sec, total: 45660257.49sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 45660257.48sec, total: 45660257.48sec
  train.py:359:image_losses (gradient), cpu: 805us, accelerator: 517us, total: 1.33ms
train.py:436:<module>, cpu: 5.05ms, accelerator: 45660257.47sec, total: 45660257.47sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_101000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 45547516.10sec, total: 45547516.11sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 45547516.10sec, total: 45547516.10sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 45547516.10sec, total: 45547516.10sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 91095032.21sec, total: 91095032.21sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 45547516.11sec, total: 45547516.11sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 45547516.10sec, total: 45547516.11sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 45547516.10sec, total: 45547516.11sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 45547516.10sec, total: 45547516.11sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.51ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.51ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.15ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 45547516.11sec, total: 45547516.11sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 45547516.11sec, total: 45547516.11sec
  train.py:359:image_losses (gradient), cpu: 806us, accelerator: 527us, total: 1.34ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_101250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 45435330.10sec, total: 45435330.10sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 45435330.10sec, total: 45435330.10sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 45435330.10sec, total: 45435330.10sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.95ms, accelerator: 90870660.21sec, total: 90870660.21sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 45435330.11sec, total: 45435330.11sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 45435330.10sec, total: 45435330.11sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 45435330.10sec, total: 45435330.11sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 45435330.10sec, total: 45435330.11sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.51ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.51ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.15ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 45435330.11sec, total: 45435330.11sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 45435330.11sec, total: 45435330.11sec
  train.py:359:image_losses (gradient), cpu: 806us, accelerator: 526us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_101500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 45323695.39sec, total: 45323695.39sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 45323695.39sec, total: 45323695.39sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 45323695.38sec, total: 45323695.38sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 90647390.77sec, total: 90647390.78sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 45323695.39sec, total: 45323695.39sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 45323695.39sec, total: 45323695.39sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 45323695.39sec, total: 45323695.39sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 45323695.39sec, total: 45323695.39sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.51ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.51ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.14ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 45323695.39sec, total: 45323695.39sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 45323695.39sec, total: 45323695.39sec
  train.py:359:image_losses (gradient), cpu: 805us, accelerator: 524us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2023.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_101750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 45212607.90sec, total: 45212607.90sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 45212607.90sec, total: 45212607.90sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 45212607.90sec, total: 45212607.90sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 90425215.80sec, total: 90425215.80sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 45212607.90sec, total: 45212607.91sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 45212607.90sec, total: 45212607.90sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 45212607.90sec, total: 45212607.90sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 45212607.90sec, total: 45212607.90sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.50ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.50ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.14ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.73ms, accelerator: 45212607.90sec, total: 45212607.90sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 45212607.90sec, total: 45212607.90sec
  train.py:359:image_losses (gradient), cpu: 802us, accelerator: 536us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_102000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 45102063.62sec, total: 45102063.62sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 45102063.62sec, total: 45102063.62sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 45102063.62sec, total: 45102063.62sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 90204127.25sec, total: 90204127.25sec
train.py:442:<module>, cpu: 5.95ms, accelerator: 45102063.63sec, total: 45102063.63sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 45102063.62sec, total: 45102063.63sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 45102063.62sec, total: 45102063.63sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 45102063.62sec, total: 45102063.63sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.50ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.50ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.14ms, total: 2.59ms
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 45102063.63sec, total: 45102063.63sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 45102063.63sec, total: 45102063.63sec
  train.py:359:image_losses (gradient), cpu: 801us, accelerator: 535us, total: 1.34ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_102250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 44992058.59sec, total: 44992058.59sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 44992058.59sec, total: 44992058.59sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 44992058.59sec, total: 44992058.59sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 89984117.18sec, total: 89984117.19sec
train.py:442:<module>, cpu: 5.95ms, accelerator: 44992058.59sec, total: 44992058.60sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 44992058.59sec, total: 44992058.59sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 44992058.59sec, total: 44992058.59sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 44992058.59sec, total: 44992058.59sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.50ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.50ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.13ms, total: 2.59ms
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 44992058.59sec, total: 44992058.60sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 44992058.59sec, total: 44992058.59sec
  train.py:359:image_losses (gradient), cpu: 800us, accelerator: 533us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_102500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 44882588.86sec, total: 44882588.86sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 44882588.86sec, total: 44882588.86sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 44882588.86sec, total: 44882588.86sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 89765177.72sec, total: 89765177.73sec
train.py:442:<module>, cpu: 5.95ms, accelerator: 44882588.86sec, total: 44882588.87sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 44882588.86sec, total: 44882588.87sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 44882588.86sec, total: 44882588.87sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 44882588.86sec, total: 44882588.87sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.50ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.50ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.13ms, total: 2.58ms
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 44882588.86sec, total: 44882588.87sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 44882588.86sec, total: 44882588.87sec
  train.py:359:image_losses (gradient), cpu: 802us, accelerator: 533us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_102750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 44773650.54sec, total: 44773650.54sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 44773650.54sec, total: 44773650.54sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 44773650.54sec, total: 44773650.54sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 89547301.08sec, total: 89547301.08sec
train.py:442:<module>, cpu: 5.95ms, accelerator: 44773650.54sec, total: 44773650.55sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 44773650.54sec, total: 44773650.54sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 44773650.54sec, total: 44773650.54sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 44773650.54sec, total: 44773650.54sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.51ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.51ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.15ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 44773650.54sec, total: 44773650.55sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 44773650.54sec, total: 44773650.54sec
  train.py:359:image_losses (gradient), cpu: 800us, accelerator: 531us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_103000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 44665239.76sec, total: 44665239.76sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 44665239.76sec, total: 44665239.76sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 44665239.76sec, total: 44665239.76sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 89330479.53sec, total: 89330479.53sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 44665239.77sec, total: 44665239.77sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 44665239.76sec, total: 44665239.77sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 44665239.76sec, total: 44665239.77sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 44665239.76sec, total: 44665239.77sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.51ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.51ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.44ms, accelerator: 1.14ms, total: 2.59ms
train.py:442:<module> (gradient), cpu: 3.71ms, accelerator: 44665239.77sec, total: 44665239.77sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 44665239.76sec, total: 44665239.77sec
  train.py:359:image_losses (gradient), cpu: 797us, accelerator: 531us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2025.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_103250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 44557352.71sec, total: 44557352.71sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 44557352.71sec, total: 44557352.71sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 44557352.71sec, total: 44557352.71sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 89114705.42sec, total: 89114705.43sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 44557352.71sec, total: 44557352.72sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 44557352.71sec, total: 44557352.71sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 44557352.71sec, total: 44557352.71sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 44557352.71sec, total: 44557352.71sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.50ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.50ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.14ms, total: 2.61ms
train.py:442:<module> (gradient), cpu: 3.72ms, accelerator: 44557352.71sec, total: 44557352.72sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 44557352.71sec, total: 44557352.71sec
  train.py:359:image_losses (gradient), cpu: 797us, accelerator: 530us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_103500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 44449985.60sec, total: 44449985.60sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 44449985.59sec, total: 44449985.60sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 44449985.59sec, total: 44449985.59sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 88899971.19sec, total: 88899971.20sec
train.py:442:<module>, cpu: 5.95ms, accelerator: 44449985.60sec, total: 44449985.60sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 44449985.60sec, total: 44449985.60sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 44449985.60sec, total: 44449985.60sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 44449985.60sec, total: 44449985.60sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.50ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.50ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.14ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.71ms, accelerator: 44449985.60sec, total: 44449985.60sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 44449985.60sec, total: 44449985.60sec
  train.py:359:image_losses (gradient), cpu: 798us, accelerator: 530us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_103750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 44343134.67sec, total: 44343134.67sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 44343134.67sec, total: 44343134.67sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 44343134.67sec, total: 44343134.67sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 88686269.34sec, total: 88686269.34sec
train.py:442:<module>, cpu: 5.95ms, accelerator: 44343134.67sec, total: 44343134.68sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 44343134.67sec, total: 44343134.67sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 44343134.67sec, total: 44343134.67sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 44343134.67sec, total: 44343134.67sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.50ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.50ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.14ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.71ms, accelerator: 44343134.67sec, total: 44343134.67sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 44343134.67sec, total: 44343134.67sec
  train.py:359:image_losses (gradient), cpu: 797us, accelerator: 529us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_104000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 44236796.22sec, total: 44236796.22sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 44236796.22sec, total: 44236796.22sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 44236796.21sec, total: 44236796.21sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 88473592.43sec, total: 88473592.44sec
train.py:442:<module>, cpu: 5.95ms, accelerator: 44236796.22sec, total: 44236796.22sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 44236796.22sec, total: 44236796.22sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 44236796.22sec, total: 44236796.22sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 44236796.22sec, total: 44236796.22sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.49ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.49ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.13ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.71ms, accelerator: 44236796.22sec, total: 44236796.22sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 44236796.22sec, total: 44236796.22sec
  train.py:359:image_losses (gradient), cpu: 794us, accelerator: 526us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_104250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 44130966.56sec, total: 44130966.56sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 44130966.56sec, total: 44130966.56sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 44130966.56sec, total: 44130966.56sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 88261933.12sec, total: 88261933.12sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 44130966.56sec, total: 44130966.57sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 44130966.56sec, total: 44130966.56sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 44130966.56sec, total: 44130966.56sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 44130966.56sec, total: 44130966.56sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.49ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.49ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.13ms, total: 2.59ms
train.py:442:<module> (gradient), cpu: 3.71ms, accelerator: 44130966.56sec, total: 44130966.57sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 44130966.56sec, total: 44130966.56sec
  train.py:359:image_losses (gradient), cpu: 794us, accelerator: 525us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_104500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 44025642.06sec, total: 44025642.06sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 44025642.06sec, total: 44025642.06sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 44025642.06sec, total: 44025642.06sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 88051284.12sec, total: 88051284.12sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 44025642.06sec, total: 44025642.07sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 44025642.06sec, total: 44025642.06sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 44025642.06sec, total: 44025642.06sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 44025642.06sec, total: 44025642.06sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.51ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.51ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.15ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.71ms, accelerator: 44025642.06sec, total: 44025642.06sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 44025642.06sec, total: 44025642.06sec
  train.py:359:image_losses (gradient), cpu: 794us, accelerator: 530us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_104750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 43920819.10sec, total: 43920819.10sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 43920819.10sec, total: 43920819.10sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 43920819.10sec, total: 43920819.10sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 87841638.20sec, total: 87841638.21sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 43920819.10sec, total: 43920819.11sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 43920819.10sec, total: 43920819.10sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 43920819.10sec, total: 43920819.10sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 43920819.10sec, total: 43920819.10sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.50ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.50ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.15ms, total: 2.61ms
train.py:442:<module> (gradient), cpu: 3.71ms, accelerator: 43920819.10sec, total: 43920819.11sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 43920819.10sec, total: 43920819.10sec
  train.py:359:image_losses (gradient), cpu: 792us, accelerator: 528us, total: 1.33ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2030.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_105000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 43816494.11sec, total: 43816494.12sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 43816494.11sec, total: 43816494.12sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 43816494.11sec, total: 43816494.11sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 87632988.23sec, total: 87632988.23sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 43816494.12sec, total: 43816494.12sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 43816494.12sec, total: 43816494.12sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 43816494.12sec, total: 43816494.12sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 43816494.12sec, total: 43816494.12sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.50ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.50ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.15ms, total: 2.61ms
train.py:442:<module> (gradient), cpu: 3.71ms, accelerator: 43816494.12sec, total: 43816494.12sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 43816494.12sec, total: 43816494.12sec
  train.py:359:image_losses (gradient), cpu: 792us, accelerator: 528us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_105250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 43712663.56sec, total: 43712663.56sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 43712663.56sec, total: 43712663.56sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 43712663.56sec, total: 43712663.56sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 87425327.12sec, total: 87425327.12sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 43712663.56sec, total: 43712663.57sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 43712663.56sec, total: 43712663.56sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 43712663.56sec, total: 43712663.56sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 43712663.56sec, total: 43712663.56sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.50ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.50ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.14ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.71ms, accelerator: 43712663.56sec, total: 43712663.57sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 43712663.56sec, total: 43712663.56sec
  train.py:359:image_losses (gradient), cpu: 791us, accelerator: 528us, total: 1.32ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_105500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 43609323.93sec, total: 43609323.93sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 43609323.93sec, total: 43609323.93sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 43609323.93sec, total: 43609323.93sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 87218647.86sec, total: 87218647.86sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 43609323.93sec, total: 43609323.94sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 43609323.93sec, total: 43609323.93sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 43609323.93sec, total: 43609323.93sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 43609323.93sec, total: 43609323.93sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.50ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.50ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.14ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.70ms, accelerator: 43609323.93sec, total: 43609323.94sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 43609323.93sec, total: 43609323.93sec
  train.py:359:image_losses (gradient), cpu: 789us, accelerator: 525us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_105750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 43506471.75sec, total: 43506471.75sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 43506471.75sec, total: 43506471.75sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 43506471.75sec, total: 43506471.75sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 87012943.50sec, total: 87012943.51sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 43506471.75sec, total: 43506471.76sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 43506471.75sec, total: 43506471.75sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 43506471.75sec, total: 43506471.75sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 43506471.75sec, total: 43506471.75sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.50ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.50ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.14ms, total: 2.59ms
train.py:442:<module> (gradient), cpu: 3.70ms, accelerator: 43506471.75sec, total: 43506471.76sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 43506471.75sec, total: 43506471.75sec
  train.py:359:image_losses (gradient), cpu: 789us, accelerator: 523us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_106000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 43404103.58sec, total: 43404103.58sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 43404103.58sec, total: 43404103.58sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 43404103.58sec, total: 43404103.58sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 86808207.16sec, total: 86808207.17sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 43404103.58sec, total: 43404103.59sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 43404103.58sec, total: 43404103.59sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 43404103.58sec, total: 43404103.59sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 43404103.58sec, total: 43404103.59sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.50ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.50ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.14ms, total: 2.59ms
train.py:442:<module> (gradient), cpu: 3.70ms, accelerator: 43404103.58sec, total: 43404103.59sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 43404103.58sec, total: 43404103.59sec
  train.py:359:image_losses (gradient), cpu: 789us, accelerator: 521us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_106250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 43302216.01sec, total: 43302216.02sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 43302216.01sec, total: 43302216.02sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 43302216.01sec, total: 43302216.01sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 86604432.03sec, total: 86604432.03sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 43302216.02sec, total: 43302216.02sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 43302216.02sec, total: 43302216.02sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 43302216.02sec, total: 43302216.02sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 43302216.02sec, total: 43302216.02sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.50ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.50ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.48ms, accelerator: 1.14ms, total: 2.63ms
train.py:442:<module> (gradient), cpu: 3.69ms, accelerator: 43302216.02sec, total: 43302216.02sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 43302216.02sec, total: 43302216.02sec
  train.py:359:image_losses (gradient), cpu: 788us, accelerator: 522us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_106500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 43200805.67sec, total: 43200805.67sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 43200805.67sec, total: 43200805.67sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 43200805.67sec, total: 43200805.67sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 86401611.35sec, total: 86401611.35sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 43200805.68sec, total: 43200805.68sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 43200805.67sec, total: 43200805.68sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 43200805.67sec, total: 43200805.68sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 43200805.67sec, total: 43200805.68sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.50ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.50ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.48ms, accelerator: 1.14ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.69ms, accelerator: 43200805.67sec, total: 43200805.68sec
  train.py:360:image_losses (gradient), cpu: 2.69ms, accelerator: 43200805.67sec, total: 43200805.68sec
  train.py:359:image_losses (gradient), cpu: 787us, accelerator: 522us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_106750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 43099869.21sec, total: 43099869.21sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 43099869.21sec, total: 43099869.21sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 43099869.21sec, total: 43099869.21sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 86199738.42sec, total: 86199738.43sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 43099869.21sec, total: 43099869.22sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 43099869.21sec, total: 43099869.21sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 43099869.21sec, total: 43099869.21sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 43099869.21sec, total: 43099869.21sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.49ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.49ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.48ms, accelerator: 1.14ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.69ms, accelerator: 43099869.21sec, total: 43099869.22sec
  train.py:360:image_losses (gradient), cpu: 2.69ms, accelerator: 43099869.21sec, total: 43099869.21sec
  train.py:359:image_losses (gradient), cpu: 786us, accelerator: 522us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_107000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 42999403.32sec, total: 42999403.32sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42999403.31sec, total: 42999403.32sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 42999403.31sec, total: 42999403.31sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 85998806.63sec, total: 85998806.63sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 42999403.32sec, total: 42999403.32sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42999403.32sec, total: 42999403.32sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42999403.32sec, total: 42999403.32sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42999403.32sec, total: 42999403.32sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.49ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.49ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.13ms, total: 2.61ms
train.py:442:<module> (gradient), cpu: 3.69ms, accelerator: 42999403.32sec, total: 42999403.32sec
  train.py:360:image_losses (gradient), cpu: 2.70ms, accelerator: 42999403.32sec, total: 42999403.32sec
  train.py:359:image_losses (gradient), cpu: 785us, accelerator: 522us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_107250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 42899404.70sec, total: 42899404.70sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42899404.70sec, total: 42899404.70sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 42899404.70sec, total: 42899404.70sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 85798809.41sec, total: 85798809.41sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 42899404.71sec, total: 42899404.71sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42899404.70sec, total: 42899404.71sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42899404.70sec, total: 42899404.71sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42899404.70sec, total: 42899404.71sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.49ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.49ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.14ms, total: 2.61ms
train.py:442:<module> (gradient), cpu: 3.69ms, accelerator: 42899404.71sec, total: 42899404.71sec
  train.py:360:image_losses (gradient), cpu: 2.69ms, accelerator: 42899404.70sec, total: 42899404.71sec
  train.py:359:image_losses (gradient), cpu: 785us, accelerator: 521us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_107500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 42799870.12sec, total: 42799870.12sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42799870.12sec, total: 42799870.12sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 42799870.12sec, total: 42799870.12sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 85599740.24sec, total: 85599740.25sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 42799870.12sec, total: 42799870.13sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42799870.12sec, total: 42799870.12sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42799870.12sec, total: 42799870.12sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42799870.12sec, total: 42799870.12sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.51ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.51ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.16ms, total: 2.63ms
train.py:442:<module> (gradient), cpu: 3.68ms, accelerator: 42799870.12sec, total: 42799870.13sec
  train.py:360:image_losses (gradient), cpu: 2.69ms, accelerator: 42799870.12sec, total: 42799870.13sec
  train.py:359:image_losses (gradient), cpu: 780us, accelerator: 519us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2040.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_107750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 42700796.35sec, total: 42700796.35sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42700796.35sec, total: 42700796.35sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 42700796.35sec, total: 42700796.35sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 85401592.70sec, total: 85401592.70sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 42700796.35sec, total: 42700796.36sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42700796.35sec, total: 42700796.35sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42700796.35sec, total: 42700796.35sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42700796.35sec, total: 42700796.35sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.50ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.50ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.48ms, accelerator: 1.15ms, total: 2.63ms
train.py:442:<module> (gradient), cpu: 3.68ms, accelerator: 42700796.35sec, total: 42700796.35sec
  train.py:360:image_losses (gradient), cpu: 2.69ms, accelerator: 42700796.35sec, total: 42700796.35sec
  train.py:359:image_losses (gradient), cpu: 780us, accelerator: 523us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2034.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_108000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 42602180.19sec, total: 42602180.19sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42602180.19sec, total: 42602180.19sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 42602180.19sec, total: 42602180.19sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 85204360.38sec, total: 85204360.38sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 42602180.19sec, total: 42602180.20sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42602180.19sec, total: 42602180.19sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42602180.19sec, total: 42602180.19sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42602180.19sec, total: 42602180.19sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.50ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.50ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.48ms, accelerator: 1.15ms, total: 2.63ms
train.py:442:<module> (gradient), cpu: 3.68ms, accelerator: 42602180.19sec, total: 42602180.20sec
  train.py:360:image_losses (gradient), cpu: 2.69ms, accelerator: 42602180.19sec, total: 42602180.19sec
  train.py:359:image_losses (gradient), cpu: 781us, accelerator: 523us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_108250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 42504018.48sec, total: 42504018.49sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42504018.48sec, total: 42504018.49sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 42504018.48sec, total: 42504018.48sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 85008036.97sec, total: 85008036.97sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 42504018.49sec, total: 42504018.49sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42504018.49sec, total: 42504018.49sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42504018.49sec, total: 42504018.49sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42504018.49sec, total: 42504018.49sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.50ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.50ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.15ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.68ms, accelerator: 42504018.49sec, total: 42504018.49sec
  train.py:360:image_losses (gradient), cpu: 2.69ms, accelerator: 42504018.49sec, total: 42504018.49sec
  train.py:359:image_losses (gradient), cpu: 779us, accelerator: 521us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_108500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 42406308.10sec, total: 42406308.10sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42406308.10sec, total: 42406308.10sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 42406308.10sec, total: 42406308.10sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 84812616.20sec, total: 84812616.20sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 42406308.10sec, total: 42406308.11sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42406308.10sec, total: 42406308.10sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42406308.10sec, total: 42406308.10sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42406308.10sec, total: 42406308.10sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.50ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.50ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.15ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.68ms, accelerator: 42406308.10sec, total: 42406308.10sec
  train.py:360:image_losses (gradient), cpu: 2.69ms, accelerator: 42406308.10sec, total: 42406308.10sec
  train.py:359:image_losses (gradient), cpu: 779us, accelerator: 525us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_108750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 42309045.92sec, total: 42309045.92sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42309045.92sec, total: 42309045.92sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 42309045.92sec, total: 42309045.92sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 84618091.85sec, total: 84618091.85sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 42309045.93sec, total: 42309045.93sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42309045.92sec, total: 42309045.93sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42309045.92sec, total: 42309045.93sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42309045.92sec, total: 42309045.93sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.51ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.51ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.16ms, total: 2.63ms
train.py:442:<module> (gradient), cpu: 3.68ms, accelerator: 42309045.92sec, total: 42309045.93sec
  train.py:360:image_losses (gradient), cpu: 2.69ms, accelerator: 42309045.92sec, total: 42309045.93sec
  train.py:359:image_losses (gradient), cpu: 779us, accelerator: 524us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_109000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 42212228.88sec, total: 42212228.89sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42212228.88sec, total: 42212228.88sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 42212228.88sec, total: 42212228.88sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 84424457.77sec, total: 84424457.77sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 42212228.89sec, total: 42212228.89sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42212228.88sec, total: 42212228.89sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42212228.88sec, total: 42212228.89sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42212228.88sec, total: 42212228.89sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.50ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.50ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.15ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.70ms, accelerator: 42212228.89sec, total: 42212228.89sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 42212228.89sec, total: 42212228.89sec
  train.py:359:image_losses (gradient), cpu: 778us, accelerator: 526us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2034.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_109250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 42115853.93sec, total: 42115853.93sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42115853.93sec, total: 42115853.93sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 42115853.93sec, total: 42115853.93sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 84231707.86sec, total: 84231707.87sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 42115853.93sec, total: 42115853.94sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42115853.93sec, total: 42115853.94sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42115853.93sec, total: 42115853.94sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42115853.93sec, total: 42115853.94sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.50ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.50ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.15ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.70ms, accelerator: 42115853.93sec, total: 42115853.94sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 42115853.93sec, total: 42115853.94sec
  train.py:359:image_losses (gradient), cpu: 781us, accelerator: 525us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_109500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 42019918.05sec, total: 42019918.05sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 42019918.05sec, total: 42019918.05sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 42019918.04sec, total: 42019918.04sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 84039836.09sec, total: 84039836.10sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 42019918.05sec, total: 42019918.05sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 42019918.05sec, total: 42019918.05sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 42019918.05sec, total: 42019918.05sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 42019918.05sec, total: 42019918.05sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.50ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.50ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.15ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.69ms, accelerator: 42019918.05sec, total: 42019918.05sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 42019918.05sec, total: 42019918.05sec
  train.py:359:image_losses (gradient), cpu: 780us, accelerator: 524us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2043.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_109750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 41924418.23sec, total: 41924418.23sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 41924418.23sec, total: 41924418.23sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 41924418.23sec, total: 41924418.23sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 83848836.47sec, total: 83848836.47sec
train.py:442:<module>, cpu: 5.88ms, accelerator: 41924418.23sec, total: 41924418.24sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 41924418.23sec, total: 41924418.24sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 41924418.23sec, total: 41924418.24sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 41924418.23sec, total: 41924418.24sec
  train.py:359:image_losses, cpu: 2.35ms, accelerator: 1.52ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.34ms, accelerator: 1.52ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.16ms, total: 2.63ms
train.py:442:<module> (gradient), cpu: 3.70ms, accelerator: 41924418.23sec, total: 41924418.24sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 41924418.23sec, total: 41924418.24sec
  train.py:359:image_losses (gradient), cpu: 777us, accelerator: 534us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_110000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 41829351.52sec, total: 41829351.53sec (20.00%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 41829351.52sec, total: 41829351.53sec (20.00%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 41829351.52sec, total: 41829351.52sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 83658703.05sec, total: 83658703.05sec
train.py:442:<module>, cpu: 5.88ms, accelerator: 41829351.53sec, total: 41829351.53sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 41829351.53sec, total: 41829351.53sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 41829351.53sec, total: 41829351.53sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 41829351.53sec, total: 41829351.53sec
  train.py:359:image_losses, cpu: 2.35ms, accelerator: 1.51ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.34ms, accelerator: 1.51ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.16ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.75ms, accelerator: 41829351.53sec, total: 41829351.53sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 41829351.53sec, total: 41829351.53sec
  train.py:359:image_losses (gradient), cpu: 825us, accelerator: 531us, total: 1.36ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_110250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 41734714.98sec, total: 41734714.98sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 41734714.98sec, total: 41734714.98sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 41734714.98sec, total: 41734714.98sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 83469429.97sec, total: 83469429.97sec
train.py:442:<module>, cpu: 5.88ms, accelerator: 41734714.99sec, total: 41734714.99sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 41734714.98sec, total: 41734714.99sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 41734714.98sec, total: 41734714.99sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 41734714.98sec, total: 41734714.99sec
  train.py:359:image_losses, cpu: 2.35ms, accelerator: 1.52ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.33ms, accelerator: 1.52ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.16ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.75ms, accelerator: 41734714.98sec, total: 41734714.99sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 41734714.98sec, total: 41734714.99sec
  train.py:359:image_losses (gradient), cpu: 824us, accelerator: 530us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.50
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_110500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 41640505.69sec, total: 41640505.69sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 41640505.69sec, total: 41640505.69sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 41640505.69sec, total: 41640505.69sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.97ms, accelerator: 83281011.39sec, total: 83281011.39sec
train.py:442:<module>, cpu: 5.87ms, accelerator: 41640505.70sec, total: 41640505.70sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 41640505.69sec, total: 41640505.70sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 41640505.69sec, total: 41640505.70sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 41640505.69sec, total: 41640505.70sec
  train.py:359:image_losses, cpu: 2.35ms, accelerator: 1.51ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.33ms, accelerator: 1.51ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.16ms, total: 2.61ms
train.py:442:<module> (gradient), cpu: 3.75ms, accelerator: 41640505.70sec, total: 41640505.70sec
  train.py:360:image_losses (gradient), cpu: 2.71ms, accelerator: 41640505.70sec, total: 41640505.70sec
  train.py:359:image_losses (gradient), cpu: 823us, accelerator: 528us, total: 1.36ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_110750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 41546720.77sec, total: 41546720.77sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 41546720.77sec, total: 41546720.77sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 402us, accelerator: 41546720.77sec, total: 41546720.77sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 83093441.54sec, total: 83093441.55sec
train.py:442:<module>, cpu: 6.08ms, accelerator: 41546720.77sec, total: 41546720.78sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 41546720.77sec, total: 41546720.77sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 41546720.77sec, total: 41546720.77sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 41546720.77sec, total: 41546720.77sec
  train.py:359:image_losses, cpu: 2.56ms, accelerator: 1.51ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.51ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.16ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 41546720.77sec, total: 41546720.78sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 41546720.77sec, total: 41546720.78sec
  train.py:359:image_losses (gradient), cpu: 821us, accelerator: 532us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2034.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_111000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 41453357.35sec, total: 41453357.35sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 41453357.35sec, total: 41453357.35sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 402us, accelerator: 41453357.35sec, total: 41453357.35sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 82906714.71sec, total: 82906714.71sec
train.py:442:<module>, cpu: 6.08ms, accelerator: 41453357.36sec, total: 41453357.36sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 41453357.35sec, total: 41453357.36sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 41453357.35sec, total: 41453357.36sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 41453357.35sec, total: 41453357.36sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.51ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.51ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.16ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 41453357.36sec, total: 41453357.36sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 41453357.36sec, total: 41453357.36sec
  train.py:359:image_losses (gradient), cpu: 821us, accelerator: 531us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_111250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 41360412.61sec, total: 41360412.61sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 41360412.61sec, total: 41360412.61sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 402us, accelerator: 41360412.60sec, total: 41360412.60sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 82720825.21sec, total: 82720825.22sec
train.py:442:<module>, cpu: 6.08ms, accelerator: 41360412.61sec, total: 41360412.61sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 41360412.61sec, total: 41360412.61sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 41360412.61sec, total: 41360412.61sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 41360412.61sec, total: 41360412.61sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.51ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.51ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.16ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 41360412.61sec, total: 41360412.61sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 41360412.61sec, total: 41360412.61sec
  train.py:359:image_losses (gradient), cpu: 820us, accelerator: 530us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_111500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 41267883.72sec, total: 41267883.72sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 41267883.72sec, total: 41267883.72sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 402us, accelerator: 41267883.72sec, total: 41267883.72sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 82535767.44sec, total: 82535767.44sec
train.py:442:<module>, cpu: 6.10ms, accelerator: 41267883.72sec, total: 41267883.73sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 41267883.72sec, total: 41267883.72sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 41267883.72sec, total: 41267883.72sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 41267883.72sec, total: 41267883.72sec
  train.py:359:image_losses, cpu: 2.58ms, accelerator: 1.51ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.57ms, accelerator: 1.51ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.54ms, accelerator: 1.16ms, total: 2.69ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 41267883.72sec, total: 41267883.72sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 41267883.72sec, total: 41267883.72sec
  train.py:359:image_losses (gradient), cpu: 850us, accelerator: 528us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_111750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 41175767.91sec, total: 41175767.91sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 41175767.91sec, total: 41175767.91sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 402us, accelerator: 41175767.90sec, total: 41175767.91sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 82351535.81sec, total: 82351535.82sec
train.py:442:<module>, cpu: 6.10ms, accelerator: 41175767.91sec, total: 41175767.92sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 41175767.91sec, total: 41175767.91sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 41175767.91sec, total: 41175767.91sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 41175767.91sec, total: 41175767.91sec
  train.py:359:image_losses, cpu: 2.58ms, accelerator: 1.51ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.56ms, accelerator: 1.51ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.53ms, accelerator: 1.16ms, total: 2.69ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 41175767.91sec, total: 41175767.91sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 41175767.91sec, total: 41175767.91sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 538us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_112000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 41084062.41sec, total: 41084062.41sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 41084062.41sec, total: 41084062.41sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 402us, accelerator: 41084062.41sec, total: 41084062.41sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 82168124.82sec, total: 82168124.83sec
train.py:442:<module>, cpu: 6.09ms, accelerator: 41084062.41sec, total: 41084062.42sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 41084062.41sec, total: 41084062.41sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 41084062.41sec, total: 41084062.41sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 41084062.41sec, total: 41084062.41sec
  train.py:359:image_losses, cpu: 2.57ms, accelerator: 1.50ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.56ms, accelerator: 1.50ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.53ms, accelerator: 1.15ms, total: 2.69ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 41084062.41sec, total: 41084062.42sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 41084062.41sec, total: 41084062.41sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 538us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_112250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40992764.49sec, total: 40992764.50sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 40992764.49sec, total: 40992764.49sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 402us, accelerator: 40992764.49sec, total: 40992764.49sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 81985528.99sec, total: 81985528.99sec
train.py:442:<module>, cpu: 6.09ms, accelerator: 40992764.50sec, total: 40992764.50sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 40992764.49sec, total: 40992764.50sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 40992764.49sec, total: 40992764.50sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 40992764.49sec, total: 40992764.50sec
  train.py:359:image_losses, cpu: 2.57ms, accelerator: 1.50ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.55ms, accelerator: 1.50ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.53ms, accelerator: 1.15ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 40992764.50sec, total: 40992764.50sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 40992764.50sec, total: 40992764.50sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 538us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_112500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 40901871.45sec, total: 40901871.45sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 40901871.45sec, total: 40901871.45sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 402us, accelerator: 40901871.44sec, total: 40901871.44sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 81803742.89sec, total: 81803742.90sec
train.py:442:<module>, cpu: 6.08ms, accelerator: 40901871.45sec, total: 40901871.46sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 40901871.45sec, total: 40901871.45sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 40901871.45sec, total: 40901871.45sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 40901871.45sec, total: 40901871.45sec
  train.py:359:image_losses, cpu: 2.56ms, accelerator: 1.50ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.55ms, accelerator: 1.50ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.15ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 40901871.45sec, total: 40901871.45sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 40901871.45sec, total: 40901871.45sec
  train.py:359:image_losses (gradient), cpu: 847us, accelerator: 536us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_112750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40811380.58sec, total: 40811380.58sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.94ms, accelerator: 40811380.58sec, total: 40811380.58sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 401us, accelerator: 40811380.58sec, total: 40811380.58sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 81622761.16sec, total: 81622761.17sec
train.py:442:<module>, cpu: 6.09ms, accelerator: 40811380.58sec, total: 40811380.59sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 40811380.58sec, total: 40811380.58sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 40811380.58sec, total: 40811380.58sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 40811380.58sec, total: 40811380.58sec
  train.py:359:image_losses, cpu: 2.56ms, accelerator: 1.50ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.50ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.16ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 40811380.58sec, total: 40811380.59sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 40811380.58sec, total: 40811380.58sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 536us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_113000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40721289.23sec, total: 40721289.23sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 40721289.23sec, total: 40721289.23sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 401us, accelerator: 40721289.23sec, total: 40721289.23sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 81442578.47sec, total: 81442578.47sec
train.py:442:<module>, cpu: 6.09ms, accelerator: 40721289.24sec, total: 40721289.24sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 40721289.23sec, total: 40721289.24sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 40721289.23sec, total: 40721289.24sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 40721289.23sec, total: 40721289.24sec
  train.py:359:image_losses, cpu: 2.56ms, accelerator: 1.50ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.50ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.15ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 40721289.23sec, total: 40721289.24sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 40721289.23sec, total: 40721289.24sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 536us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_113250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40631594.76sec, total: 40631594.76sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 40631594.76sec, total: 40631594.76sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 401us, accelerator: 40631594.76sec, total: 40631594.76sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 81263189.53sec, total: 81263189.53sec
train.py:442:<module>, cpu: 6.11ms, accelerator: 40631594.77sec, total: 40631594.77sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 40631594.76sec, total: 40631594.77sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 40631594.76sec, total: 40631594.77sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 40631594.76sec, total: 40631594.77sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.50ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.50ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.15ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 40631594.77sec, total: 40631594.77sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 40631594.76sec, total: 40631594.77sec
  train.py:359:image_losses (gradient), cpu: 846us, accelerator: 535us, total: 1.39ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_113500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40542294.55sec, total: 40542294.56sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 40542294.55sec, total: 40542294.56sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 401us, accelerator: 40542294.55sec, total: 40542294.55sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 81084589.11sec, total: 81084589.11sec
train.py:442:<module>, cpu: 6.11ms, accelerator: 40542294.56sec, total: 40542294.56sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 40542294.56sec, total: 40542294.56sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 40542294.56sec, total: 40542294.56sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 40542294.56sec, total: 40542294.56sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.50ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.50ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.15ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 40542294.56sec, total: 40542294.56sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 40542294.56sec, total: 40542294.56sec
  train.py:359:image_losses (gradient), cpu: 843us, accelerator: 567us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_113750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40453386.01sec, total: 40453386.02sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 40453386.01sec, total: 40453386.01sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 401us, accelerator: 40453386.01sec, total: 40453386.01sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 80906772.03sec, total: 80906772.03sec
train.py:442:<module>, cpu: 6.10ms, accelerator: 40453386.02sec, total: 40453386.02sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 40453386.01sec, total: 40453386.02sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 40453386.01sec, total: 40453386.02sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 40453386.01sec, total: 40453386.02sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.50ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.50ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.15ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 40453386.02sec, total: 40453386.02sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 40453386.02sec, total: 40453386.02sec
  train.py:359:image_losses (gradient), cpu: 843us, accelerator: 579us, total: 1.43ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_114000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40364866.57sec, total: 40364866.57sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 40364866.57sec, total: 40364866.57sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 401us, accelerator: 40364866.57sec, total: 40364866.57sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 80729733.14sec, total: 80729733.14sec
train.py:442:<module>, cpu: 6.10ms, accelerator: 40364866.57sec, total: 40364866.58sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 40364866.57sec, total: 40364866.57sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 40364866.57sec, total: 40364866.57sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 40364866.57sec, total: 40364866.57sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.50ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.50ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.15ms, total: 2.66ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 40364866.57sec, total: 40364866.58sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 40364866.57sec, total: 40364866.57sec
  train.py:359:image_losses (gradient), cpu: 844us, accelerator: 577us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_114250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40276733.67sec, total: 40276733.67sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 40276733.67sec, total: 40276733.67sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 401us, accelerator: 40276733.67sec, total: 40276733.67sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 80553467.35sec, total: 80553467.35sec
train.py:442:<module>, cpu: 6.09ms, accelerator: 40276733.68sec, total: 40276733.68sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 40276733.67sec, total: 40276733.68sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 40276733.67sec, total: 40276733.68sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 40276733.67sec, total: 40276733.68sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.49ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.49ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.15ms, total: 2.66ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 40276733.68sec, total: 40276733.68sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 40276733.67sec, total: 40276733.68sec
  train.py:359:image_losses (gradient), cpu: 840us, accelerator: 576us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_114500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40188984.80sec, total: 40188984.80sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 40188984.80sec, total: 40188984.80sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 401us, accelerator: 40188984.80sec, total: 40188984.80sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 80377969.60sec, total: 80377969.60sec
train.py:442:<module>, cpu: 6.09ms, accelerator: 40188984.80sec, total: 40188984.81sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 40188984.80sec, total: 40188984.80sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 40188984.80sec, total: 40188984.80sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 40188984.80sec, total: 40188984.80sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.49ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.49ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.14ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 40188984.80sec, total: 40188984.80sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 40188984.80sec, total: 40188984.80sec
  train.py:359:image_losses (gradient), cpu: 839us, accelerator: 575us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_114750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40101617.44sec, total: 40101617.44sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 40101617.44sec, total: 40101617.44sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 401us, accelerator: 40101617.44sec, total: 40101617.44sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 80203234.88sec, total: 80203234.88sec
train.py:442:<module>, cpu: 6.09ms, accelerator: 40101617.44sec, total: 40101617.45sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 40101617.44sec, total: 40101617.44sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 40101617.44sec, total: 40101617.44sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 40101617.44sec, total: 40101617.44sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.50ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.50ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.50ms, accelerator: 1.14ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 40101617.44sec, total: 40101617.45sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 40101617.44sec, total: 40101617.44sec
  train.py:359:image_losses (gradient), cpu: 839us, accelerator: 574us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_115000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 40014629.12sec, total: 40014629.12sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 40014629.11sec, total: 40014629.12sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 400us, accelerator: 40014629.11sec, total: 40014629.11sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 80029258.23sec, total: 80029258.24sec
train.py:442:<module>, cpu: 6.08ms, accelerator: 40014629.12sec, total: 40014629.12sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 40014629.12sec, total: 40014629.12sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 40014629.12sec, total: 40014629.12sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 40014629.12sec, total: 40014629.12sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.50ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.50ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.50ms, accelerator: 1.14ms, total: 2.64ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 40014629.12sec, total: 40014629.12sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 40014629.12sec, total: 40014629.12sec
  train.py:359:image_losses (gradient), cpu: 838us, accelerator: 578us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_115250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 39928017.36sec, total: 39928017.37sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39928017.36sec, total: 39928017.37sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 400us, accelerator: 39928017.36sec, total: 39928017.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 79856034.73sec, total: 79856034.73sec
train.py:442:<module>, cpu: 6.08ms, accelerator: 39928017.37sec, total: 39928017.37sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 39928017.37sec, total: 39928017.37sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 39928017.37sec, total: 39928017.37sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 39928017.37sec, total: 39928017.37sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.50ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.50ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.50ms, accelerator: 1.14ms, total: 2.64ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 39928017.37sec, total: 39928017.37sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39928017.37sec, total: 39928017.37sec
  train.py:359:image_losses (gradient), cpu: 837us, accelerator: 577us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_115500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 39841779.75sec, total: 39841779.75sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39841779.74sec, total: 39841779.75sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 39841779.74sec, total: 39841779.74sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 79683559.49sec, total: 79683559.50sec
train.py:442:<module>, cpu: 6.07ms, accelerator: 39841779.75sec, total: 39841779.75sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 39841779.75sec, total: 39841779.75sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 39841779.75sec, total: 39841779.75sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 39841779.75sec, total: 39841779.75sec
  train.py:359:image_losses, cpu: 2.53ms, accelerator: 1.50ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.50ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.50ms, accelerator: 1.14ms, total: 2.64ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 39841779.75sec, total: 39841779.75sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39841779.75sec, total: 39841779.75sec
  train.py:359:image_losses (gradient), cpu: 837us, accelerator: 577us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2043.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_115750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 39755913.84sec, total: 39755913.84sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39755913.84sec, total: 39755913.84sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 39755913.84sec, total: 39755913.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 79511827.68sec, total: 79511827.69sec
train.py:442:<module>, cpu: 6.12ms, accelerator: 39755913.84sec, total: 39755913.85sec
  train.py:360:image_losses, cpu: 3.00ms, accelerator: 39755913.84sec, total: 39755913.85sec
    train.py:322:loss_fn, cpu: 2.99ms, accelerator: 39755913.84sec, total: 39755913.85sec
      train.py:349:msssim, cpu: 2.94ms, accelerator: 39755913.84sec, total: 39755913.84sec
  train.py:359:image_losses, cpu: 2.53ms, accelerator: 1.50ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.50ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.50ms, accelerator: 1.14ms, total: 2.63ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 39755913.84sec, total: 39755913.85sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39755913.84sec, total: 39755913.85sec
  train.py:359:image_losses (gradient), cpu: 853us, accelerator: 576us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_116000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 39670417.25sec, total: 39670417.25sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39670417.25sec, total: 39670417.25sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 39670417.25sec, total: 39670417.25sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 79340834.51sec, total: 79340834.51sec
train.py:442:<module>, cpu: 6.13ms, accelerator: 39670417.25sec, total: 39670417.26sec
  train.py:360:image_losses, cpu: 3.00ms, accelerator: 39670417.25sec, total: 39670417.26sec
    train.py:322:loss_fn, cpu: 2.99ms, accelerator: 39670417.25sec, total: 39670417.26sec
      train.py:349:msssim, cpu: 2.94ms, accelerator: 39670417.25sec, total: 39670417.26sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.50ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.50ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.14ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 39670417.25sec, total: 39670417.26sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39670417.25sec, total: 39670417.26sec
  train.py:359:image_losses (gradient), cpu: 852us, accelerator: 575us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_116250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 39585287.60sec, total: 39585287.60sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39585287.60sec, total: 39585287.60sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 39585287.60sec, total: 39585287.60sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 79170575.20sec, total: 79170575.21sec
train.py:442:<module>, cpu: 6.13ms, accelerator: 39585287.60sec, total: 39585287.61sec
  train.py:360:image_losses, cpu: 3.00ms, accelerator: 39585287.60sec, total: 39585287.61sec
    train.py:322:loss_fn, cpu: 2.99ms, accelerator: 39585287.60sec, total: 39585287.61sec
      train.py:349:msssim, cpu: 2.94ms, accelerator: 39585287.60sec, total: 39585287.61sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.49ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.49ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.13ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 39585287.60sec, total: 39585287.61sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39585287.60sec, total: 39585287.61sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 573us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_116500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 39500522.53sec, total: 39500522.53sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39500522.53sec, total: 39500522.53sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 39500522.53sec, total: 39500522.53sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 79001045.06sec, total: 79001045.07sec
train.py:442:<module>, cpu: 6.12ms, accelerator: 39500522.53sec, total: 39500522.54sec
  train.py:360:image_losses, cpu: 3.00ms, accelerator: 39500522.53sec, total: 39500522.54sec
    train.py:322:loss_fn, cpu: 2.98ms, accelerator: 39500522.53sec, total: 39500522.54sec
      train.py:349:msssim, cpu: 2.94ms, accelerator: 39500522.53sec, total: 39500522.54sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.50ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.50ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.14ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 39500522.53sec, total: 39500522.54sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39500522.53sec, total: 39500522.54sec
  train.py:359:image_losses (gradient), cpu: 847us, accelerator: 572us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_116750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 39416119.71sec, total: 39416119.71sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39416119.71sec, total: 39416119.71sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 39416119.70sec, total: 39416119.70sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 78832239.41sec, total: 78832239.42sec
train.py:442:<module>, cpu: 6.12ms, accelerator: 39416119.71sec, total: 39416119.71sec
  train.py:360:image_losses, cpu: 3.00ms, accelerator: 39416119.71sec, total: 39416119.71sec
    train.py:322:loss_fn, cpu: 2.98ms, accelerator: 39416119.71sec, total: 39416119.71sec
      train.py:349:msssim, cpu: 2.94ms, accelerator: 39416119.71sec, total: 39416119.71sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.50ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.50ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.14ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 39416119.71sec, total: 39416119.71sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39416119.71sec, total: 39416119.71sec
  train.py:359:image_losses (gradient), cpu: 849us, accelerator: 573us, total: 1.43ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_117000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 39332076.81sec, total: 39332076.81sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39332076.81sec, total: 39332076.81sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 39332076.80sec, total: 39332076.81sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 78664153.61sec, total: 78664153.62sec
train.py:442:<module>, cpu: 6.12ms, accelerator: 39332076.81sec, total: 39332076.82sec
  train.py:360:image_losses, cpu: 3.00ms, accelerator: 39332076.81sec, total: 39332076.81sec
    train.py:322:loss_fn, cpu: 2.99ms, accelerator: 39332076.81sec, total: 39332076.81sec
      train.py:349:msssim, cpu: 2.94ms, accelerator: 39332076.81sec, total: 39332076.81sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.50ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.50ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.14ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 39332076.81sec, total: 39332076.81sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39332076.81sec, total: 39332076.81sec
  train.py:359:image_losses (gradient), cpu: 849us, accelerator: 572us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_117250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 39248391.54sec, total: 39248391.54sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39248391.54sec, total: 39248391.54sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 39248391.53sec, total: 39248391.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 78496783.07sec, total: 78496783.08sec
train.py:442:<module>, cpu: 6.14ms, accelerator: 39248391.54sec, total: 39248391.55sec
  train.py:360:image_losses, cpu: 3.00ms, accelerator: 39248391.54sec, total: 39248391.54sec
    train.py:322:loss_fn, cpu: 2.98ms, accelerator: 39248391.54sec, total: 39248391.54sec
      train.py:349:msssim, cpu: 2.94ms, accelerator: 39248391.54sec, total: 39248391.54sec
  train.py:359:image_losses, cpu: 2.56ms, accelerator: 1.50ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.55ms, accelerator: 1.50ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.53ms, accelerator: 1.14ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 39248391.54sec, total: 39248391.54sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39248391.54sec, total: 39248391.54sec
  train.py:359:image_losses (gradient), cpu: 849us, accelerator: 571us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_117500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 39165061.62sec, total: 39165061.62sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39165061.62sec, total: 39165061.62sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 400us, accelerator: 39165061.62sec, total: 39165061.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 78330123.24sec, total: 78330123.24sec
train.py:442:<module>, cpu: 6.14ms, accelerator: 39165061.62sec, total: 39165061.63sec
  train.py:360:image_losses, cpu: 3.00ms, accelerator: 39165061.62sec, total: 39165061.62sec
    train.py:322:loss_fn, cpu: 2.98ms, accelerator: 39165061.62sec, total: 39165061.62sec
      train.py:349:msssim, cpu: 2.94ms, accelerator: 39165061.62sec, total: 39165061.62sec
  train.py:359:image_losses, cpu: 2.56ms, accelerator: 1.50ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.55ms, accelerator: 1.50ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.53ms, accelerator: 1.15ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 39165061.62sec, total: 39165061.62sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39165061.62sec, total: 39165061.62sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 569us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_117750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 39082084.79sec, total: 39082084.79sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 39082084.79sec, total: 39082084.79sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 400us, accelerator: 39082084.79sec, total: 39082084.79sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 78164169.59sec, total: 78164169.59sec
train.py:442:<module>, cpu: 6.15ms, accelerator: 39082084.80sec, total: 39082084.80sec
  train.py:360:image_losses, cpu: 2.99ms, accelerator: 39082084.79sec, total: 39082084.80sec
    train.py:322:loss_fn, cpu: 2.98ms, accelerator: 39082084.79sec, total: 39082084.80sec
      train.py:349:msssim, cpu: 2.93ms, accelerator: 39082084.79sec, total: 39082084.80sec
  train.py:359:image_losses, cpu: 2.57ms, accelerator: 1.50ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.56ms, accelerator: 1.50ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.53ms, accelerator: 1.15ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 39082084.80sec, total: 39082084.80sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 39082084.79sec, total: 39082084.80sec
  train.py:359:image_losses (gradient), cpu: 847us, accelerator: 568us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_118000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38999458.82sec, total: 38999458.82sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38999458.82sec, total: 38999458.82sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 38999458.82sec, total: 38999458.82sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 77998917.64sec, total: 77998917.65sec
train.py:442:<module>, cpu: 6.17ms, accelerator: 38999458.82sec, total: 38999458.83sec
  train.py:360:image_losses, cpu: 2.99ms, accelerator: 38999458.82sec, total: 38999458.82sec
    train.py:322:loss_fn, cpu: 2.98ms, accelerator: 38999458.82sec, total: 38999458.82sec
      train.py:349:msssim, cpu: 2.93ms, accelerator: 38999458.82sec, total: 38999458.82sec
  train.py:359:image_losses, cpu: 2.60ms, accelerator: 1.50ms, total: 4.12ms
    train.py:322:loss_fn, cpu: 2.58ms, accelerator: 1.50ms, total: 4.10ms
      train.py:342:hfe, cpu: 1.53ms, accelerator: 1.15ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 38999458.82sec, total: 38999458.83sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38999458.82sec, total: 38999458.83sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 568us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_118250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38917181.48sec, total: 38917181.48sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38917181.48sec, total: 38917181.48sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 38917181.48sec, total: 38917181.48sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 77834362.96sec, total: 77834362.97sec
train.py:442:<module>, cpu: 6.23ms, accelerator: 38917181.48sec, total: 38917181.49sec
  train.py:360:image_losses, cpu: 2.99ms, accelerator: 38917181.48sec, total: 38917181.49sec
    train.py:322:loss_fn, cpu: 2.98ms, accelerator: 38917181.48sec, total: 38917181.49sec
      train.py:349:msssim, cpu: 2.93ms, accelerator: 38917181.48sec, total: 38917181.49sec
  train.py:359:image_losses, cpu: 2.65ms, accelerator: 1.54ms, total: 4.20ms
    train.py:322:loss_fn, cpu: 2.64ms, accelerator: 1.54ms, total: 4.19ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.15ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 38917181.48sec, total: 38917181.49sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38917181.48sec, total: 38917181.49sec
  train.py:359:image_losses (gradient), cpu: 849us, accelerator: 567us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_118500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38835250.57sec, total: 38835250.57sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38835250.57sec, total: 38835250.57sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 38835250.57sec, total: 38835250.57sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 77670501.15sec, total: 77670501.15sec
train.py:442:<module>, cpu: 6.25ms, accelerator: 38835250.58sec, total: 38835250.58sec
  train.py:360:image_losses, cpu: 2.99ms, accelerator: 38835250.57sec, total: 38835250.58sec
    train.py:322:loss_fn, cpu: 2.98ms, accelerator: 38835250.57sec, total: 38835250.58sec
      train.py:349:msssim, cpu: 2.93ms, accelerator: 38835250.57sec, total: 38835250.58sec
  train.py:359:image_losses, cpu: 2.65ms, accelerator: 1.56ms, total: 4.22ms
    train.py:322:loss_fn, cpu: 2.64ms, accelerator: 1.56ms, total: 4.21ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.15ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 38835250.58sec, total: 38835250.58sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38835250.57sec, total: 38835250.58sec
  train.py:359:image_losses (gradient), cpu: 849us, accelerator: 566us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_118750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38753663.91sec, total: 38753663.91sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38753663.91sec, total: 38753663.91sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 38753663.91sec, total: 38753663.91sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 77507327.83sec, total: 77507327.83sec
train.py:442:<module>, cpu: 6.24ms, accelerator: 38753663.92sec, total: 38753663.92sec
  train.py:360:image_losses, cpu: 2.99ms, accelerator: 38753663.91sec, total: 38753663.92sec
    train.py:322:loss_fn, cpu: 2.98ms, accelerator: 38753663.91sec, total: 38753663.92sec
      train.py:349:msssim, cpu: 2.93ms, accelerator: 38753663.91sec, total: 38753663.92sec
  train.py:359:image_losses, cpu: 2.65ms, accelerator: 1.55ms, total: 4.21ms
    train.py:322:loss_fn, cpu: 2.63ms, accelerator: 1.55ms, total: 4.20ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.14ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 38753663.91sec, total: 38753663.92sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38753663.91sec, total: 38753663.92sec
  train.py:359:image_losses (gradient), cpu: 860us, accelerator: 566us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_119000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38672419.33sec, total: 38672419.34sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38672419.33sec, total: 38672419.34sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 38672419.33sec, total: 38672419.33sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 77344838.67sec, total: 77344838.67sec
train.py:442:<module>, cpu: 6.24ms, accelerator: 38672419.34sec, total: 38672419.34sec
  train.py:360:image_losses, cpu: 2.99ms, accelerator: 38672419.33sec, total: 38672419.34sec
    train.py:322:loss_fn, cpu: 2.98ms, accelerator: 38672419.33sec, total: 38672419.34sec
      train.py:349:msssim, cpu: 2.93ms, accelerator: 38672419.33sec, total: 38672419.34sec
  train.py:359:image_losses, cpu: 2.64ms, accelerator: 1.55ms, total: 4.21ms
    train.py:322:loss_fn, cpu: 2.63ms, accelerator: 1.55ms, total: 4.20ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.15ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 38672419.34sec, total: 38672419.34sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38672419.34sec, total: 38672419.34sec
  train.py:359:image_losses (gradient), cpu: 864us, accelerator: 565us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_119250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38591514.69sec, total: 38591514.69sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 38591514.69sec, total: 38591514.69sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 38591514.69sec, total: 38591514.69sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 77183029.38sec, total: 77183029.39sec
train.py:442:<module>, cpu: 6.26ms, accelerator: 38591514.69sec, total: 38591514.70sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 38591514.69sec, total: 38591514.69sec
    train.py:322:loss_fn, cpu: 2.97ms, accelerator: 38591514.69sec, total: 38591514.69sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 38591514.69sec, total: 38591514.69sec
  train.py:359:image_losses, cpu: 2.65ms, accelerator: 1.55ms, total: 4.22ms
    train.py:322:loss_fn, cpu: 2.63ms, accelerator: 1.55ms, total: 4.20ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.14ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 38591514.69sec, total: 38591514.70sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38591514.69sec, total: 38591514.70sec
  train.py:359:image_losses (gradient), cpu: 862us, accelerator: 562us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2043.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_119500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38510947.85sec, total: 38510947.86sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 38510947.85sec, total: 38510947.86sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 38510947.85sec, total: 38510947.85sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 77021895.71sec, total: 77021895.71sec
train.py:442:<module>, cpu: 6.25ms, accelerator: 38510947.86sec, total: 38510947.86sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 38510947.86sec, total: 38510947.86sec
    train.py:322:loss_fn, cpu: 2.97ms, accelerator: 38510947.86sec, total: 38510947.86sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 38510947.86sec, total: 38510947.86sec
  train.py:359:image_losses, cpu: 2.65ms, accelerator: 1.55ms, total: 4.21ms
    train.py:322:loss_fn, cpu: 2.63ms, accelerator: 1.55ms, total: 4.20ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.14ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 38510947.86sec, total: 38510947.86sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38510947.86sec, total: 38510947.86sec
  train.py:359:image_losses (gradient), cpu: 861us, accelerator: 560us, total: 1.43ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_119750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38430716.71sec, total: 38430716.71sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38430716.71sec, total: 38430716.71sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 398us, accelerator: 38430716.71sec, total: 38430716.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 76861433.43sec, total: 76861433.43sec
train.py:442:<module>, cpu: 6.25ms, accelerator: 38430716.72sec, total: 38430716.72sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 38430716.71sec, total: 38430716.72sec
    train.py:322:loss_fn, cpu: 2.97ms, accelerator: 38430716.71sec, total: 38430716.72sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 38430716.71sec, total: 38430716.72sec
  train.py:359:image_losses, cpu: 2.64ms, accelerator: 1.55ms, total: 4.20ms
    train.py:322:loss_fn, cpu: 2.63ms, accelerator: 1.55ms, total: 4.19ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.14ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 38430716.72sec, total: 38430716.72sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38430716.71sec, total: 38430716.72sec
  train.py:359:image_losses (gradient), cpu: 859us, accelerator: 559us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_120000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38350819.17sec, total: 38350819.17sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38350819.17sec, total: 38350819.17sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 398us, accelerator: 38350819.17sec, total: 38350819.17sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 76701638.35sec, total: 76701638.35sec
train.py:442:<module>, cpu: 6.24ms, accelerator: 38350819.18sec, total: 38350819.18sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 38350819.17sec, total: 38350819.18sec
    train.py:322:loss_fn, cpu: 2.97ms, accelerator: 38350819.17sec, total: 38350819.18sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 38350819.17sec, total: 38350819.18sec
  train.py:359:image_losses, cpu: 2.64ms, accelerator: 1.55ms, total: 4.20ms
    train.py:322:loss_fn, cpu: 2.62ms, accelerator: 1.55ms, total: 4.18ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.14ms, total: 2.66ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 38350819.18sec, total: 38350819.18sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38350819.17sec, total: 38350819.18sec
  train.py:359:image_losses (gradient), cpu: 859us, accelerator: 564us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_120250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38271253.16sec, total: 38271253.16sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38271253.16sec, total: 38271253.16sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 398us, accelerator: 38271253.16sec, total: 38271253.16sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 76542506.32sec, total: 76542506.32sec
train.py:442:<module>, cpu: 6.24ms, accelerator: 38271253.16sec, total: 38271253.17sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 38271253.16sec, total: 38271253.16sec
    train.py:322:loss_fn, cpu: 2.97ms, accelerator: 38271253.16sec, total: 38271253.16sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 38271253.16sec, total: 38271253.16sec
  train.py:359:image_losses, cpu: 2.64ms, accelerator: 1.55ms, total: 4.19ms
    train.py:322:loss_fn, cpu: 2.62ms, accelerator: 1.55ms, total: 4.18ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 1.14ms, total: 2.66ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 38271253.16sec, total: 38271253.16sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38271253.16sec, total: 38271253.16sec
  train.py:359:image_losses (gradient), cpu: 858us, accelerator: 564us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_120500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38192016.61sec, total: 38192016.61sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38192016.61sec, total: 38192016.61sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 38192016.61sec, total: 38192016.61sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 76384033.22sec, total: 76384033.22sec
train.py:442:<module>, cpu: 6.23ms, accelerator: 38192016.61sec, total: 38192016.62sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 38192016.61sec, total: 38192016.61sec
    train.py:322:loss_fn, cpu: 2.97ms, accelerator: 38192016.61sec, total: 38192016.61sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 38192016.61sec, total: 38192016.61sec
  train.py:359:image_losses, cpu: 2.63ms, accelerator: 1.56ms, total: 4.20ms
    train.py:322:loss_fn, cpu: 2.62ms, accelerator: 1.56ms, total: 4.19ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.16ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 38192016.61sec, total: 38192016.62sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38192016.61sec, total: 38192016.61sec
  train.py:359:image_losses (gradient), cpu: 857us, accelerator: 564us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_120750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38113107.48sec, total: 38113107.49sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38113107.48sec, total: 38113107.49sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 38113107.48sec, total: 38113107.48sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 76226214.97sec, total: 76226214.97sec
train.py:442:<module>, cpu: 6.23ms, accelerator: 38113107.49sec, total: 38113107.49sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 38113107.49sec, total: 38113107.49sec
    train.py:322:loss_fn, cpu: 2.97ms, accelerator: 38113107.49sec, total: 38113107.49sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 38113107.49sec, total: 38113107.49sec
  train.py:359:image_losses, cpu: 2.63ms, accelerator: 1.57ms, total: 4.22ms
    train.py:322:loss_fn, cpu: 2.62ms, accelerator: 1.57ms, total: 4.20ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.17ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 38113107.49sec, total: 38113107.49sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38113107.49sec, total: 38113107.49sec
  train.py:359:image_losses (gradient), cpu: 855us, accelerator: 562us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_121000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 38034523.76sec, total: 38034523.76sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 38034523.76sec, total: 38034523.76sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 38034523.76sec, total: 38034523.76sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 76069047.52sec, total: 76069047.52sec
train.py:442:<module>, cpu: 6.22ms, accelerator: 38034523.76sec, total: 38034523.77sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 38034523.76sec, total: 38034523.76sec
    train.py:322:loss_fn, cpu: 2.97ms, accelerator: 38034523.76sec, total: 38034523.76sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 38034523.76sec, total: 38034523.76sec
  train.py:359:image_losses, cpu: 2.63ms, accelerator: 1.57ms, total: 4.21ms
    train.py:322:loss_fn, cpu: 2.61ms, accelerator: 1.57ms, total: 4.20ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.16ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 38034523.76sec, total: 38034523.76sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 38034523.76sec, total: 38034523.76sec
  train.py:359:image_losses (gradient), cpu: 854us, accelerator: 561us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_121250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 37956263.42sec, total: 37956263.42sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 37956263.42sec, total: 37956263.42sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 398us, accelerator: 37956263.42sec, total: 37956263.42sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 75912526.84sec, total: 75912526.85sec
train.py:442:<module>, cpu: 6.22ms, accelerator: 37956263.42sec, total: 37956263.43sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 37956263.42sec, total: 37956263.42sec
    train.py:322:loss_fn, cpu: 2.97ms, accelerator: 37956263.42sec, total: 37956263.42sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 37956263.42sec, total: 37956263.42sec
  train.py:359:image_losses, cpu: 2.63ms, accelerator: 1.56ms, total: 4.21ms
    train.py:322:loss_fn, cpu: 2.62ms, accelerator: 1.56ms, total: 4.20ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.16ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 37956263.42sec, total: 37956263.43sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 37956263.42sec, total: 37956263.42sec
  train.py:359:image_losses (gradient), cpu: 855us, accelerator: 560us, total: 1.42ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_121500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 37878324.48sec, total: 37878324.48sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 37878324.48sec, total: 37878324.48sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 397us, accelerator: 37878324.48sec, total: 37878324.48sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 75756648.96sec, total: 75756648.97sec
train.py:442:<module>, cpu: 6.22ms, accelerator: 37878324.48sec, total: 37878324.49sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 37878324.48sec, total: 37878324.49sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37878324.48sec, total: 37878324.49sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 37878324.48sec, total: 37878324.49sec
  train.py:359:image_losses, cpu: 2.63ms, accelerator: 1.56ms, total: 4.21ms
    train.py:322:loss_fn, cpu: 2.61ms, accelerator: 1.56ms, total: 4.19ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.16ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 37878324.48sec, total: 37878324.49sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 37878324.48sec, total: 37878324.49sec
  train.py:359:image_losses (gradient), cpu: 862us, accelerator: 557us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_121750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 37800704.96sec, total: 37800704.97sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 37800704.96sec, total: 37800704.97sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 398us, accelerator: 37800704.96sec, total: 37800704.96sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 75601409.93sec, total: 75601409.93sec
train.py:442:<module>, cpu: 6.22ms, accelerator: 37800704.97sec, total: 37800704.97sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 37800704.96sec, total: 37800704.97sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37800704.96sec, total: 37800704.97sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 37800704.96sec, total: 37800704.97sec
  train.py:359:image_losses, cpu: 2.62ms, accelerator: 1.56ms, total: 4.20ms
    train.py:322:loss_fn, cpu: 2.61ms, accelerator: 1.56ms, total: 4.18ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.16ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 37800704.97sec, total: 37800704.97sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 37800704.97sec, total: 37800704.97sec
  train.py:359:image_losses (gradient), cpu: 861us, accelerator: 555us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_122000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 37723402.91sec, total: 37723402.91sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 37723402.91sec, total: 37723402.91sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 37723402.91sec, total: 37723402.91sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 75446805.82sec, total: 75446805.82sec
train.py:442:<module>, cpu: 6.21ms, accelerator: 37723402.91sec, total: 37723402.92sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 37723402.91sec, total: 37723402.91sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37723402.91sec, total: 37723402.91sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 37723402.91sec, total: 37723402.91sec
  train.py:359:image_losses, cpu: 2.62ms, accelerator: 1.57ms, total: 4.20ms
    train.py:322:loss_fn, cpu: 2.61ms, accelerator: 1.57ms, total: 4.18ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 1.16ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 37723402.91sec, total: 37723402.91sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 37723402.91sec, total: 37723402.91sec
  train.py:359:image_losses (gradient), cpu: 859us, accelerator: 554us, total: 1.42ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_122250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 37646416.37sec, total: 37646416.37sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 37646416.37sec, total: 37646416.37sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 37646416.37sec, total: 37646416.37sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 75292832.75sec, total: 75292832.75sec
train.py:442:<module>, cpu: 6.21ms, accelerator: 37646416.37sec, total: 37646416.38sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 37646416.37sec, total: 37646416.38sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37646416.37sec, total: 37646416.38sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 37646416.37sec, total: 37646416.38sec
  train.py:359:image_losses, cpu: 2.62ms, accelerator: 1.56ms, total: 4.19ms
    train.py:322:loss_fn, cpu: 2.60ms, accelerator: 1.56ms, total: 4.18ms
      train.py:342:hfe, cpu: 1.50ms, accelerator: 1.16ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 37646416.37sec, total: 37646416.38sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 37646416.37sec, total: 37646416.38sec
  train.py:359:image_losses (gradient), cpu: 859us, accelerator: 554us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_122500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 37569743.43sec, total: 37569743.43sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 37569743.43sec, total: 37569743.43sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 37569743.42sec, total: 37569743.42sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 75139486.85sec, total: 75139486.86sec
train.py:442:<module>, cpu: 6.20ms, accelerator: 37569743.43sec, total: 37569743.44sec
  train.py:360:image_losses, cpu: 2.98ms, accelerator: 37569743.43sec, total: 37569743.43sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37569743.43sec, total: 37569743.43sec
      train.py:349:msssim, cpu: 2.92ms, accelerator: 37569743.43sec, total: 37569743.43sec
  train.py:359:image_losses, cpu: 2.61ms, accelerator: 1.58ms, total: 4.21ms
    train.py:322:loss_fn, cpu: 2.60ms, accelerator: 1.58ms, total: 4.19ms
      train.py:342:hfe, cpu: 1.50ms, accelerator: 1.17ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 37569743.43sec, total: 37569743.43sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 37569743.43sec, total: 37569743.43sec
  train.py:359:image_losses (gradient), cpu: 857us, accelerator: 554us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_122750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 37493382.16sec, total: 37493382.16sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 37493382.16sec, total: 37493382.16sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 399us, accelerator: 37493382.16sec, total: 37493382.16sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 74986764.32sec, total: 74986764.32sec
train.py:442:<module>, cpu: 6.20ms, accelerator: 37493382.16sec, total: 37493382.17sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 37493382.16sec, total: 37493382.16sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37493382.16sec, total: 37493382.16sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 37493382.16sec, total: 37493382.16sec
  train.py:359:image_losses, cpu: 2.61ms, accelerator: 1.58ms, total: 4.20ms
    train.py:322:loss_fn, cpu: 2.60ms, accelerator: 1.58ms, total: 4.18ms
      train.py:342:hfe, cpu: 1.50ms, accelerator: 1.18ms, total: 2.68ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 37493382.16sec, total: 37493382.17sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 37493382.16sec, total: 37493382.16sec
  train.py:359:image_losses (gradient), cpu: 856us, accelerator: 553us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_123000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 37417330.67sec, total: 37417330.68sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 37417330.67sec, total: 37417330.68sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 398us, accelerator: 37417330.67sec, total: 37417330.67sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 74834661.35sec, total: 74834661.35sec
train.py:442:<module>, cpu: 6.20ms, accelerator: 37417330.68sec, total: 37417330.68sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 37417330.68sec, total: 37417330.68sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37417330.68sec, total: 37417330.68sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 37417330.68sec, total: 37417330.68sec
  train.py:359:image_losses, cpu: 2.61ms, accelerator: 1.58ms, total: 4.19ms
    train.py:322:loss_fn, cpu: 2.59ms, accelerator: 1.58ms, total: 4.18ms
      train.py:342:hfe, cpu: 1.50ms, accelerator: 1.17ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 37417330.68sec, total: 37417330.68sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 37417330.68sec, total: 37417330.68sec
  train.py:359:image_losses (gradient), cpu: 856us, accelerator: 553us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2035.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_123250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 37341587.09sec, total: 37341587.09sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 37341587.09sec, total: 37341587.09sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 398us, accelerator: 37341587.09sec, total: 37341587.09sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 74683174.18sec, total: 74683174.18sec
train.py:442:<module>, cpu: 6.19ms, accelerator: 37341587.09sec, total: 37341587.10sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 37341587.09sec, total: 37341587.09sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37341587.09sec, total: 37341587.09sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 37341587.09sec, total: 37341587.09sec
  train.py:359:image_losses, cpu: 2.60ms, accelerator: 1.57ms, total: 4.19ms
    train.py:322:loss_fn, cpu: 2.59ms, accelerator: 1.57ms, total: 4.17ms
      train.py:342:hfe, cpu: 1.50ms, accelerator: 1.17ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 37341587.09sec, total: 37341587.10sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 37341587.09sec, total: 37341587.09sec
  train.py:359:image_losses (gradient), cpu: 855us, accelerator: 548us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2029.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_123500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 37266149.54sec, total: 37266149.54sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 37266149.54sec, total: 37266149.54sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 398us, accelerator: 37266149.54sec, total: 37266149.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 74532299.08sec, total: 74532299.09sec
train.py:442:<module>, cpu: 6.19ms, accelerator: 37266149.54sec, total: 37266149.55sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 37266149.54sec, total: 37266149.54sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37266149.54sec, total: 37266149.54sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 37266149.54sec, total: 37266149.54sec
  train.py:359:image_losses, cpu: 2.60ms, accelerator: 1.57ms, total: 4.18ms
    train.py:322:loss_fn, cpu: 2.58ms, accelerator: 1.57ms, total: 4.17ms
      train.py:342:hfe, cpu: 1.49ms, accelerator: 1.17ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 37266149.54sec, total: 37266149.55sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 37266149.54sec, total: 37266149.54sec
  train.py:359:image_losses (gradient), cpu: 855us, accelerator: 548us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_123750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 37191016.17sec, total: 37191016.18sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 37191016.17sec, total: 37191016.18sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 398us, accelerator: 37191016.17sec, total: 37191016.17sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 74382032.35sec, total: 74382032.35sec
train.py:442:<module>, cpu: 6.18ms, accelerator: 37191016.18sec, total: 37191016.18sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 37191016.17sec, total: 37191016.18sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37191016.17sec, total: 37191016.18sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 37191016.17sec, total: 37191016.18sec
  train.py:359:image_losses, cpu: 2.59ms, accelerator: 1.57ms, total: 4.17ms
    train.py:322:loss_fn, cpu: 2.58ms, accelerator: 1.57ms, total: 4.16ms
      train.py:342:hfe, cpu: 1.49ms, accelerator: 1.17ms, total: 2.66ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 37191016.18sec, total: 37191016.18sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 37191016.18sec, total: 37191016.18sec
  train.py:359:image_losses (gradient), cpu: 856us, accelerator: 548us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_124000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 37116185.16sec, total: 37116185.16sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 37116185.15sec, total: 37116185.16sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 398us, accelerator: 37116185.15sec, total: 37116185.15sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 74232370.31sec, total: 74232370.32sec
train.py:442:<module>, cpu: 6.17ms, accelerator: 37116185.16sec, total: 37116185.16sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 37116185.16sec, total: 37116185.16sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 37116185.16sec, total: 37116185.16sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 37116185.16sec, total: 37116185.16sec
  train.py:359:image_losses, cpu: 2.59ms, accelerator: 1.57ms, total: 4.17ms
    train.py:322:loss_fn, cpu: 2.58ms, accelerator: 1.57ms, total: 4.15ms
      train.py:342:hfe, cpu: 1.49ms, accelerator: 1.17ms, total: 2.66ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 37116185.16sec, total: 37116185.16sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 37116185.16sec, total: 37116185.16sec
  train.py:359:image_losses (gradient), cpu: 853us, accelerator: 547us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_124250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 37041654.66sec, total: 37041654.67sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 37041654.66sec, total: 37041654.66sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 397us, accelerator: 37041654.66sec, total: 37041654.66sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 74083309.33sec, total: 74083309.33sec
train.py:442:<module>, cpu: 6.17ms, accelerator: 37041654.67sec, total: 37041654.67sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 37041654.66sec, total: 37041654.67sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 37041654.66sec, total: 37041654.67sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 37041654.66sec, total: 37041654.67sec
  train.py:359:image_losses, cpu: 2.59ms, accelerator: 1.57ms, total: 4.17ms
    train.py:322:loss_fn, cpu: 2.58ms, accelerator: 1.57ms, total: 4.15ms
      train.py:342:hfe, cpu: 1.49ms, accelerator: 1.17ms, total: 2.66ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 37041654.67sec, total: 37041654.67sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 37041654.66sec, total: 37041654.67sec
  train.py:359:image_losses (gradient), cpu: 852us, accelerator: 547us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_124500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 36967422.89sec, total: 36967422.89sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 36967422.89sec, total: 36967422.89sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 397us, accelerator: 36967422.89sec, total: 36967422.89sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 73934845.78sec, total: 73934845.79sec
train.py:442:<module>, cpu: 6.17ms, accelerator: 36967422.89sec, total: 36967422.90sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 36967422.89sec, total: 36967422.89sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 36967422.89sec, total: 36967422.89sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 36967422.89sec, total: 36967422.89sec
  train.py:359:image_losses, cpu: 2.59ms, accelerator: 1.58ms, total: 4.17ms
    train.py:322:loss_fn, cpu: 2.57ms, accelerator: 1.58ms, total: 4.16ms
      train.py:342:hfe, cpu: 1.49ms, accelerator: 1.17ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 36967422.89sec, total: 36967422.90sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 36967422.89sec, total: 36967422.89sec
  train.py:359:image_losses (gradient), cpu: 851us, accelerator: 545us, total: 1.40ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_124750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 36893488.05sec, total: 36893488.05sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 36893488.04sec, total: 36893488.05sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 36893488.04sec, total: 36893488.04sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 73786976.09sec, total: 73786976.09sec
train.py:442:<module>, cpu: 6.17ms, accelerator: 36893488.05sec, total: 36893488.05sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 36893488.05sec, total: 36893488.05sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 36893488.05sec, total: 36893488.05sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 36893488.05sec, total: 36893488.05sec
  train.py:359:image_losses, cpu: 2.59ms, accelerator: 1.57ms, total: 4.18ms
    train.py:322:loss_fn, cpu: 2.58ms, accelerator: 1.57ms, total: 4.16ms
      train.py:342:hfe, cpu: 1.49ms, accelerator: 1.18ms, total: 2.67ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 36893488.05sec, total: 36893488.05sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36893488.05sec, total: 36893488.05sec
  train.py:359:image_losses (gradient), cpu: 849us, accelerator: 545us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_125000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 36819848.35sec, total: 36819848.35sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 36819848.35sec, total: 36819848.35sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 36819848.35sec, total: 36819848.35sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 73639696.70sec, total: 73639696.70sec
train.py:442:<module>, cpu: 6.17ms, accelerator: 36819848.35sec, total: 36819848.36sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 36819848.35sec, total: 36819848.35sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 36819848.35sec, total: 36819848.35sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 36819848.35sec, total: 36819848.35sec
  train.py:359:image_losses, cpu: 2.59ms, accelerator: 1.57ms, total: 4.17ms
    train.py:322:loss_fn, cpu: 2.58ms, accelerator: 1.57ms, total: 4.16ms
      train.py:342:hfe, cpu: 1.48ms, accelerator: 1.18ms, total: 2.66ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 36819848.35sec, total: 36819848.35sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36819848.35sec, total: 36819848.35sec
  train.py:359:image_losses (gradient), cpu: 850us, accelerator: 545us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_125250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36746502.04sec, total: 36746502.04sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 36746502.04sec, total: 36746502.04sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 36746502.03sec, total: 36746502.04sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 73493004.07sec, total: 73493004.08sec
train.py:442:<module>, cpu: 6.17ms, accelerator: 36746502.04sec, total: 36746502.05sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 36746502.04sec, total: 36746502.04sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 36746502.04sec, total: 36746502.04sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 36746502.04sec, total: 36746502.04sec
  train.py:359:image_losses, cpu: 2.59ms, accelerator: 1.57ms, total: 4.17ms
    train.py:322:loss_fn, cpu: 2.57ms, accelerator: 1.57ms, total: 4.16ms
      train.py:342:hfe, cpu: 1.48ms, accelerator: 1.17ms, total: 2.66ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 36746502.04sec, total: 36746502.04sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36746502.04sec, total: 36746502.04sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 542us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_125500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36673447.36sec, total: 36673447.36sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36673447.36sec, total: 36673447.36sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 36673447.36sec, total: 36673447.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 73346894.72sec, total: 73346894.73sec
train.py:442:<module>, cpu: 6.17ms, accelerator: 36673447.36sec, total: 36673447.37sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 36673447.36sec, total: 36673447.36sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 36673447.36sec, total: 36673447.36sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 36673447.36sec, total: 36673447.36sec
  train.py:359:image_losses, cpu: 2.58ms, accelerator: 1.57ms, total: 4.17ms
    train.py:322:loss_fn, cpu: 2.57ms, accelerator: 1.57ms, total: 4.15ms
      train.py:342:hfe, cpu: 1.48ms, accelerator: 1.17ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 36673447.36sec, total: 36673447.37sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36673447.36sec, total: 36673447.36sec
  train.py:359:image_losses (gradient), cpu: 853us, accelerator: 541us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_125750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36600682.58sec, total: 36600682.59sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36600682.58sec, total: 36600682.59sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 36600682.58sec, total: 36600682.58sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 73201365.17sec, total: 73201365.17sec
train.py:442:<module>, cpu: 6.17ms, accelerator: 36600682.59sec, total: 36600682.59sec
  train.py:360:image_losses, cpu: 2.97ms, accelerator: 36600682.59sec, total: 36600682.59sec
    train.py:322:loss_fn, cpu: 2.96ms, accelerator: 36600682.59sec, total: 36600682.59sec
      train.py:349:msssim, cpu: 2.91ms, accelerator: 36600682.59sec, total: 36600682.59sec
  train.py:359:image_losses, cpu: 2.58ms, accelerator: 1.57ms, total: 4.16ms
    train.py:322:loss_fn, cpu: 2.57ms, accelerator: 1.57ms, total: 4.15ms
      train.py:342:hfe, cpu: 1.48ms, accelerator: 1.17ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 36600682.59sec, total: 36600682.59sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36600682.59sec, total: 36600682.59sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 541us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_126000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36528205.99sec, total: 36528205.99sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36528205.98sec, total: 36528205.99sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 36528205.98sec, total: 36528205.98sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 73056411.97sec, total: 73056411.98sec
train.py:442:<module>, cpu: 6.17ms, accelerator: 36528205.99sec, total: 36528205.99sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 36528205.99sec, total: 36528205.99sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 36528205.99sec, total: 36528205.99sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 36528205.99sec, total: 36528205.99sec
  train.py:359:image_losses, cpu: 2.58ms, accelerator: 1.57ms, total: 4.16ms
    train.py:322:loss_fn, cpu: 2.56ms, accelerator: 1.57ms, total: 4.14ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.17ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 36528205.99sec, total: 36528205.99sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36528205.99sec, total: 36528205.99sec
  train.py:359:image_losses (gradient), cpu: 847us, accelerator: 539us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_126250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36456015.85sec, total: 36456015.86sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36456015.85sec, total: 36456015.86sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 36456015.85sec, total: 36456015.85sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 72912031.71sec, total: 72912031.71sec
train.py:442:<module>, cpu: 6.16ms, accelerator: 36456015.86sec, total: 36456015.86sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 36456015.86sec, total: 36456015.86sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 36456015.86sec, total: 36456015.86sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 36456015.86sec, total: 36456015.86sec
  train.py:359:image_losses, cpu: 2.58ms, accelerator: 1.57ms, total: 4.16ms
    train.py:322:loss_fn, cpu: 2.56ms, accelerator: 1.57ms, total: 4.14ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.17ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 36456015.86sec, total: 36456015.86sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36456015.86sec, total: 36456015.86sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 539us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_126500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36384110.50sec, total: 36384110.50sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36384110.50sec, total: 36384110.50sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 36384110.50sec, total: 36384110.50sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 72768221.00sec, total: 72768221.00sec
train.py:442:<module>, cpu: 6.16ms, accelerator: 36384110.50sec, total: 36384110.51sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 36384110.50sec, total: 36384110.50sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 36384110.50sec, total: 36384110.50sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 36384110.50sec, total: 36384110.50sec
  train.py:359:image_losses, cpu: 2.57ms, accelerator: 1.57ms, total: 4.15ms
    train.py:322:loss_fn, cpu: 2.56ms, accelerator: 1.57ms, total: 4.14ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.17ms, total: 2.65ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 36384110.50sec, total: 36384110.50sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36384110.50sec, total: 36384110.50sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 539us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_126750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36312488.23sec, total: 36312488.23sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36312488.23sec, total: 36312488.23sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 36312488.23sec, total: 36312488.23sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 72624976.47sec, total: 72624976.47sec
train.py:442:<module>, cpu: 6.15ms, accelerator: 36312488.24sec, total: 36312488.24sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 36312488.23sec, total: 36312488.24sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 36312488.23sec, total: 36312488.24sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 36312488.23sec, total: 36312488.24sec
  train.py:359:image_losses, cpu: 2.57ms, accelerator: 1.57ms, total: 4.14ms
    train.py:322:loss_fn, cpu: 2.55ms, accelerator: 1.57ms, total: 4.13ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.17ms, total: 2.64ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 36312488.24sec, total: 36312488.24sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36312488.23sec, total: 36312488.24sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 539us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_127000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36241147.39sec, total: 36241147.39sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36241147.39sec, total: 36241147.39sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 36241147.39sec, total: 36241147.39sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 72482294.78sec, total: 72482294.79sec
train.py:442:<module>, cpu: 6.15ms, accelerator: 36241147.39sec, total: 36241147.40sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 36241147.39sec, total: 36241147.40sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 36241147.39sec, total: 36241147.40sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 36241147.39sec, total: 36241147.40sec
  train.py:359:image_losses, cpu: 2.56ms, accelerator: 1.56ms, total: 4.14ms
    train.py:322:loss_fn, cpu: 2.55ms, accelerator: 1.56ms, total: 4.12ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.17ms, total: 2.64ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 36241147.39sec, total: 36241147.40sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36241147.39sec, total: 36241147.40sec
  train.py:359:image_losses (gradient), cpu: 844us, accelerator: 537us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_127250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36170086.32sec, total: 36170086.32sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36170086.32sec, total: 36170086.32sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 36170086.32sec, total: 36170086.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 72340172.64sec, total: 72340172.64sec
train.py:442:<module>, cpu: 6.16ms, accelerator: 36170086.32sec, total: 36170086.33sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 36170086.32sec, total: 36170086.32sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 36170086.32sec, total: 36170086.32sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 36170086.32sec, total: 36170086.32sec
  train.py:359:image_losses, cpu: 2.57ms, accelerator: 1.56ms, total: 4.13ms
    train.py:322:loss_fn, cpu: 2.55ms, accelerator: 1.56ms, total: 4.12ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.17ms, total: 2.63ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 36170086.32sec, total: 36170086.32sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36170086.32sec, total: 36170086.32sec
  train.py:359:image_losses (gradient), cpu: 842us, accelerator: 536us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2043.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_127500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36099303.37sec, total: 36099303.37sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36099303.37sec, total: 36099303.37sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 36099303.37sec, total: 36099303.37sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 72198606.74sec, total: 72198606.75sec
train.py:442:<module>, cpu: 6.16ms, accelerator: 36099303.37sec, total: 36099303.38sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 36099303.37sec, total: 36099303.37sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 36099303.37sec, total: 36099303.37sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 36099303.37sec, total: 36099303.37sec
  train.py:359:image_losses, cpu: 2.56ms, accelerator: 1.56ms, total: 4.13ms
    train.py:322:loss_fn, cpu: 2.55ms, accelerator: 1.56ms, total: 4.12ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 1.16ms, total: 2.63ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 36099303.37sec, total: 36099303.38sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36099303.37sec, total: 36099303.37sec
  train.py:359:image_losses (gradient), cpu: 842us, accelerator: 535us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_127750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 36028796.92sec, total: 36028796.92sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36028796.92sec, total: 36028796.92sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 36028796.92sec, total: 36028796.92sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 72057593.84sec, total: 72057593.84sec
train.py:442:<module>, cpu: 6.15ms, accelerator: 36028796.92sec, total: 36028796.93sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 36028796.92sec, total: 36028796.92sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 36028796.92sec, total: 36028796.92sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 36028796.92sec, total: 36028796.92sec
  train.py:359:image_losses, cpu: 2.56ms, accelerator: 1.55ms, total: 4.12ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.55ms, total: 4.11ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.16ms, total: 2.63ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 36028796.92sec, total: 36028796.92sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 36028796.92sec, total: 36028796.92sec
  train.py:359:image_losses (gradient), cpu: 839us, accelerator: 539us, total: 1.39ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_128000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 35958565.35sec, total: 35958565.35sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35958565.35sec, total: 35958565.35sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35958565.34sec, total: 35958565.34sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 71917130.69sec, total: 71917130.70sec
train.py:442:<module>, cpu: 6.15ms, accelerator: 35958565.35sec, total: 35958565.35sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 35958565.35sec, total: 35958565.35sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 35958565.35sec, total: 35958565.35sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 35958565.35sec, total: 35958565.35sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.55ms, total: 4.12ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.55ms, total: 4.10ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.16ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 35958565.35sec, total: 35958565.35sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35958565.35sec, total: 35958565.35sec
  train.py:359:image_losses (gradient), cpu: 836us, accelerator: 537us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_128250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 35888607.05sec, total: 35888607.05sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35888607.05sec, total: 35888607.05sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35888607.05sec, total: 35888607.05sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 71777214.10sec, total: 71777214.10sec
train.py:442:<module>, cpu: 6.14ms, accelerator: 35888607.05sec, total: 35888607.06sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 35888607.05sec, total: 35888607.05sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 35888607.05sec, total: 35888607.05sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 35888607.05sec, total: 35888607.05sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.55ms, total: 4.11ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.55ms, total: 4.10ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.16ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35888607.05sec, total: 35888607.05sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35888607.05sec, total: 35888607.05sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 542us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_128500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 35818920.43sec, total: 35818920.43sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35818920.43sec, total: 35818920.43sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35818920.43sec, total: 35818920.43sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 71637840.86sec, total: 71637840.87sec
train.py:442:<module>, cpu: 6.13ms, accelerator: 35818920.43sec, total: 35818920.44sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 35818920.43sec, total: 35818920.44sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 35818920.43sec, total: 35818920.44sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 35818920.43sec, total: 35818920.44sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.55ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.55ms, total: 4.09ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.15ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35818920.43sec, total: 35818920.44sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35818920.43sec, total: 35818920.44sec
  train.py:359:image_losses (gradient), cpu: 833us, accelerator: 540us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_128750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 35749503.92sec, total: 35749503.92sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35749503.92sec, total: 35749503.92sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35749503.92sec, total: 35749503.92sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 71499007.84sec, total: 71499007.84sec
train.py:442:<module>, cpu: 6.13ms, accelerator: 35749503.92sec, total: 35749503.93sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 35749503.92sec, total: 35749503.92sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 35749503.92sec, total: 35749503.92sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 35749503.92sec, total: 35749503.92sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.55ms, total: 4.11ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.55ms, total: 4.09ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 1.16ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 35749503.92sec, total: 35749503.93sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35749503.92sec, total: 35749503.92sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 543us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_129000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 35680355.94sec, total: 35680355.94sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35680355.94sec, total: 35680355.94sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35680355.94sec, total: 35680355.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 71360711.89sec, total: 71360711.89sec
train.py:442:<module>, cpu: 6.13ms, accelerator: 35680355.95sec, total: 35680355.95sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 35680355.94sec, total: 35680355.95sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 35680355.94sec, total: 35680355.95sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 35680355.94sec, total: 35680355.95sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.55ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.55ms, total: 4.09ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.16ms, total: 2.62ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 35680355.94sec, total: 35680355.95sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35680355.94sec, total: 35680355.95sec
  train.py:359:image_losses (gradient), cpu: 835us, accelerator: 543us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_129250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 35611474.95sec, total: 35611474.95sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35611474.95sec, total: 35611474.95sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35611474.94sec, total: 35611474.95sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 71222949.89sec, total: 71222949.90sec
train.py:442:<module>, cpu: 6.12ms, accelerator: 35611474.95sec, total: 35611474.96sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 35611474.95sec, total: 35611474.95sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 35611474.95sec, total: 35611474.95sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 35611474.95sec, total: 35611474.95sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.55ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.55ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.16ms, total: 2.61ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35611474.95sec, total: 35611474.95sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35611474.95sec, total: 35611474.95sec
  train.py:359:image_losses (gradient), cpu: 833us, accelerator: 541us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_129500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 35542859.39sec, total: 35542859.39sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35542859.39sec, total: 35542859.39sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35542859.39sec, total: 35542859.39sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 71085718.78sec, total: 71085718.78sec
train.py:442:<module>, cpu: 6.12ms, accelerator: 35542859.39sec, total: 35542859.40sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 35542859.39sec, total: 35542859.39sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 35542859.39sec, total: 35542859.39sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 35542859.39sec, total: 35542859.39sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.55ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.55ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.15ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35542859.39sec, total: 35542859.39sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35542859.39sec, total: 35542859.39sec
  train.py:359:image_losses (gradient), cpu: 832us, accelerator: 541us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2040.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_129750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 35474507.74sec, total: 35474507.74sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 35474507.73sec, total: 35474507.74sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35474507.73sec, total: 35474507.73sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 70949015.47sec, total: 70949015.48sec
train.py:442:<module>, cpu: 6.13ms, accelerator: 35474507.74sec, total: 35474507.74sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 35474507.74sec, total: 35474507.74sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 35474507.74sec, total: 35474507.74sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 35474507.74sec, total: 35474507.74sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.54ms, total: 4.11ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.54ms, total: 4.09ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 1.15ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35474507.74sec, total: 35474507.74sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35474507.74sec, total: 35474507.74sec
  train.py:359:image_losses (gradient), cpu: 832us, accelerator: 540us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_130000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 35406418.47sec, total: 35406418.47sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35406418.47sec, total: 35406418.47sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35406418.47sec, total: 35406418.47sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 70812836.94sec, total: 70812836.94sec
train.py:442:<module>, cpu: 6.12ms, accelerator: 35406418.47sec, total: 35406418.48sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 35406418.47sec, total: 35406418.47sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 35406418.47sec, total: 35406418.47sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 35406418.47sec, total: 35406418.47sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.54ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.54ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.44ms, accelerator: 1.15ms, total: 2.60ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35406418.47sec, total: 35406418.48sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35406418.47sec, total: 35406418.47sec
  train.py:359:image_losses (gradient), cpu: 832us, accelerator: 539us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_130250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 35338590.08sec, total: 35338590.08sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35338590.08sec, total: 35338590.08sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35338590.08sec, total: 35338590.08sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 70677180.16sec, total: 70677180.17sec
train.py:442:<module>, cpu: 6.12ms, accelerator: 35338590.08sec, total: 35338590.09sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 35338590.08sec, total: 35338590.09sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 35338590.08sec, total: 35338590.09sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 35338590.08sec, total: 35338590.09sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.54ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.54ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.44ms, accelerator: 1.15ms, total: 2.59ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35338590.08sec, total: 35338590.09sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35338590.08sec, total: 35338590.09sec
  train.py:359:image_losses (gradient), cpu: 832us, accelerator: 538us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_130500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 35271021.08sec, total: 35271021.08sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35271021.07sec, total: 35271021.08sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 35271021.07sec, total: 35271021.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 70542042.15sec, total: 70542042.16sec
train.py:442:<module>, cpu: 6.11ms, accelerator: 35271021.08sec, total: 35271021.08sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 35271021.08sec, total: 35271021.08sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 35271021.08sec, total: 35271021.08sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 35271021.08sec, total: 35271021.08sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.54ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.54ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.44ms, accelerator: 1.15ms, total: 2.59ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35271021.08sec, total: 35271021.08sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35271021.08sec, total: 35271021.08sec
  train.py:359:image_losses (gradient), cpu: 832us, accelerator: 538us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_130750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 35203709.97sec, total: 35203709.97sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35203709.97sec, total: 35203709.97sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35203709.96sec, total: 35203709.96sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 70407419.93sec, total: 70407419.94sec
train.py:442:<module>, cpu: 6.11ms, accelerator: 35203709.97sec, total: 35203709.98sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 35203709.97sec, total: 35203709.97sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 35203709.97sec, total: 35203709.97sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 35203709.97sec, total: 35203709.97sec
  train.py:359:image_losses, cpu: 2.54ms, accelerator: 1.53ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.53ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.44ms, accelerator: 1.14ms, total: 2.58ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35203709.97sec, total: 35203709.97sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35203709.97sec, total: 35203709.97sec
  train.py:359:image_losses (gradient), cpu: 830us, accelerator: 561us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_131000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 35136655.28sec, total: 35136655.28sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35136655.28sec, total: 35136655.28sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35136655.28sec, total: 35136655.28sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 70273310.56sec, total: 70273310.57sec
train.py:442:<module>, cpu: 6.11ms, accelerator: 35136655.28sec, total: 35136655.29sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 35136655.28sec, total: 35136655.28sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 35136655.28sec, total: 35136655.28sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 35136655.28sec, total: 35136655.28sec
  train.py:359:image_losses, cpu: 2.53ms, accelerator: 1.56ms, total: 4.11ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.56ms, total: 4.09ms
      train.py:342:hfe, cpu: 1.43ms, accelerator: 1.14ms, total: 2.58ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35136655.28sec, total: 35136655.29sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35136655.28sec, total: 35136655.28sec
  train.py:359:image_losses (gradient), cpu: 829us, accelerator: 559us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_131250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 35069855.56sec, total: 35069855.56sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35069855.56sec, total: 35069855.56sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 35069855.55sec, total: 35069855.55sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 70139711.11sec, total: 70139711.12sec
train.py:442:<module>, cpu: 6.11ms, accelerator: 35069855.56sec, total: 35069855.56sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 35069855.56sec, total: 35069855.56sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 35069855.56sec, total: 35069855.56sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 35069855.56sec, total: 35069855.56sec
  train.py:359:image_losses, cpu: 2.53ms, accelerator: 1.56ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.52ms, accelerator: 1.56ms, total: 4.09ms
      train.py:342:hfe, cpu: 1.43ms, accelerator: 1.14ms, total: 2.58ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 35069855.56sec, total: 35069855.56sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35069855.56sec, total: 35069855.56sec
  train.py:359:image_losses (gradient), cpu: 829us, accelerator: 560us, total: 1.40ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_131500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 35003309.34sec, total: 35003309.34sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35003309.34sec, total: 35003309.34sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 35003309.34sec, total: 35003309.34sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 70006618.68sec, total: 70006618.69sec
train.py:442:<module>, cpu: 6.10ms, accelerator: 35003309.34sec, total: 35003309.35sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 35003309.34sec, total: 35003309.34sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 35003309.34sec, total: 35003309.34sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 35003309.34sec, total: 35003309.34sec
  train.py:359:image_losses, cpu: 2.53ms, accelerator: 1.56ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.51ms, accelerator: 1.56ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.43ms, accelerator: 1.14ms, total: 2.57ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 35003309.34sec, total: 35003309.35sec
  train.py:360:image_losses (gradient), cpu: 2.73ms, accelerator: 35003309.34sec, total: 35003309.34sec
  train.py:359:image_losses (gradient), cpu: 854us, accelerator: 560us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_131750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34937015.19sec, total: 34937015.20sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34937015.19sec, total: 34937015.20sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 34937015.19sec, total: 34937015.19sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 69874030.39sec, total: 69874030.39sec
train.py:442:<module>, cpu: 6.10ms, accelerator: 34937015.20sec, total: 34937015.20sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34937015.20sec, total: 34937015.20sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34937015.20sec, total: 34937015.20sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34937015.19sec, total: 34937015.20sec
  train.py:359:image_losses, cpu: 2.53ms, accelerator: 1.56ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.51ms, accelerator: 1.56ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.43ms, accelerator: 1.14ms, total: 2.57ms
train.py:442:<module> (gradient), cpu: 3.84ms, accelerator: 34937015.20sec, total: 34937015.20sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 34937015.20sec, total: 34937015.20sec
  train.py:359:image_losses (gradient), cpu: 854us, accelerator: 558us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2031.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_132000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34870971.69sec, total: 34870971.69sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34870971.69sec, total: 34870971.69sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 396us, accelerator: 34870971.69sec, total: 34870971.69sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 69741943.38sec, total: 69741943.38sec
train.py:442:<module>, cpu: 6.10ms, accelerator: 34870971.69sec, total: 34870971.70sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34870971.69sec, total: 34870971.69sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34870971.69sec, total: 34870971.69sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34870971.69sec, total: 34870971.69sec
  train.py:359:image_losses, cpu: 2.52ms, accelerator: 1.55ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.51ms, accelerator: 1.55ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.43ms, accelerator: 1.13ms, total: 2.56ms
train.py:442:<module> (gradient), cpu: 3.84ms, accelerator: 34870971.69sec, total: 34870971.69sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 34870971.69sec, total: 34870971.69sec
  train.py:359:image_losses (gradient), cpu: 854us, accelerator: 557us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_132250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34805177.40sec, total: 34805177.40sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34805177.40sec, total: 34805177.40sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 34805177.40sec, total: 34805177.40sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 69610354.80sec, total: 69610354.81sec
train.py:442:<module>, cpu: 6.10ms, accelerator: 34805177.40sec, total: 34805177.41sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34805177.40sec, total: 34805177.40sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34805177.40sec, total: 34805177.40sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34805177.40sec, total: 34805177.40sec
  train.py:359:image_losses, cpu: 2.53ms, accelerator: 1.55ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.51ms, accelerator: 1.55ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.42ms, accelerator: 1.13ms, total: 2.56ms
train.py:442:<module> (gradient), cpu: 3.84ms, accelerator: 34805177.40sec, total: 34805177.41sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 34805177.40sec, total: 34805177.40sec
  train.py:359:image_losses (gradient), cpu: 852us, accelerator: 559us, total: 1.42ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_132500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34739630.93sec, total: 34739630.93sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34739630.93sec, total: 34739630.93sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 34739630.93sec, total: 34739630.93sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 69479261.86sec, total: 69479261.86sec
train.py:442:<module>, cpu: 6.09ms, accelerator: 34739630.93sec, total: 34739630.94sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34739630.93sec, total: 34739630.93sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34739630.93sec, total: 34739630.93sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34739630.93sec, total: 34739630.93sec
  train.py:359:image_losses, cpu: 2.52ms, accelerator: 1.57ms, total: 4.11ms
    train.py:322:loss_fn, cpu: 2.51ms, accelerator: 1.57ms, total: 4.09ms
      train.py:342:hfe, cpu: 1.42ms, accelerator: 1.13ms, total: 2.56ms
train.py:442:<module> (gradient), cpu: 3.84ms, accelerator: 34739630.93sec, total: 34739630.93sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 34739630.93sec, total: 34739630.93sec
  train.py:359:image_losses (gradient), cpu: 852us, accelerator: 559us, total: 1.42ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_132750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34674330.87sec, total: 34674330.87sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34674330.87sec, total: 34674330.87sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 34674330.87sec, total: 34674330.87sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 69348661.74sec, total: 69348661.74sec
train.py:442:<module>, cpu: 6.09ms, accelerator: 34674330.87sec, total: 34674330.88sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34674330.87sec, total: 34674330.87sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34674330.87sec, total: 34674330.87sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34674330.87sec, total: 34674330.87sec
  train.py:359:image_losses, cpu: 2.52ms, accelerator: 1.57ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.51ms, accelerator: 1.57ms, total: 4.09ms
      train.py:342:hfe, cpu: 1.42ms, accelerator: 1.13ms, total: 2.55ms
train.py:442:<module> (gradient), cpu: 3.84ms, accelerator: 34674330.87sec, total: 34674330.88sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 34674330.87sec, total: 34674330.87sec
  train.py:359:image_losses (gradient), cpu: 852us, accelerator: 559us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_133000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34609275.84sec, total: 34609275.84sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34609275.84sec, total: 34609275.84sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 34609275.84sec, total: 34609275.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 69218551.68sec, total: 69218551.68sec
train.py:442:<module>, cpu: 6.08ms, accelerator: 34609275.84sec, total: 34609275.85sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34609275.84sec, total: 34609275.84sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34609275.84sec, total: 34609275.84sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34609275.84sec, total: 34609275.84sec
  train.py:359:image_losses, cpu: 2.52ms, accelerator: 1.57ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.50ms, accelerator: 1.57ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.42ms, accelerator: 1.12ms, total: 2.54ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 34609275.84sec, total: 34609275.85sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 34609275.84sec, total: 34609275.84sec
  train.py:359:image_losses (gradient), cpu: 850us, accelerator: 558us, total: 1.41ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_133250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34544464.46sec, total: 34544464.46sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34544464.46sec, total: 34544464.46sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 34544464.46sec, total: 34544464.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 69088928.92sec, total: 69088928.93sec
train.py:442:<module>, cpu: 6.08ms, accelerator: 34544464.46sec, total: 34544464.47sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34544464.46sec, total: 34544464.47sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34544464.46sec, total: 34544464.47sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34544464.46sec, total: 34544464.47sec
  train.py:359:image_losses, cpu: 2.51ms, accelerator: 1.56ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.50ms, accelerator: 1.56ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.42ms, accelerator: 1.12ms, total: 2.54ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 34544464.46sec, total: 34544464.47sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 34544464.46sec, total: 34544464.47sec
  train.py:359:image_losses (gradient), cpu: 849us, accelerator: 557us, total: 1.41ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_133500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34479895.37sec, total: 34479895.37sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34479895.37sec, total: 34479895.37sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 34479895.37sec, total: 34479895.37sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 68959790.74sec, total: 68959790.74sec
train.py:442:<module>, cpu: 6.07ms, accelerator: 34479895.37sec, total: 34479895.38sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 34479895.37sec, total: 34479895.37sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 34479895.37sec, total: 34479895.37sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 34479895.37sec, total: 34479895.37sec
  train.py:359:image_losses, cpu: 2.51ms, accelerator: 1.56ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.50ms, accelerator: 1.56ms, total: 4.07ms
      train.py:342:hfe, cpu: 1.42ms, accelerator: 1.12ms, total: 2.54ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 34479895.37sec, total: 34479895.38sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 34479895.37sec, total: 34479895.37sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 555us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_133750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34415567.21sec, total: 34415567.21sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34415567.21sec, total: 34415567.21sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 34415567.20sec, total: 34415567.20sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 68831134.41sec, total: 68831134.42sec
train.py:442:<module>, cpu: 6.07ms, accelerator: 34415567.21sec, total: 34415567.21sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34415567.21sec, total: 34415567.21sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34415567.21sec, total: 34415567.21sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34415567.21sec, total: 34415567.21sec
  train.py:359:image_losses, cpu: 2.51ms, accelerator: 1.56ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.50ms, accelerator: 1.56ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.41ms, accelerator: 1.12ms, total: 2.53ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 34415567.21sec, total: 34415567.21sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 34415567.21sec, total: 34415567.21sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 553us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_134000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34351478.63sec, total: 34351478.63sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34351478.63sec, total: 34351478.63sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 34351478.62sec, total: 34351478.63sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 68702957.25sec, total: 68702957.26sec
train.py:442:<module>, cpu: 6.07ms, accelerator: 34351478.63sec, total: 34351478.64sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34351478.63sec, total: 34351478.63sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34351478.63sec, total: 34351478.63sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34351478.63sec, total: 34351478.63sec
  train.py:359:image_losses, cpu: 2.51ms, accelerator: 1.55ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.49ms, accelerator: 1.55ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.41ms, accelerator: 1.12ms, total: 2.53ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 34351478.63sec, total: 34351478.63sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 34351478.63sec, total: 34351478.63sec
  train.py:359:image_losses (gradient), cpu: 847us, accelerator: 552us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2040.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_134250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34287628.29sec, total: 34287628.30sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34287628.29sec, total: 34287628.30sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 395us, accelerator: 34287628.29sec, total: 34287628.29sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 68575256.59sec, total: 68575256.59sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 34287628.30sec, total: 34287628.30sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34287628.30sec, total: 34287628.30sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34287628.30sec, total: 34287628.30sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34287628.30sec, total: 34287628.30sec
  train.py:359:image_losses, cpu: 2.50ms, accelerator: 1.55ms, total: 4.07ms
    train.py:322:loss_fn, cpu: 2.49ms, accelerator: 1.55ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.41ms, accelerator: 1.12ms, total: 2.53ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 34287628.30sec, total: 34287628.30sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 34287628.30sec, total: 34287628.30sec
  train.py:359:image_losses (gradient), cpu: 847us, accelerator: 552us, total: 1.40ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_134500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 34224014.88sec, total: 34224014.89sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34224014.88sec, total: 34224014.89sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 34224014.88sec, total: 34224014.88sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 68448029.77sec, total: 68448029.77sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 34224014.89sec, total: 34224014.89sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 34224014.89sec, total: 34224014.89sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34224014.89sec, total: 34224014.89sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 34224014.88sec, total: 34224014.89sec
  train.py:359:image_losses, cpu: 2.50ms, accelerator: 1.55ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.48ms, accelerator: 1.55ms, total: 4.05ms
      train.py:342:hfe, cpu: 1.41ms, accelerator: 1.11ms, total: 2.53ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 34224014.89sec, total: 34224014.89sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 34224014.89sec, total: 34224014.89sec
  train.py:359:image_losses (gradient), cpu: 846us, accelerator: 556us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_134750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 34160637.08sec, total: 34160637.08sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34160637.08sec, total: 34160637.08sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 34160637.08sec, total: 34160637.08sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 68321274.16sec, total: 68321274.16sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 34160637.08sec, total: 34160637.09sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 34160637.08sec, total: 34160637.08sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 34160637.08sec, total: 34160637.08sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 34160637.08sec, total: 34160637.08sec
  train.py:359:image_losses, cpu: 2.50ms, accelerator: 1.55ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.48ms, accelerator: 1.55ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.41ms, accelerator: 1.11ms, total: 2.52ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 34160637.08sec, total: 34160637.08sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 34160637.08sec, total: 34160637.08sec
  train.py:359:image_losses (gradient), cpu: 846us, accelerator: 553us, total: 1.41ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_135000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 34097493.57sec, total: 34097493.57sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34097493.57sec, total: 34097493.57sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 34097493.57sec, total: 34097493.57sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 68194987.15sec, total: 68194987.15sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 34097493.57sec, total: 34097493.58sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 34097493.57sec, total: 34097493.58sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 34097493.57sec, total: 34097493.58sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 34097493.57sec, total: 34097493.58sec
  train.py:359:image_losses, cpu: 2.49ms, accelerator: 1.54ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.48ms, accelerator: 1.54ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.41ms, accelerator: 1.11ms, total: 2.52ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 34097493.57sec, total: 34097493.58sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 34097493.57sec, total: 34097493.58sec
  train.py:359:image_losses (gradient), cpu: 846us, accelerator: 559us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_135250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 34034583.07sec, total: 34034583.07sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 34034583.07sec, total: 34034583.07sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 34034583.07sec, total: 34034583.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 68069166.14sec, total: 68069166.14sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 34034583.07sec, total: 34034583.08sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 34034583.07sec, total: 34034583.07sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 34034583.07sec, total: 34034583.07sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 34034583.07sec, total: 34034583.07sec
  train.py:359:image_losses, cpu: 2.49ms, accelerator: 1.54ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.48ms, accelerator: 1.54ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.41ms, accelerator: 1.11ms, total: 2.51ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 34034583.07sec, total: 34034583.07sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 34034583.07sec, total: 34034583.07sec
  train.py:359:image_losses (gradient), cpu: 844us, accelerator: 558us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_135500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 33971904.28sec, total: 33971904.28sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 33971904.28sec, total: 33971904.28sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 33971904.28sec, total: 33971904.28sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 67943808.56sec, total: 67943808.56sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 33971904.28sec, total: 33971904.29sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33971904.28sec, total: 33971904.28sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33971904.28sec, total: 33971904.28sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33971904.28sec, total: 33971904.28sec
  train.py:359:image_losses, cpu: 2.49ms, accelerator: 1.54ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.48ms, accelerator: 1.54ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.40ms, accelerator: 1.10ms, total: 2.51ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 33971904.28sec, total: 33971904.28sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33971904.28sec, total: 33971904.28sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 558us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_135750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 33909455.92sec, total: 33909455.93sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 33909455.92sec, total: 33909455.92sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 33909455.92sec, total: 33909455.92sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 67818911.85sec, total: 67818911.85sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 33909455.93sec, total: 33909455.93sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33909455.92sec, total: 33909455.93sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33909455.92sec, total: 33909455.93sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33909455.92sec, total: 33909455.93sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.54ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.47ms, accelerator: 1.54ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.40ms, accelerator: 1.10ms, total: 2.51ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 33909455.93sec, total: 33909455.93sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33909455.93sec, total: 33909455.93sec
  train.py:359:image_losses (gradient), cpu: 846us, accelerator: 558us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_136000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 33847236.74sec, total: 33847236.74sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 33847236.74sec, total: 33847236.74sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 33847236.74sec, total: 33847236.74sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 67694473.48sec, total: 67694473.48sec
train.py:442:<module>, cpu: 6.04ms, accelerator: 33847236.74sec, total: 33847236.75sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33847236.74sec, total: 33847236.74sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33847236.74sec, total: 33847236.74sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33847236.74sec, total: 33847236.74sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.53ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.47ms, accelerator: 1.53ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.40ms, accelerator: 1.10ms, total: 2.50ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 33847236.74sec, total: 33847236.74sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33847236.74sec, total: 33847236.74sec
  train.py:359:image_losses (gradient), cpu: 846us, accelerator: 557us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_136250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 33785245.46sec, total: 33785245.46sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 33785245.46sec, total: 33785245.46sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 33785245.46sec, total: 33785245.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 67570490.93sec, total: 67570490.93sec
train.py:442:<module>, cpu: 6.04ms, accelerator: 33785245.47sec, total: 33785245.47sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33785245.46sec, total: 33785245.47sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33785245.46sec, total: 33785245.47sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33785245.46sec, total: 33785245.47sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.54ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.47ms, accelerator: 1.54ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.40ms, accelerator: 1.11ms, total: 2.52ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 33785245.46sec, total: 33785245.47sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33785245.46sec, total: 33785245.47sec
  train.py:359:image_losses (gradient), cpu: 841us, accelerator: 557us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_136500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 33723480.85sec, total: 33723480.85sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33723480.84sec, total: 33723480.85sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 33723480.84sec, total: 33723480.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 67446961.69sec, total: 67446961.70sec
train.py:442:<module>, cpu: 6.04ms, accelerator: 33723480.85sec, total: 33723480.85sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33723480.85sec, total: 33723480.85sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33723480.85sec, total: 33723480.85sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33723480.85sec, total: 33723480.85sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.54ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.54ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.40ms, accelerator: 1.11ms, total: 2.51ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 33723480.85sec, total: 33723480.85sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33723480.85sec, total: 33723480.85sec
  train.py:359:image_losses (gradient), cpu: 841us, accelerator: 557us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2038.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_136750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 33661941.65sec, total: 33661941.65sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33661941.65sec, total: 33661941.65sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 33661941.64sec, total: 33661941.65sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 67323883.29sec, total: 67323883.30sec
train.py:442:<module>, cpu: 6.07ms, accelerator: 33661941.65sec, total: 33661941.66sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33661941.65sec, total: 33661941.65sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33661941.65sec, total: 33661941.65sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33661941.65sec, total: 33661941.65sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.54ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.54ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.40ms, accelerator: 1.11ms, total: 2.51ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 33661941.65sec, total: 33661941.65sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33661941.65sec, total: 33661941.65sec
  train.py:359:image_losses (gradient), cpu: 840us, accelerator: 557us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_137000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 33600626.64sec, total: 33600626.64sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33600626.63sec, total: 33600626.64sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 33600626.63sec, total: 33600626.63sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 67201253.27sec, total: 67201253.27sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 33600626.64sec, total: 33600626.64sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33600626.64sec, total: 33600626.64sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33600626.64sec, total: 33600626.64sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33600626.64sec, total: 33600626.64sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.53ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.53ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.11ms, total: 2.50ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 33600626.64sec, total: 33600626.64sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33600626.64sec, total: 33600626.64sec
  train.py:359:image_losses (gradient), cpu: 839us, accelerator: 556us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_137250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 33539534.59sec, total: 33539534.59sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33539534.59sec, total: 33539534.59sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 33539534.58sec, total: 33539534.58sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 67079069.17sec, total: 67079069.18sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 33539534.59sec, total: 33539534.60sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33539534.59sec, total: 33539534.59sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33539534.59sec, total: 33539534.59sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33539534.59sec, total: 33539534.59sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.53ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.45ms, accelerator: 1.53ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.10ms, total: 2.50ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 33539534.59sec, total: 33539534.59sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33539534.59sec, total: 33539534.59sec
  train.py:359:image_losses (gradient), cpu: 839us, accelerator: 556us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_137500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 33478664.29sec, total: 33478664.29sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33478664.29sec, total: 33478664.29sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 33478664.29sec, total: 33478664.29sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 66957328.58sec, total: 66957328.58sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 33478664.29sec, total: 33478664.30sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33478664.29sec, total: 33478664.29sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33478664.29sec, total: 33478664.29sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33478664.29sec, total: 33478664.29sec
  train.py:359:image_losses, cpu: 2.46ms, accelerator: 1.53ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.45ms, accelerator: 1.53ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.10ms, total: 2.49ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 33478664.29sec, total: 33478664.29sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33478664.29sec, total: 33478664.29sec
  train.py:359:image_losses (gradient), cpu: 839us, accelerator: 554us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2031.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_137750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 33418014.53sec, total: 33418014.54sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33418014.53sec, total: 33418014.53sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 33418014.53sec, total: 33418014.53sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 66836029.07sec, total: 66836029.07sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 33418014.54sec, total: 33418014.54sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33418014.53sec, total: 33418014.54sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33418014.53sec, total: 33418014.54sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33418014.53sec, total: 33418014.54sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.53ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.53ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.10ms, total: 2.50ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 33418014.54sec, total: 33418014.54sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33418014.53sec, total: 33418014.54sec
  train.py:359:image_losses (gradient), cpu: 841us, accelerator: 552us, total: 1.40ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_138000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 33357584.13sec, total: 33357584.13sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33357584.13sec, total: 33357584.13sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 33357584.13sec, total: 33357584.13sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 66715168.26sec, total: 66715168.26sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 33357584.13sec, total: 33357584.14sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33357584.13sec, total: 33357584.13sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33357584.13sec, total: 33357584.13sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33357584.13sec, total: 33357584.13sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.53ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.45ms, accelerator: 1.53ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.10ms, total: 2.49ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 33357584.13sec, total: 33357584.13sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33357584.13sec, total: 33357584.13sec
  train.py:359:image_losses (gradient), cpu: 839us, accelerator: 551us, total: 1.40ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2040.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_138250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 33297371.88sec, total: 33297371.88sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33297371.88sec, total: 33297371.88sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 33297371.88sec, total: 33297371.88sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 66594743.76sec, total: 66594743.77sec
train.py:442:<module>, cpu: 6.07ms, accelerator: 33297371.88sec, total: 33297371.89sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33297371.88sec, total: 33297371.89sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33297371.88sec, total: 33297371.89sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33297371.88sec, total: 33297371.89sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.52ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.52ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.09ms, total: 2.49ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 33297371.88sec, total: 33297371.89sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33297371.88sec, total: 33297371.89sec
  train.py:359:image_losses (gradient), cpu: 838us, accelerator: 549us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_138500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 33237376.62sec, total: 33237376.62sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33237376.62sec, total: 33237376.62sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 33237376.62sec, total: 33237376.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 66474753.24sec, total: 66474753.24sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 33237376.62sec, total: 33237376.63sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33237376.62sec, total: 33237376.62sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33237376.62sec, total: 33237376.62sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33237376.62sec, total: 33237376.62sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.52ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.52ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.09ms, total: 2.48ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 33237376.62sec, total: 33237376.62sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33237376.62sec, total: 33237376.62sec
  train.py:359:image_losses (gradient), cpu: 837us, accelerator: 549us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_138750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 33177597.16sec, total: 33177597.16sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33177597.16sec, total: 33177597.16sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 33177597.16sec, total: 33177597.16sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 66355194.33sec, total: 66355194.33sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 33177597.17sec, total: 33177597.17sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33177597.16sec, total: 33177597.17sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33177597.16sec, total: 33177597.17sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33177597.16sec, total: 33177597.17sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.52ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.52ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.09ms, total: 2.48ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 33177597.16sec, total: 33177597.17sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33177597.16sec, total: 33177597.17sec
  train.py:359:image_losses (gradient), cpu: 836us, accelerator: 548us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2022.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_139000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 33118032.36sec, total: 33118032.36sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33118032.36sec, total: 33118032.36sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 33118032.35sec, total: 33118032.35sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 66236064.71sec, total: 66236064.72sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 33118032.36sec, total: 33118032.37sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33118032.36sec, total: 33118032.36sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33118032.36sec, total: 33118032.36sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33118032.36sec, total: 33118032.36sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.52ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.52ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.09ms, total: 2.48ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 33118032.36sec, total: 33118032.36sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33118032.36sec, total: 33118032.36sec
  train.py:359:image_losses (gradient), cpu: 837us, accelerator: 547us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2035.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_139250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 33058681.04sec, total: 33058681.05sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33058681.04sec, total: 33058681.05sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 33058681.04sec, total: 33058681.04sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 66117362.09sec, total: 66117362.09sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 33058681.05sec, total: 33058681.05sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 33058681.04sec, total: 33058681.05sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 33058681.04sec, total: 33058681.05sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 33058681.04sec, total: 33058681.05sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.51ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.47ms, accelerator: 1.51ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.40ms, accelerator: 1.09ms, total: 2.49ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 33058681.05sec, total: 33058681.05sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 33058681.05sec, total: 33058681.05sec
  train.py:359:image_losses (gradient), cpu: 835us, accelerator: 546us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_139500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32999542.08sec, total: 32999542.08sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32999542.08sec, total: 32999542.08sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32999542.08sec, total: 32999542.08sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 65999084.16sec, total: 65999084.16sec
train.py:442:<module>, cpu: 6.07ms, accelerator: 32999542.08sec, total: 32999542.09sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 32999542.08sec, total: 32999542.08sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 32999542.08sec, total: 32999542.08sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 32999542.08sec, total: 32999542.08sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.51ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.47ms, accelerator: 1.51ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.09ms, total: 2.48ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32999542.08sec, total: 32999542.09sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 32999542.08sec, total: 32999542.08sec
  train.py:359:image_losses (gradient), cpu: 835us, accelerator: 546us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_139750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32940614.33sec, total: 32940614.33sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32940614.33sec, total: 32940614.33sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32940614.32sec, total: 32940614.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 65881228.65sec, total: 65881228.66sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 32940614.33sec, total: 32940614.33sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 32940614.33sec, total: 32940614.33sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 32940614.33sec, total: 32940614.33sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 32940614.33sec, total: 32940614.33sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.51ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.47ms, accelerator: 1.51ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.08ms, total: 2.48ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32940614.33sec, total: 32940614.33sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 32940614.33sec, total: 32940614.33sec
  train.py:359:image_losses (gradient), cpu: 835us, accelerator: 544us, total: 1.39ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_140000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32881896.65sec, total: 32881896.66sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32881896.65sec, total: 32881896.65sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32881896.65sec, total: 32881896.65sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 65763793.31sec, total: 65763793.31sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 32881896.66sec, total: 32881896.66sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 32881896.65sec, total: 32881896.66sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 32881896.65sec, total: 32881896.66sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 32881896.65sec, total: 32881896.66sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.51ms, total: 4.00ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.51ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.08ms, total: 2.48ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32881896.66sec, total: 32881896.66sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 32881896.65sec, total: 32881896.66sec
  train.py:359:image_losses (gradient), cpu: 835us, accelerator: 543us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_140250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32823387.94sec, total: 32823387.94sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32823387.94sec, total: 32823387.94sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32823387.94sec, total: 32823387.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 65646775.88sec, total: 65646775.89sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 32823387.94sec, total: 32823387.95sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32823387.94sec, total: 32823387.94sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32823387.94sec, total: 32823387.94sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32823387.94sec, total: 32823387.94sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.50ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.50ms, total: 3.98ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.08ms, total: 2.48ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32823387.94sec, total: 32823387.95sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 32823387.94sec, total: 32823387.94sec
  train.py:359:image_losses (gradient), cpu: 833us, accelerator: 542us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_140500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32765087.07sec, total: 32765087.08sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32765087.07sec, total: 32765087.07sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32765087.07sec, total: 32765087.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 65530174.15sec, total: 65530174.15sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 32765087.08sec, total: 32765087.08sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32765087.07sec, total: 32765087.08sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32765087.07sec, total: 32765087.08sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32765087.07sec, total: 32765087.08sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.50ms, total: 3.99ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.50ms, total: 3.97ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.08ms, total: 2.47ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32765087.08sec, total: 32765087.08sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 32765087.08sec, total: 32765087.08sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 542us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_140750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32706992.95sec, total: 32706992.95sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32706992.95sec, total: 32706992.95sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32706992.95sec, total: 32706992.95sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 65413985.90sec, total: 65413985.90sec
train.py:442:<module>, cpu: 6.04ms, accelerator: 32706992.95sec, total: 32706992.96sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32706992.95sec, total: 32706992.95sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32706992.95sec, total: 32706992.95sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32706992.95sec, total: 32706992.95sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.50ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.50ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.08ms, total: 2.47ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 32706992.95sec, total: 32706992.95sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32706992.95sec, total: 32706992.95sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 542us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_141000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32649104.47sec, total: 32649104.47sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32649104.46sec, total: 32649104.47sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32649104.46sec, total: 32649104.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 65298208.93sec, total: 65298208.93sec
train.py:442:<module>, cpu: 6.04ms, accelerator: 32649104.47sec, total: 32649104.47sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32649104.47sec, total: 32649104.47sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32649104.47sec, total: 32649104.47sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32649104.47sec, total: 32649104.47sec
  train.py:359:image_losses, cpu: 2.46ms, accelerator: 1.50ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.45ms, accelerator: 1.50ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.08ms, total: 2.46ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 32649104.47sec, total: 32649104.47sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32649104.47sec, total: 32649104.47sec
  train.py:359:image_losses (gradient), cpu: 833us, accelerator: 541us, total: 1.38ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_141250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32591420.53sec, total: 32591420.54sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32591420.53sec, total: 32591420.54sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32591420.53sec, total: 32591420.53sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 65182841.07sec, total: 65182841.07sec
train.py:442:<module>, cpu: 6.03ms, accelerator: 32591420.54sec, total: 32591420.54sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32591420.54sec, total: 32591420.54sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32591420.54sec, total: 32591420.54sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32591420.54sec, total: 32591420.54sec
  train.py:359:image_losses, cpu: 2.46ms, accelerator: 1.49ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.45ms, accelerator: 1.49ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.07ms, total: 2.46ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32591420.54sec, total: 32591420.54sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32591420.54sec, total: 32591420.54sec
  train.py:359:image_losses (gradient), cpu: 829us, accelerator: 541us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_141500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32533940.08sec, total: 32533940.08sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32533940.07sec, total: 32533940.08sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32533940.07sec, total: 32533940.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 65067880.15sec, total: 65067880.16sec
train.py:442:<module>, cpu: 6.03ms, accelerator: 32533940.08sec, total: 32533940.08sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32533940.08sec, total: 32533940.08sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32533940.08sec, total: 32533940.08sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32533940.08sec, total: 32533940.08sec
  train.py:359:image_losses, cpu: 2.46ms, accelerator: 1.49ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.49ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.07ms, total: 2.46ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32533940.08sec, total: 32533940.08sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32533940.08sec, total: 32533940.08sec
  train.py:359:image_losses (gradient), cpu: 829us, accelerator: 539us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_141750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32476662.01sec, total: 32476662.01sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32476662.01sec, total: 32476662.01sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32476662.01sec, total: 32476662.01sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 64953324.02sec, total: 64953324.03sec
train.py:442:<module>, cpu: 6.04ms, accelerator: 32476662.01sec, total: 32476662.02sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32476662.01sec, total: 32476662.02sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32476662.01sec, total: 32476662.02sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32476662.01sec, total: 32476662.02sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.49ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.49ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.07ms, total: 2.47ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32476662.01sec, total: 32476662.02sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32476662.01sec, total: 32476662.02sec
  train.py:359:image_losses (gradient), cpu: 828us, accelerator: 539us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2033.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_142000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32419585.28sec, total: 32419585.28sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 32419585.28sec, total: 32419585.28sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32419585.27sec, total: 32419585.28sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 64839170.55sec, total: 64839170.56sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 32419585.28sec, total: 32419585.29sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32419585.28sec, total: 32419585.28sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32419585.28sec, total: 32419585.28sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32419585.28sec, total: 32419585.28sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.49ms, total: 3.97ms
    train.py:322:loss_fn, cpu: 2.45ms, accelerator: 1.49ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.07ms, total: 2.46ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32419585.28sec, total: 32419585.28sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32419585.28sec, total: 32419585.28sec
  train.py:359:image_losses (gradient), cpu: 828us, accelerator: 537us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2035.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_142250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32362708.81sec, total: 32362708.81sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 32362708.81sec, total: 32362708.81sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32362708.81sec, total: 32362708.81sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 64725417.62sec, total: 64725417.63sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 32362708.81sec, total: 32362708.82sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32362708.81sec, total: 32362708.82sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32362708.81sec, total: 32362708.82sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32362708.81sec, total: 32362708.82sec
  train.py:359:image_losses, cpu: 2.46ms, accelerator: 1.49ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.45ms, accelerator: 1.49ms, total: 3.95ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.07ms, total: 2.46ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32362708.81sec, total: 32362708.82sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32362708.81sec, total: 32362708.82sec
  train.py:359:image_losses (gradient), cpu: 827us, accelerator: 537us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_142500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32306031.56sec, total: 32306031.56sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 32306031.56sec, total: 32306031.56sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32306031.56sec, total: 32306031.56sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 64612063.13sec, total: 64612063.13sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 32306031.57sec, total: 32306031.57sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32306031.56sec, total: 32306031.57sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 32306031.56sec, total: 32306031.57sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32306031.56sec, total: 32306031.57sec
  train.py:359:image_losses, cpu: 2.46ms, accelerator: 1.49ms, total: 3.96ms
    train.py:322:loss_fn, cpu: 2.45ms, accelerator: 1.49ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.06ms, total: 2.45ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32306031.57sec, total: 32306031.57sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32306031.56sec, total: 32306031.57sec
  train.py:359:image_losses (gradient), cpu: 824us, accelerator: 536us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_142750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32249552.49sec, total: 32249552.49sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 32249552.49sec, total: 32249552.49sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32249552.49sec, total: 32249552.49sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 64499104.98sec, total: 64499104.98sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 32249552.49sec, total: 32249552.50sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32249552.49sec, total: 32249552.49sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32249552.49sec, total: 32249552.49sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32249552.49sec, total: 32249552.49sec
  train.py:359:image_losses, cpu: 2.46ms, accelerator: 1.48ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.48ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.06ms, total: 2.45ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32249552.49sec, total: 32249552.49sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32249552.49sec, total: 32249552.49sec
  train.py:359:image_losses (gradient), cpu: 824us, accelerator: 535us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_143000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32193270.55sec, total: 32193270.55sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 32193270.54sec, total: 32193270.55sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32193270.54sec, total: 32193270.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 64386541.09sec, total: 64386541.10sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 32193270.55sec, total: 32193270.55sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32193270.55sec, total: 32193270.55sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 32193270.55sec, total: 32193270.55sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32193270.55sec, total: 32193270.55sec
  train.py:359:image_losses, cpu: 2.46ms, accelerator: 1.48ms, total: 3.95ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.48ms, total: 3.94ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.06ms, total: 2.45ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32193270.55sec, total: 32193270.55sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32193270.55sec, total: 32193270.55sec
  train.py:359:image_losses (gradient), cpu: 824us, accelerator: 534us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2038.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_143250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32137184.71sec, total: 32137184.71sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 32137184.71sec, total: 32137184.71sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32137184.71sec, total: 32137184.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 64274369.42sec, total: 64274369.42sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 32137184.71sec, total: 32137184.72sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32137184.71sec, total: 32137184.71sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 32137184.71sec, total: 32137184.71sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32137184.71sec, total: 32137184.71sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.48ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.48ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.06ms, total: 2.44ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32137184.71sec, total: 32137184.71sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32137184.71sec, total: 32137184.71sec
  train.py:359:image_losses (gradient), cpu: 824us, accelerator: 535us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2024.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_143500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32081293.95sec, total: 32081293.95sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 32081293.95sec, total: 32081293.95sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32081293.95sec, total: 32081293.95sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 64162587.91sec, total: 64162587.91sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 32081293.95sec, total: 32081293.96sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32081293.95sec, total: 32081293.96sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 32081293.95sec, total: 32081293.96sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32081293.95sec, total: 32081293.96sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.48ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.48ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.06ms, total: 2.44ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32081293.95sec, total: 32081293.96sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32081293.95sec, total: 32081293.96sec
  train.py:359:image_losses (gradient), cpu: 823us, accelerator: 540us, total: 1.37ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_143750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 32025597.26sec, total: 32025597.26sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 32025597.26sec, total: 32025597.26sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 32025597.26sec, total: 32025597.26sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 64051194.52sec, total: 64051194.53sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 32025597.26sec, total: 32025597.27sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 32025597.26sec, total: 32025597.27sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 32025597.26sec, total: 32025597.27sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 32025597.26sec, total: 32025597.27sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.48ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.48ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.06ms, total: 2.44ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 32025597.26sec, total: 32025597.27sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 32025597.26sec, total: 32025597.27sec
  train.py:359:image_losses (gradient), cpu: 825us, accelerator: 540us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_144000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 31970093.63sec, total: 31970093.63sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 31970093.63sec, total: 31970093.63sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 31970093.62sec, total: 31970093.63sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 63940187.25sec, total: 63940187.26sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 31970093.63sec, total: 31970093.64sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 31970093.63sec, total: 31970093.63sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31970093.63sec, total: 31970093.63sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 31970093.63sec, total: 31970093.63sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.47ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.47ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.05ms, total: 2.44ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31970093.63sec, total: 31970093.63sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31970093.63sec, total: 31970093.63sec
  train.py:359:image_losses (gradient), cpu: 825us, accelerator: 539us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2022.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_144250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 31914782.05sec, total: 31914782.05sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 31914782.05sec, total: 31914782.05sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 31914782.04sec, total: 31914782.04sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 63829564.09sec, total: 63829564.10sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 31914782.05sec, total: 31914782.05sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31914782.05sec, total: 31914782.05sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31914782.05sec, total: 31914782.05sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31914782.05sec, total: 31914782.05sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.47ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.47ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.05ms, total: 2.44ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31914782.05sec, total: 31914782.05sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31914782.05sec, total: 31914782.05sec
  train.py:359:image_losses (gradient), cpu: 825us, accelerator: 538us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_144500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 31859661.52sec, total: 31859661.53sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 31859661.52sec, total: 31859661.53sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 31859661.52sec, total: 31859661.52sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 63719323.05sec, total: 63719323.05sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 31859661.53sec, total: 31859661.53sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31859661.53sec, total: 31859661.53sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31859661.53sec, total: 31859661.53sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31859661.53sec, total: 31859661.53sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.47ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.43ms, accelerator: 1.47ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.05ms, total: 2.44ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31859661.53sec, total: 31859661.53sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31859661.53sec, total: 31859661.53sec
  train.py:359:image_losses (gradient), cpu: 828us, accelerator: 538us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2018.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_144750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 31804731.07sec, total: 31804731.08sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 31804731.07sec, total: 31804731.07sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 31804731.07sec, total: 31804731.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 63609462.15sec, total: 63609462.15sec
train.py:442:<module>, cpu: 6.06ms, accelerator: 31804731.08sec, total: 31804731.08sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31804731.07sec, total: 31804731.08sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31804731.07sec, total: 31804731.08sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31804731.07sec, total: 31804731.08sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.47ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.47ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 1.05ms, total: 2.44ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31804731.08sec, total: 31804731.08sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31804731.07sec, total: 31804731.08sec
  train.py:359:image_losses (gradient), cpu: 826us, accelerator: 537us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_145000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 31749989.71sec, total: 31749989.71sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 31749989.71sec, total: 31749989.71sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 31749989.71sec, total: 31749989.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 63499979.42sec, total: 63499979.43sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 31749989.71sec, total: 31749989.72sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31749989.71sec, total: 31749989.72sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31749989.71sec, total: 31749989.72sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31749989.71sec, total: 31749989.72sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.46ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.46ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.05ms, total: 2.44ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31749989.71sec, total: 31749989.72sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 31749989.71sec, total: 31749989.72sec
  train.py:359:image_losses (gradient), cpu: 823us, accelerator: 537us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_145250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 31695436.47sec, total: 31695436.47sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 31695436.46sec, total: 31695436.47sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 31695436.46sec, total: 31695436.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 63390872.93sec, total: 63390872.93sec
train.py:442:<module>, cpu: 6.05ms, accelerator: 31695436.47sec, total: 31695436.47sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31695436.47sec, total: 31695436.47sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31695436.47sec, total: 31695436.47sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31695436.47sec, total: 31695436.47sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.46ms, total: 3.92ms
    train.py:322:loss_fn, cpu: 2.43ms, accelerator: 1.46ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.05ms, total: 2.43ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31695436.47sec, total: 31695436.47sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31695436.47sec, total: 31695436.47sec
  train.py:359:image_losses (gradient), cpu: 822us, accelerator: 536us, total: 1.37ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_145500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 31641070.36sec, total: 31641070.37sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 31641070.36sec, total: 31641070.37sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 31641070.36sec, total: 31641070.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 63282140.73sec, total: 63282140.73sec
train.py:442:<module>, cpu: 6.04ms, accelerator: 31641070.37sec, total: 31641070.37sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31641070.37sec, total: 31641070.37sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31641070.37sec, total: 31641070.37sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31641070.37sec, total: 31641070.37sec
  train.py:359:image_losses, cpu: 2.44ms, accelerator: 1.46ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.43ms, accelerator: 1.46ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.04ms, total: 2.43ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31641070.37sec, total: 31641070.37sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31641070.37sec, total: 31641070.37sec
  train.py:359:image_losses (gradient), cpu: 822us, accelerator: 536us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_145750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 31586890.45sec, total: 31586890.45sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 31586890.45sec, total: 31586890.45sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 31586890.45sec, total: 31586890.45sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 63173780.90sec, total: 63173780.90sec
train.py:442:<module>, cpu: 6.04ms, accelerator: 31586890.45sec, total: 31586890.46sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31586890.45sec, total: 31586890.45sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31586890.45sec, total: 31586890.45sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31586890.45sec, total: 31586890.45sec
  train.py:359:image_losses, cpu: 2.44ms, accelerator: 1.46ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.43ms, accelerator: 1.46ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.04ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31586890.45sec, total: 31586890.46sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31586890.45sec, total: 31586890.45sec
  train.py:359:image_losses (gradient), cpu: 821us, accelerator: 535us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_146000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 31532895.77sec, total: 31532895.77sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 31532895.76sec, total: 31532895.77sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 31532895.76sec, total: 31532895.76sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 63065791.53sec, total: 63065791.54sec
train.py:442:<module>, cpu: 6.04ms, accelerator: 31532895.77sec, total: 31532895.77sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31532895.77sec, total: 31532895.77sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31532895.77sec, total: 31532895.77sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31532895.77sec, total: 31532895.77sec
  train.py:359:image_losses, cpu: 2.44ms, accelerator: 1.45ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.43ms, accelerator: 1.45ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.04ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31532895.77sec, total: 31532895.77sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 31532895.77sec, total: 31532895.77sec
  train.py:359:image_losses (gradient), cpu: 820us, accelerator: 532us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_146250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 31479085.36sec, total: 31479085.36sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 31479085.36sec, total: 31479085.36sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 394us, accelerator: 31479085.36sec, total: 31479085.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 62958170.73sec, total: 62958170.73sec
train.py:442:<module>, cpu: 6.03ms, accelerator: 31479085.37sec, total: 31479085.37sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31479085.36sec, total: 31479085.37sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31479085.36sec, total: 31479085.37sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31479085.36sec, total: 31479085.37sec
  train.py:359:image_losses, cpu: 2.44ms, accelerator: 1.45ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.42ms, accelerator: 1.45ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.04ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31479085.36sec, total: 31479085.37sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31479085.36sec, total: 31479085.37sec
  train.py:359:image_losses (gradient), cpu: 820us, accelerator: 532us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_146500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 31425458.30sec, total: 31425458.30sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 31425458.30sec, total: 31425458.30sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 31425458.30sec, total: 31425458.30sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 62850916.60sec, total: 62850916.61sec
train.py:442:<module>, cpu: 6.03ms, accelerator: 31425458.30sec, total: 31425458.31sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31425458.30sec, total: 31425458.30sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31425458.30sec, total: 31425458.30sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31425458.30sec, total: 31425458.30sec
  train.py:359:image_losses, cpu: 2.44ms, accelerator: 1.45ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.42ms, accelerator: 1.45ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.04ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31425458.30sec, total: 31425458.31sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31425458.30sec, total: 31425458.30sec
  train.py:359:image_losses (gradient), cpu: 820us, accelerator: 532us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_146750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 31372013.64sec, total: 31372013.65sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 31372013.64sec, total: 31372013.65sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 31372013.64sec, total: 31372013.64sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 62744027.29sec, total: 62744027.29sec
train.py:442:<module>, cpu: 6.03ms, accelerator: 31372013.65sec, total: 31372013.65sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31372013.64sec, total: 31372013.65sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31372013.64sec, total: 31372013.65sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31372013.64sec, total: 31372013.65sec
  train.py:359:image_losses, cpu: 2.44ms, accelerator: 1.46ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.42ms, accelerator: 1.46ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.04ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31372013.65sec, total: 31372013.65sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31372013.65sec, total: 31372013.65sec
  train.py:359:image_losses (gradient), cpu: 819us, accelerator: 534us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_147000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 31318750.46sec, total: 31318750.46sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 31318750.46sec, total: 31318750.46sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 393us, accelerator: 31318750.46sec, total: 31318750.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 62637500.93sec, total: 62637500.93sec
train.py:442:<module>, cpu: 6.03ms, accelerator: 31318750.47sec, total: 31318750.47sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31318750.46sec, total: 31318750.47sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31318750.46sec, total: 31318750.47sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31318750.46sec, total: 31318750.47sec
  train.py:359:image_losses, cpu: 2.43ms, accelerator: 1.46ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.42ms, accelerator: 1.46ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 1.04ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31318750.46sec, total: 31318750.47sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 31318750.46sec, total: 31318750.47sec
  train.py:359:image_losses (gradient), cpu: 818us, accelerator: 532us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_147250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 31265667.84sec, total: 31265667.84sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 31265667.83sec, total: 31265667.84sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 31265667.83sec, total: 31265667.83sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 62531335.67sec, total: 62531335.67sec
train.py:442:<module>, cpu: 6.02ms, accelerator: 31265667.84sec, total: 31265667.84sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31265667.84sec, total: 31265667.84sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31265667.84sec, total: 31265667.84sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31265667.84sec, total: 31265667.84sec
  train.py:359:image_losses, cpu: 2.43ms, accelerator: 1.47ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.42ms, accelerator: 1.47ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.05ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 31265667.84sec, total: 31265667.84sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31265667.84sec, total: 31265667.84sec
  train.py:359:image_losses (gradient), cpu: 817us, accelerator: 531us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_147500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 31212764.84sec, total: 31212764.85sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 31212764.84sec, total: 31212764.84sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 31212764.84sec, total: 31212764.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 62425529.69sec, total: 62425529.69sec
train.py:442:<module>, cpu: 6.02ms, accelerator: 31212764.85sec, total: 31212764.85sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 31212764.84sec, total: 31212764.85sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 31212764.84sec, total: 31212764.85sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31212764.84sec, total: 31212764.85sec
  train.py:359:image_losses, cpu: 2.43ms, accelerator: 1.47ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.47ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.04ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 31212764.85sec, total: 31212764.85sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31212764.84sec, total: 31212764.85sec
  train.py:359:image_losses (gradient), cpu: 815us, accelerator: 530us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_147750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 31160040.58sec, total: 31160040.58sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 31160040.58sec, total: 31160040.58sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 31160040.58sec, total: 31160040.58sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 62320081.16sec, total: 62320081.16sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 31160040.58sec, total: 31160040.59sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 31160040.58sec, total: 31160040.58sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 31160040.58sec, total: 31160040.58sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 31160040.58sec, total: 31160040.58sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.47ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.47ms, total: 3.89ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.04ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 31160040.58sec, total: 31160040.58sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31160040.58sec, total: 31160040.58sec
  train.py:359:image_losses (gradient), cpu: 815us, accelerator: 529us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_148000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 31107494.14sec, total: 31107494.14sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 31107494.14sec, total: 31107494.14sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 31107494.13sec, total: 31107494.13sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 62214988.27sec, total: 62214988.28sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 31107494.14sec, total: 31107494.14sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 31107494.14sec, total: 31107494.14sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 31107494.14sec, total: 31107494.14sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 31107494.14sec, total: 31107494.14sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.46ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.46ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.04ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 31107494.14sec, total: 31107494.14sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31107494.14sec, total: 31107494.14sec
  train.py:359:image_losses (gradient), cpu: 815us, accelerator: 528us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_148250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 31055124.62sec, total: 31055124.62sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 31055124.62sec, total: 31055124.62sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 31055124.62sec, total: 31055124.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 62110249.24sec, total: 62110249.24sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 31055124.62sec, total: 31055124.63sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 31055124.62sec, total: 31055124.62sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 31055124.62sec, total: 31055124.62sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 31055124.62sec, total: 31055124.62sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.46ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.46ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.04ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 31055124.62sec, total: 31055124.62sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 31055124.62sec, total: 31055124.62sec
  train.py:359:image_losses (gradient), cpu: 815us, accelerator: 528us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_148500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 31002931.13sec, total: 31002931.13sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 31002931.13sec, total: 31002931.13sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 31002931.13sec, total: 31002931.13sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 62005862.26sec, total: 62005862.27sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 31002931.13sec, total: 31002931.14sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 31002931.13sec, total: 31002931.13sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 31002931.13sec, total: 31002931.13sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 31002931.13sec, total: 31002931.13sec
  train.py:359:image_losses, cpu: 2.43ms, accelerator: 1.46ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.42ms, accelerator: 1.46ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.04ms, total: 2.42ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 31002931.13sec, total: 31002931.14sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 31002931.13sec, total: 31002931.13sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 527us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_148750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30950912.79sec, total: 30950912.79sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30950912.79sec, total: 30950912.79sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30950912.79sec, total: 30950912.79sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 61901825.58sec, total: 61901825.58sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 30950912.79sec, total: 30950912.80sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30950912.79sec, total: 30950912.79sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30950912.79sec, total: 30950912.79sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30950912.79sec, total: 30950912.79sec
  train.py:359:image_losses, cpu: 2.43ms, accelerator: 1.46ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.42ms, accelerator: 1.46ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.04ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30950912.79sec, total: 30950912.80sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 30950912.79sec, total: 30950912.79sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 527us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_149000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30899068.71sec, total: 30899068.72sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30899068.71sec, total: 30899068.72sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30899068.71sec, total: 30899068.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 61798137.43sec, total: 61798137.43sec
train.py:442:<module>, cpu: 6.00ms, accelerator: 30899068.72sec, total: 30899068.72sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30899068.72sec, total: 30899068.72sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30899068.72sec, total: 30899068.72sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30899068.72sec, total: 30899068.72sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.45ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.45ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.04ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30899068.72sec, total: 30899068.72sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 30899068.72sec, total: 30899068.72sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 527us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_149250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30847398.03sec, total: 30847398.03sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30847398.03sec, total: 30847398.03sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30847398.03sec, total: 30847398.03sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 61694796.06sec, total: 61694796.07sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 30847398.03sec, total: 30847398.04sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 30847398.03sec, total: 30847398.04sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 30847398.03sec, total: 30847398.04sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 30847398.03sec, total: 30847398.04sec
  train.py:359:image_losses, cpu: 2.43ms, accelerator: 1.45ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.45ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30847398.03sec, total: 30847398.04sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 30847398.03sec, total: 30847398.04sec
  train.py:359:image_losses (gradient), cpu: 813us, accelerator: 525us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_149500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30795899.87sec, total: 30795899.87sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30795899.87sec, total: 30795899.87sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30795899.87sec, total: 30795899.87sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 61591799.74sec, total: 61591799.75sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 30795899.87sec, total: 30795899.88sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30795899.87sec, total: 30795899.87sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30795899.87sec, total: 30795899.87sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30795899.87sec, total: 30795899.87sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.45ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.45ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 30795899.87sec, total: 30795899.88sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30795899.87sec, total: 30795899.87sec
  train.py:359:image_losses (gradient), cpu: 813us, accelerator: 524us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2035.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_149750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30744573.37sec, total: 30744573.37sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30744573.37sec, total: 30744573.37sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30744573.37sec, total: 30744573.37sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 61489146.74sec, total: 61489146.75sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 30744573.37sec, total: 30744573.38sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30744573.37sec, total: 30744573.38sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30744573.37sec, total: 30744573.38sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30744573.37sec, total: 30744573.37sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.44ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.44ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30744573.37sec, total: 30744573.38sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30744573.37sec, total: 30744573.38sec
  train.py:359:image_losses (gradient), cpu: 811us, accelerator: 524us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_150000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30693417.68sec, total: 30693417.68sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30693417.67sec, total: 30693417.68sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30693417.67sec, total: 30693417.67sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 61386835.35sec, total: 61386835.36sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 30693417.68sec, total: 30693417.68sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30693417.68sec, total: 30693417.68sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30693417.68sec, total: 30693417.68sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30693417.68sec, total: 30693417.68sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.44ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.44ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30693417.68sec, total: 30693417.68sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30693417.68sec, total: 30693417.68sec
  train.py:359:image_losses (gradient), cpu: 810us, accelerator: 521us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_150250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30642431.93sec, total: 30642431.93sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30642431.93sec, total: 30642431.93sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30642431.93sec, total: 30642431.93sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 61284863.86sec, total: 61284863.87sec
train.py:442:<module>, cpu: 6.00ms, accelerator: 30642431.93sec, total: 30642431.94sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30642431.93sec, total: 30642431.94sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30642431.93sec, total: 30642431.94sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30642431.93sec, total: 30642431.94sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.45ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.40ms, accelerator: 1.45ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.04ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30642431.93sec, total: 30642431.94sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30642431.93sec, total: 30642431.94sec
  train.py:359:image_losses (gradient), cpu: 809us, accelerator: 521us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_150500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30591615.29sec, total: 30591615.30sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30591615.29sec, total: 30591615.30sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30591615.29sec, total: 30591615.29sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 61183230.59sec, total: 61183230.59sec
train.py:442:<module>, cpu: 6.00ms, accelerator: 30591615.30sec, total: 30591615.30sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30591615.30sec, total: 30591615.30sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30591615.30sec, total: 30591615.30sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30591615.30sec, total: 30591615.30sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.45ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.40ms, accelerator: 1.45ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.04ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30591615.30sec, total: 30591615.30sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30591615.30sec, total: 30591615.30sec
  train.py:359:image_losses (gradient), cpu: 809us, accelerator: 520us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2040.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_150750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30540966.93sec, total: 30540966.93sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30540966.92sec, total: 30540966.93sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30540966.92sec, total: 30540966.92sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 61081933.85sec, total: 61081933.85sec
train.py:442:<module>, cpu: 6.00ms, accelerator: 30540966.93sec, total: 30540966.93sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30540966.93sec, total: 30540966.93sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30540966.93sec, total: 30540966.93sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30540966.93sec, total: 30540966.93sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.45ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.45ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.04ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30540966.93sec, total: 30540966.93sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30540966.93sec, total: 30540966.93sec
  train.py:359:image_losses (gradient), cpu: 808us, accelerator: 519us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_151000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30490485.99sec, total: 30490485.99sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30490485.99sec, total: 30490485.99sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30490485.99sec, total: 30490485.99sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 60980971.98sec, total: 60980971.98sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 30490485.99sec, total: 30490486.00sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30490485.99sec, total: 30490485.99sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30490485.99sec, total: 30490485.99sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30490485.99sec, total: 30490485.99sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.45ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.40ms, accelerator: 1.45ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30490485.99sec, total: 30490485.99sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30490485.99sec, total: 30490485.99sec
  train.py:359:image_losses (gradient), cpu: 807us, accelerator: 519us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_151250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30440171.65sec, total: 30440171.66sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30440171.65sec, total: 30440171.66sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30440171.65sec, total: 30440171.65sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 60880343.31sec, total: 60880343.31sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 30440171.66sec, total: 30440171.66sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30440171.66sec, total: 30440171.66sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30440171.66sec, total: 30440171.66sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30440171.66sec, total: 30440171.66sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.45ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.40ms, accelerator: 1.45ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30440171.66sec, total: 30440171.66sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30440171.66sec, total: 30440171.66sec
  train.py:359:image_losses (gradient), cpu: 807us, accelerator: 518us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_151500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30390023.10sec, total: 30390023.10sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30390023.10sec, total: 30390023.10sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30390023.10sec, total: 30390023.10sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 60780046.20sec, total: 60780046.21sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 30390023.10sec, total: 30390023.11sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30390023.10sec, total: 30390023.11sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30390023.10sec, total: 30390023.11sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30390023.10sec, total: 30390023.11sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.45ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.40ms, accelerator: 1.45ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.41ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30390023.10sec, total: 30390023.11sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 30390023.10sec, total: 30390023.11sec
  train.py:359:image_losses (gradient), cpu: 806us, accelerator: 516us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_151750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30340039.51sec, total: 30340039.51sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30340039.51sec, total: 30340039.51sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30340039.51sec, total: 30340039.51sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 60680079.02sec, total: 60680079.03sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 30340039.51sec, total: 30340039.52sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30340039.51sec, total: 30340039.51sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30340039.51sec, total: 30340039.51sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30340039.51sec, total: 30340039.51sec
  train.py:359:image_losses, cpu: 2.41ms, accelerator: 1.45ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.40ms, accelerator: 1.45ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 30340039.51sec, total: 30340039.52sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 30340039.51sec, total: 30340039.52sec
  train.py:359:image_losses (gradient), cpu: 806us, accelerator: 515us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_152000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.37ms, accelerator: 30290220.07sec, total: 30290220.07sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30290220.07sec, total: 30290220.07sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30290220.07sec, total: 30290220.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 60580440.14sec, total: 60580440.15sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 30290220.07sec, total: 30290220.08sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30290220.07sec, total: 30290220.07sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 30290220.07sec, total: 30290220.07sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30290220.07sec, total: 30290220.07sec
  train.py:359:image_losses, cpu: 2.41ms, accelerator: 1.44ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.40ms, accelerator: 1.44ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30290220.07sec, total: 30290220.08sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30290220.07sec, total: 30290220.07sec
  train.py:359:image_losses (gradient), cpu: 806us, accelerator: 515us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_152250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 30240563.97sec, total: 30240563.97sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30240563.97sec, total: 30240563.97sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30240563.97sec, total: 30240563.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 60481127.94sec, total: 60481127.95sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 30240563.97sec, total: 30240563.98sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30240563.97sec, total: 30240563.98sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 30240563.97sec, total: 30240563.98sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30240563.97sec, total: 30240563.98sec
  train.py:359:image_losses, cpu: 2.41ms, accelerator: 1.44ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.39ms, accelerator: 1.44ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30240563.97sec, total: 30240563.98sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30240563.97sec, total: 30240563.98sec
  train.py:359:image_losses (gradient), cpu: 806us, accelerator: 515us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_152500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 30191070.41sec, total: 30191070.42sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30191070.41sec, total: 30191070.41sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30191070.41sec, total: 30191070.41sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 60382140.83sec, total: 60382140.83sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 30191070.42sec, total: 30191070.42sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30191070.41sec, total: 30191070.42sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 30191070.41sec, total: 30191070.42sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30191070.41sec, total: 30191070.42sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.44ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.39ms, accelerator: 1.44ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30191070.42sec, total: 30191070.42sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 30191070.41sec, total: 30191070.42sec
  train.py:359:image_losses (gradient), cpu: 804us, accelerator: 514us, total: 1.33ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_152750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 30141738.60sec, total: 30141738.60sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30141738.60sec, total: 30141738.60sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30141738.60sec, total: 30141738.60sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 60283477.20sec, total: 60283477.20sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 30141738.60sec, total: 30141738.61sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30141738.60sec, total: 30141738.60sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30141738.60sec, total: 30141738.60sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30141738.60sec, total: 30141738.60sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.44ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.39ms, accelerator: 1.44ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30141738.60sec, total: 30141738.60sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30141738.60sec, total: 30141738.60sec
  train.py:359:image_losses (gradient), cpu: 803us, accelerator: 513us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_153000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 30092567.74sec, total: 30092567.74sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30092567.74sec, total: 30092567.74sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 392us, accelerator: 30092567.73sec, total: 30092567.74sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 60185135.47sec, total: 60185135.48sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 30092567.74sec, total: 30092567.75sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30092567.74sec, total: 30092567.74sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30092567.74sec, total: 30092567.74sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30092567.74sec, total: 30092567.74sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.44ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.39ms, accelerator: 1.44ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30092567.74sec, total: 30092567.74sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30092567.74sec, total: 30092567.74sec
  train.py:359:image_losses (gradient), cpu: 803us, accelerator: 512us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_153250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 30043557.04sec, total: 30043557.04sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 30043557.04sec, total: 30043557.04sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 30043557.04sec, total: 30043557.04sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 60087114.08sec, total: 60087114.09sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 30043557.04sec, total: 30043557.05sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 30043557.04sec, total: 30043557.04sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 30043557.04sec, total: 30043557.04sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 30043557.04sec, total: 30043557.04sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.44ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.44ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 30043557.04sec, total: 30043557.05sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 30043557.04sec, total: 30043557.04sec
  train.py:359:image_losses (gradient), cpu: 803us, accelerator: 511us, total: 1.32ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_153500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29994705.73sec, total: 29994705.73sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29994705.73sec, total: 29994705.73sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 29994705.73sec, total: 29994705.73sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59989411.46sec, total: 59989411.46sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 29994705.73sec, total: 29994705.74sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29994705.73sec, total: 29994705.73sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 29994705.73sec, total: 29994705.73sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 29994705.73sec, total: 29994705.73sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.44ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.44ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 29994705.73sec, total: 29994705.73sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29994705.73sec, total: 29994705.73sec
  train.py:359:image_losses (gradient), cpu: 803us, accelerator: 510us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_153750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29946013.02sec, total: 29946013.03sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29946013.02sec, total: 29946013.02sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 29946013.02sec, total: 29946013.02sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59892026.05sec, total: 59892026.05sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 29946013.03sec, total: 29946013.03sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29946013.02sec, total: 29946013.03sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 29946013.02sec, total: 29946013.03sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 29946013.02sec, total: 29946013.03sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.44ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.44ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 29946013.03sec, total: 29946013.03sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29946013.03sec, total: 29946013.03sec
  train.py:359:image_losses (gradient), cpu: 815us, accelerator: 510us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_154000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29897478.16sec, total: 29897478.16sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29897478.16sec, total: 29897478.16sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 29897478.15sec, total: 29897478.16sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59794956.31sec, total: 59794956.32sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 29897478.16sec, total: 29897478.17sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29897478.16sec, total: 29897478.16sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 29897478.16sec, total: 29897478.16sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 29897478.16sec, total: 29897478.16sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.44ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.44ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 29897478.16sec, total: 29897478.16sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29897478.16sec, total: 29897478.16sec
  train.py:359:image_losses (gradient), cpu: 815us, accelerator: 510us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_154250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29849100.36sec, total: 29849100.36sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29849100.36sec, total: 29849100.36sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 29849100.36sec, total: 29849100.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59698200.72sec, total: 59698200.73sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 29849100.36sec, total: 29849100.37sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29849100.36sec, total: 29849100.36sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 29849100.36sec, total: 29849100.36sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 29849100.36sec, total: 29849100.36sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.43ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.43ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 29849100.36sec, total: 29849100.37sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29849100.36sec, total: 29849100.36sec
  train.py:359:image_losses (gradient), cpu: 813us, accelerator: 509us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_154500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29800878.87sec, total: 29800878.88sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29800878.87sec, total: 29800878.87sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 391us, accelerator: 29800878.87sec, total: 29800878.87sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59601757.75sec, total: 59601757.75sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 29800878.88sec, total: 29800878.88sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29800878.87sec, total: 29800878.88sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 29800878.87sec, total: 29800878.88sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 29800878.87sec, total: 29800878.88sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.43ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.43ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.02ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 29800878.88sec, total: 29800878.88sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29800878.87sec, total: 29800878.88sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 508us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_154750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29752812.94sec, total: 29752812.94sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 29752812.94sec, total: 29752812.94sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 29752812.94sec, total: 29752812.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59505625.88sec, total: 59505625.88sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 29752812.94sec, total: 29752812.95sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29752812.94sec, total: 29752812.94sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 29752812.94sec, total: 29752812.94sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 29752812.94sec, total: 29752812.94sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.43ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.43ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 29752812.94sec, total: 29752812.95sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29752812.94sec, total: 29752812.94sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 508us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_155000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29704901.81sec, total: 29704901.81sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29704901.81sec, total: 29704901.81sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 29704901.81sec, total: 29704901.81sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59409803.62sec, total: 59409803.62sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 29704901.81sec, total: 29704901.82sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29704901.81sec, total: 29704901.81sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29704901.81sec, total: 29704901.81sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 29704901.81sec, total: 29704901.81sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.43ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.43ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.02ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 29704901.81sec, total: 29704901.81sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29704901.81sec, total: 29704901.81sec
  train.py:359:image_losses (gradient), cpu: 810us, accelerator: 507us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_155250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29657144.73sec, total: 29657144.73sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29657144.73sec, total: 29657144.73sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 29657144.73sec, total: 29657144.73sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59314289.46sec, total: 59314289.47sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 29657144.73sec, total: 29657144.74sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29657144.73sec, total: 29657144.74sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29657144.73sec, total: 29657144.74sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 29657144.73sec, total: 29657144.73sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.44ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.44ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 29657144.73sec, total: 29657144.74sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29657144.73sec, total: 29657144.74sec
  train.py:359:image_losses (gradient), cpu: 808us, accelerator: 508us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_155500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29609540.97sec, total: 29609540.97sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29609540.97sec, total: 29609540.97sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 29609540.97sec, total: 29609540.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59219081.94sec, total: 59219081.94sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 29609540.97sec, total: 29609540.98sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29609540.97sec, total: 29609540.97sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29609540.97sec, total: 29609540.97sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 29609540.97sec, total: 29609540.97sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.44ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.44ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 29609540.97sec, total: 29609540.97sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29609540.97sec, total: 29609540.97sec
  train.py:359:image_losses (gradient), cpu: 808us, accelerator: 508us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_155750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29562089.78sec, total: 29562089.78sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29562089.78sec, total: 29562089.78sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29562089.78sec, total: 29562089.78sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59124179.56sec, total: 59124179.57sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 29562089.78sec, total: 29562089.79sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29562089.78sec, total: 29562089.78sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29562089.78sec, total: 29562089.78sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29562089.78sec, total: 29562089.78sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.44ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.44ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 29562089.78sec, total: 29562089.79sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29562089.78sec, total: 29562089.78sec
  train.py:359:image_losses (gradient), cpu: 808us, accelerator: 508us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_156000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29514790.44sec, total: 29514790.44sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29514790.44sec, total: 29514790.44sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29514790.43sec, total: 29514790.43sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 59029580.87sec, total: 59029580.88sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 29514790.44sec, total: 29514790.45sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29514790.44sec, total: 29514790.44sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29514790.44sec, total: 29514790.44sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29514790.44sec, total: 29514790.44sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.44ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.44ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 29514790.44sec, total: 29514790.44sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29514790.44sec, total: 29514790.44sec
  train.py:359:image_losses (gradient), cpu: 808us, accelerator: 507us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_156250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29467642.21sec, total: 29467642.21sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29467642.21sec, total: 29467642.21sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29467642.21sec, total: 29467642.21sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 58935284.42sec, total: 58935284.42sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 29467642.21sec, total: 29467642.22sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29467642.21sec, total: 29467642.21sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29467642.21sec, total: 29467642.21sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29467642.21sec, total: 29467642.21sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.44ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.44ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 29467642.21sec, total: 29467642.21sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29467642.21sec, total: 29467642.21sec
  train.py:359:image_losses (gradient), cpu: 808us, accelerator: 506us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_156500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29420644.37sec, total: 29420644.38sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29420644.37sec, total: 29420644.38sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29420644.37sec, total: 29420644.37sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 58841288.75sec, total: 58841288.75sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 29420644.38sec, total: 29420644.38sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29420644.38sec, total: 29420644.38sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29420644.38sec, total: 29420644.38sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 29420644.38sec, total: 29420644.38sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.43ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.43ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.40ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 29420644.38sec, total: 29420644.38sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 29420644.38sec, total: 29420644.38sec
  train.py:359:image_losses (gradient), cpu: 808us, accelerator: 513us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_156750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29373796.21sec, total: 29373796.22sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 29373796.21sec, total: 29373796.22sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29373796.21sec, total: 29373796.21sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 58747592.43sec, total: 58747592.43sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 29373796.22sec, total: 29373796.22sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 29373796.22sec, total: 29373796.22sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29373796.22sec, total: 29373796.22sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29373796.22sec, total: 29373796.22sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.43ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.43ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 29373796.22sec, total: 29373796.22sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29373796.22sec, total: 29373796.22sec
  train.py:359:image_losses (gradient), cpu: 807us, accelerator: 512us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_157000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29327097.02sec, total: 29327097.02sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 29327097.01sec, total: 29327097.02sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29327097.01sec, total: 29327097.01sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 58654194.03sec, total: 58654194.04sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 29327097.02sec, total: 29327097.02sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 29327097.02sec, total: 29327097.02sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29327097.02sec, total: 29327097.02sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29327097.02sec, total: 29327097.02sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.43ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.43ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 29327097.02sec, total: 29327097.02sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29327097.02sec, total: 29327097.02sec
  train.py:359:image_losses (gradient), cpu: 807us, accelerator: 510us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_157250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29280546.07sec, total: 29280546.07sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 29280546.07sec, total: 29280546.07sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29280546.07sec, total: 29280546.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 58561092.14sec, total: 58561092.14sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 29280546.07sec, total: 29280546.08sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 29280546.07sec, total: 29280546.07sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29280546.07sec, total: 29280546.07sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29280546.07sec, total: 29280546.07sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.43ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.43ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.02ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 29280546.07sec, total: 29280546.07sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29280546.07sec, total: 29280546.07sec
  train.py:359:image_losses (gradient), cpu: 807us, accelerator: 510us, total: 1.32ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_157500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29234142.67sec, total: 29234142.67sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 29234142.67sec, total: 29234142.67sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29234142.66sec, total: 29234142.67sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 58468285.33sec, total: 58468285.34sec
train.py:442:<module>, cpu: 6.01ms, accelerator: 29234142.67sec, total: 29234142.68sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 29234142.67sec, total: 29234142.67sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29234142.67sec, total: 29234142.67sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29234142.67sec, total: 29234142.67sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.43ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.43ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.02ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 29234142.67sec, total: 29234142.67sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29234142.67sec, total: 29234142.67sec
  train.py:359:image_losses (gradient), cpu: 806us, accelerator: 510us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_157750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29187886.11sec, total: 29187886.11sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 29187886.11sec, total: 29187886.11sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29187886.11sec, total: 29187886.11sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 58375772.22sec, total: 58375772.23sec
train.py:442:<module>, cpu: 6.00ms, accelerator: 29187886.11sec, total: 29187886.12sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 29187886.11sec, total: 29187886.12sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29187886.11sec, total: 29187886.12sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29187886.11sec, total: 29187886.12sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.42ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.42ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.02ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 29187886.11sec, total: 29187886.12sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 29187886.11sec, total: 29187886.12sec
  train.py:359:image_losses (gradient), cpu: 803us, accelerator: 508us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_158000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29141775.71sec, total: 29141775.71sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 29141775.71sec, total: 29141775.71sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29141775.71sec, total: 29141775.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 58283551.42sec, total: 58283551.42sec
train.py:442:<module>, cpu: 6.00ms, accelerator: 29141775.71sec, total: 29141775.72sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 29141775.71sec, total: 29141775.71sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29141775.71sec, total: 29141775.71sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29141775.71sec, total: 29141775.71sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.42ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.42ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.02ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 29141775.71sec, total: 29141775.71sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29141775.71sec, total: 29141775.71sec
  train.py:359:image_losses (gradient), cpu: 800us, accelerator: 507us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_158250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.36ms, accelerator: 29095810.76sec, total: 29095810.76sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 29095810.76sec, total: 29095810.76sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29095810.76sec, total: 29095810.76sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 58191621.52sec, total: 58191621.53sec
train.py:442:<module>, cpu: 6.00ms, accelerator: 29095810.76sec, total: 29095810.77sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 29095810.76sec, total: 29095810.77sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29095810.76sec, total: 29095810.77sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29095810.76sec, total: 29095810.77sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.42ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.42ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.02ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 29095810.76sec, total: 29095810.77sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29095810.76sec, total: 29095810.77sec
  train.py:359:image_losses (gradient), cpu: 800us, accelerator: 507us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_158500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 29049990.59sec, total: 29049990.59sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 29049990.59sec, total: 29049990.59sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29049990.58sec, total: 29049990.59sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 58099981.18sec, total: 58099981.18sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 29049990.59sec, total: 29049990.60sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 29049990.59sec, total: 29049990.59sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 29049990.59sec, total: 29049990.59sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29049990.59sec, total: 29049990.59sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.43ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.43ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 29049990.59sec, total: 29049990.59sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 29049990.59sec, total: 29049990.59sec
  train.py:359:image_losses (gradient), cpu: 799us, accelerator: 507us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_158750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 29004314.50sec, total: 29004314.50sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 29004314.50sec, total: 29004314.50sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 29004314.50sec, total: 29004314.50sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 58008629.00sec, total: 58008629.01sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 29004314.50sec, total: 29004314.51sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 29004314.50sec, total: 29004314.51sec
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 29004314.50sec, total: 29004314.51sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 29004314.50sec, total: 29004314.51sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.43ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.43ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 29004314.50sec, total: 29004314.51sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 29004314.50sec, total: 29004314.51sec
  train.py:359:image_losses (gradient), cpu: 799us, accelerator: 506us, total: 1.31ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_159000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28958781.83sec, total: 28958781.83sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 28958781.82sec, total: 28958781.83sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 28958781.82sec, total: 28958781.82sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57917563.65sec, total: 57917563.66sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 28958781.83sec, total: 28958781.83sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 28958781.83sec, total: 28958781.83sec
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 28958781.83sec, total: 28958781.83sec
      train.py:349:msssim, cpu: 2.84ms, accelerator: 28958781.83sec, total: 28958781.83sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.43ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.43ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28958781.83sec, total: 28958781.83sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28958781.83sec, total: 28958781.83sec
  train.py:359:image_losses (gradient), cpu: 799us, accelerator: 506us, total: 1.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_159250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28913391.89sec, total: 28913391.89sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 28913391.88sec, total: 28913391.89sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 28913391.88sec, total: 28913391.88sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57826783.77sec, total: 57826783.78sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 28913391.89sec, total: 28913391.89sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 28913391.89sec, total: 28913391.89sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 28913391.89sec, total: 28913391.89sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 28913391.89sec, total: 28913391.89sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.43ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.43ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28913391.89sec, total: 28913391.89sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28913391.89sec, total: 28913391.89sec
  train.py:359:image_losses (gradient), cpu: 798us, accelerator: 526us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_159500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28868144.01sec, total: 28868144.01sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 28868144.01sec, total: 28868144.01sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 28868144.01sec, total: 28868144.01sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57736288.02sec, total: 57736288.03sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 28868144.01sec, total: 28868144.02sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 28868144.01sec, total: 28868144.01sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 28868144.01sec, total: 28868144.01sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 28868144.01sec, total: 28868144.01sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.42ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.42ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28868144.01sec, total: 28868144.02sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28868144.01sec, total: 28868144.01sec
  train.py:359:image_losses (gradient), cpu: 798us, accelerator: 525us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_159750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28823037.54sec, total: 28823037.54sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 28823037.53sec, total: 28823037.54sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 28823037.53sec, total: 28823037.53sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57646075.07sec, total: 57646075.08sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 28823037.54sec, total: 28823037.54sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 28823037.54sec, total: 28823037.54sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 28823037.54sec, total: 28823037.54sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 28823037.54sec, total: 28823037.54sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.42ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.42ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28823037.54sec, total: 28823037.54sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28823037.54sec, total: 28823037.54sec
  train.py:359:image_losses (gradient), cpu: 797us, accelerator: 522us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_160000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28778071.80sec, total: 28778071.80sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 28778071.80sec, total: 28778071.80sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 28778071.80sec, total: 28778071.80sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57556143.60sec, total: 57556143.60sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28778071.80sec, total: 28778071.81sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 28778071.80sec, total: 28778071.80sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 28778071.80sec, total: 28778071.80sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 28778071.80sec, total: 28778071.80sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.42ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.42ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.02ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28778071.80sec, total: 28778071.80sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28778071.80sec, total: 28778071.80sec
  train.py:359:image_losses (gradient), cpu: 797us, accelerator: 522us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_160250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28733246.14sec, total: 28733246.14sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 28733246.14sec, total: 28733246.14sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 28733246.14sec, total: 28733246.14sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57466492.28sec, total: 57466492.29sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28733246.14sec, total: 28733246.15sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 28733246.14sec, total: 28733246.15sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 28733246.14sec, total: 28733246.15sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 28733246.14sec, total: 28733246.15sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.43ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.43ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28733246.14sec, total: 28733246.15sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28733246.14sec, total: 28733246.15sec
  train.py:359:image_losses (gradient), cpu: 795us, accelerator: 520us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_160500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28688559.91sec, total: 28688559.91sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28688559.91sec, total: 28688559.91sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 28688559.91sec, total: 28688559.91sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57377119.82sec, total: 57377119.83sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28688559.91sec, total: 28688559.92sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 28688559.91sec, total: 28688559.91sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 28688559.91sec, total: 28688559.91sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 28688559.91sec, total: 28688559.91sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.42ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.42ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.03ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28688559.91sec, total: 28688559.92sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28688559.91sec, total: 28688559.92sec
  train.py:359:image_losses (gradient), cpu: 795us, accelerator: 520us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_160750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28644012.46sec, total: 28644012.46sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28644012.46sec, total: 28644012.46sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 28644012.46sec, total: 28644012.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57288024.92sec, total: 57288024.92sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28644012.46sec, total: 28644012.47sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 28644012.46sec, total: 28644012.46sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 28644012.46sec, total: 28644012.46sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 28644012.46sec, total: 28644012.46sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.42ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.42ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.03ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28644012.46sec, total: 28644012.46sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28644012.46sec, total: 28644012.46sec
  train.py:359:image_losses (gradient), cpu: 795us, accelerator: 520us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_161000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28599603.14sec, total: 28599603.14sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28599603.14sec, total: 28599603.14sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 390us, accelerator: 28599603.13sec, total: 28599603.13sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57199206.27sec, total: 57199206.28sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 28599603.14sec, total: 28599603.14sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 28599603.14sec, total: 28599603.14sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 28599603.14sec, total: 28599603.14sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 28599603.14sec, total: 28599603.14sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.42ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.42ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.02ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28599603.14sec, total: 28599603.14sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28599603.14sec, total: 28599603.14sec
  train.py:359:image_losses (gradient), cpu: 795us, accelerator: 519us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_161250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28555331.30sec, total: 28555331.31sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28555331.30sec, total: 28555331.31sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 28555331.30sec, total: 28555331.30sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57110662.61sec, total: 57110662.61sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 28555331.31sec, total: 28555331.31sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 28555331.31sec, total: 28555331.31sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 28555331.31sec, total: 28555331.31sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 28555331.31sec, total: 28555331.31sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.42ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.42ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.02ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28555331.31sec, total: 28555331.31sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28555331.31sec, total: 28555331.31sec
  train.py:359:image_losses (gradient), cpu: 795us, accelerator: 524us, total: 1.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_161500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28511196.33sec, total: 28511196.33sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28511196.32sec, total: 28511196.33sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 28511196.32sec, total: 28511196.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 57022392.65sec, total: 57022392.66sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 28511196.33sec, total: 28511196.33sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28511196.33sec, total: 28511196.33sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28511196.33sec, total: 28511196.33sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 28511196.33sec, total: 28511196.33sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.42ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.42ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.02ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28511196.33sec, total: 28511196.33sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28511196.33sec, total: 28511196.33sec
  train.py:359:image_losses (gradient), cpu: 795us, accelerator: 524us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_161750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28467197.57sec, total: 28467197.57sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28467197.57sec, total: 28467197.57sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 28467197.56sec, total: 28467197.56sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56934395.13sec, total: 56934395.14sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28467197.57sec, total: 28467197.57sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28467197.57sec, total: 28467197.57sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28467197.57sec, total: 28467197.57sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 28467197.57sec, total: 28467197.57sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.42ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.42ms, total: 3.77ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28467197.57sec, total: 28467197.57sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28467197.57sec, total: 28467197.57sec
  train.py:359:image_losses (gradient), cpu: 794us, accelerator: 523us, total: 1.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_162000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28423334.40sec, total: 28423334.40sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28423334.39sec, total: 28423334.40sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 389us, accelerator: 28423334.39sec, total: 28423334.39sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56846668.79sec, total: 56846668.80sec
train.py:442:<module>, cpu: 5.99ms, accelerator: 28423334.40sec, total: 28423334.40sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28423334.40sec, total: 28423334.40sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28423334.40sec, total: 28423334.40sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 28423334.40sec, total: 28423334.40sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.41ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.41ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.76ms, accelerator: 28423334.40sec, total: 28423334.40sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28423334.40sec, total: 28423334.40sec
  train.py:359:image_losses (gradient), cpu: 792us, accelerator: 537us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_162250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28379606.19sec, total: 28379606.19sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28379606.19sec, total: 28379606.19sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 28379606.19sec, total: 28379606.19sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56759212.38sec, total: 56759212.38sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28379606.19sec, total: 28379606.20sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28379606.19sec, total: 28379606.19sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28379606.19sec, total: 28379606.19sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 28379606.19sec, total: 28379606.19sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.41ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.41ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.76ms, accelerator: 28379606.19sec, total: 28379606.19sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28379606.19sec, total: 28379606.19sec
  train.py:359:image_losses (gradient), cpu: 792us, accelerator: 537us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_162500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28336012.32sec, total: 28336012.33sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28336012.32sec, total: 28336012.32sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 28336012.32sec, total: 28336012.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56672024.65sec, total: 56672024.65sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28336012.33sec, total: 28336012.33sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28336012.32sec, total: 28336012.33sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28336012.32sec, total: 28336012.33sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 28336012.32sec, total: 28336012.33sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.43ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.43ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.76ms, accelerator: 28336012.33sec, total: 28336012.33sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28336012.33sec, total: 28336012.33sec
  train.py:359:image_losses (gradient), cpu: 792us, accelerator: 537us, total: 1.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_162750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28292552.18sec, total: 28292552.18sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28292552.18sec, total: 28292552.18sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 28292552.18sec, total: 28292552.18sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56585104.37sec, total: 56585104.37sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28292552.18sec, total: 28292552.19sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28292552.18sec, total: 28292552.19sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28292552.18sec, total: 28292552.19sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 28292552.18sec, total: 28292552.19sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.43ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.43ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.75ms, accelerator: 28292552.18sec, total: 28292552.19sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28292552.18sec, total: 28292552.19sec
  train.py:359:image_losses (gradient), cpu: 790us, accelerator: 537us, total: 1.33ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_163000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28249225.15sec, total: 28249225.15sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28249225.15sec, total: 28249225.15sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 28249225.15sec, total: 28249225.15sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56498450.30sec, total: 56498450.30sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28249225.15sec, total: 28249225.16sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28249225.15sec, total: 28249225.15sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28249225.15sec, total: 28249225.15sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 28249225.15sec, total: 28249225.15sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.43ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.43ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.01ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28249225.15sec, total: 28249225.16sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28249225.15sec, total: 28249225.15sec
  train.py:359:image_losses (gradient), cpu: 804us, accelerator: 539us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_163250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28206030.62sec, total: 28206030.62sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28206030.61sec, total: 28206030.62sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 28206030.61sec, total: 28206030.61sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56412061.23sec, total: 56412061.24sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28206030.62sec, total: 28206030.62sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28206030.62sec, total: 28206030.62sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28206030.62sec, total: 28206030.62sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 28206030.62sec, total: 28206030.62sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.43ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.43ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28206030.62sec, total: 28206030.62sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28206030.62sec, total: 28206030.62sec
  train.py:359:image_losses (gradient), cpu: 803us, accelerator: 540us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_163500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28162967.97sec, total: 28162967.98sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28162967.97sec, total: 28162967.97sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 28162967.97sec, total: 28162967.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56325935.95sec, total: 56325935.95sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 28162967.98sec, total: 28162967.98sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28162967.97sec, total: 28162967.98sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28162967.97sec, total: 28162967.98sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 28162967.97sec, total: 28162967.98sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.44ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.44ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.03ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28162967.98sec, total: 28162967.98sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28162967.97sec, total: 28162967.98sec
  train.py:359:image_losses (gradient), cpu: 803us, accelerator: 541us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_163750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28120036.62sec, total: 28120036.62sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28120036.62sec, total: 28120036.62sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 28120036.62sec, total: 28120036.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56240073.24sec, total: 56240073.25sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 28120036.62sec, total: 28120036.63sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28120036.62sec, total: 28120036.62sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28120036.62sec, total: 28120036.62sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 28120036.62sec, total: 28120036.62sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.44ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.44ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.03ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28120036.62sec, total: 28120036.63sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28120036.62sec, total: 28120036.62sec
  train.py:359:image_losses (gradient), cpu: 804us, accelerator: 540us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_164000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28077235.96sec, total: 28077235.96sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28077235.95sec, total: 28077235.96sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 28077235.95sec, total: 28077235.95sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56154471.91sec, total: 56154471.92sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 28077235.96sec, total: 28077235.96sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 28077235.96sec, total: 28077235.96sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 28077235.96sec, total: 28077235.96sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 28077235.96sec, total: 28077235.96sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.44ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.34ms, accelerator: 1.44ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.03ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28077235.96sec, total: 28077235.96sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28077235.96sec, total: 28077235.96sec
  train.py:359:image_losses (gradient), cpu: 804us, accelerator: 546us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_164250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 28034565.38sec, total: 28034565.39sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 28034565.38sec, total: 28034565.39sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 28034565.38sec, total: 28034565.38sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 56069130.77sec, total: 56069130.77sec
train.py:442:<module>, cpu: 5.98ms, accelerator: 28034565.39sec, total: 28034565.39sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 28034565.39sec, total: 28034565.39sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 28034565.39sec, total: 28034565.39sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 28034565.39sec, total: 28034565.39sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.43ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.43ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 28034565.39sec, total: 28034565.39sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 28034565.39sec, total: 28034565.39sec
  train.py:359:image_losses (gradient), cpu: 803us, accelerator: 546us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_164500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 27992024.31sec, total: 27992024.32sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 27992024.31sec, total: 27992024.31sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 27992024.31sec, total: 27992024.31sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 55984048.63sec, total: 55984048.63sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 27992024.32sec, total: 27992024.32sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27992024.31sec, total: 27992024.32sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27992024.31sec, total: 27992024.32sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 27992024.31sec, total: 27992024.32sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.43ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.34ms, accelerator: 1.43ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 27992024.32sec, total: 27992024.32sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27992024.32sec, total: 27992024.32sec
  train.py:359:image_losses (gradient), cpu: 802us, accelerator: 545us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_164750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 27949612.16sec, total: 27949612.16sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 27949612.15sec, total: 27949612.16sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 27949612.15sec, total: 27949612.15sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 55899224.31sec, total: 55899224.32sec
train.py:442:<module>, cpu: 5.97ms, accelerator: 27949612.16sec, total: 27949612.16sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27949612.16sec, total: 27949612.16sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27949612.16sec, total: 27949612.16sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27949612.16sec, total: 27949612.16sec
  train.py:359:image_losses, cpu: 2.35ms, accelerator: 1.43ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.34ms, accelerator: 1.43ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 27949612.16sec, total: 27949612.16sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27949612.16sec, total: 27949612.16sec
  train.py:359:image_losses (gradient), cpu: 802us, accelerator: 545us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_165000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 27907328.33sec, total: 27907328.33sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 27907328.32sec, total: 27907328.33sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 27907328.32sec, total: 27907328.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 55814656.65sec, total: 55814656.65sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 27907328.33sec, total: 27907328.33sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27907328.33sec, total: 27907328.33sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27907328.33sec, total: 27907328.33sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27907328.33sec, total: 27907328.33sec
  train.py:359:image_losses, cpu: 2.35ms, accelerator: 1.43ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.34ms, accelerator: 1.43ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 27907328.33sec, total: 27907328.33sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27907328.33sec, total: 27907328.33sec
  train.py:359:image_losses (gradient), cpu: 800us, accelerator: 542us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_165250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 27865172.24sec, total: 27865172.24sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 27865172.24sec, total: 27865172.24sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27865172.24sec, total: 27865172.24sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 55730344.48sec, total: 55730344.48sec
train.py:442:<module>, cpu: 5.96ms, accelerator: 27865172.24sec, total: 27865172.25sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27865172.24sec, total: 27865172.24sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27865172.24sec, total: 27865172.24sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27865172.24sec, total: 27865172.24sec
  train.py:359:image_losses, cpu: 2.35ms, accelerator: 1.47ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.33ms, accelerator: 1.47ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.03ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 27865172.24sec, total: 27865172.25sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27865172.24sec, total: 27865172.24sec
  train.py:359:image_losses (gradient), cpu: 802us, accelerator: 542us, total: 1.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_165500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 27823143.32sec, total: 27823143.32sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 27823143.32sec, total: 27823143.32sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27823143.32sec, total: 27823143.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 55646286.65sec, total: 55646286.65sec
train.py:442:<module>, cpu: 5.95ms, accelerator: 27823143.33sec, total: 27823143.33sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27823143.32sec, total: 27823143.33sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27823143.32sec, total: 27823143.33sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27823143.32sec, total: 27823143.33sec
  train.py:359:image_losses, cpu: 2.34ms, accelerator: 1.48ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.33ms, accelerator: 1.48ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.03ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 27823143.32sec, total: 27823143.33sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27823143.32sec, total: 27823143.33sec
  train.py:359:image_losses (gradient), cpu: 819us, accelerator: 540us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2038.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_165750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 27781241.00sec, total: 27781241.00sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 27781241.00sec, total: 27781241.00sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27781241.00sec, total: 27781241.00sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 55562482.00sec, total: 55562482.00sec
train.py:442:<module>, cpu: 5.95ms, accelerator: 27781241.00sec, total: 27781241.01sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27781241.00sec, total: 27781241.00sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27781241.00sec, total: 27781241.00sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27781241.00sec, total: 27781241.00sec
  train.py:359:image_losses, cpu: 2.34ms, accelerator: 1.48ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.33ms, accelerator: 1.48ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.03ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27781241.00sec, total: 27781241.00sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27781241.00sec, total: 27781241.00sec
  train.py:359:image_losses (gradient), cpu: 818us, accelerator: 540us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2026.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_166000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27739464.70sec, total: 27739464.70sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27739464.70sec, total: 27739464.70sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27739464.69sec, total: 27739464.69sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 55478929.39sec, total: 55478929.40sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 27739464.70sec, total: 27739464.70sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27739464.70sec, total: 27739464.70sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27739464.70sec, total: 27739464.70sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27739464.70sec, total: 27739464.70sec
  train.py:359:image_losses, cpu: 2.34ms, accelerator: 1.49ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.32ms, accelerator: 1.49ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.05ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27739464.70sec, total: 27739464.70sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27739464.70sec, total: 27739464.70sec
  train.py:359:image_losses (gradient), cpu: 817us, accelerator: 538us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2031.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_166250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27697813.85sec, total: 27697813.85sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27697813.85sec, total: 27697813.85sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27697813.85sec, total: 27697813.85sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 55395627.70sec, total: 55395627.70sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 27697813.85sec, total: 27697813.86sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27697813.85sec, total: 27697813.85sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27697813.85sec, total: 27697813.85sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27697813.85sec, total: 27697813.85sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.50ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.32ms, accelerator: 1.50ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.06ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27697813.85sec, total: 27697813.85sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27697813.85sec, total: 27697813.85sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 539us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_166500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27656287.89sec, total: 27656287.89sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27656287.89sec, total: 27656287.89sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27656287.89sec, total: 27656287.89sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 55312575.78sec, total: 55312575.79sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 27656287.89sec, total: 27656287.90sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27656287.89sec, total: 27656287.89sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27656287.89sec, total: 27656287.89sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27656287.89sec, total: 27656287.89sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.50ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.32ms, accelerator: 1.50ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.06ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27656287.89sec, total: 27656287.90sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27656287.89sec, total: 27656287.89sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 539us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_166750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27614886.26sec, total: 27614886.26sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27614886.26sec, total: 27614886.26sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27614886.26sec, total: 27614886.26sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 55229772.52sec, total: 55229772.53sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 27614886.26sec, total: 27614886.27sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27614886.26sec, total: 27614886.27sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27614886.26sec, total: 27614886.27sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27614886.26sec, total: 27614886.27sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.51ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.32ms, accelerator: 1.51ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.06ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27614886.26sec, total: 27614886.27sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27614886.26sec, total: 27614886.27sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 538us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_167000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27573608.41sec, total: 27573608.41sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27573608.40sec, total: 27573608.41sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27573608.40sec, total: 27573608.40sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 55147216.81sec, total: 55147216.81sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 27573608.41sec, total: 27573608.41sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27573608.41sec, total: 27573608.41sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27573608.41sec, total: 27573608.41sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27573608.41sec, total: 27573608.41sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.51ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.32ms, accelerator: 1.51ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.06ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27573608.41sec, total: 27573608.41sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27573608.41sec, total: 27573608.41sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 538us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_167250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27532453.77sec, total: 27532453.77sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27532453.76sec, total: 27532453.77sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27532453.76sec, total: 27532453.76sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 55064907.53sec, total: 55064907.54sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 27532453.77sec, total: 27532453.77sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27532453.77sec, total: 27532453.77sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27532453.77sec, total: 27532453.77sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 27532453.77sec, total: 27532453.77sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.51ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.51ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.06ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27532453.77sec, total: 27532453.77sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27532453.77sec, total: 27532453.77sec
  train.py:359:image_losses (gradient), cpu: 816us, accelerator: 537us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_167500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27491421.79sec, total: 27491421.79sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27491421.79sec, total: 27491421.79sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27491421.79sec, total: 27491421.79sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54982843.59sec, total: 54982843.59sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 27491421.80sec, total: 27491421.80sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27491421.79sec, total: 27491421.80sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27491421.79sec, total: 27491421.80sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27491421.79sec, total: 27491421.80sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.51ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.51ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.06ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27491421.79sec, total: 27491421.80sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27491421.79sec, total: 27491421.80sec
  train.py:359:image_losses (gradient), cpu: 816us, accelerator: 537us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_167750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27450511.94sec, total: 27450511.94sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27450511.94sec, total: 27450511.94sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27450511.94sec, total: 27450511.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54901023.88sec, total: 54901023.88sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 27450511.94sec, total: 27450511.95sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27450511.94sec, total: 27450511.94sec
    train.py:322:loss_fn, cpu: 2.91ms, accelerator: 27450511.94sec, total: 27450511.94sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27450511.94sec, total: 27450511.94sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.52ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.52ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27450511.94sec, total: 27450511.94sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27450511.94sec, total: 27450511.94sec
  train.py:359:image_losses (gradient), cpu: 815us, accelerator: 537us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_168000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27409723.66sec, total: 27409723.66sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27409723.66sec, total: 27409723.66sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27409723.66sec, total: 27409723.66sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54819447.32sec, total: 54819447.32sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 27409723.66sec, total: 27409723.67sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27409723.66sec, total: 27409723.66sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27409723.66sec, total: 27409723.66sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 27409723.66sec, total: 27409723.66sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.52ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.52ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27409723.66sec, total: 27409723.67sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27409723.66sec, total: 27409723.66sec
  train.py:359:image_losses (gradient), cpu: 815us, accelerator: 546us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2038.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_168250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27369056.41sec, total: 27369056.42sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27369056.41sec, total: 27369056.41sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27369056.41sec, total: 27369056.41sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54738112.83sec, total: 54738112.83sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 27369056.42sec, total: 27369056.42sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 27369056.41sec, total: 27369056.42sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27369056.41sec, total: 27369056.42sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 27369056.41sec, total: 27369056.42sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.52ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.52ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27369056.42sec, total: 27369056.42sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27369056.42sec, total: 27369056.42sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 559us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_168500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27328509.66sec, total: 27328509.67sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27328509.66sec, total: 27328509.66sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27328509.66sec, total: 27328509.66sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54657019.33sec, total: 54657019.33sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 27328509.67sec, total: 27328509.67sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27328509.66sec, total: 27328509.67sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27328509.66sec, total: 27328509.67sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27328509.66sec, total: 27328509.67sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.53ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.53ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27328509.67sec, total: 27328509.67sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27328509.66sec, total: 27328509.67sec
  train.py:359:image_losses (gradient), cpu: 814us, accelerator: 560us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_168750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27288082.87sec, total: 27288082.88sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27288082.87sec, total: 27288082.88sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27288082.87sec, total: 27288082.87sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54576165.75sec, total: 54576165.75sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 27288082.88sec, total: 27288082.88sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 27288082.88sec, total: 27288082.88sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27288082.88sec, total: 27288082.88sec
      train.py:349:msssim, cpu: 2.86ms, accelerator: 27288082.88sec, total: 27288082.88sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.52ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.52ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27288082.88sec, total: 27288082.88sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27288082.88sec, total: 27288082.88sec
  train.py:359:image_losses (gradient), cpu: 813us, accelerator: 560us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_169000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27247775.51sec, total: 27247775.52sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27247775.51sec, total: 27247775.51sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27247775.51sec, total: 27247775.51sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54495551.03sec, total: 54495551.03sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 27247775.52sec, total: 27247775.52sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 27247775.51sec, total: 27247775.52sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27247775.51sec, total: 27247775.52sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 27247775.51sec, total: 27247775.52sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.52ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.52ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27247775.52sec, total: 27247775.52sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27247775.52sec, total: 27247775.52sec
  train.py:359:image_losses (gradient), cpu: 812us, accelerator: 559us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_169250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27207587.05sec, total: 27207587.06sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27207587.05sec, total: 27207587.06sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27207587.05sec, total: 27207587.05sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54415174.11sec, total: 54415174.11sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 27207587.06sec, total: 27207587.06sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 27207587.06sec, total: 27207587.06sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27207587.06sec, total: 27207587.06sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 27207587.06sec, total: 27207587.06sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.52ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.52ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 27207587.06sec, total: 27207587.06sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27207587.06sec, total: 27207587.06sec
  train.py:359:image_losses (gradient), cpu: 812us, accelerator: 560us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_169500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27167516.97sec, total: 27167516.97sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27167516.97sec, total: 27167516.97sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27167516.97sec, total: 27167516.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54335033.94sec, total: 54335033.95sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 27167516.97sec, total: 27167516.98sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 27167516.97sec, total: 27167516.97sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27167516.97sec, total: 27167516.97sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 27167516.97sec, total: 27167516.97sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.52ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.52ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 27167516.97sec, total: 27167516.98sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27167516.97sec, total: 27167516.97sec
  train.py:359:image_losses (gradient), cpu: 811us, accelerator: 560us, total: 1.37ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_169750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27127564.74sec, total: 27127564.74sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27127564.74sec, total: 27127564.74sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27127564.74sec, total: 27127564.74sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 54255129.48sec, total: 54255129.48sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 27127564.74sec, total: 27127564.75sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 27127564.74sec, total: 27127564.74sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27127564.74sec, total: 27127564.74sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 27127564.74sec, total: 27127564.74sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.52ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.52ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 27127564.74sec, total: 27127564.75sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27127564.74sec, total: 27127564.74sec
  train.py:359:image_losses (gradient), cpu: 810us, accelerator: 556us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_170000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27087729.84sec, total: 27087729.84sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 27087729.84sec, total: 27087729.84sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27087729.84sec, total: 27087729.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54175459.69sec, total: 54175459.69sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 27087729.85sec, total: 27087729.85sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 27087729.84sec, total: 27087729.85sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27087729.84sec, total: 27087729.85sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 27087729.84sec, total: 27087729.85sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.52ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.52ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 27087729.84sec, total: 27087729.85sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27087729.84sec, total: 27087729.85sec
  train.py:359:image_losses (gradient), cpu: 809us, accelerator: 556us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_170250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27048011.76sec, total: 27048011.77sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 27048011.76sec, total: 27048011.76sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27048011.76sec, total: 27048011.76sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54096023.53sec, total: 54096023.53sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 27048011.77sec, total: 27048011.77sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 27048011.76sec, total: 27048011.77sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27048011.76sec, total: 27048011.77sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 27048011.76sec, total: 27048011.77sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.52ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.52ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.39ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 27048011.77sec, total: 27048011.77sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27048011.77sec, total: 27048011.77sec
  train.py:359:image_losses (gradient), cpu: 809us, accelerator: 555us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_170500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 27008409.99sec, total: 27008409.99sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 27008409.99sec, total: 27008409.99sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 27008409.99sec, total: 27008409.99sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 54016819.98sec, total: 54016819.98sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 27008409.99sec, total: 27008410.00sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 27008409.99sec, total: 27008409.99sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 27008409.99sec, total: 27008409.99sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 27008409.99sec, total: 27008409.99sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.52ms, total: 3.85ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.52ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.77ms, accelerator: 27008409.99sec, total: 27008410.00sec
  train.py:360:image_losses (gradient), cpu: 2.75ms, accelerator: 27008409.99sec, total: 27008409.99sec
  train.py:359:image_losses (gradient), cpu: 811us, accelerator: 555us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2027.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_170750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 26968924.01sec, total: 26968924.01sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 26968924.01sec, total: 26968924.01sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 26968924.01sec, total: 26968924.01sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 53937848.02sec, total: 53937848.03sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 26968924.01sec, total: 26968924.02sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26968924.01sec, total: 26968924.01sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26968924.01sec, total: 26968924.01sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26968924.01sec, total: 26968924.01sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.52ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.52ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 26968924.01sec, total: 26968924.02sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 26968924.01sec, total: 26968924.01sec
  train.py:359:image_losses (gradient), cpu: 821us, accelerator: 554us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_171000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 26929553.32sec, total: 26929553.32sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 26929553.32sec, total: 26929553.32sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 26929553.32sec, total: 26929553.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 53859106.64sec, total: 53859106.64sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 26929553.32sec, total: 26929553.33sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26929553.32sec, total: 26929553.32sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26929553.32sec, total: 26929553.32sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26929553.32sec, total: 26929553.32sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.51ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.51ms, total: 3.83ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.07ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.78ms, accelerator: 26929553.32sec, total: 26929553.32sec
  train.py:360:image_losses (gradient), cpu: 2.74ms, accelerator: 26929553.32sec, total: 26929553.32sec
  train.py:359:image_losses (gradient), cpu: 821us, accelerator: 554us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2023.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_171250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 26890297.41sec, total: 26890297.41sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26890297.41sec, total: 26890297.41sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 26890297.41sec, total: 26890297.41sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53780594.82sec, total: 53780594.82sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 26890297.41sec, total: 26890297.42sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26890297.41sec, total: 26890297.41sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26890297.41sec, total: 26890297.41sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26890297.41sec, total: 26890297.41sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.51ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.51ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.06ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 26890297.41sec, total: 26890297.42sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 26890297.41sec, total: 26890297.41sec
  train.py:359:image_losses (gradient), cpu: 820us, accelerator: 553us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_171500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 26851155.78sec, total: 26851155.78sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26851155.78sec, total: 26851155.78sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 26851155.78sec, total: 26851155.78sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53702311.57sec, total: 53702311.57sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 26851155.79sec, total: 26851155.79sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26851155.78sec, total: 26851155.79sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26851155.78sec, total: 26851155.79sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26851155.78sec, total: 26851155.79sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.51ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.51ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.06ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 26851155.79sec, total: 26851155.79sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 26851155.78sec, total: 26851155.79sec
  train.py:359:image_losses (gradient), cpu: 819us, accelerator: 553us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_171750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 26812127.94sec, total: 26812127.94sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26812127.94sec, total: 26812127.94sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 26812127.94sec, total: 26812127.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53624255.88sec, total: 53624255.89sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 26812127.94sec, total: 26812127.95sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26812127.94sec, total: 26812127.94sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26812127.94sec, total: 26812127.94sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26812127.94sec, total: 26812127.94sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.50ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.50ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.06ms, total: 2.38ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26812127.94sec, total: 26812127.95sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 26812127.94sec, total: 26812127.94sec
  train.py:359:image_losses (gradient), cpu: 817us, accelerator: 553us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_172000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26773213.39sec, total: 26773213.39sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 26773213.38sec, total: 26773213.39sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 26773213.38sec, total: 26773213.38sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53546426.77sec, total: 53546426.78sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 26773213.39sec, total: 26773213.39sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26773213.39sec, total: 26773213.39sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26773213.39sec, total: 26773213.39sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26773213.39sec, total: 26773213.39sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.50ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.50ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.06ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26773213.39sec, total: 26773213.39sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 26773213.39sec, total: 26773213.39sec
  train.py:359:image_losses (gradient), cpu: 815us, accelerator: 552us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_172250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26734411.63sec, total: 26734411.63sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 26734411.63sec, total: 26734411.63sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 26734411.63sec, total: 26734411.63sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53468823.26sec, total: 53468823.26sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 26734411.63sec, total: 26734411.64sec
  train.py:360:image_losses, cpu: 2.92ms, accelerator: 26734411.63sec, total: 26734411.63sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26734411.63sec, total: 26734411.63sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26734411.63sec, total: 26734411.63sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.50ms, total: 3.83ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.50ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.06ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26734411.63sec, total: 26734411.63sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 26734411.63sec, total: 26734411.63sec
  train.py:359:image_losses (gradient), cpu: 813us, accelerator: 552us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_172500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26695722.18sec, total: 26695722.18sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26695722.17sec, total: 26695722.18sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 26695722.17sec, total: 26695722.17sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53391444.35sec, total: 53391444.35sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 26695722.18sec, total: 26695722.18sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26695722.18sec, total: 26695722.18sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26695722.18sec, total: 26695722.18sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26695722.18sec, total: 26695722.18sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.50ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.50ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.06ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26695722.18sec, total: 26695722.18sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 26695722.18sec, total: 26695722.18sec
  train.py:359:image_losses (gradient), cpu: 813us, accelerator: 548us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_172750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26657144.54sec, total: 26657144.54sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26657144.54sec, total: 26657144.54sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26657144.54sec, total: 26657144.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53314289.08sec, total: 53314289.09sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 26657144.54sec, total: 26657144.55sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26657144.54sec, total: 26657144.55sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26657144.54sec, total: 26657144.55sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26657144.54sec, total: 26657144.55sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.50ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.50ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.06ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26657144.54sec, total: 26657144.55sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 26657144.54sec, total: 26657144.55sec
  train.py:359:image_losses (gradient), cpu: 812us, accelerator: 549us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_173000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 26618678.24sec, total: 26618678.25sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26618678.24sec, total: 26618678.24sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26618678.24sec, total: 26618678.24sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53237356.49sec, total: 53237356.49sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 26618678.25sec, total: 26618678.25sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26618678.24sec, total: 26618678.25sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26618678.24sec, total: 26618678.25sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26618678.24sec, total: 26618678.25sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.50ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.50ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.06ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26618678.25sec, total: 26618678.25sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 26618678.24sec, total: 26618678.25sec
  train.py:359:image_losses (gradient), cpu: 811us, accelerator: 549us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_173250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26580322.80sec, total: 26580322.80sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26580322.80sec, total: 26580322.80sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26580322.80sec, total: 26580322.80sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53160645.60sec, total: 53160645.60sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 26580322.80sec, total: 26580322.81sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26580322.80sec, total: 26580322.80sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26580322.80sec, total: 26580322.80sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26580322.80sec, total: 26580322.80sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.50ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.50ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.06ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26580322.80sec, total: 26580322.81sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26580322.80sec, total: 26580322.80sec
  train.py:359:image_losses (gradient), cpu: 811us, accelerator: 547us, total: 1.37ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2030.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_173500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26542077.73sec, total: 26542077.73sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26542077.73sec, total: 26542077.73sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26542077.73sec, total: 26542077.73sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53084155.46sec, total: 53084155.47sec
train.py:442:<module>, cpu: 5.88ms, accelerator: 26542077.73sec, total: 26542077.74sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26542077.73sec, total: 26542077.73sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26542077.73sec, total: 26542077.73sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26542077.73sec, total: 26542077.73sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.50ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.50ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.06ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26542077.73sec, total: 26542077.74sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26542077.73sec, total: 26542077.73sec
  train.py:359:image_losses (gradient), cpu: 810us, accelerator: 547us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_173750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26503942.56sec, total: 26503942.56sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26503942.56sec, total: 26503942.56sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26503942.56sec, total: 26503942.56sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 53007885.12sec, total: 53007885.13sec
train.py:442:<module>, cpu: 5.88ms, accelerator: 26503942.56sec, total: 26503942.57sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 26503942.56sec, total: 26503942.57sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 26503942.56sec, total: 26503942.57sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 26503942.56sec, total: 26503942.57sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.50ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.50ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.06ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26503942.56sec, total: 26503942.57sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26503942.56sec, total: 26503942.57sec
  train.py:359:image_losses (gradient), cpu: 810us, accelerator: 547us, total: 1.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_174000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26465916.82sec, total: 26465916.82sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26465916.82sec, total: 26465916.82sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26465916.82sec, total: 26465916.82sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52931833.64sec, total: 52931833.64sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 26465916.82sec, total: 26465916.83sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26465916.82sec, total: 26465916.82sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 26465916.82sec, total: 26465916.82sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26465916.82sec, total: 26465916.82sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.49ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.49ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.05ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26465916.82sec, total: 26465916.82sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26465916.82sec, total: 26465916.82sec
  train.py:359:image_losses (gradient), cpu: 809us, accelerator: 546us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_174250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26428000.03sec, total: 26428000.03sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26428000.03sec, total: 26428000.03sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26428000.03sec, total: 26428000.03sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52856000.07sec, total: 52856000.07sec
train.py:442:<module>, cpu: 5.95ms, accelerator: 26428000.04sec, total: 26428000.04sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26428000.03sec, total: 26428000.04sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 26428000.03sec, total: 26428000.04sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26428000.03sec, total: 26428000.04sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.49ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.49ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.05ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 26428000.03sec, total: 26428000.04sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26428000.03sec, total: 26428000.04sec
  train.py:359:image_losses (gradient), cpu: 809us, accelerator: 545us, total: 1.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_174500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26390191.74sec, total: 26390191.74sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26390191.73sec, total: 26390191.74sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26390191.73sec, total: 26390191.73sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52780383.47sec, total: 52780383.48sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 26390191.74sec, total: 26390191.74sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26390191.74sec, total: 26390191.74sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 26390191.74sec, total: 26390191.74sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26390191.74sec, total: 26390191.74sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.49ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.49ms, total: 3.80ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.05ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 26390191.74sec, total: 26390191.74sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26390191.74sec, total: 26390191.74sec
  train.py:359:image_losses (gradient), cpu: 831us, accelerator: 543us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_174750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26352491.46sec, total: 26352491.46sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26352491.46sec, total: 26352491.46sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26352491.46sec, total: 26352491.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52704982.92sec, total: 52704982.93sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 26352491.46sec, total: 26352491.47sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26352491.46sec, total: 26352491.47sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 26352491.46sec, total: 26352491.47sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26352491.46sec, total: 26352491.47sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.49ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.49ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.05ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 26352491.46sec, total: 26352491.47sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26352491.46sec, total: 26352491.47sec
  train.py:359:image_losses (gradient), cpu: 830us, accelerator: 543us, total: 1.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_175000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26314898.75sec, total: 26314898.75sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26314898.75sec, total: 26314898.75sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26314898.75sec, total: 26314898.75sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52629797.50sec, total: 52629797.50sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 26314898.75sec, total: 26314898.76sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26314898.75sec, total: 26314898.75sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 26314898.75sec, total: 26314898.75sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26314898.75sec, total: 26314898.75sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.49ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.49ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.05ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 26314898.75sec, total: 26314898.75sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26314898.75sec, total: 26314898.75sec
  train.py:359:image_losses (gradient), cpu: 835us, accelerator: 543us, total: 1.39ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_175250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26277413.14sec, total: 26277413.14sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26277413.14sec, total: 26277413.14sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26277413.14sec, total: 26277413.14sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52554826.28sec, total: 52554826.28sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 26277413.14sec, total: 26277413.15sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26277413.14sec, total: 26277413.14sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 26277413.14sec, total: 26277413.14sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26277413.14sec, total: 26277413.14sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.48ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.48ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.05ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 26277413.14sec, total: 26277413.14sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26277413.14sec, total: 26277413.14sec
  train.py:359:image_losses (gradient), cpu: 833us, accelerator: 549us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_175500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26240034.17sec, total: 26240034.17sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26240034.17sec, total: 26240034.17sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26240034.17sec, total: 26240034.17sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52480068.34sec, total: 52480068.35sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 26240034.17sec, total: 26240034.18sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26240034.17sec, total: 26240034.18sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 26240034.17sec, total: 26240034.18sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26240034.17sec, total: 26240034.18sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.48ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.48ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.05ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 26240034.17sec, total: 26240034.18sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26240034.17sec, total: 26240034.18sec
  train.py:359:image_losses (gradient), cpu: 832us, accelerator: 551us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_175750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26202761.40sec, total: 26202761.40sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26202761.40sec, total: 26202761.40sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26202761.39sec, total: 26202761.39sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52405522.79sec, total: 52405522.80sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 26202761.40sec, total: 26202761.40sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26202761.40sec, total: 26202761.40sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 26202761.40sec, total: 26202761.40sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26202761.40sec, total: 26202761.40sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.48ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.48ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.05ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 26202761.40sec, total: 26202761.40sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26202761.40sec, total: 26202761.40sec
  train.py:359:image_losses (gradient), cpu: 832us, accelerator: 550us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2058.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_176000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26165594.36sec, total: 26165594.36sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26165594.36sec, total: 26165594.36sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26165594.36sec, total: 26165594.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52331188.72sec, total: 52331188.72sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 26165594.36sec, total: 26165594.37sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26165594.36sec, total: 26165594.36sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 26165594.36sec, total: 26165594.36sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26165594.36sec, total: 26165594.36sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.48ms, total: 3.80ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.48ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.04ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 26165594.36sec, total: 26165594.36sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 26165594.36sec, total: 26165594.36sec
  train.py:359:image_losses (gradient), cpu: 831us, accelerator: 550us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_176250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26128532.61sec, total: 26128532.61sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26128532.61sec, total: 26128532.61sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26128532.61sec, total: 26128532.61sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52257065.22sec, total: 52257065.23sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 26128532.61sec, total: 26128532.62sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26128532.61sec, total: 26128532.61sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 26128532.61sec, total: 26128532.61sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26128532.61sec, total: 26128532.61sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.48ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.48ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.04ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 26128532.61sec, total: 26128532.62sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 26128532.61sec, total: 26128532.61sec
  train.py:359:image_losses (gradient), cpu: 831us, accelerator: 549us, total: 1.39ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_176500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26091575.70sec, total: 26091575.71sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26091575.70sec, total: 26091575.71sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 26091575.70sec, total: 26091575.70sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52183151.41sec, total: 52183151.41sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 26091575.71sec, total: 26091575.71sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 26091575.71sec, total: 26091575.71sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 26091575.71sec, total: 26091575.71sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 26091575.71sec, total: 26091575.71sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.48ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.48ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.04ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 26091575.71sec, total: 26091575.71sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26091575.71sec, total: 26091575.71sec
  train.py:359:image_losses (gradient), cpu: 831us, accelerator: 550us, total: 1.39ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2033.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_176750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26054723.20sec, total: 26054723.20sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26054723.20sec, total: 26054723.20sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 26054723.19sec, total: 26054723.19sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52109446.39sec, total: 52109446.40sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 26054723.20sec, total: 26054723.20sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26054723.20sec, total: 26054723.20sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 26054723.20sec, total: 26054723.20sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26054723.20sec, total: 26054723.20sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.48ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.48ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.04ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 26054723.20sec, total: 26054723.20sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26054723.20sec, total: 26054723.20sec
  train.py:359:image_losses (gradient), cpu: 831us, accelerator: 547us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_177000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 26017974.64sec, total: 26017974.65sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26017974.64sec, total: 26017974.65sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 26017974.64sec, total: 26017974.64sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 52035949.29sec, total: 52035949.29sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 26017974.65sec, total: 26017974.65sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 26017974.65sec, total: 26017974.65sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 26017974.65sec, total: 26017974.65sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 26017974.65sec, total: 26017974.65sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.48ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.48ms, total: 3.78ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.04ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 26017974.65sec, total: 26017974.65sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 26017974.65sec, total: 26017974.65sec
  train.py:359:image_losses (gradient), cpu: 831us, accelerator: 547us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_177250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25981329.61sec, total: 25981329.61sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25981329.61sec, total: 25981329.61sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25981329.61sec, total: 25981329.61sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 51962659.22sec, total: 51962659.22sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25981329.61sec, total: 25981329.62sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 25981329.61sec, total: 25981329.61sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 25981329.61sec, total: 25981329.61sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 25981329.61sec, total: 25981329.61sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.47ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.47ms, total: 3.77ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.04ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25981329.61sec, total: 25981329.62sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 25981329.61sec, total: 25981329.61sec
  train.py:359:image_losses (gradient), cpu: 830us, accelerator: 546us, total: 1.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2026.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_177500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25944787.66sec, total: 25944787.66sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25944787.65sec, total: 25944787.66sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25944787.65sec, total: 25944787.65sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 51889575.31sec, total: 51889575.32sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25944787.66sec, total: 25944787.66sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 25944787.66sec, total: 25944787.66sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 25944787.66sec, total: 25944787.66sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 25944787.66sec, total: 25944787.66sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.47ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.47ms, total: 3.77ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.04ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25944787.66sec, total: 25944787.66sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 25944787.66sec, total: 25944787.66sec
  train.py:359:image_losses (gradient), cpu: 830us, accelerator: 574us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_177750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25908348.35sec, total: 25908348.35sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25908348.35sec, total: 25908348.35sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25908348.34sec, total: 25908348.35sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 51816696.69sec, total: 51816696.70sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25908348.35sec, total: 25908348.36sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 25908348.35sec, total: 25908348.35sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 25908348.35sec, total: 25908348.35sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 25908348.35sec, total: 25908348.35sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.47ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.47ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.04ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25908348.35sec, total: 25908348.35sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 25908348.35sec, total: 25908348.35sec
  train.py:359:image_losses (gradient), cpu: 830us, accelerator: 573us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_178000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25872011.25sec, total: 25872011.25sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25872011.25sec, total: 25872011.25sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25872011.25sec, total: 25872011.25sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 51744022.51sec, total: 51744022.51sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25872011.26sec, total: 25872011.26sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 25872011.25sec, total: 25872011.26sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 25872011.25sec, total: 25872011.26sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 25872011.25sec, total: 25872011.26sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.47ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.47ms, total: 3.77ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.04ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25872011.25sec, total: 25872011.26sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25872011.25sec, total: 25872011.26sec
  train.py:359:image_losses (gradient), cpu: 830us, accelerator: 571us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_178250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25835775.94sec, total: 25835775.94sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25835775.94sec, total: 25835775.94sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25835775.94sec, total: 25835775.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 51671551.89sec, total: 51671551.89sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25835775.95sec, total: 25835775.95sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 25835775.94sec, total: 25835775.95sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 25835775.94sec, total: 25835775.95sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 25835775.94sec, total: 25835775.95sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.47ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.47ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.03ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25835775.94sec, total: 25835775.95sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25835775.94sec, total: 25835775.95sec
  train.py:359:image_losses (gradient), cpu: 829us, accelerator: 571us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2030.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_178500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25799641.99sec, total: 25799641.99sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25799641.99sec, total: 25799641.99sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 25799641.99sec, total: 25799641.99sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 51599283.98sec, total: 51599283.99sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25799641.99sec, total: 25799642.00sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 25799641.99sec, total: 25799641.99sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 25799641.99sec, total: 25799641.99sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 25799641.99sec, total: 25799641.99sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.47ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.47ms, total: 3.77ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.03ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 25799641.99sec, total: 25799642.00sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25799641.99sec, total: 25799641.99sec
  train.py:359:image_losses (gradient), cpu: 826us, accelerator: 571us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_178750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25763608.97sec, total: 25763608.97sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25763608.97sec, total: 25763608.97sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 25763608.97sec, total: 25763608.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 51527217.94sec, total: 51527217.95sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 25763608.97sec, total: 25763608.98sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 25763608.97sec, total: 25763608.97sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25763608.97sec, total: 25763608.97sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 25763608.97sec, total: 25763608.97sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.47ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.47ms, total: 3.77ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 1.03ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 25763608.97sec, total: 25763608.98sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25763608.97sec, total: 25763608.97sec
  train.py:359:image_losses (gradient), cpu: 825us, accelerator: 570us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_179000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25727676.46sec, total: 25727676.46sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25727676.46sec, total: 25727676.46sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 25727676.46sec, total: 25727676.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 51455352.92sec, total: 51455352.93sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 25727676.46sec, total: 25727676.47sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 25727676.46sec, total: 25727676.47sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25727676.46sec, total: 25727676.47sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 25727676.46sec, total: 25727676.47sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.46ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.46ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 1.03ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.80ms, accelerator: 25727676.46sec, total: 25727676.47sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25727676.46sec, total: 25727676.47sec
  train.py:359:image_losses (gradient), cpu: 824us, accelerator: 570us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_179250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25691844.04sec, total: 25691844.04sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25691844.04sec, total: 25691844.04sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 25691844.04sec, total: 25691844.04sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 51383688.09sec, total: 51383688.09sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 25691844.05sec, total: 25691844.05sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25691844.04sec, total: 25691844.05sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25691844.04sec, total: 25691844.05sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25691844.04sec, total: 25691844.05sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.46ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.46ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 1.03ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 25691844.05sec, total: 25691844.05sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25691844.04sec, total: 25691844.05sec
  train.py:359:image_losses (gradient), cpu: 823us, accelerator: 571us, total: 1.40ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2042.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_179500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25656111.30sec, total: 25656111.30sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25656111.30sec, total: 25656111.30sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25656111.30sec, total: 25656111.30sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 51312222.60sec, total: 51312222.60sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 25656111.30sec, total: 25656111.31sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25656111.30sec, total: 25656111.30sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25656111.30sec, total: 25656111.30sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25656111.30sec, total: 25656111.30sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.46ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.46ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 1.03ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.79ms, accelerator: 25656111.30sec, total: 25656111.30sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25656111.30sec, total: 25656111.30sec
  train.py:359:image_losses (gradient), cpu: 823us, accelerator: 571us, total: 1.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_179750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25620477.81sec, total: 25620477.81sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25620477.81sec, total: 25620477.81sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25620477.81sec, total: 25620477.81sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 51240955.62sec, total: 51240955.62sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25620477.81sec, total: 25620477.82sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 25620477.81sec, total: 25620477.81sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25620477.81sec, total: 25620477.81sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 25620477.81sec, total: 25620477.81sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.46ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.46ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 1.03ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25620477.81sec, total: 25620477.82sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25620477.81sec, total: 25620477.81sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 571us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_180000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25584943.17sec, total: 25584943.17sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25584943.17sec, total: 25584943.17sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25584943.16sec, total: 25584943.16sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 51169886.33sec, total: 51169886.34sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 25584943.17sec, total: 25584943.18sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25584943.17sec, total: 25584943.17sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25584943.17sec, total: 25584943.17sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25584943.17sec, total: 25584943.17sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.46ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.46ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.03ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25584943.17sec, total: 25584943.17sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25584943.17sec, total: 25584943.17sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 571us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2060.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_180250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25549506.96sec, total: 25549506.96sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25549506.96sec, total: 25549506.96sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25549506.95sec, total: 25549506.96sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 51099013.91sec, total: 51099013.92sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 25549506.96sec, total: 25549506.97sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25549506.96sec, total: 25549506.96sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25549506.96sec, total: 25549506.96sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25549506.96sec, total: 25549506.96sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.45ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.02ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25549506.96sec, total: 25549506.96sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25549506.96sec, total: 25549506.96sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 570us, total: 1.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_180500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25514168.77sec, total: 25514168.77sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25514168.77sec, total: 25514168.77sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25514168.77sec, total: 25514168.77sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 51028337.55sec, total: 51028337.55sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 25514168.78sec, total: 25514168.78sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 25514168.77sec, total: 25514168.78sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25514168.77sec, total: 25514168.78sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 25514168.77sec, total: 25514168.78sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.45ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.02ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25514168.78sec, total: 25514168.78sec
  train.py:360:image_losses (gradient), cpu: 2.76ms, accelerator: 25514168.77sec, total: 25514168.78sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 585us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_180750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25478928.21sec, total: 25478928.21sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25478928.21sec, total: 25478928.21sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 25478928.21sec, total: 25478928.21sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50957856.42sec, total: 50957856.42sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25478928.21sec, total: 25478928.22sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25478928.21sec, total: 25478928.21sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25478928.21sec, total: 25478928.21sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25478928.21sec, total: 25478928.21sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.45ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.02ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25478928.21sec, total: 25478928.21sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 25478928.21sec, total: 25478928.21sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 585us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_181000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25443784.86sec, total: 25443784.86sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25443784.86sec, total: 25443784.86sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25443784.86sec, total: 25443784.86sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50887569.72sec, total: 50887569.72sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25443784.86sec, total: 25443784.87sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25443784.86sec, total: 25443784.86sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25443784.86sec, total: 25443784.86sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25443784.86sec, total: 25443784.86sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.45ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.02ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.81ms, accelerator: 25443784.86sec, total: 25443784.87sec
  train.py:360:image_losses (gradient), cpu: 2.77ms, accelerator: 25443784.86sec, total: 25443784.86sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 585us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_181250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25408738.32sec, total: 25408738.33sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25408738.32sec, total: 25408738.32sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25408738.32sec, total: 25408738.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50817476.65sec, total: 50817476.65sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 25408738.33sec, total: 25408738.33sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25408738.32sec, total: 25408738.33sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25408738.32sec, total: 25408738.33sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25408738.32sec, total: 25408738.33sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.45ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.02ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 25408738.33sec, total: 25408738.33sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25408738.32sec, total: 25408738.33sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 585us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_181500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25373788.20sec, total: 25373788.20sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25373788.20sec, total: 25373788.20sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25373788.20sec, total: 25373788.20sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50747576.41sec, total: 50747576.41sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 25373788.20sec, total: 25373788.21sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25373788.20sec, total: 25373788.21sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25373788.20sec, total: 25373788.21sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25373788.20sec, total: 25373788.21sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.45ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.02ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 25373788.20sec, total: 25373788.21sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25373788.20sec, total: 25373788.21sec
  train.py:359:image_losses (gradient), cpu: 833us, accelerator: 584us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_181750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25338934.10sec, total: 25338934.10sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25338934.10sec, total: 25338934.10sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25338934.10sec, total: 25338934.10sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50677868.20sec, total: 50677868.20sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 25338934.10sec, total: 25338934.11sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25338934.10sec, total: 25338934.10sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25338934.10sec, total: 25338934.10sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25338934.10sec, total: 25338934.10sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.45ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.02ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 25338934.10sec, total: 25338934.10sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25338934.10sec, total: 25338934.10sec
  train.py:359:image_losses (gradient), cpu: 833us, accelerator: 583us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2028.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_182000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25304175.61sec, total: 25304175.62sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25304175.61sec, total: 25304175.62sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25304175.61sec, total: 25304175.61sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50608351.23sec, total: 50608351.23sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 25304175.62sec, total: 25304175.62sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25304175.62sec, total: 25304175.62sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25304175.62sec, total: 25304175.62sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25304175.62sec, total: 25304175.62sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.01ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 25304175.62sec, total: 25304175.62sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25304175.62sec, total: 25304175.62sec
  train.py:359:image_losses (gradient), cpu: 836us, accelerator: 582us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_182250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25269512.36sec, total: 25269512.36sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25269512.36sec, total: 25269512.36sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25269512.36sec, total: 25269512.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50539024.72sec, total: 50539024.73sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 25269512.36sec, total: 25269512.37sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25269512.36sec, total: 25269512.36sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25269512.36sec, total: 25269512.36sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25269512.36sec, total: 25269512.36sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.44ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.01ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.82ms, accelerator: 25269512.36sec, total: 25269512.37sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25269512.36sec, total: 25269512.36sec
  train.py:359:image_losses (gradient), cpu: 836us, accelerator: 587us, total: 1.43ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2056.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_182500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 25234943.94sec, total: 25234943.95sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25234943.94sec, total: 25234943.94sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25234943.94sec, total: 25234943.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50469887.89sec, total: 50469887.89sec
train.py:442:<module>, cpu: 5.94ms, accelerator: 25234943.95sec, total: 25234943.95sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25234943.94sec, total: 25234943.95sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25234943.94sec, total: 25234943.95sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25234943.94sec, total: 25234943.95sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.01ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 25234943.95sec, total: 25234943.95sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25234943.95sec, total: 25234943.95sec
  train.py:359:image_losses (gradient), cpu: 836us, accelerator: 587us, total: 1.43ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_182750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25200469.98sec, total: 25200469.98sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 25200469.98sec, total: 25200469.98sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25200469.97sec, total: 25200469.98sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50400939.95sec, total: 50400939.96sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 25200469.98sec, total: 25200469.99sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25200469.98sec, total: 25200469.98sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25200469.98sec, total: 25200469.98sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25200469.98sec, total: 25200469.98sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.01ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 25200469.98sec, total: 25200469.98sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25200469.98sec, total: 25200469.98sec
  train.py:359:image_losses (gradient), cpu: 836us, accelerator: 586us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_183000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25166090.07sec, total: 25166090.07sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25166090.07sec, total: 25166090.07sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25166090.07sec, total: 25166090.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50332180.15sec, total: 50332180.15sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 25166090.07sec, total: 25166090.08sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25166090.07sec, total: 25166090.08sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25166090.07sec, total: 25166090.08sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25166090.07sec, total: 25166090.08sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.75ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.01ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 25166090.07sec, total: 25166090.08sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25166090.07sec, total: 25166090.08sec
  train.py:359:image_losses (gradient), cpu: 835us, accelerator: 585us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_183250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25131803.85sec, total: 25131803.85sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25131803.85sec, total: 25131803.85sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25131803.84sec, total: 25131803.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50263607.69sec, total: 50263607.70sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 25131803.85sec, total: 25131803.85sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25131803.85sec, total: 25131803.85sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25131803.85sec, total: 25131803.85sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25131803.85sec, total: 25131803.85sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.44ms, total: 3.75ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.73ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.01ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 25131803.85sec, total: 25131803.85sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25131803.85sec, total: 25131803.85sec
  train.py:359:image_losses (gradient), cpu: 835us, accelerator: 584us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_183500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25097610.92sec, total: 25097610.92sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25097610.91sec, total: 25097610.92sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25097610.91sec, total: 25097610.91sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 50195221.83sec, total: 50195221.84sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25097610.92sec, total: 25097610.92sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25097610.92sec, total: 25097610.92sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25097610.92sec, total: 25097610.92sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25097610.92sec, total: 25097610.92sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.43ms, total: 3.75ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.43ms, total: 3.73ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.01ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 25097610.92sec, total: 25097610.92sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25097610.92sec, total: 25097610.92sec
  train.py:359:image_losses (gradient), cpu: 835us, accelerator: 584us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_183750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25063510.90sec, total: 25063510.90sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25063510.90sec, total: 25063510.90sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 25063510.90sec, total: 25063510.90sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 50127021.80sec, total: 50127021.81sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25063510.90sec, total: 25063510.91sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25063510.90sec, total: 25063510.90sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25063510.90sec, total: 25063510.90sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25063510.90sec, total: 25063510.90sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.44ms, total: 3.74ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.44ms, total: 3.73ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.01ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 25063510.90sec, total: 25063510.91sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25063510.90sec, total: 25063510.90sec
  train.py:359:image_losses (gradient), cpu: 834us, accelerator: 583us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_184000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 25029503.42sec, total: 25029503.43sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 25029503.42sec, total: 25029503.42sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 25029503.42sec, total: 25029503.42sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 50059006.85sec, total: 50059006.85sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 25029503.43sec, total: 25029503.43sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 25029503.42sec, total: 25029503.43sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 25029503.42sec, total: 25029503.43sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 25029503.42sec, total: 25029503.43sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.43ms, total: 3.74ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.43ms, total: 3.73ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.01ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 25029503.43sec, total: 25029503.43sec
  train.py:360:image_losses (gradient), cpu: 2.78ms, accelerator: 25029503.42sec, total: 25029503.43sec
  train.py:359:image_losses (gradient), cpu: 833us, accelerator: 583us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_184250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24995588.11sec, total: 24995588.11sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24995588.11sec, total: 24995588.11sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24995588.11sec, total: 24995588.11sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 49991176.21sec, total: 49991176.22sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24995588.11sec, total: 24995588.12sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24995588.11sec, total: 24995588.11sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24995588.11sec, total: 24995588.11sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24995588.11sec, total: 24995588.11sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.43ms, total: 3.74ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.43ms, total: 3.73ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.01ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 24995588.11sec, total: 24995588.11sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24995588.11sec, total: 24995588.11sec
  train.py:359:image_losses (gradient), cpu: 831us, accelerator: 582us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_184500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24961764.58sec, total: 24961764.58sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24961764.58sec, total: 24961764.58sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24961764.58sec, total: 24961764.58sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49923529.16sec, total: 49923529.16sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24961764.58sec, total: 24961764.59sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24961764.58sec, total: 24961764.58sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24961764.58sec, total: 24961764.58sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24961764.58sec, total: 24961764.58sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.43ms, total: 3.74ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.43ms, total: 3.73ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.01ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 24961764.58sec, total: 24961764.58sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24961764.58sec, total: 24961764.58sec
  train.py:359:image_losses (gradient), cpu: 831us, accelerator: 582us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2046.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_184750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24928032.46sec, total: 24928032.47sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24928032.46sec, total: 24928032.46sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24928032.46sec, total: 24928032.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49856064.93sec, total: 49856064.93sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 24928032.47sec, total: 24928032.47sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24928032.46sec, total: 24928032.47sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24928032.46sec, total: 24928032.47sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24928032.46sec, total: 24928032.47sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.43ms, total: 3.74ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.43ms, total: 3.73ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.01ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 24928032.47sec, total: 24928032.47sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24928032.46sec, total: 24928032.47sec
  train.py:359:image_losses (gradient), cpu: 831us, accelerator: 581us, total: 1.42ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_185000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24894391.39sec, total: 24894391.40sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24894391.39sec, total: 24894391.40sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24894391.39sec, total: 24894391.39sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49788782.79sec, total: 49788782.79sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24894391.40sec, total: 24894391.40sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24894391.40sec, total: 24894391.40sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24894391.40sec, total: 24894391.40sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24894391.40sec, total: 24894391.40sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.43ms, total: 3.74ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.43ms, total: 3.73ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.01ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 24894391.40sec, total: 24894391.40sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24894391.40sec, total: 24894391.40sec
  train.py:359:image_losses (gradient), cpu: 829us, accelerator: 580us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_185250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24860841.00sec, total: 24860841.00sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24860841.00sec, total: 24860841.00sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24860841.00sec, total: 24860841.00sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 49721682.00sec, total: 49721682.01sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24860841.00sec, total: 24860841.01sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24860841.00sec, total: 24860841.01sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24860841.00sec, total: 24860841.01sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24860841.00sec, total: 24860841.01sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.43ms, total: 3.73ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.43ms, total: 3.72ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.01ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 24860841.00sec, total: 24860841.01sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24860841.00sec, total: 24860841.01sec
  train.py:359:image_losses (gradient), cpu: 832us, accelerator: 580us, total: 1.42ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2049.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_185500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24827380.92sec, total: 24827380.92sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24827380.92sec, total: 24827380.92sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24827380.92sec, total: 24827380.92sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49654761.84sec, total: 49654761.84sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24827380.92sec, total: 24827380.93sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24827380.92sec, total: 24827380.92sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24827380.92sec, total: 24827380.92sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24827380.92sec, total: 24827380.92sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.43ms, total: 3.73ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.43ms, total: 3.71ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.00ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.83ms, accelerator: 24827380.92sec, total: 24827380.93sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24827380.92sec, total: 24827380.92sec
  train.py:359:image_losses (gradient), cpu: 832us, accelerator: 579us, total: 1.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_185750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24794010.78sec, total: 24794010.79sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24794010.78sec, total: 24794010.78sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24794010.78sec, total: 24794010.78sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49588021.57sec, total: 49588021.57sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24794010.79sec, total: 24794010.79sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24794010.78sec, total: 24794010.79sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24794010.78sec, total: 24794010.79sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24794010.78sec, total: 24794010.79sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.43ms, total: 3.73ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.43ms, total: 3.72ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.01ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24794010.79sec, total: 24794010.79sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24794010.78sec, total: 24794010.79sec
  train.py:359:image_losses (gradient), cpu: 872us, accelerator: 579us, total: 1.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2031.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_186000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24760730.23sec, total: 24760730.23sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24760730.23sec, total: 24760730.23sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24760730.23sec, total: 24760730.23sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49521460.47sec, total: 49521460.47sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24760730.23sec, total: 24760730.24sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24760730.23sec, total: 24760730.24sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24760730.23sec, total: 24760730.24sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24760730.23sec, total: 24760730.24sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.43ms, total: 3.73ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.43ms, total: 3.72ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.00ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24760730.23sec, total: 24760730.24sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24760730.23sec, total: 24760730.24sec
  train.py:359:image_losses (gradient), cpu: 871us, accelerator: 578us, total: 1.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2040.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_186250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24727538.91sec, total: 24727538.91sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24727538.90sec, total: 24727538.91sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24727538.90sec, total: 24727538.90sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49455077.81sec, total: 49455077.81sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24727538.91sec, total: 24727538.91sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24727538.91sec, total: 24727538.91sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24727538.91sec, total: 24727538.91sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24727538.91sec, total: 24727538.91sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.43ms, total: 3.73ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.43ms, total: 3.71ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.00ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24727538.91sec, total: 24727538.91sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24727538.91sec, total: 24727538.91sec
  train.py:359:image_losses (gradient), cpu: 874us, accelerator: 577us, total: 1.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_186500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24694436.44sec, total: 24694436.44sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24694436.44sec, total: 24694436.44sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24694436.44sec, total: 24694436.44sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49388872.89sec, total: 49388872.89sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 24694436.45sec, total: 24694436.45sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24694436.44sec, total: 24694436.45sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24694436.44sec, total: 24694436.45sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24694436.44sec, total: 24694436.45sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.42ms, total: 3.72ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.42ms, total: 3.71ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.00ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24694436.45sec, total: 24694436.45sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24694436.44sec, total: 24694436.45sec
  train.py:359:image_losses (gradient), cpu: 873us, accelerator: 577us, total: 1.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_186750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24661422.49sec, total: 24661422.49sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24661422.49sec, total: 24661422.49sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24661422.49sec, total: 24661422.49sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49322844.98sec, total: 49322844.99sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 24661422.49sec, total: 24661422.50sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24661422.49sec, total: 24661422.49sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24661422.49sec, total: 24661422.49sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24661422.49sec, total: 24661422.49sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.42ms, total: 3.72ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.42ms, total: 3.71ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.00ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24661422.49sec, total: 24661422.50sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24661422.49sec, total: 24661422.49sec
  train.py:359:image_losses (gradient), cpu: 871us, accelerator: 576us, total: 1.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2061.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_187000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24628496.69sec, total: 24628496.69sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24628496.69sec, total: 24628496.69sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24628496.69sec, total: 24628496.69sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49256993.39sec, total: 49256993.39sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 24628496.70sec, total: 24628496.70sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24628496.69sec, total: 24628496.70sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24628496.69sec, total: 24628496.70sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24628496.69sec, total: 24628496.70sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.42ms, total: 3.72ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.42ms, total: 3.70ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.00ms, total: 2.31ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24628496.69sec, total: 24628496.70sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 24628496.69sec, total: 24628496.70sec
  train.py:359:image_losses (gradient), cpu: 870us, accelerator: 576us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_187250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24595658.70sec, total: 24595658.70sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24595658.70sec, total: 24595658.70sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24595658.70sec, total: 24595658.70sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49191317.40sec, total: 49191317.40sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 24595658.70sec, total: 24595658.71sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24595658.70sec, total: 24595658.70sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24595658.70sec, total: 24595658.70sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24595658.70sec, total: 24595658.70sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.42ms, total: 3.71ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.42ms, total: 3.70ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.00ms, total: 2.31ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24595658.70sec, total: 24595658.70sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 24595658.70sec, total: 24595658.70sec
  train.py:359:image_losses (gradient), cpu: 869us, accelerator: 575us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_187500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24562908.15sec, total: 24562908.15sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24562908.15sec, total: 24562908.15sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24562908.15sec, total: 24562908.15sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49125816.31sec, total: 49125816.31sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 24562908.16sec, total: 24562908.16sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24562908.15sec, total: 24562908.16sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24562908.15sec, total: 24562908.16sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24562908.15sec, total: 24562908.16sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.42ms, total: 3.71ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.42ms, total: 3.70ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.00ms, total: 2.31ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24562908.16sec, total: 24562908.16sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 24562908.15sec, total: 24562908.16sec
  train.py:359:image_losses (gradient), cpu: 869us, accelerator: 575us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2052.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_187750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24530244.71sec, total: 24530244.71sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24530244.71sec, total: 24530244.71sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24530244.71sec, total: 24530244.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 49060489.42sec, total: 49060489.43sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 24530244.71sec, total: 24530244.72sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24530244.71sec, total: 24530244.72sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24530244.71sec, total: 24530244.72sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24530244.71sec, total: 24530244.72sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.43ms, total: 3.72ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.43ms, total: 3.71ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.01ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24530244.71sec, total: 24530244.72sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24530244.71sec, total: 24530244.72sec
  train.py:359:image_losses (gradient), cpu: 870us, accelerator: 575us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2041.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_188000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24497668.03sec, total: 24497668.03sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24497668.02sec, total: 24497668.03sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24497668.02sec, total: 24497668.02sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 48995336.05sec, total: 48995336.06sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 24497668.03sec, total: 24497668.03sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24497668.03sec, total: 24497668.03sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24497668.03sec, total: 24497668.03sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24497668.03sec, total: 24497668.03sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.42ms, total: 3.72ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.42ms, total: 3.70ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.01ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24497668.03sec, total: 24497668.03sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24497668.03sec, total: 24497668.03sec
  train.py:359:image_losses (gradient), cpu: 869us, accelerator: 573us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_188250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24465177.75sec, total: 24465177.75sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24465177.75sec, total: 24465177.75sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24465177.75sec, total: 24465177.75sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 48930355.50sec, total: 48930355.50sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 24465177.75sec, total: 24465177.76sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24465177.75sec, total: 24465177.75sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24465177.75sec, total: 24465177.75sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24465177.75sec, total: 24465177.75sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.42ms, total: 3.71ms
    train.py:322:loss_fn, cpu: 2.26ms, accelerator: 1.42ms, total: 3.70ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.01ms, total: 2.31ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24465177.75sec, total: 24465177.76sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24465177.75sec, total: 24465177.75sec
  train.py:359:image_losses (gradient), cpu: 867us, accelerator: 573us, total: 1.45ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2055.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_188500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24432773.54sec, total: 24432773.54sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24432773.54sec, total: 24432773.54sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24432773.54sec, total: 24432773.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 48865547.08sec, total: 48865547.09sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 24432773.54sec, total: 24432773.55sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24432773.54sec, total: 24432773.54sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24432773.54sec, total: 24432773.54sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24432773.54sec, total: 24432773.54sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.44ms, total: 3.72ms
    train.py:322:loss_fn, cpu: 2.26ms, accelerator: 1.44ms, total: 3.71ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.01ms, total: 2.31ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 24432773.54sec, total: 24432773.55sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24432773.54sec, total: 24432773.54sec
  train.py:359:image_losses (gradient), cpu: 865us, accelerator: 570us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_188750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24400455.06sec, total: 24400455.06sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24400455.06sec, total: 24400455.06sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24400455.05sec, total: 24400455.06sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 48800910.11sec, total: 48800910.12sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 24400455.06sec, total: 24400455.07sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24400455.06sec, total: 24400455.06sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24400455.06sec, total: 24400455.06sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24400455.06sec, total: 24400455.06sec
  train.py:359:image_losses, cpu: 2.27ms, accelerator: 1.45ms, total: 3.73ms
    train.py:322:loss_fn, cpu: 2.26ms, accelerator: 1.45ms, total: 3.72ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.01ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 24400455.06sec, total: 24400455.06sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24400455.06sec, total: 24400455.06sec
  train.py:359:image_losses (gradient), cpu: 864us, accelerator: 570us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_189000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 24368221.96sec, total: 24368221.96sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24368221.96sec, total: 24368221.96sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24368221.96sec, total: 24368221.96sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 48736443.92sec, total: 48736443.92sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 24368221.96sec, total: 24368221.97sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24368221.96sec, total: 24368221.96sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24368221.96sec, total: 24368221.96sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24368221.96sec, total: 24368221.96sec
  train.py:359:image_losses, cpu: 2.27ms, accelerator: 1.45ms, total: 3.73ms
    train.py:322:loss_fn, cpu: 2.26ms, accelerator: 1.45ms, total: 3.72ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.02ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 24368221.96sec, total: 24368221.97sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24368221.96sec, total: 24368221.96sec
  train.py:359:image_losses (gradient), cpu: 862us, accelerator: 573us, total: 1.45ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_189250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24336073.91sec, total: 24336073.91sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24336073.91sec, total: 24336073.91sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 384us, accelerator: 24336073.91sec, total: 24336073.91sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 48672147.82sec, total: 48672147.82sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 24336073.91sec, total: 24336073.92sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24336073.91sec, total: 24336073.91sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24336073.91sec, total: 24336073.91sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24336073.91sec, total: 24336073.91sec
  train.py:359:image_losses, cpu: 2.27ms, accelerator: 1.45ms, total: 3.73ms
    train.py:322:loss_fn, cpu: 2.26ms, accelerator: 1.45ms, total: 3.71ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.01ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 24336073.91sec, total: 24336073.91sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24336073.91sec, total: 24336073.91sec
  train.py:359:image_losses (gradient), cpu: 862us, accelerator: 573us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_189500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24304010.57sec, total: 24304010.57sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24304010.57sec, total: 24304010.57sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24304010.57sec, total: 24304010.57sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 48608021.14sec, total: 48608021.15sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 24304010.57sec, total: 24304010.58sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24304010.57sec, total: 24304010.57sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24304010.57sec, total: 24304010.57sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24304010.57sec, total: 24304010.57sec
  train.py:359:image_losses, cpu: 2.27ms, accelerator: 1.45ms, total: 3.73ms
    train.py:322:loss_fn, cpu: 2.26ms, accelerator: 1.45ms, total: 3.71ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.01ms, total: 2.31ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 24304010.57sec, total: 24304010.58sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24304010.57sec, total: 24304010.57sec
  train.py:359:image_losses (gradient), cpu: 862us, accelerator: 571us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2051.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_189750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24272031.61sec, total: 24272031.61sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24272031.61sec, total: 24272031.61sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24272031.61sec, total: 24272031.61sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 48544063.22sec, total: 48544063.22sec
train.py:442:<module>, cpu: 5.89ms, accelerator: 24272031.61sec, total: 24272031.62sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24272031.61sec, total: 24272031.61sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24272031.61sec, total: 24272031.61sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24272031.61sec, total: 24272031.61sec
  train.py:359:image_losses, cpu: 2.27ms, accelerator: 1.44ms, total: 3.72ms
    train.py:322:loss_fn, cpu: 2.26ms, accelerator: 1.44ms, total: 3.71ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 1.01ms, total: 2.31ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 24272031.61sec, total: 24272031.62sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24272031.61sec, total: 24272031.61sec
  train.py:359:image_losses (gradient), cpu: 861us, accelerator: 571us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_190000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24240136.69sec, total: 24240136.69sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24240136.69sec, total: 24240136.69sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 384us, accelerator: 24240136.69sec, total: 24240136.69sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 48480273.39sec, total: 48480273.39sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 24240136.70sec, total: 24240136.70sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24240136.69sec, total: 24240136.70sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24240136.69sec, total: 24240136.70sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24240136.69sec, total: 24240136.70sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.46ms, total: 3.75ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.46ms, total: 3.73ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 1.01ms, total: 2.32ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 24240136.69sec, total: 24240136.70sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24240136.69sec, total: 24240136.70sec
  train.py:359:image_losses (gradient), cpu: 861us, accelerator: 569us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2044.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_190250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24208325.49sec, total: 24208325.49sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24208325.49sec, total: 24208325.49sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 384us, accelerator: 24208325.49sec, total: 24208325.49sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 48416650.98sec, total: 48416650.98sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 24208325.49sec, total: 24208325.50sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24208325.49sec, total: 24208325.49sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24208325.49sec, total: 24208325.49sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24208325.49sec, total: 24208325.49sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.45ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.45ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.01ms, total: 2.33ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 24208325.49sec, total: 24208325.50sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24208325.49sec, total: 24208325.49sec
  train.py:359:image_losses (gradient), cpu: 861us, accelerator: 568us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2063.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_190500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 24176597.67sec, total: 24176597.67sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 24176597.67sec, total: 24176597.67sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 384us, accelerator: 24176597.67sec, total: 24176597.67sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.98ms, accelerator: 48353195.34sec, total: 48353195.35sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 24176597.67sec, total: 24176597.68sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 24176597.67sec, total: 24176597.68sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 24176597.67sec, total: 24176597.68sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 24176597.67sec, total: 24176597.67sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.46ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.46ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 1.02ms, total: 2.34ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 24176597.67sec, total: 24176597.68sec
  train.py:360:image_losses (gradient), cpu: 2.79ms, accelerator: 24176597.67sec, total: 24176597.68sec
  train.py:359:image_losses (gradient), cpu: 861us, accelerator: 568us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_190750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 24144952.91sec, total: 24144952.91sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24144952.91sec, total: 24144952.91sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 384us, accelerator: 24144952.91sec, total: 24144952.91sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 48289905.82sec, total: 48289905.82sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24144952.91sec, total: 24144952.92sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 24144952.91sec, total: 24144952.91sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24144952.91sec, total: 24144952.91sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 24144952.91sec, total: 24144952.91sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.46ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.46ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24144952.91sec, total: 24144952.92sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 24144952.91sec, total: 24144952.91sec
  train.py:359:image_losses (gradient), cpu: 861us, accelerator: 567us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2032.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_191000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 24113390.88sec, total: 24113390.88sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24113390.88sec, total: 24113390.88sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 384us, accelerator: 24113390.88sec, total: 24113390.88sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 48226781.76sec, total: 48226781.76sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24113390.88sec, total: 24113390.89sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 24113390.88sec, total: 24113390.88sec
    train.py:322:loss_fn, cpu: 2.95ms, accelerator: 24113390.88sec, total: 24113390.88sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 24113390.88sec, total: 24113390.88sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.47ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.47ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24113390.88sec, total: 24113390.89sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 24113390.88sec, total: 24113390.88sec
  train.py:359:image_losses (gradient), cpu: 861us, accelerator: 567us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_191250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 24081911.26sec, total: 24081911.26sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24081911.26sec, total: 24081911.26sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24081911.26sec, total: 24081911.26sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 48163822.52sec, total: 48163822.52sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24081911.26sec, total: 24081911.27sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 24081911.26sec, total: 24081911.26sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24081911.26sec, total: 24081911.26sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 24081911.26sec, total: 24081911.26sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.46ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.46ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24081911.26sec, total: 24081911.26sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 24081911.26sec, total: 24081911.26sec
  train.py:359:image_losses (gradient), cpu: 861us, accelerator: 565us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_191500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 24050513.72sec, total: 24050513.72sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24050513.72sec, total: 24050513.72sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24050513.72sec, total: 24050513.72sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 48101027.44sec, total: 48101027.44sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24050513.72sec, total: 24050513.73sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 24050513.72sec, total: 24050513.72sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24050513.72sec, total: 24050513.72sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 24050513.72sec, total: 24050513.72sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.46ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.46ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24050513.72sec, total: 24050513.73sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 24050513.72sec, total: 24050513.72sec
  train.py:359:image_losses (gradient), cpu: 861us, accelerator: 564us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2036.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_191750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 24019197.95sec, total: 24019197.95sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 24019197.95sec, total: 24019197.95sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 24019197.94sec, total: 24019197.95sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 48038395.89sec, total: 48038395.90sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 24019197.95sec, total: 24019197.96sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 24019197.95sec, total: 24019197.95sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 24019197.95sec, total: 24019197.95sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 24019197.95sec, total: 24019197.95sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.46ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.46ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 24019197.95sec, total: 24019197.95sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 24019197.95sec, total: 24019197.95sec
  train.py:359:image_losses (gradient), cpu: 860us, accelerator: 564us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_192000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 23987963.62sec, total: 23987963.62sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23987963.62sec, total: 23987963.62sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23987963.62sec, total: 23987963.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 47975927.24sec, total: 47975927.24sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 23987963.62sec, total: 23987963.63sec
  train.py:360:image_losses, cpu: 2.96ms, accelerator: 23987963.62sec, total: 23987963.62sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 23987963.62sec, total: 23987963.62sec
      train.py:349:msssim, cpu: 2.90ms, accelerator: 23987963.62sec, total: 23987963.62sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.46ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.46ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 23987963.62sec, total: 23987963.62sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23987963.62sec, total: 23987963.62sec
  train.py:359:image_losses (gradient), cpu: 859us, accelerator: 564us, total: 1.43ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_192250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 23956810.42sec, total: 23956810.42sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23956810.42sec, total: 23956810.42sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23956810.42sec, total: 23956810.42sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 47913620.84sec, total: 47913620.84sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 23956810.42sec, total: 23956810.43sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 23956810.42sec, total: 23956810.42sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 23956810.42sec, total: 23956810.42sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 23956810.42sec, total: 23956810.42sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.46ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.46ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.87ms, accelerator: 23956810.42sec, total: 23956810.43sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23956810.42sec, total: 23956810.42sec
  train.py:359:image_losses (gradient), cpu: 859us, accelerator: 564us, total: 1.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_192500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 23925738.03sec, total: 23925738.03sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23925738.03sec, total: 23925738.03sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23925738.03sec, total: 23925738.03sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 47851476.07sec, total: 47851476.07sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 23925738.04sec, total: 23925738.04sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 23925738.03sec, total: 23925738.04sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 23925738.03sec, total: 23925738.04sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 23925738.03sec, total: 23925738.04sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.46ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.46ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.02ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23925738.03sec, total: 23925738.04sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23925738.03sec, total: 23925738.04sec
  train.py:359:image_losses (gradient), cpu: 856us, accelerator: 577us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2053.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_192750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 23894746.14sec, total: 23894746.15sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23894746.14sec, total: 23894746.15sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23894746.14sec, total: 23894746.14sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 47789492.29sec, total: 47789492.29sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 23894746.15sec, total: 23894746.15sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 23894746.14sec, total: 23894746.15sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 23894746.14sec, total: 23894746.15sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 23894746.14sec, total: 23894746.15sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.46ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.46ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23894746.15sec, total: 23894746.15sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23894746.15sec, total: 23894746.15sec
  train.py:359:image_losses (gradient), cpu: 857us, accelerator: 577us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_193000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 23863834.44sec, total: 23863834.44sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23863834.44sec, total: 23863834.44sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23863834.44sec, total: 23863834.44sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 47727668.88sec, total: 47727668.89sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23863834.44sec, total: 23863834.45sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 23863834.44sec, total: 23863834.45sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 23863834.44sec, total: 23863834.45sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 23863834.44sec, total: 23863834.45sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.45ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23863834.44sec, total: 23863834.45sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23863834.44sec, total: 23863834.45sec
  train.py:359:image_losses (gradient), cpu: 855us, accelerator: 577us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_193250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 23833002.61sec, total: 23833002.62sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23833002.61sec, total: 23833002.61sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23833002.61sec, total: 23833002.61sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 47666005.23sec, total: 47666005.23sec
train.py:442:<module>, cpu: 5.93ms, accelerator: 23833002.62sec, total: 23833002.62sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 23833002.61sec, total: 23833002.62sec
    train.py:322:loss_fn, cpu: 2.94ms, accelerator: 23833002.61sec, total: 23833002.62sec
      train.py:349:msssim, cpu: 2.89ms, accelerator: 23833002.61sec, total: 23833002.62sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.45ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.45ms, total: 3.77ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 1.01ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23833002.62sec, total: 23833002.62sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23833002.62sec, total: 23833002.62sec
  train.py:359:image_losses (gradient), cpu: 855us, accelerator: 588us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2045.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_193500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 23802250.35sec, total: 23802250.35sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23802250.35sec, total: 23802250.35sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23802250.35sec, total: 23802250.35sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 3.99ms, accelerator: 47604500.71sec, total: 47604500.71sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 23802250.35sec, total: 23802250.36sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 23802250.35sec, total: 23802250.36sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23802250.35sec, total: 23802250.36sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23802250.35sec, total: 23802250.36sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.45ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.45ms, total: 3.77ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.01ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23802250.35sec, total: 23802250.36sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23802250.35sec, total: 23802250.36sec
  train.py:359:image_losses (gradient), cpu: 855us, accelerator: 590us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_193750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23771577.35sec, total: 23771577.35sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23771577.35sec, total: 23771577.35sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23771577.35sec, total: 23771577.35sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 47543154.70sec, total: 47543154.70sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 23771577.35sec, total: 23771577.36sec
  train.py:360:image_losses, cpu: 2.95ms, accelerator: 23771577.35sec, total: 23771577.35sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23771577.35sec, total: 23771577.35sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23771577.35sec, total: 23771577.35sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.45ms, total: 3.78ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.45ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.01ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23771577.35sec, total: 23771577.36sec
  train.py:360:image_losses (gradient), cpu: 2.81ms, accelerator: 23771577.35sec, total: 23771577.35sec
  train.py:359:image_losses (gradient), cpu: 854us, accelerator: 590us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2057.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_194000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23740983.30sec, total: 23740983.30sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23740983.30sec, total: 23740983.30sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23740983.30sec, total: 23740983.30sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 47481966.60sec, total: 47481966.60sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 23740983.30sec, total: 23740983.31sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23740983.30sec, total: 23740983.30sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23740983.30sec, total: 23740983.30sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23740983.30sec, total: 23740983.30sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.45ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.45ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.01ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23740983.30sec, total: 23740983.30sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23740983.30sec, total: 23740983.30sec
  train.py:359:image_losses (gradient), cpu: 853us, accelerator: 590us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_194250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23710467.90sec, total: 23710467.90sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23710467.90sec, total: 23710467.90sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23710467.89sec, total: 23710467.89sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 47420935.79sec, total: 47420935.80sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23710467.90sec, total: 23710467.90sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23710467.90sec, total: 23710467.90sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23710467.90sec, total: 23710467.90sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23710467.90sec, total: 23710467.90sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.45ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.45ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.01ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23710467.90sec, total: 23710467.90sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23710467.90sec, total: 23710467.90sec
  train.py:359:image_losses (gradient), cpu: 852us, accelerator: 589us, total: 1.45ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_194500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23680030.84sec, total: 23680030.84sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23680030.84sec, total: 23680030.84sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 385us, accelerator: 23680030.84sec, total: 23680030.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 47360061.68sec, total: 47360061.68sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23680030.84sec, total: 23680030.85sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23680030.84sec, total: 23680030.84sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23680030.84sec, total: 23680030.84sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23680030.84sec, total: 23680030.84sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.45ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.45ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.01ms, total: 2.37ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23680030.84sec, total: 23680030.84sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23680030.84sec, total: 23680030.84sec
  train.py:359:image_losses (gradient), cpu: 852us, accelerator: 589us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_194750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23649671.82sec, total: 23649671.83sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23649671.82sec, total: 23649671.83sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 23649671.82sec, total: 23649671.82sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 47299343.65sec, total: 47299343.65sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23649671.83sec, total: 23649671.83sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23649671.83sec, total: 23649671.83sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23649671.83sec, total: 23649671.83sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23649671.83sec, total: 23649671.83sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.45ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.01ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23649671.83sec, total: 23649671.83sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23649671.83sec, total: 23649671.83sec
  train.py:359:image_losses (gradient), cpu: 851us, accelerator: 588us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_195000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23619390.55sec, total: 23619390.56sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23619390.55sec, total: 23619390.56sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 23619390.55sec, total: 23619390.55sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 47238781.11sec, total: 47238781.11sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 23619390.56sec, total: 23619390.56sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23619390.56sec, total: 23619390.56sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23619390.56sec, total: 23619390.56sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23619390.56sec, total: 23619390.56sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.45ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.01ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23619390.56sec, total: 23619390.56sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23619390.56sec, total: 23619390.56sec
  train.py:359:image_losses (gradient), cpu: 851us, accelerator: 587us, total: 1.45ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2050.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_195250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23589186.73sec, total: 23589186.73sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23589186.73sec, total: 23589186.73sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 23589186.73sec, total: 23589186.73sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 47178373.46sec, total: 47178373.47sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23589186.73sec, total: 23589186.74sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23589186.73sec, total: 23589186.73sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23589186.73sec, total: 23589186.73sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23589186.73sec, total: 23589186.73sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.45ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.01ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23589186.73sec, total: 23589186.74sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23589186.73sec, total: 23589186.73sec
  train.py:359:image_losses (gradient), cpu: 851us, accelerator: 586us, total: 1.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_195500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23559060.06sec, total: 23559060.06sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23559060.05sec, total: 23559060.06sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 23559060.05sec, total: 23559060.05sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 47118120.11sec, total: 47118120.11sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23559060.06sec, total: 23559060.06sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23559060.06sec, total: 23559060.06sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23559060.06sec, total: 23559060.06sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23559060.06sec, total: 23559060.06sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.45ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 1.01ms, total: 2.36ms
train.py:442:<module> (gradient), cpu: 3.86ms, accelerator: 23559060.06sec, total: 23559060.06sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23559060.06sec, total: 23559060.06sec
  train.py:359:image_losses (gradient), cpu: 851us, accelerator: 586us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2037.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_195750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23529010.23sec, total: 23529010.24sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23529010.23sec, total: 23529010.23sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 387us, accelerator: 23529010.23sec, total: 23529010.23sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 47058020.47sec, total: 47058020.47sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23529010.24sec, total: 23529010.24sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23529010.23sec, total: 23529010.24sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23529010.23sec, total: 23529010.24sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23529010.23sec, total: 23529010.24sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.44ms, total: 3.75ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23529010.24sec, total: 23529010.24sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23529010.23sec, total: 23529010.24sec
  train.py:359:image_losses (gradient), cpu: 850us, accelerator: 586us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2043.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_196000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23499036.97sec, total: 23499036.97sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23499036.97sec, total: 23499036.97sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 23499036.97sec, total: 23499036.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.00ms, accelerator: 46998073.94sec, total: 46998073.95sec
train.py:442:<module>, cpu: 5.92ms, accelerator: 23499036.97sec, total: 23499036.98sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23499036.97sec, total: 23499036.98sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23499036.97sec, total: 23499036.98sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23499036.97sec, total: 23499036.98sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.44ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.44ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23499036.97sec, total: 23499036.98sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23499036.97sec, total: 23499036.98sec
  train.py:359:image_losses (gradient), cpu: 848us, accelerator: 585us, total: 1.44ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_196250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23469139.98sec, total: 23469139.98sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23469139.98sec, total: 23469139.98sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 23469139.98sec, total: 23469139.98sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 46938279.96sec, total: 46938279.96sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23469139.98sec, total: 23469139.99sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23469139.98sec, total: 23469139.98sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23469139.98sec, total: 23469139.98sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23469139.98sec, total: 23469139.98sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.44ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.00ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23469139.98sec, total: 23469139.98sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23469139.98sec, total: 23469139.98sec
  train.py:359:image_losses (gradient), cpu: 847us, accelerator: 584us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_196500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23439318.96sec, total: 23439318.96sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23439318.96sec, total: 23439318.96sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 23439318.96sec, total: 23439318.96sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 46878637.92sec, total: 46878637.93sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23439318.96sec, total: 23439318.97sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23439318.96sec, total: 23439318.97sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23439318.96sec, total: 23439318.97sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23439318.96sec, total: 23439318.97sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.30ms, accelerator: 1.44ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.00ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23439318.96sec, total: 23439318.97sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23439318.96sec, total: 23439318.97sec
  train.py:359:image_losses (gradient), cpu: 847us, accelerator: 584us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_196750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23409573.63sec, total: 23409573.64sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23409573.63sec, total: 23409573.63sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 23409573.63sec, total: 23409573.63sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 46819147.27sec, total: 46819147.27sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23409573.64sec, total: 23409573.64sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23409573.63sec, total: 23409573.64sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23409573.63sec, total: 23409573.64sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23409573.63sec, total: 23409573.64sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.00ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23409573.64sec, total: 23409573.64sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23409573.63sec, total: 23409573.64sec
  train.py:359:image_losses (gradient), cpu: 847us, accelerator: 583us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2064.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_197000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23379903.71sec, total: 23379903.71sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23379903.70sec, total: 23379903.71sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 23379903.70sec, total: 23379903.70sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.01ms, accelerator: 46759807.41sec, total: 46759807.41sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23379903.71sec, total: 23379903.71sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23379903.71sec, total: 23379903.71sec
    train.py:322:loss_fn, cpu: 2.93ms, accelerator: 23379903.71sec, total: 23379903.71sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23379903.71sec, total: 23379903.71sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23379903.71sec, total: 23379903.71sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23379903.71sec, total: 23379903.71sec
  train.py:359:image_losses (gradient), cpu: 846us, accelerator: 583us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2048.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_197250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23350308.89sec, total: 23350308.89sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23350308.89sec, total: 23350308.89sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 23350308.89sec, total: 23350308.89sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.02ms, accelerator: 46700617.78sec, total: 46700617.78sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23350308.89sec, total: 23350308.90sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23350308.89sec, total: 23350308.89sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 23350308.89sec, total: 23350308.89sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23350308.89sec, total: 23350308.89sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23350308.89sec, total: 23350308.90sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23350308.89sec, total: 23350308.89sec
  train.py:359:image_losses (gradient), cpu: 846us, accelerator: 590us, total: 1.44ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2047.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_197500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23320788.90sec, total: 23320788.91sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23320788.90sec, total: 23320788.91sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 23320788.90sec, total: 23320788.90sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.03ms, accelerator: 46641577.81sec, total: 46641577.81sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23320788.91sec, total: 23320788.91sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23320788.91sec, total: 23320788.91sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 23320788.91sec, total: 23320788.91sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23320788.90sec, total: 23320788.91sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23320788.91sec, total: 23320788.91sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23320788.91sec, total: 23320788.91sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 588us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_197750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23291343.46sec, total: 23291343.47sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23291343.46sec, total: 23291343.46sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 386us, accelerator: 23291343.46sec, total: 23291343.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.03ms, accelerator: 46582686.93sec, total: 46582686.93sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23291343.47sec, total: 23291343.47sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23291343.46sec, total: 23291343.47sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 23291343.46sec, total: 23291343.47sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23291343.46sec, total: 23291343.47sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23291343.47sec, total: 23291343.47sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23291343.46sec, total: 23291343.47sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 588us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_198000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23261972.29sec, total: 23261972.29sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23261972.29sec, total: 23261972.29sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 23261972.28sec, total: 23261972.28sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.03ms, accelerator: 46523944.57sec, total: 46523944.58sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23261972.29sec, total: 23261972.29sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23261972.29sec, total: 23261972.29sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 23261972.29sec, total: 23261972.29sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23261972.29sec, total: 23261972.29sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23261972.29sec, total: 23261972.29sec
  train.py:360:image_losses (gradient), cpu: 2.81ms, accelerator: 23261972.29sec, total: 23261972.29sec
  train.py:359:image_losses (gradient), cpu: 844us, accelerator: 591us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2039.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_198250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23232675.09sec, total: 23232675.09sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23232675.09sec, total: 23232675.09sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 23232675.09sec, total: 23232675.09sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.02ms, accelerator: 46465350.18sec, total: 46465350.19sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23232675.09sec, total: 23232675.10sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23232675.09sec, total: 23232675.10sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 23232675.09sec, total: 23232675.10sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23232675.09sec, total: 23232675.10sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23232675.09sec, total: 23232675.10sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23232675.09sec, total: 23232675.10sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 590us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_198500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23203451.60sec, total: 23203451.60sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23203451.60sec, total: 23203451.60sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 23203451.60sec, total: 23203451.60sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.02ms, accelerator: 46406903.20sec, total: 46406903.21sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23203451.60sec, total: 23203451.61sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23203451.60sec, total: 23203451.61sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 23203451.60sec, total: 23203451.61sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23203451.60sec, total: 23203451.61sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.44ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23203451.60sec, total: 23203451.61sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23203451.60sec, total: 23203451.61sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 593us, total: 1.44ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2054.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_198750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23174301.54sec, total: 23174301.54sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23174301.54sec, total: 23174301.54sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 23174301.53sec, total: 23174301.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.02ms, accelerator: 46348603.07sec, total: 46348603.08sec
train.py:442:<module>, cpu: 5.91ms, accelerator: 23174301.54sec, total: 23174301.55sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23174301.54sec, total: 23174301.54sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 23174301.54sec, total: 23174301.54sec
      train.py:349:msssim, cpu: 2.88ms, accelerator: 23174301.54sec, total: 23174301.54sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.44ms, total: 3.75ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.44ms, total: 3.74ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23174301.54sec, total: 23174301.54sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23174301.54sec, total: 23174301.54sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 592us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk_Global_DJF_F/timelines/t.json_199000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 23145224.62sec, total: 23145224.62sec (16.67%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 23145224.62sec, total: 23145224.62sec (16.67%)
top 3 operation type: DepthwiseConv2dNativeBackpropInput, cpu: 388us, accelerator: 23145224.62sec, total: 23145224.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.02ms, accelerator: 46290449.24sec, total: 46290449.25sec
train.py:442:<module>, cpu: 5.90ms, accelerator: 23145224.62sec, total: 23145224.63sec
  train.py:360:image_losses, cpu: 2.94ms, accelerator: 23145224.62sec, total: 23145224.63sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 23145224.62sec, total: 23145224.63sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 23145224.62sec, total: 23145224.63sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.45ms, total: 3.76ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.45ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 1.01ms, total: 2.35ms
train.py:442:<module> (gradient), cpu: 3.85ms, accelerator: 23145224.62sec, total: 23145224.63sec
  train.py:360:image_losses (gradient), cpu: 2.80ms, accelerator: 23145224.62sec, total: 23145224.63sec
  train.py:359:image_losses (gradient), cpu: 845us, accelerator: 592us, total: 1.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
-------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
-------------------------------------------------------
