/software/openmpi-3.1.2-el7-x86_64/bin/mpirun
/software/Anaconda3-5.3.0-el7-x86_64/bin/python
/software/cuda-9.0-el7-x86_64/bin/nvcc
Parsing Inputs...
Parsing Inputs...
Parsing Inputs...
Parsing Inputs...
midway2-gpu02:28558:28680 [0] INFO NET : Using interface ib0:172.25.221.192<0>
midway2-gpu02:28558:28680 [0] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu02:28558:28680 [0] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu02:28558:28680 [0] INFO Using internal Network IB
midway2-gpu02:28558:28680 [0] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu02:28558:28680 [0] INFO NET : Using interface ib0:172.25.221.192<0>
midway2-gpu02:28558:28680 [0] INFO NET/Socket : 1 interfaces found
NCCL version 2.2.13+cuda9.0
midway2-gpu02:28560:28679 [2] INFO NET : Using interface ib0:172.25.221.192<0>
midway2-gpu02:28560:28679 [2] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu02:28560:28679 [2] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu02:28560:28679 [2] INFO Using internal Network IB
midway2-gpu02:28560:28679 [2] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu02:28561:28682 [3] INFO NET : Using interface ib0:172.25.221.192<0>
midway2-gpu02:28561:28682 [3] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu02:28559:28681 [1] INFO NET : Using interface ib0:172.25.221.192<0>
midway2-gpu02:28559:28681 [1] INFO NET/IB : Using interface ib0 for sideband communication
midway2-gpu02:28561:28682 [3] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu02:28561:28682 [3] INFO Using internal Network IB
midway2-gpu02:28561:28682 [3] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu02:28559:28681 [1] INFO NET/IB: [0] mlx5_0:1/IB 
midway2-gpu02:28559:28681 [1] INFO Using internal Network IB
midway2-gpu02:28559:28681 [1] INFO Using NCCL Low-latency algorithm for sizes below 16384
midway2-gpu02:28558:28680 [0] INFO comm 0x7ff308888ff0 rank 0 nranks 4
midway2-gpu02:28558:28680 [0] INFO CUDA Dev 0, IB Ports : mlx5_0/1(SOC) 
midway2-gpu02:28561:28682 [3] INFO comm 0x7f4a98871c70 rank 3 nranks 4
midway2-gpu02:28561:28682 [3] INFO NET : Using interface ib0:172.25.221.192<0>
midway2-gpu02:28561:28682 [3] INFO NET/Socket : 1 interfaces found
midway2-gpu02:28561:28682 [3] INFO CUDA Dev 3, IB Ports : mlx5_0/1(PHB) 
midway2-gpu02:28559:28681 [1] INFO comm 0x7ff7c88719e0 rank 1 nranks 4
midway2-gpu02:28559:28681 [1] INFO NET : Using interface ib0:172.25.221.192<0>
midway2-gpu02:28559:28681 [1] INFO NET/Socket : 1 interfaces found
midway2-gpu02:28559:28681 [1] INFO CUDA Dev 1, IB Ports : mlx5_0/1(SOC) 
midway2-gpu02:28560:28679 [2] INFO comm 0x7f2950871ba0 rank 2 nranks 4
midway2-gpu02:28560:28679 [2] INFO NET : Using interface ib0:172.25.221.192<0>
midway2-gpu02:28560:28679 [2] INFO NET/Socket : 1 interfaces found
midway2-gpu02:28560:28679 [2] INFO CUDA Dev 2, IB Ports : mlx5_0/1(PHB) 
midway2-gpu02:28558:28680 [0] INFO Using 128 threads
midway2-gpu02:28558:28680 [0] INFO Min Comp Cap 3
midway2-gpu02:28558:28680 [0] INFO NCCL_SINGLE_RING_THRESHOLD=131072
midway2-gpu02:28558:28680 [0] INFO Ring 00 :    0   1   2   3
midway2-gpu02:28558:28680 [0] INFO Ring 01 :    0   1   2   3
midway2-gpu02:28561:28682 [3] INFO 3[28561] -> 0[28558] via direct shared memory
midway2-gpu02:28558:28680 [0] INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC
midway2-gpu02:28559:28681 [1] INFO 1[28559] -> 2[28560] via direct shared memory
midway2-gpu02:28560:28679 [2] INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC
midway2-gpu02:28559:28681 [1] INFO 1[28559] -> 2[28560] via direct shared memory
midway2-gpu02:28561:28682 [3] INFO 3[28561] -> 0[28558] via direct shared memory
midway2-gpu02:28558:28680 [0] INFO Ring 01 : 0[0] -> 1[1] via P2P/IPC
midway2-gpu02:28560:28679 [2] INFO Ring 01 : 2[2] -> 3[3] via P2P/IPC
midway2-gpu02:28558:28680 [0] INFO Launch mode Parallel
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_0.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.80

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.31sec, accelerator: 0us, total: 8.31sec (92.50%)
top 2 operation type: ImageSummary, cpu: 173.63ms, accelerator: 0us, total: 173.63ms (1.93%)
top 3 operation type: HistogramSummary, cpu: 109.80ms, accelerator: 0us, total: 109.80ms (1.22%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: difference, cpu: 68.73ms, accelerator: 0us, total: 68.73ms
train.py:511:<module>, cpu: 8.32sec, accelerator: 12.65ms, total: 8.33sec
  __init__.py:194:compute_gradients, cpu: 8.32sec, accelerator: 304us, total: 8.32sec
    __init__.py:83:allreduce, cpu: 8.31sec, accelerator: 0us, total: 8.31sec
    __init__.py:86:allreduce, cpu: 3.15ms, accelerator: 304us, total: 3.45ms
  __init__.py:185:compute_gradients, cpu: 1.89ms, accelerator: 12.34ms, total: 14.24ms
train.py:515:<module>, cpu: 88.15ms, accelerator: 0us, total: 88.15ms
train.py:441:<module> (gradient), cpu: 3.63ms, accelerator: 67.51ms, total: 71.13ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 7.69sec, accelerator: 0us, total: 7.69sec (92.60%)
top 2 operation type: ImageSummary, cpu: 187.65ms, accelerator: 0us, total: 187.65ms (2.26%)
top 3 operation type: HistogramSummary, cpu: 110.70ms, accelerator: 0us, total: 110.70ms (1.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: difference, cpu: 70.53ms, accelerator: 0us, total: 70.53ms
train.py:511:<module>, cpu: 7.70sec, accelerator: 15.98ms, total: 7.71sec
  __init__.py:194:compute_gradients, cpu: 7.69sec, accelerator: 3.89ms, total: 7.70sec
    __init__.py:83:allreduce, cpu: 7.69sec, accelerator: 0us, total: 7.69sec
    __init__.py:86:allreduce, cpu: 2.41ms, accelerator: 3.89ms, total: 6.30ms
  __init__.py:185:compute_gradients, cpu: 2.04ms, accelerator: 12.09ms, total: 14.15ms
train.py:515:<module>, cpu: 90.80ms, accelerator: 0us, total: 90.80ms
train.py:449:<module>, cpu: 70.56ms, accelerator: 208us, total: 70.76ms
  summary.py:146:image, cpu: 70.53ms, accelerator: 0us, total: 70.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.53sec, accelerator: 0us, total: 8.53sec (92.76%)
top 2 operation type: ImageSummary, cpu: 258.29ms, accelerator: 0us, total: 258.29ms (2.81%)
top 3 operation type: HistogramSummary, cpu: 130.86ms, accelerator: 0us, total: 130.86ms (1.42%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 88.19ms, accelerator: 0us, total: 88.19ms
top 3 graph node: difference, cpu: 86.18ms, accelerator: 0us, total: 86.18ms
train.py:511:<module>, cpu: 8.57sec, accelerator: 15.65ms, total: 8.58sec
  __init__.py:194:compute_gradients, cpu: 8.56sec, accelerator: 5.69ms, total: 8.57sec
    __init__.py:83:allreduce, cpu: 8.53sec, accelerator: 0us, total: 8.53sec
    __init__.py:86:allreduce, cpu: 30.63ms, accelerator: 5.69ms, total: 36.33ms
  __init__.py:185:compute_gradients, cpu: 4.69ms, accelerator: 9.97ms, total: 14.68ms
train.py:447:<module>, cpu: 88.19ms, accelerator: 0us, total: 88.19ms
train.py:449:<module>, cpu: 86.20ms, accelerator: 141us, total: 86.35ms
  summary.py:146:image, cpu: 86.18ms, accelerator: 0us, total: 86.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.48sec, accelerator: 0us, total: 8.48sec (92.77%)
top 2 operation type: ImageSummary, cpu: 288.47ms, accelerator: 0us, total: 288.47ms (3.16%)
top 3 operation type: HistogramSummary, cpu: 115.71ms, accelerator: 0us, total: 115.71ms (1.27%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 100.64ms, accelerator: 0us, total: 100.64ms
top 3 graph node: difference, cpu: 98.21ms, accelerator: 0us, total: 98.21ms
train.py:511:<module>, cpu: 8.51sec, accelerator: 11.94ms, total: 8.52sec
  __init__.py:194:compute_gradients, cpu: 8.50sec, accelerator: 4.33ms, total: 8.51sec
    __init__.py:83:allreduce, cpu: 8.48sec, accelerator: 0us, total: 8.48sec
    __init__.py:86:allreduce, cpu: 23.42ms, accelerator: 4.33ms, total: 27.76ms
  __init__.py:185:compute_gradients, cpu: 4.02ms, accelerator: 7.61ms, total: 11.66ms
train.py:448:<module>, cpu: 100.65ms, accelerator: 0us, total: 100.65ms
train.py:449:<module>, cpu: 98.24ms, accelerator: 107us, total: 98.34ms
  summary.py:146:image, cpu: 98.21ms, accelerator: 0us, total: 98.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_1000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.35sec, accelerator: 0us, total: 8.35sec (93.07%)
top 2 operation type: ImageSummary, cpu: 268.82ms, accelerator: 0us, total: 268.82ms (3.00%)
top 3 operation type: HistogramSummary, cpu: 116.78ms, accelerator: 0us, total: 116.78ms (1.30%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 94.32ms, accelerator: 0us, total: 94.32ms
top 3 graph node: difference, cpu: 90.29ms, accelerator: 0us, total: 90.29ms
train.py:511:<module>, cpu: 8.38sec, accelerator: 9.74ms, total: 8.39sec
  __init__.py:194:compute_gradients, cpu: 8.37sec, accelerator: 3.53ms, total: 8.38sec
    __init__.py:83:allreduce, cpu: 8.35sec, accelerator: 0us, total: 8.35sec
    __init__.py:86:allreduce, cpu: 24.35ms, accelerator: 3.53ms, total: 27.89ms
  __init__.py:185:compute_gradients, cpu: 3.86ms, accelerator: 6.21ms, total: 10.11ms
train.py:448:<module>, cpu: 94.32ms, accelerator: 0us, total: 94.32ms
train.py:449:<module>, cpu: 90.32ms, accelerator: 87us, total: 90.40ms
  summary.py:146:image, cpu: 90.30ms, accelerator: 0us, total: 90.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_1250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.59sec, accelerator: 0us, total: 8.59sec (93.21%)
top 2 operation type: ImageSummary, cpu: 295.06ms, accelerator: 0us, total: 295.06ms (3.20%)
top 3 operation type: HistogramSummary, cpu: 122.67ms, accelerator: 0us, total: 122.67ms (1.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 103.74ms, accelerator: 0us, total: 103.74ms
top 3 graph node: original, cpu: 97.69ms, accelerator: 0us, total: 97.69ms
train.py:511:<module>, cpu: 8.62sec, accelerator: 8.69ms, total: 8.63sec
  __init__.py:194:compute_gradients, cpu: 8.62sec, accelerator: 2.99ms, total: 8.62sec
    __init__.py:83:allreduce, cpu: 8.59sec, accelerator: 0us, total: 8.59sec
    __init__.py:86:allreduce, cpu: 20.77ms, accelerator: 2.99ms, total: 23.77ms
  __init__.py:185:compute_gradients, cpu: 3.61ms, accelerator: 5.70ms, total: 9.35ms
train.py:448:<module>, cpu: 103.74ms, accelerator: 0us, total: 103.74ms
train.py:447:<module>, cpu: 97.70ms, accelerator: 0us, total: 97.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_1500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 9.02sec, accelerator: 0us, total: 9.02sec (93.48%)
top 2 operation type: ImageSummary, cpu: 314.98ms, accelerator: 0us, total: 314.98ms (3.27%)
top 3 operation type: HistogramSummary, cpu: 125.85ms, accelerator: 0us, total: 125.85ms (1.30%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 110.50ms, accelerator: 0us, total: 110.50ms
top 3 graph node: original, cpu: 108.15ms, accelerator: 0us, total: 108.15ms
train.py:511:<module>, cpu: 9.04sec, accelerator: 7.55ms, total: 9.05sec
  __init__.py:194:compute_gradients, cpu: 9.04sec, accelerator: 2.59ms, total: 9.04sec
    __init__.py:83:allreduce, cpu: 9.02sec, accelerator: 0us, total: 9.02sec
    __init__.py:86:allreduce, cpu: 20.56ms, accelerator: 2.59ms, total: 23.16ms
  __init__.py:185:compute_gradients, cpu: 3.55ms, accelerator: 4.96ms, total: 8.54ms
train.py:448:<module>, cpu: 110.51ms, accelerator: 0us, total: 110.51ms
train.py:447:<module>, cpu: 108.15ms, accelerator: 0us, total: 108.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_1750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 9.11sec, accelerator: 0us, total: 9.11sec (93.44%)
top 2 operation type: ImageSummary, cpu: 332.70ms, accelerator: 0us, total: 332.70ms (3.41%)
top 3 operation type: HistogramSummary, cpu: 128.81ms, accelerator: 0us, total: 128.81ms (1.32%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 116.80ms, accelerator: 0us, total: 116.80ms
top 3 graph node: autoencoded, cpu: 111.34ms, accelerator: 0us, total: 111.34ms
train.py:511:<module>, cpu: 9.14sec, accelerator: 7.25ms, total: 9.14sec
  __init__.py:194:compute_gradients, cpu: 9.13sec, accelerator: 2.31ms, total: 9.13sec
    __init__.py:83:allreduce, cpu: 9.11sec, accelerator: 0us, total: 9.11sec
    __init__.py:86:allreduce, cpu: 19.30ms, accelerator: 2.31ms, total: 21.63ms
  __init__.py:185:compute_gradients, cpu: 3.38ms, accelerator: 4.94ms, total: 8.36ms
train.py:447:<module>, cpu: 116.81ms, accelerator: 0us, total: 116.81ms
train.py:448:<module>, cpu: 111.34ms, accelerator: 0us, total: 111.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2121.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_2000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 9.09sec, accelerator: 0us, total: 9.09sec (93.59%)
top 2 operation type: ImageSummary, cpu: 337.39ms, accelerator: 0us, total: 337.39ms (3.47%)
top 3 operation type: HistogramSummary, cpu: 120.16ms, accelerator: 0us, total: 120.16ms (1.24%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 120.46ms, accelerator: 0us, total: 120.46ms
top 3 graph node: autoencoded, cpu: 109.83ms, accelerator: 0us, total: 109.83ms
train.py:511:<module>, cpu: 9.12sec, accelerator: 6.54ms, total: 9.12sec
  __init__.py:194:compute_gradients, cpu: 9.11sec, accelerator: 2.08ms, total: 9.11sec
    __init__.py:83:allreduce, cpu: 9.09sec, accelerator: 0us, total: 9.09sec
    __init__.py:86:allreduce, cpu: 19.31ms, accelerator: 2.08ms, total: 21.42ms
  __init__.py:185:compute_gradients, cpu: 3.19ms, accelerator: 4.45ms, total: 7.68ms
train.py:447:<module>, cpu: 120.47ms, accelerator: 0us, total: 120.47ms
train.py:448:<module>, cpu: 109.83ms, accelerator: 0us, total: 109.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_2250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.90sec, accelerator: 0us, total: 8.90sec (93.61%)
top 2 operation type: ImageSummary, cpu: 330.96ms, accelerator: 0us, total: 330.96ms (3.48%)
top 3 operation type: HistogramSummary, cpu: 120.97ms, accelerator: 0us, total: 120.97ms (1.27%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 116.40ms, accelerator: 0us, total: 116.40ms
top 3 graph node: autoencoded, cpu: 108.44ms, accelerator: 0us, total: 108.44ms
train.py:511:<module>, cpu: 8.92sec, accelerator: 5.97ms, total: 8.92sec
  __init__.py:194:compute_gradients, cpu: 8.91sec, accelerator: 1.90ms, total: 8.92sec
    __init__.py:83:allreduce, cpu: 8.90sec, accelerator: 0us, total: 8.90sec
    __init__.py:86:allreduce, cpu: 17.57ms, accelerator: 1.90ms, total: 19.50ms
  __init__.py:185:compute_gradients, cpu: 3.04ms, accelerator: 4.07ms, total: 7.15ms
train.py:447:<module>, cpu: 116.41ms, accelerator: 0us, total: 116.41ms
train.py:448:<module>, cpu: 108.45ms, accelerator: 0us, total: 108.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_2500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.86sec, accelerator: 0us, total: 8.86sec (93.51%)
top 2 operation type: ImageSummary, cpu: 343.77ms, accelerator: 0us, total: 343.77ms (3.63%)
top 3 operation type: HistogramSummary, cpu: 124.75ms, accelerator: 0us, total: 124.75ms (1.32%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 121.22ms, accelerator: 0us, total: 121.22ms
top 3 graph node: autoencoded, cpu: 115.94ms, accelerator: 0us, total: 115.94ms
train.py:511:<module>, cpu: 8.88sec, accelerator: 5.51ms, total: 8.89sec
  __init__.py:194:compute_gradients, cpu: 8.88sec, accelerator: 1.76ms, total: 8.88sec
    __init__.py:83:allreduce, cpu: 8.86sec, accelerator: 0us, total: 8.86sec
    __init__.py:86:allreduce, cpu: 16.89ms, accelerator: 1.76ms, total: 18.67ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 3.75ms, total: 6.72ms
train.py:447:<module>, cpu: 121.23ms, accelerator: 0us, total: 121.23ms
train.py:448:<module>, cpu: 115.95ms, accelerator: 0us, total: 115.95ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2069.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_2750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.66sec, accelerator: 0us, total: 8.66sec (93.40%)
top 2 operation type: ImageSummary, cpu: 347.81ms, accelerator: 0us, total: 347.81ms (3.75%)
top 3 operation type: HistogramSummary, cpu: 122.81ms, accelerator: 0us, total: 122.81ms (1.32%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 120.59ms, accelerator: 0us, total: 120.59ms
top 3 graph node: autoencoded, cpu: 117.89ms, accelerator: 0us, total: 117.89ms
train.py:511:<module>, cpu: 8.68sec, accelerator: 5.77ms, total: 8.69sec
  __init__.py:194:compute_gradients, cpu: 8.68sec, accelerator: 1.64ms, total: 8.68sec
    __init__.py:83:allreduce, cpu: 8.66sec, accelerator: 0us, total: 8.66sec
    __init__.py:86:allreduce, cpu: 16.60ms, accelerator: 1.64ms, total: 18.26ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 4.13ms, total: 7.03ms
train.py:447:<module>, cpu: 120.59ms, accelerator: 0us, total: 120.59ms
train.py:448:<module>, cpu: 117.90ms, accelerator: 0us, total: 117.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_3000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.76sec, accelerator: 0us, total: 8.76sec (93.47%)
top 2 operation type: ImageSummary, cpu: 348.33ms, accelerator: 0us, total: 348.33ms (3.72%)
top 3 operation type: HistogramSummary, cpu: 124.55ms, accelerator: 0us, total: 124.55ms (1.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: original, cpu: 120.00ms, accelerator: 0us, total: 120.00ms
top 3 graph node: autoencoded, cpu: 118.25ms, accelerator: 0us, total: 118.25ms
train.py:511:<module>, cpu: 8.78sec, accelerator: 5.40ms, total: 8.78sec
  __init__.py:194:compute_gradients, cpu: 8.77sec, accelerator: 1.55ms, total: 8.77sec
    __init__.py:83:allreduce, cpu: 8.76sec, accelerator: 0us, total: 8.76sec
    __init__.py:86:allreduce, cpu: 16.56ms, accelerator: 1.55ms, total: 18.14ms
  __init__.py:185:compute_gradients, cpu: 3.19ms, accelerator: 3.85ms, total: 7.09ms
train.py:447:<module>, cpu: 120.01ms, accelerator: 0us, total: 120.01ms
train.py:448:<module>, cpu: 118.26ms, accelerator: 0us, total: 118.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_3250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.60sec, accelerator: 0us, total: 8.60sec (93.42%)
top 2 operation type: ImageSummary, cpu: 346.58ms, accelerator: 0us, total: 346.58ms (3.76%)
top 3 operation type: HistogramSummary, cpu: 122.15ms, accelerator: 0us, total: 122.15ms (1.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 122.48ms, accelerator: 0us, total: 122.48ms
top 3 graph node: original, cpu: 115.86ms, accelerator: 0us, total: 115.86ms
train.py:511:<module>, cpu: 8.62sec, accelerator: 5.09ms, total: 8.62sec
  __init__.py:194:compute_gradients, cpu: 8.62sec, accelerator: 1.47ms, total: 8.62sec
    __init__.py:83:allreduce, cpu: 8.60sec, accelerator: 0us, total: 8.60sec
    __init__.py:86:allreduce, cpu: 15.59ms, accelerator: 1.47ms, total: 17.08ms
  __init__.py:185:compute_gradients, cpu: 3.18ms, accelerator: 3.62ms, total: 6.84ms
train.py:448:<module>, cpu: 122.49ms, accelerator: 0us, total: 122.49ms
train.py:447:<module>, cpu: 115.87ms, accelerator: 0us, total: 115.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_3500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.53sec, accelerator: 0us, total: 8.53sec (93.39%)
top 2 operation type: ImageSummary, cpu: 346.37ms, accelerator: 0us, total: 346.37ms (3.79%)
top 3 operation type: HistogramSummary, cpu: 119.79ms, accelerator: 0us, total: 119.79ms (1.31%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 121.61ms, accelerator: 0us, total: 121.61ms
top 3 graph node: original, cpu: 114.84ms, accelerator: 0us, total: 114.84ms
train.py:511:<module>, cpu: 8.55sec, accelerator: 4.84ms, total: 8.55sec
  __init__.py:194:compute_gradients, cpu: 8.54sec, accelerator: 1.43ms, total: 8.54sec
    __init__.py:83:allreduce, cpu: 8.53sec, accelerator: 0us, total: 8.53sec
    __init__.py:86:allreduce, cpu: 14.82ms, accelerator: 1.43ms, total: 16.27ms
  __init__.py:185:compute_gradients, cpu: 3.10ms, accelerator: 3.41ms, total: 6.55ms
train.py:448:<module>, cpu: 121.61ms, accelerator: 0us, total: 121.61ms
train.py:447:<module>, cpu: 114.85ms, accelerator: 0us, total: 114.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_3750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.46sec, accelerator: 0us, total: 8.46sec (93.38%)
top 2 operation type: ImageSummary, cpu: 345.61ms, accelerator: 0us, total: 345.61ms (3.81%)
top 3 operation type: HistogramSummary, cpu: 119.19ms, accelerator: 0us, total: 119.19ms (1.32%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 123.70ms, accelerator: 0us, total: 123.70ms
top 3 graph node: original, cpu: 112.16ms, accelerator: 0us, total: 112.16ms
train.py:511:<module>, cpu: 8.48sec, accelerator: 4.61ms, total: 8.48sec
  __init__.py:194:compute_gradients, cpu: 8.48sec, accelerator: 1.37ms, total: 8.48sec
    __init__.py:83:allreduce, cpu: 8.46sec, accelerator: 0us, total: 8.46sec
    __init__.py:86:allreduce, cpu: 14.03ms, accelerator: 1.37ms, total: 15.43ms
  __init__.py:185:compute_gradients, cpu: 3.02ms, accelerator: 3.24ms, total: 6.31ms
train.py:448:<module>, cpu: 123.71ms, accelerator: 0us, total: 123.71ms
train.py:447:<module>, cpu: 112.16ms, accelerator: 0us, total: 112.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_4000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.37sec, accelerator: 0us, total: 8.37sec (93.35%)
top 2 operation type: ImageSummary, cpu: 344.20ms, accelerator: 0us, total: 344.20ms (3.84%)
top 3 operation type: HistogramSummary, cpu: 119.18ms, accelerator: 0us, total: 119.18ms (1.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 126.81ms, accelerator: 0us, total: 126.81ms
top 3 graph node: difference, cpu: 109.09ms, accelerator: 0us, total: 109.09ms
train.py:511:<module>, cpu: 8.39sec, accelerator: 4.93ms, total: 8.39sec
  __init__.py:194:compute_gradients, cpu: 8.38sec, accelerator: 1.30ms, total: 8.39sec
    __init__.py:83:allreduce, cpu: 8.37sec, accelerator: 0us, total: 8.37sec
    __init__.py:86:allreduce, cpu: 13.31ms, accelerator: 1.30ms, total: 14.64ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 3.63ms, total: 6.64ms
train.py:448:<module>, cpu: 126.81ms, accelerator: 0us, total: 126.81ms
train.py:449:<module>, cpu: 109.13ms, accelerator: 54us, total: 109.19ms
  summary.py:146:image, cpu: 109.09ms, accelerator: 0us, total: 109.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_4250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.33sec, accelerator: 0us, total: 8.33sec (93.35%)
top 2 operation type: ImageSummary, cpu: 344.71ms, accelerator: 0us, total: 344.71ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 118.30ms, accelerator: 0us, total: 118.30ms (1.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 128.53ms, accelerator: 0us, total: 128.53ms
top 3 graph node: original, cpu: 108.45ms, accelerator: 0us, total: 108.45ms
train.py:511:<module>, cpu: 8.34sec, accelerator: 5.40ms, total: 8.35sec
  __init__.py:194:compute_gradients, cpu: 8.34sec, accelerator: 1.25ms, total: 8.34sec
    __init__.py:83:allreduce, cpu: 8.33sec, accelerator: 0us, total: 8.33sec
    __init__.py:86:allreduce, cpu: 12.70ms, accelerator: 1.25ms, total: 13.97ms
  __init__.py:185:compute_gradients, cpu: 2.91ms, accelerator: 4.15ms, total: 7.10ms
train.py:448:<module>, cpu: 128.53ms, accelerator: 0us, total: 128.53ms
train.py:447:<module>, cpu: 108.46ms, accelerator: 0us, total: 108.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_4500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.38sec, accelerator: 0us, total: 8.38sec (93.42%)
top 2 operation type: ImageSummary, cpu: 346.02ms, accelerator: 0us, total: 346.02ms (3.86%)
top 3 operation type: HistogramSummary, cpu: 116.27ms, accelerator: 0us, total: 116.27ms (1.30%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 129.79ms, accelerator: 0us, total: 129.79ms
top 3 graph node: difference, cpu: 108.35ms, accelerator: 0us, total: 108.35ms
train.py:511:<module>, cpu: 8.39sec, accelerator: 5.16ms, total: 8.40sec
  __init__.py:194:compute_gradients, cpu: 8.39sec, accelerator: 1.20ms, total: 8.39sec
    __init__.py:83:allreduce, cpu: 8.38sec, accelerator: 0us, total: 8.38sec
    __init__.py:86:allreduce, cpu: 12.33ms, accelerator: 1.20ms, total: 13.55ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 3.96ms, total: 6.85ms
train.py:448:<module>, cpu: 129.80ms, accelerator: 0us, total: 129.80ms
train.py:449:<module>, cpu: 108.39ms, accelerator: 50us, total: 108.44ms
  summary.py:146:image, cpu: 108.36ms, accelerator: 0us, total: 108.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_4750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.41sec, accelerator: 0us, total: 8.41sec (93.44%)
top 2 operation type: ImageSummary, cpu: 348.46ms, accelerator: 0us, total: 348.46ms (3.87%)
top 3 operation type: HistogramSummary, cpu: 117.44ms, accelerator: 0us, total: 117.44ms (1.31%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 131.02ms, accelerator: 0us, total: 131.02ms
top 3 graph node: difference, cpu: 108.77ms, accelerator: 0us, total: 108.77ms
train.py:511:<module>, cpu: 8.42sec, accelerator: 4.95ms, total: 8.43sec
  __init__.py:194:compute_gradients, cpu: 8.42sec, accelerator: 1.16ms, total: 8.42sec
    __init__.py:83:allreduce, cpu: 8.41sec, accelerator: 0us, total: 8.41sec
    __init__.py:86:allreduce, cpu: 11.79ms, accelerator: 1.16ms, total: 12.98ms
  __init__.py:185:compute_gradients, cpu: 2.80ms, accelerator: 3.79ms, total: 6.63ms
train.py:448:<module>, cpu: 131.03ms, accelerator: 0us, total: 131.03ms
train.py:449:<module>, cpu: 108.82ms, accelerator: 47us, total: 108.87ms
  summary.py:146:image, cpu: 108.78ms, accelerator: 0us, total: 108.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_5000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.33sec, accelerator: 0us, total: 8.33sec (93.46%)
top 2 operation type: ImageSummary, cpu: 343.62ms, accelerator: 0us, total: 343.62ms (3.85%)
top 3 operation type: HistogramSummary, cpu: 116.72ms, accelerator: 0us, total: 116.72ms (1.31%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 129.30ms, accelerator: 0us, total: 129.30ms
top 3 graph node: original, cpu: 107.23ms, accelerator: 0us, total: 107.23ms
train.py:511:<module>, cpu: 8.35sec, accelerator: 4.76ms, total: 8.35sec
  __init__.py:194:compute_gradients, cpu: 8.35sec, accelerator: 1.12ms, total: 8.35sec
    __init__.py:83:allreduce, cpu: 8.33sec, accelerator: 0us, total: 8.33sec
    __init__.py:86:allreduce, cpu: 12.28ms, accelerator: 1.12ms, total: 13.43ms
  __init__.py:185:compute_gradients, cpu: 2.76ms, accelerator: 3.64ms, total: 6.43ms
train.py:448:<module>, cpu: 129.30ms, accelerator: 0us, total: 129.30ms
train.py:447:<module>, cpu: 107.24ms, accelerator: 0us, total: 107.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_5250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: HorovodAllreduce, cpu: 8.24sec, accelerator: 0us, total: 8.24sec (93.40%)
top 2 operation type: ImageSummary, cpu: 343.46ms, accelerator: 0us, total: 343.46ms (3.89%)
top 3 operation type: HistogramSummary, cpu: 115.61ms, accelerator: 0us, total: 115.61ms (1.31%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: autoencoded, cpu: 130.88ms, accelerator: 0us, total: 130.88ms
top 3 graph node: difference, cpu: 106.86ms, accelerator: 0us, total: 106.86ms
train.py:511:<module>, cpu: 8.25sec, accelerator: 4.58ms, total: 8.26sec
  __init__.py:194:compute_gradients, cpu: 8.25sec, accelerator: 1.09ms, total: 8.25sec
    __init__.py:83:allreduce, cpu: 8.24sec, accelerator: 0us, total: 8.24sec
    __init__.py:86:allreduce, cpu: 11.82ms, accelerator: 1.09ms, total: 12.93ms
  __init__.py:185:compute_gradients, cpu: 2.71ms, accelerator: 3.50ms, total: 6.25ms
train.py:448:<module>, cpu: 130.89ms, accelerator: 0us, total: 130.89ms
train.py:449:<module>, cpu: 106.90ms, accelerator: 43us, total: 106.95ms
  summary.py:146:image, cpu: 106.87ms, accelerator: 0us, total: 106.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_5500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 802032348.78sec, total: 802032348.78sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.20sec, accelerator: 0us, total: 8.20sec (0.00%)
top 3 operation type: ImageSummary, cpu: 343.09ms, accelerator: 0us, total: 343.09ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 130.20ms, accelerator: 0us, total: 130.20ms
train.py:442:<module>, cpu: 5.72ms, accelerator: 802032348.80sec, total: 802032348.80sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 802032348.79sec, total: 802032348.79sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 802032348.79sec, total: 802032348.79sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 802032348.79sec, total: 802032348.79sec
  train.py:359:image_losses, cpu: 2.59ms, accelerator: 1.78ms, total: 4.38ms
    train.py:322:loss_fn, cpu: 2.57ms, accelerator: 1.78ms, total: 4.36ms
      train.py:342:hfe, cpu: 1.94ms, accelerator: 197us, total: 2.14ms
      train.py:343:hfe, cpu: 284us, accelerator: 984us, total: 1.27ms
  train.py:358:image_losses, cpu: 148us, accelerator: 3.21ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 135us, accelerator: 3.21ms, total: 3.35ms
train.py:511:<module>, cpu: 8.21sec, accelerator: 4.42ms, total: 8.22sec
  __init__.py:194:compute_gradients, cpu: 8.21sec, accelerator: 1.05ms, total: 8.21sec
    __init__.py:83:allreduce, cpu: 8.20sec, accelerator: 0us, total: 8.20sec
    __init__.py:86:allreduce, cpu: 11.39ms, accelerator: 1.05ms, total: 12.46ms
  __init__.py:185:compute_gradients, cpu: 2.68ms, accelerator: 3.37ms, total: 6.09ms
train.py:448:<module>, cpu: 130.21ms, accelerator: 0us, total: 130.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_5750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 768614334.25sec, total: 768614334.25sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec (0.00%)
top 3 operation type: ImageSummary, cpu: 342.07ms, accelerator: 0us, total: 342.07ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 131.36ms, accelerator: 0us, total: 131.36ms
train.py:442:<module>, cpu: 5.64ms, accelerator: 768614334.26sec, total: 768614334.27sec
  train.py:360:image_losses, cpu: 2.75ms, accelerator: 768614334.26sec, total: 768614334.26sec
    train.py:322:loss_fn, cpu: 2.74ms, accelerator: 768614334.26sec, total: 768614334.26sec
      train.py:349:msssim, cpu: 2.69ms, accelerator: 768614334.26sec, total: 768614334.26sec
  train.py:359:image_losses, cpu: 2.53ms, accelerator: 1.78ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.51ms, accelerator: 1.78ms, total: 4.29ms
      train.py:342:hfe, cpu: 1.87ms, accelerator: 192us, total: 2.06ms
      train.py:343:hfe, cpu: 303us, accelerator: 945us, total: 1.25ms
  train.py:358:image_losses, cpu: 146us, accelerator: 3.08ms, total: 3.23ms
    train.py:322:loss_fn, cpu: 133us, accelerator: 3.08ms, total: 3.21ms
train.py:511:<module>, cpu: 8.22sec, accelerator: 4.39ms, total: 8.22sec
  __init__.py:194:compute_gradients, cpu: 8.22sec, accelerator: 1.02ms, total: 8.22sec
    __init__.py:83:allreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec
    __init__.py:86:allreduce, cpu: 11.08ms, accelerator: 1.02ms, total: 12.12ms
  __init__.py:185:compute_gradients, cpu: 2.63ms, accelerator: 3.37ms, total: 6.04ms
train.py:448:<module>, cpu: 131.37ms, accelerator: 0us, total: 131.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_6000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 392us, accelerator: 737869760.88sec, total: 737869760.88sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.32sec, accelerator: 0us, total: 8.32sec (0.00%)
top 3 operation type: ImageSummary, cpu: 347.94ms, accelerator: 0us, total: 347.94ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 132.42ms, accelerator: 0us, total: 132.42ms
train.py:442:<module>, cpu: 5.56ms, accelerator: 737869760.89sec, total: 737869760.90sec
  train.py:360:image_losses, cpu: 2.73ms, accelerator: 737869760.89sec, total: 737869760.89sec
    train.py:322:loss_fn, cpu: 2.72ms, accelerator: 737869760.89sec, total: 737869760.89sec
      train.py:349:msssim, cpu: 2.67ms, accelerator: 737869760.89sec, total: 737869760.89sec
  train.py:359:image_losses, cpu: 2.46ms, accelerator: 1.71ms, total: 4.18ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.71ms, total: 4.16ms
      train.py:342:hfe, cpu: 1.81ms, accelerator: 183us, total: 1.99ms
      train.py:343:hfe, cpu: 297us, accelerator: 910us, total: 1.21ms
  train.py:358:image_losses, cpu: 149us, accelerator: 2.96ms, total: 3.11ms
    train.py:322:loss_fn, cpu: 136us, accelerator: 2.96ms, total: 3.10ms
train.py:511:<module>, cpu: 8.33sec, accelerator: 4.25ms, total: 8.33sec
  __init__.py:194:compute_gradients, cpu: 8.33sec, accelerator: 998us, total: 8.33sec
    __init__.py:83:allreduce, cpu: 8.32sec, accelerator: 0us, total: 8.32sec
    __init__.py:86:allreduce, cpu: 10.76ms, accelerator: 998us, total: 11.78ms
  __init__.py:185:compute_gradients, cpu: 2.60ms, accelerator: 3.25ms, total: 5.89ms
train.py:448:<module>, cpu: 132.42ms, accelerator: 0us, total: 132.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_6250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 709490154.69sec, total: 709490154.69sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.32sec, accelerator: 0us, total: 8.32sec (0.00%)
top 3 operation type: ImageSummary, cpu: 345.89ms, accelerator: 0us, total: 345.89ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 131.70ms, accelerator: 0us, total: 131.70ms
train.py:442:<module>, cpu: 5.48ms, accelerator: 709490154.71sec, total: 709490154.71sec
  train.py:360:image_losses, cpu: 2.73ms, accelerator: 709490154.70sec, total: 709490154.70sec
    train.py:322:loss_fn, cpu: 2.71ms, accelerator: 709490154.70sec, total: 709490154.70sec
      train.py:349:msssim, cpu: 2.66ms, accelerator: 709490154.70sec, total: 709490154.70sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.65ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.65ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.75ms, accelerator: 179us, total: 1.93ms
      train.py:343:hfe, cpu: 292us, accelerator: 876us, total: 1.17ms
  train.py:358:image_losses, cpu: 146us, accelerator: 2.84ms, total: 2.99ms
    train.py:322:loss_fn, cpu: 133us, accelerator: 2.84ms, total: 2.98ms
train.py:511:<module>, cpu: 8.33sec, accelerator: 4.12ms, total: 8.34sec
  __init__.py:194:compute_gradients, cpu: 8.33sec, accelerator: 971us, total: 8.33sec
    __init__.py:83:allreduce, cpu: 8.32sec, accelerator: 0us, total: 8.32sec
    __init__.py:86:allreduce, cpu: 10.42ms, accelerator: 971us, total: 11.41ms
  __init__.py:185:compute_gradients, cpu: 2.58ms, accelerator: 3.15ms, total: 5.78ms
train.py:448:<module>, cpu: 131.70ms, accelerator: 0us, total: 131.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_6500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 388us, accelerator: 683212741.56sec, total: 683212741.56sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.27sec, accelerator: 0us, total: 8.27sec (0.00%)
top 3 operation type: ImageSummary, cpu: 345.29ms, accelerator: 0us, total: 345.29ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 132.62ms, accelerator: 0us, total: 132.62ms
train.py:442:<module>, cpu: 5.53ms, accelerator: 683212741.57sec, total: 683212741.57sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 683212741.56sec, total: 683212741.57sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 683212741.56sec, total: 683212741.57sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 683212741.56sec, total: 683212741.57sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.60ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.60ms, total: 3.99ms
      train.py:342:hfe, cpu: 1.75ms, accelerator: 175us, total: 1.93ms
      train.py:343:hfe, cpu: 298us, accelerator: 848us, total: 1.15ms
  train.py:358:image_losses, cpu: 148us, accelerator: 2.74ms, total: 2.89ms
    train.py:322:loss_fn, cpu: 135us, accelerator: 2.74ms, total: 2.88ms
train.py:511:<module>, cpu: 8.28sec, accelerator: 4.48ms, total: 8.29sec
  __init__.py:194:compute_gradients, cpu: 8.28sec, accelerator: 941us, total: 8.28sec
    __init__.py:83:allreduce, cpu: 8.27sec, accelerator: 0us, total: 8.27sec
    __init__.py:86:allreduce, cpu: 10.13ms, accelerator: 941us, total: 11.10ms
  __init__.py:185:compute_gradients, cpu: 2.59ms, accelerator: 3.54ms, total: 6.16ms
train.py:448:<module>, cpu: 132.62ms, accelerator: 0us, total: 132.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_6750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 387us, accelerator: 658812286.50sec, total: 658812286.50sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.34sec, accelerator: 0us, total: 8.34sec (0.00%)
top 3 operation type: ImageSummary, cpu: 350.12ms, accelerator: 0us, total: 350.12ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 134.63ms, accelerator: 0us, total: 134.63ms
train.py:442:<module>, cpu: 5.44ms, accelerator: 658812286.51sec, total: 658812286.52sec
  train.py:360:image_losses, cpu: 2.74ms, accelerator: 658812286.51sec, total: 658812286.51sec
    train.py:322:loss_fn, cpu: 2.73ms, accelerator: 658812286.51sec, total: 658812286.51sec
      train.py:349:msssim, cpu: 2.68ms, accelerator: 658812286.51sec, total: 658812286.51sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.54ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.32ms, accelerator: 1.54ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.70ms, accelerator: 171us, total: 1.88ms
      train.py:343:hfe, cpu: 295us, accelerator: 819us, total: 1.12ms
  train.py:358:image_losses, cpu: 145us, accelerator: 2.64ms, total: 2.79ms
    train.py:322:loss_fn, cpu: 132us, accelerator: 2.64ms, total: 2.78ms
train.py:511:<module>, cpu: 8.35sec, accelerator: 4.35ms, total: 8.35sec
  __init__.py:194:compute_gradients, cpu: 8.35sec, accelerator: 919us, total: 8.35sec
    __init__.py:83:allreduce, cpu: 8.34sec, accelerator: 0us, total: 8.34sec
    __init__.py:86:allreduce, cpu: 9.85ms, accelerator: 919us, total: 10.80ms
  __init__.py:185:compute_gradients, cpu: 2.55ms, accelerator: 3.43ms, total: 6.03ms
train.py:448:<module>, cpu: 134.63ms, accelerator: 0us, total: 134.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_7000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 385us, accelerator: 636094621.45sec, total: 636094621.45sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.30sec, accelerator: 0us, total: 8.30sec (0.00%)
top 3 operation type: ImageSummary, cpu: 347.91ms, accelerator: 0us, total: 347.91ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 134.36ms, accelerator: 0us, total: 134.36ms
train.py:442:<module>, cpu: 5.36ms, accelerator: 636094621.46sec, total: 636094621.47sec
  train.py:360:image_losses, cpu: 2.72ms, accelerator: 636094621.46sec, total: 636094621.46sec
    train.py:322:loss_fn, cpu: 2.71ms, accelerator: 636094621.46sec, total: 636094621.46sec
      train.py:349:msssim, cpu: 2.66ms, accelerator: 636094621.46sec, total: 636094621.46sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.50ms, total: 3.79ms
    train.py:322:loss_fn, cpu: 2.26ms, accelerator: 1.50ms, total: 3.77ms
      train.py:342:hfe, cpu: 1.65ms, accelerator: 168us, total: 1.82ms
      train.py:343:hfe, cpu: 296us, accelerator: 789us, total: 1.09ms
  train.py:358:image_losses, cpu: 144us, accelerator: 2.55ms, total: 2.70ms
    train.py:322:loss_fn, cpu: 131us, accelerator: 2.55ms, total: 2.68ms
train.py:511:<module>, cpu: 8.31sec, accelerator: 4.62ms, total: 8.32sec
  __init__.py:194:compute_gradients, cpu: 8.31sec, accelerator: 899us, total: 8.31sec
    __init__.py:83:allreduce, cpu: 8.30sec, accelerator: 0us, total: 8.30sec
    __init__.py:86:allreduce, cpu: 9.58ms, accelerator: 899us, total: 10.51ms
  __init__.py:185:compute_gradients, cpu: 2.53ms, accelerator: 3.72ms, total: 6.29ms
train.py:448:<module>, cpu: 134.36ms, accelerator: 0us, total: 134.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_7250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 558us, accelerator: 614891467.40sec, total: 614891467.40sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.31sec, accelerator: 0us, total: 8.31sec (0.00%)
top 3 operation type: ImageSummary, cpu: 352.12ms, accelerator: 0us, total: 352.12ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.05ms, accelerator: 0us, total: 136.05ms
train.py:442:<module>, cpu: 5.95ms, accelerator: 614891467.41sec, total: 614891467.42sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 614891467.41sec, total: 614891467.41sec
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 614891467.41sec, total: 614891467.41sec
      train.py:349:msssim, cpu: 2.84ms, accelerator: 614891467.41sec, total: 614891467.41sec
  train.py:359:image_losses, cpu: 2.69ms, accelerator: 1.45ms, total: 4.15ms
    train.py:322:loss_fn, cpu: 2.67ms, accelerator: 1.45ms, total: 4.13ms
      train.py:342:hfe, cpu: 2.07ms, accelerator: 165us, total: 2.24ms
      train.py:343:hfe, cpu: 292us, accelerator: 766us, total: 1.06ms
  train.py:358:image_losses, cpu: 142us, accelerator: 2.47ms, total: 2.61ms
    train.py:322:loss_fn, cpu: 129us, accelerator: 2.47ms, total: 2.60ms
train.py:511:<module>, cpu: 8.32sec, accelerator: 4.49ms, total: 8.32sec
  __init__.py:194:compute_gradients, cpu: 8.32sec, accelerator: 878us, total: 8.32sec
    __init__.py:83:allreduce, cpu: 8.31sec, accelerator: 0us, total: 8.31sec
    __init__.py:86:allreduce, cpu: 9.79ms, accelerator: 878us, total: 10.69ms
  __init__.py:185:compute_gradients, cpu: 2.72ms, accelerator: 3.61ms, total: 6.37ms
train.py:448:<module>, cpu: 136.05ms, accelerator: 0us, total: 136.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_7500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 549us, accelerator: 595056258.78sec, total: 595056258.78sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.29sec, accelerator: 0us, total: 8.29sec (0.00%)
top 3 operation type: ImageSummary, cpu: 351.91ms, accelerator: 0us, total: 351.91ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.93ms, accelerator: 0us, total: 136.93ms
train.py:442:<module>, cpu: 5.99ms, accelerator: 595056258.79sec, total: 595056258.79sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 595056258.78sec, total: 595056258.78sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 595056258.78sec, total: 595056258.78sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 595056258.78sec, total: 595056258.78sec
  train.py:359:image_losses, cpu: 2.73ms, accelerator: 1.41ms, total: 4.15ms
    train.py:322:loss_fn, cpu: 2.71ms, accelerator: 1.41ms, total: 4.14ms
      train.py:342:hfe, cpu: 2.03ms, accelerator: 162us, total: 2.19ms
      train.py:343:hfe, cpu: 366us, accelerator: 744us, total: 1.11ms
  train.py:358:image_losses, cpu: 144us, accelerator: 2.39ms, total: 2.53ms
    train.py:322:loss_fn, cpu: 131us, accelerator: 2.39ms, total: 2.52ms
train.py:511:<module>, cpu: 8.31sec, accelerator: 4.37ms, total: 8.31sec
  __init__.py:194:compute_gradients, cpu: 8.30sec, accelerator: 861us, total: 8.31sec
    __init__.py:83:allreduce, cpu: 8.29sec, accelerator: 0us, total: 8.29sec
    __init__.py:86:allreduce, cpu: 9.69ms, accelerator: 861us, total: 10.57ms
  __init__.py:185:compute_gradients, cpu: 2.70ms, accelerator: 3.51ms, total: 6.26ms
train.py:448:<module>, cpu: 136.93ms, accelerator: 0us, total: 136.93ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2135.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_7750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 547us, accelerator: 576460750.69sec, total: 576460750.69sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec (0.00%)
top 3 operation type: ImageSummary, cpu: 351.70ms, accelerator: 0us, total: 351.70ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.37ms, accelerator: 0us, total: 137.37ms
train.py:442:<module>, cpu: 5.91ms, accelerator: 576460750.70sec, total: 576460750.70sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 576460750.69sec, total: 576460750.70sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 576460750.69sec, total: 576460750.70sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 576460750.69sec, total: 576460750.70sec
  train.py:359:image_losses, cpu: 2.66ms, accelerator: 1.37ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.65ms, accelerator: 1.37ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.97ms, accelerator: 157us, total: 2.13ms
      train.py:343:hfe, cpu: 358us, accelerator: 724us, total: 1.09ms
  train.py:358:image_losses, cpu: 143us, accelerator: 2.31ms, total: 2.46ms
    train.py:322:loss_fn, cpu: 130us, accelerator: 2.31ms, total: 2.44ms
train.py:511:<module>, cpu: 8.29sec, accelerator: 4.25ms, total: 8.30sec
  __init__.py:194:compute_gradients, cpu: 8.29sec, accelerator: 839us, total: 8.29sec
    __init__.py:83:allreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec
    __init__.py:86:allreduce, cpu: 9.76ms, accelerator: 839us, total: 10.62ms
  __init__.py:185:compute_gradients, cpu: 2.69ms, accelerator: 3.42ms, total: 6.15ms
train.py:448:<module>, cpu: 137.37ms, accelerator: 0us, total: 137.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_8000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 541us, accelerator: 558992243.09sec, total: 558992243.09sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.25sec, accelerator: 0us, total: 8.25sec (0.00%)
top 3 operation type: ImageSummary, cpu: 349.96ms, accelerator: 0us, total: 349.96ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.81ms, accelerator: 0us, total: 137.81ms
train.py:442:<module>, cpu: 6.02ms, accelerator: 558992243.10sec, total: 558992243.11sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 558992243.10sec, total: 558992243.10sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 558992243.10sec, total: 558992243.10sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 558992243.10sec, total: 558992243.10sec
  train.py:359:image_losses, cpu: 2.78ms, accelerator: 1.34ms, total: 4.12ms
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 1.34ms, total: 4.11ms
      train.py:342:hfe, cpu: 2.10ms, accelerator: 153us, total: 2.26ms
      train.py:343:hfe, cpu: 353us, accelerator: 706us, total: 1.06ms
  train.py:358:image_losses, cpu: 140us, accelerator: 2.25ms, total: 2.39ms
    train.py:322:loss_fn, cpu: 127us, accelerator: 2.25ms, total: 2.37ms
train.py:511:<module>, cpu: 8.26sec, accelerator: 4.15ms, total: 8.27sec
  __init__.py:194:compute_gradients, cpu: 8.26sec, accelerator: 822us, total: 8.26sec
    __init__.py:83:allreduce, cpu: 8.25sec, accelerator: 0us, total: 8.25sec
    __init__.py:86:allreduce, cpu: 9.53ms, accelerator: 822us, total: 10.38ms
  __init__.py:185:compute_gradients, cpu: 2.67ms, accelerator: 3.33ms, total: 6.05ms
train.py:448:<module>, cpu: 137.82ms, accelerator: 0us, total: 137.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_8250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 533us, accelerator: 542551294.77sec, total: 542551294.77sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.23sec, accelerator: 0us, total: 8.23sec (0.00%)
top 3 operation type: ImageSummary, cpu: 350.54ms, accelerator: 0us, total: 350.54ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.05ms, accelerator: 0us, total: 137.05ms
train.py:442:<module>, cpu: 5.93ms, accelerator: 542551294.78sec, total: 542551294.78sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 542551294.77sec, total: 542551294.77sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 542551294.77sec, total: 542551294.77sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 542551294.77sec, total: 542551294.77sec
  train.py:359:image_losses, cpu: 2.72ms, accelerator: 1.30ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.71ms, accelerator: 1.30ms, total: 4.02ms
      train.py:342:hfe, cpu: 2.06ms, accelerator: 150us, total: 2.21ms
      train.py:343:hfe, cpu: 346us, accelerator: 687us, total: 1.04ms
  train.py:358:image_losses, cpu: 138us, accelerator: 2.18ms, total: 2.32ms
    train.py:322:loss_fn, cpu: 125us, accelerator: 2.18ms, total: 2.31ms
train.py:511:<module>, cpu: 8.24sec, accelerator: 4.06ms, total: 8.25sec
  __init__.py:194:compute_gradients, cpu: 8.24sec, accelerator: 808us, total: 8.24sec
    __init__.py:83:allreduce, cpu: 8.23sec, accelerator: 0us, total: 8.23sec
    __init__.py:86:allreduce, cpu: 9.30ms, accelerator: 808us, total: 10.13ms
  __init__.py:185:compute_gradients, cpu: 2.67ms, accelerator: 3.25ms, total: 5.96ms
train.py:448:<module>, cpu: 137.05ms, accelerator: 0us, total: 137.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2124.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_8500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 540us, accelerator: 527049829.20sec, total: 527049829.20sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec (0.00%)
top 3 operation type: ImageSummary, cpu: 350.71ms, accelerator: 0us, total: 350.71ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.76ms, accelerator: 0us, total: 137.76ms
train.py:442:<module>, cpu: 5.96ms, accelerator: 527049829.21sec, total: 527049829.22sec
  train.py:360:image_losses, cpu: 2.93ms, accelerator: 527049829.21sec, total: 527049829.21sec
    train.py:322:loss_fn, cpu: 2.92ms, accelerator: 527049829.21sec, total: 527049829.21sec
      train.py:349:msssim, cpu: 2.87ms, accelerator: 527049829.21sec, total: 527049829.21sec
  train.py:359:image_losses, cpu: 2.67ms, accelerator: 1.57ms, total: 4.25ms
    train.py:322:loss_fn, cpu: 2.65ms, accelerator: 1.57ms, total: 4.23ms
      train.py:342:hfe, cpu: 2.00ms, accelerator: 146us, total: 2.15ms
      train.py:343:hfe, cpu: 345us, accelerator: 868us, total: 1.22ms
  train.py:358:image_losses, cpu: 137us, accelerator: 2.13ms, total: 2.27ms
    train.py:322:loss_fn, cpu: 124us, accelerator: 2.13ms, total: 2.25ms
train.py:511:<module>, cpu: 8.22sec, accelerator: 4.01ms, total: 8.22sec
  __init__.py:194:compute_gradients, cpu: 8.21sec, accelerator: 795us, total: 8.22sec
    __init__.py:83:allreduce, cpu: 8.21sec, accelerator: 0us, total: 8.21sec
    __init__.py:86:allreduce, cpu: 9.26ms, accelerator: 795us, total: 10.08ms
  __init__.py:185:compute_gradients, cpu: 2.64ms, accelerator: 3.22ms, total: 5.91ms
train.py:448:<module>, cpu: 137.77ms, accelerator: 0us, total: 137.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2133.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_8750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 533us, accelerator: 512409556.17sec, total: 512409556.17sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec (0.00%)
top 3 operation type: ImageSummary, cpu: 351.21ms, accelerator: 0us, total: 351.21ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.50ms, accelerator: 0us, total: 138.50ms
train.py:442:<module>, cpu: 5.95ms, accelerator: 512409556.18sec, total: 512409556.18sec
  train.py:360:image_losses, cpu: 2.91ms, accelerator: 512409556.17sec, total: 512409556.18sec
    train.py:322:loss_fn, cpu: 2.90ms, accelerator: 512409556.17sec, total: 512409556.18sec
      train.py:349:msssim, cpu: 2.85ms, accelerator: 512409556.17sec, total: 512409556.18sec
  train.py:359:image_losses, cpu: 2.68ms, accelerator: 1.53ms, total: 4.22ms
    train.py:322:loss_fn, cpu: 2.66ms, accelerator: 1.53ms, total: 4.20ms
      train.py:342:hfe, cpu: 2.00ms, accelerator: 146us, total: 2.15ms
      train.py:343:hfe, cpu: 348us, accelerator: 846us, total: 1.20ms
  train.py:358:image_losses, cpu: 141us, accelerator: 2.07ms, total: 2.21ms
    train.py:322:loss_fn, cpu: 128us, accelerator: 2.07ms, total: 2.20ms
train.py:511:<module>, cpu: 8.23sec, accelerator: 3.93ms, total: 8.23sec
  __init__.py:194:compute_gradients, cpu: 8.22sec, accelerator: 781us, total: 8.23sec
    __init__.py:83:allreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec
    __init__.py:86:allreduce, cpu: 9.07ms, accelerator: 781us, total: 9.87ms
  __init__.py:185:compute_gradients, cpu: 2.65ms, accelerator: 3.15ms, total: 5.83ms
train.py:448:<module>, cpu: 138.51ms, accelerator: 0us, total: 138.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_9000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 530us, accelerator: 498560649.24sec, total: 498560649.24sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.29sec, accelerator: 0us, total: 8.29sec (0.00%)
top 3 operation type: ImageSummary, cpu: 352.28ms, accelerator: 0us, total: 352.28ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.88ms, accelerator: 0us, total: 138.88ms
train.py:442:<module>, cpu: 6.01ms, accelerator: 498560649.25sec, total: 498560649.26sec
  train.py:360:image_losses, cpu: 2.90ms, accelerator: 498560649.25sec, total: 498560649.25sec
    train.py:322:loss_fn, cpu: 2.89ms, accelerator: 498560649.25sec, total: 498560649.25sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 498560649.25sec, total: 498560649.25sec
  train.py:359:image_losses, cpu: 2.76ms, accelerator: 1.50ms, total: 4.26ms
    train.py:322:loss_fn, cpu: 2.74ms, accelerator: 1.50ms, total: 4.24ms
      train.py:342:hfe, cpu: 2.06ms, accelerator: 143us, total: 2.21ms
      train.py:343:hfe, cpu: 367us, accelerator: 827us, total: 1.20ms
  train.py:358:image_losses, cpu: 138us, accelerator: 2.02ms, total: 2.15ms
    train.py:322:loss_fn, cpu: 125us, accelerator: 2.02ms, total: 2.14ms
train.py:511:<module>, cpu: 8.30sec, accelerator: 3.84ms, total: 8.30sec
  __init__.py:194:compute_gradients, cpu: 8.30sec, accelerator: 770us, total: 8.30sec
    __init__.py:83:allreduce, cpu: 8.29sec, accelerator: 0us, total: 8.29sec
    __init__.py:86:allreduce, cpu: 8.87ms, accelerator: 770us, total: 9.66ms
  __init__.py:185:compute_gradients, cpu: 2.64ms, accelerator: 3.07ms, total: 5.76ms
train.py:448:<module>, cpu: 138.88ms, accelerator: 0us, total: 138.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_9250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 521us, accelerator: 485440632.16sec, total: 485440632.16sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.27sec, accelerator: 0us, total: 8.27sec (0.00%)
top 3 operation type: ImageSummary, cpu: 353.94ms, accelerator: 0us, total: 353.94ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.21ms, accelerator: 0us, total: 140.21ms
train.py:442:<module>, cpu: 5.93ms, accelerator: 485440632.17sec, total: 485440632.18sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 485440632.17sec, total: 485440632.17sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 485440632.17sec, total: 485440632.17sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 485440632.17sec, total: 485440632.17sec
  train.py:359:image_losses, cpu: 2.70ms, accelerator: 1.72ms, total: 4.43ms
    train.py:322:loss_fn, cpu: 2.68ms, accelerator: 1.72ms, total: 4.41ms
      train.py:342:hfe, cpu: 2.02ms, accelerator: 282us, total: 2.30ms
      train.py:343:hfe, cpu: 361us, accelerator: 871us, total: 1.24ms
  train.py:358:image_losses, cpu: 139us, accelerator: 1.98ms, total: 2.12ms
    train.py:322:loss_fn, cpu: 126us, accelerator: 1.98ms, total: 2.10ms
train.py:511:<module>, cpu: 8.28sec, accelerator: 3.78ms, total: 8.29sec
  __init__.py:194:compute_gradients, cpu: 8.28sec, accelerator: 756us, total: 8.28sec
    __init__.py:83:allreduce, cpu: 8.27sec, accelerator: 0us, total: 8.27sec
    __init__.py:86:allreduce, cpu: 8.81ms, accelerator: 756us, total: 9.60ms
  __init__.py:185:compute_gradients, cpu: 2.62ms, accelerator: 3.02ms, total: 5.70ms
train.py:448:<module>, cpu: 140.21ms, accelerator: 0us, total: 140.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_9500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 519us, accelerator: 472993436.46sec, total: 472993436.46sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.30sec, accelerator: 0us, total: 8.30sec (0.00%)
top 3 operation type: ImageSummary, cpu: 351.16ms, accelerator: 0us, total: 351.16ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.87ms, accelerator: 0us, total: 139.87ms
train.py:442:<module>, cpu: 5.86ms, accelerator: 472993436.47sec, total: 472993436.48sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 472993436.47sec, total: 472993436.47sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 472993436.47sec, total: 472993436.47sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 472993436.47sec, total: 472993436.47sec
  train.py:359:image_losses, cpu: 2.65ms, accelerator: 1.67ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.63ms, accelerator: 1.67ms, total: 4.32ms
      train.py:342:hfe, cpu: 1.97ms, accelerator: 276us, total: 2.25ms
      train.py:343:hfe, cpu: 355us, accelerator: 848us, total: 1.21ms
  train.py:358:image_losses, cpu: 137us, accelerator: 1.93ms, total: 2.07ms
    train.py:322:loss_fn, cpu: 124us, accelerator: 1.93ms, total: 2.05ms
train.py:511:<module>, cpu: 8.31sec, accelerator: 3.70ms, total: 8.31sec
  __init__.py:194:compute_gradients, cpu: 8.31sec, accelerator: 741us, total: 8.31sec
    __init__.py:83:allreduce, cpu: 8.30sec, accelerator: 0us, total: 8.30sec
    __init__.py:86:allreduce, cpu: 8.64ms, accelerator: 741us, total: 9.41ms
  __init__.py:185:compute_gradients, cpu: 2.59ms, accelerator: 2.96ms, total: 5.60ms
train.py:448:<module>, cpu: 139.88ms, accelerator: 0us, total: 139.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_9750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 515us, accelerator: 461168600.55sec, total: 461168600.55sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec (0.00%)
top 3 operation type: ImageSummary, cpu: 350.03ms, accelerator: 0us, total: 350.03ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.79ms, accelerator: 0us, total: 139.79ms
train.py:442:<module>, cpu: 5.89ms, accelerator: 461168600.56sec, total: 461168600.57sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 461168600.56sec, total: 461168600.56sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 461168600.56sec, total: 461168600.56sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 461168600.56sec, total: 461168600.56sec
  train.py:359:image_losses, cpu: 2.67ms, accelerator: 1.64ms, total: 4.31ms
    train.py:322:loss_fn, cpu: 2.65ms, accelerator: 1.64ms, total: 4.30ms
      train.py:342:hfe, cpu: 1.98ms, accelerator: 269us, total: 2.25ms
      train.py:343:hfe, cpu: 367us, accelerator: 829us, total: 1.20ms
  train.py:358:image_losses, cpu: 141us, accelerator: 1.88ms, total: 2.02ms
    train.py:322:loss_fn, cpu: 128us, accelerator: 1.88ms, total: 2.01ms
train.py:511:<module>, cpu: 8.30sec, accelerator: 3.64ms, total: 8.30sec
  __init__.py:194:compute_gradients, cpu: 8.29sec, accelerator: 734us, total: 8.29sec
    __init__.py:83:allreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec
    __init__.py:86:allreduce, cpu: 8.50ms, accelerator: 734us, total: 9.25ms
  __init__.py:185:compute_gradients, cpu: 2.69ms, accelerator: 2.90ms, total: 5.64ms
train.py:448:<module>, cpu: 139.80ms, accelerator: 0us, total: 139.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_10000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 513us, accelerator: 449920585.90sec, total: 449920585.90sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.29sec, accelerator: 0us, total: 8.29sec (0.00%)
top 3 operation type: ImageSummary, cpu: 349.05ms, accelerator: 0us, total: 349.05ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.53ms, accelerator: 0us, total: 139.53ms
train.py:442:<module>, cpu: 5.86ms, accelerator: 449920585.91sec, total: 449920585.92sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 449920585.91sec, total: 449920585.91sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 449920585.91sec, total: 449920585.91sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 449920585.91sec, total: 449920585.91sec
  train.py:359:image_losses, cpu: 2.62ms, accelerator: 1.60ms, total: 4.23ms
    train.py:322:loss_fn, cpu: 2.61ms, accelerator: 1.60ms, total: 4.22ms
      train.py:342:hfe, cpu: 1.94ms, accelerator: 264us, total: 2.20ms
      train.py:343:hfe, cpu: 363us, accelerator: 811us, total: 1.18ms
  train.py:358:image_losses, cpu: 140us, accelerator: 1.83ms, total: 1.98ms
    train.py:322:loss_fn, cpu: 127us, accelerator: 1.83ms, total: 1.96ms
train.py:511:<module>, cpu: 8.30sec, accelerator: 3.56ms, total: 8.31sec
  __init__.py:194:compute_gradients, cpu: 8.30sec, accelerator: 717us, total: 8.30sec
    __init__.py:83:allreduce, cpu: 8.29sec, accelerator: 0us, total: 8.29sec
    __init__.py:86:allreduce, cpu: 8.47ms, accelerator: 717us, total: 9.22ms
  __init__.py:185:compute_gradients, cpu: 2.67ms, accelerator: 2.84ms, total: 5.56ms
train.py:448:<module>, cpu: 139.54ms, accelerator: 0us, total: 139.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_10250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 508us, accelerator: 439208191.00sec, total: 439208191.00sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec (0.00%)
top 3 operation type: ImageSummary, cpu: 348.95ms, accelerator: 0us, total: 348.95ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.90ms, accelerator: 0us, total: 139.90ms
train.py:442:<module>, cpu: 5.83ms, accelerator: 439208191.01sec, total: 439208191.02sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 439208191.01sec, total: 439208191.01sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 439208191.01sec, total: 439208191.01sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 439208191.01sec, total: 439208191.01sec
  train.py:359:image_losses, cpu: 2.61ms, accelerator: 1.76ms, total: 4.39ms
    train.py:322:loss_fn, cpu: 2.59ms, accelerator: 1.76ms, total: 4.37ms
      train.py:342:hfe, cpu: 1.92ms, accelerator: 262us, total: 2.19ms
      train.py:343:hfe, cpu: 357us, accelerator: 937us, total: 1.30ms
  train.py:358:image_losses, cpu: 138us, accelerator: 1.80ms, total: 1.94ms
    train.py:322:loss_fn, cpu: 125us, accelerator: 1.80ms, total: 1.93ms
train.py:511:<module>, cpu: 8.29sec, accelerator: 3.50ms, total: 8.29sec
  __init__.py:194:compute_gradients, cpu: 8.28sec, accelerator: 709us, total: 8.29sec
    __init__.py:83:allreduce, cpu: 8.28sec, accelerator: 0us, total: 8.28sec
    __init__.py:86:allreduce, cpu: 8.33ms, accelerator: 709us, total: 9.07ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.79ms, total: 5.83ms
train.py:448:<module>, cpu: 139.91ms, accelerator: 0us, total: 139.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2117.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_10500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 503us, accelerator: 428994047.02sec, total: 428994047.02sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.25sec, accelerator: 0us, total: 8.25sec (0.00%)
top 3 operation type: ImageSummary, cpu: 347.20ms, accelerator: 0us, total: 347.20ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.39ms, accelerator: 0us, total: 139.39ms
train.py:442:<module>, cpu: 5.84ms, accelerator: 428994047.03sec, total: 428994047.04sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 428994047.03sec, total: 428994047.03sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 428994047.03sec, total: 428994047.03sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 428994047.03sec, total: 428994047.03sec
  train.py:359:image_losses, cpu: 2.63ms, accelerator: 1.73ms, total: 4.37ms
    train.py:322:loss_fn, cpu: 2.62ms, accelerator: 1.73ms, total: 4.36ms
      train.py:342:hfe, cpu: 1.89ms, accelerator: 257us, total: 2.15ms
      train.py:343:hfe, cpu: 419us, accelerator: 917us, total: 1.34ms
  train.py:358:image_losses, cpu: 137us, accelerator: 1.76ms, total: 1.90ms
    train.py:322:loss_fn, cpu: 124us, accelerator: 1.76ms, total: 1.88ms
train.py:511:<module>, cpu: 8.26sec, accelerator: 3.44ms, total: 8.27sec
  __init__.py:194:compute_gradients, cpu: 8.26sec, accelerator: 700us, total: 8.26sec
    __init__.py:83:allreduce, cpu: 8.25sec, accelerator: 0us, total: 8.25sec
    __init__.py:86:allreduce, cpu: 8.23ms, accelerator: 700us, total: 8.96ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.75ms, total: 5.75ms
train.py:448:<module>, cpu: 139.40ms, accelerator: 0us, total: 139.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2133.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_10750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 500us, accelerator: 419244182.32sec, total: 419244182.32sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.25sec, accelerator: 0us, total: 8.25sec (0.00%)
top 3 operation type: ImageSummary, cpu: 345.26ms, accelerator: 0us, total: 345.26ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.89ms, accelerator: 0us, total: 138.89ms
train.py:442:<module>, cpu: 5.81ms, accelerator: 419244182.33sec, total: 419244182.33sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 419244182.32sec, total: 419244182.33sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 419244182.32sec, total: 419244182.33sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 419244182.32sec, total: 419244182.33sec
  train.py:359:image_losses, cpu: 2.62ms, accelerator: 1.70ms, total: 4.33ms
    train.py:322:loss_fn, cpu: 2.60ms, accelerator: 1.70ms, total: 4.31ms
      train.py:342:hfe, cpu: 1.88ms, accelerator: 253us, total: 2.14ms
      train.py:343:hfe, cpu: 415us, accelerator: 900us, total: 1.32ms
  train.py:358:image_losses, cpu: 135us, accelerator: 1.72ms, total: 1.86ms
    train.py:322:loss_fn, cpu: 122us, accelerator: 1.72ms, total: 1.84ms
train.py:511:<module>, cpu: 8.26sec, accelerator: 3.38ms, total: 8.26sec
  __init__.py:194:compute_gradients, cpu: 8.26sec, accelerator: 693us, total: 8.26sec
    __init__.py:83:allreduce, cpu: 8.25sec, accelerator: 0us, total: 8.25sec
    __init__.py:86:allreduce, cpu: 8.08ms, accelerator: 693us, total: 8.80ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.69ms, total: 5.67ms
train.py:448:<module>, cpu: 138.89ms, accelerator: 0us, total: 138.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_11000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 498us, accelerator: 409927644.93sec, total: 409927644.93sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.23sec, accelerator: 0us, total: 8.23sec (0.00%)
top 3 operation type: ImageSummary, cpu: 343.99ms, accelerator: 0us, total: 343.99ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.72ms, accelerator: 0us, total: 138.72ms
train.py:442:<module>, cpu: 5.86ms, accelerator: 409927644.94sec, total: 409927644.95sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 409927644.94sec, total: 409927644.94sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 409927644.94sec, total: 409927644.94sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 409927644.94sec, total: 409927644.94sec
  train.py:359:image_losses, cpu: 2.67ms, accelerator: 1.83ms, total: 4.50ms
    train.py:322:loss_fn, cpu: 2.65ms, accelerator: 1.83ms, total: 4.48ms
      train.py:342:hfe, cpu: 1.94ms, accelerator: 294us, total: 2.23ms
      train.py:343:hfe, cpu: 411us, accelerator: 940us, total: 1.35ms
  train.py:358:image_losses, cpu: 134us, accelerator: 1.72ms, total: 1.85ms
    train.py:322:loss_fn, cpu: 121us, accelerator: 1.72ms, total: 1.84ms
train.py:511:<module>, cpu: 8.24sec, accelerator: 3.64ms, total: 8.25sec
  __init__.py:194:compute_gradients, cpu: 8.24sec, accelerator: 940us, total: 8.24sec
    __init__.py:83:allreduce, cpu: 8.23sec, accelerator: 0us, total: 8.23sec
    __init__.py:86:allreduce, cpu: 8.02ms, accelerator: 940us, total: 8.98ms
  __init__.py:185:compute_gradients, cpu: 3.12ms, accelerator: 2.70ms, total: 5.86ms
train.py:448:<module>, cpu: 138.72ms, accelerator: 0us, total: 138.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_11250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 494us, accelerator: 401016174.39sec, total: 401016174.39sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec (0.00%)
top 3 operation type: ImageSummary, cpu: 342.69ms, accelerator: 0us, total: 342.69ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.33ms, accelerator: 0us, total: 138.33ms
train.py:442:<module>, cpu: 5.79ms, accelerator: 401016174.40sec, total: 401016174.41sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 401016174.40sec, total: 401016174.40sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 401016174.40sec, total: 401016174.40sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 401016174.40sec, total: 401016174.40sec
  train.py:359:image_losses, cpu: 2.62ms, accelerator: 1.79ms, total: 4.42ms
    train.py:322:loss_fn, cpu: 2.60ms, accelerator: 1.79ms, total: 4.40ms
      train.py:342:hfe, cpu: 1.90ms, accelerator: 289us, total: 2.19ms
      train.py:343:hfe, cpu: 404us, accelerator: 921us, total: 1.33ms
  train.py:358:image_losses, cpu: 133us, accelerator: 1.68ms, total: 1.82ms
    train.py:322:loss_fn, cpu: 120us, accelerator: 1.68ms, total: 1.80ms
train.py:511:<module>, cpu: 8.23sec, accelerator: 3.60ms, total: 8.23sec
  __init__.py:194:compute_gradients, cpu: 8.22sec, accelerator: 931us, total: 8.23sec
    __init__.py:83:allreduce, cpu: 8.22sec, accelerator: 0us, total: 8.22sec
    __init__.py:86:allreduce, cpu: 7.97ms, accelerator: 931us, total: 8.93ms
  __init__.py:185:compute_gradients, cpu: 3.11ms, accelerator: 2.67ms, total: 5.82ms
train.py:448:<module>, cpu: 138.34ms, accelerator: 0us, total: 138.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_11500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 488us, accelerator: 392483915.36sec, total: 392483915.36sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.19sec, accelerator: 0us, total: 8.19sec (0.00%)
top 3 operation type: ImageSummary, cpu: 341.42ms, accelerator: 0us, total: 341.42ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.87ms, accelerator: 0us, total: 138.87ms
train.py:442:<module>, cpu: 5.73ms, accelerator: 392483915.37sec, total: 392483915.38sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 392483915.37sec, total: 392483915.37sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 392483915.37sec, total: 392483915.37sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 392483915.37sec, total: 392483915.37sec
  train.py:359:image_losses, cpu: 2.57ms, accelerator: 1.76ms, total: 4.34ms
    train.py:322:loss_fn, cpu: 2.56ms, accelerator: 1.76ms, total: 4.33ms
      train.py:342:hfe, cpu: 1.86ms, accelerator: 286us, total: 2.15ms
      train.py:343:hfe, cpu: 399us, accelerator: 903us, total: 1.31ms
  train.py:358:image_losses, cpu: 132us, accelerator: 1.65ms, total: 1.78ms
    train.py:322:loss_fn, cpu: 119us, accelerator: 1.65ms, total: 1.77ms
train.py:511:<module>, cpu: 8.20sec, accelerator: 3.54ms, total: 8.20sec
  __init__.py:194:compute_gradients, cpu: 8.20sec, accelerator: 918us, total: 8.20sec
    __init__.py:83:allreduce, cpu: 8.19sec, accelerator: 0us, total: 8.19sec
    __init__.py:86:allreduce, cpu: 7.86ms, accelerator: 918us, total: 8.79ms
  __init__.py:185:compute_gradients, cpu: 3.10ms, accelerator: 2.63ms, total: 5.76ms
train.py:448:<module>, cpu: 138.87ms, accelerator: 0us, total: 138.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_11750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 485us, accelerator: 384307167.13sec, total: 384307167.13sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec (0.00%)
top 3 operation type: ImageSummary, cpu: 341.62ms, accelerator: 0us, total: 341.62ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.91ms, accelerator: 0us, total: 138.91ms
train.py:442:<module>, cpu: 5.70ms, accelerator: 384307167.14sec, total: 384307167.14sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 384307167.13sec, total: 384307167.13sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 384307167.13sec, total: 384307167.13sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 384307167.13sec, total: 384307167.13sec
  train.py:359:image_losses, cpu: 2.56ms, accelerator: 1.73ms, total: 4.29ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.73ms, total: 4.28ms
      train.py:342:hfe, cpu: 1.85ms, accelerator: 280us, total: 2.14ms
      train.py:343:hfe, cpu: 395us, accelerator: 886us, total: 1.28ms
  train.py:358:image_losses, cpu: 131us, accelerator: 1.61ms, total: 1.75ms
    train.py:322:loss_fn, cpu: 118us, accelerator: 1.61ms, total: 1.73ms
train.py:511:<module>, cpu: 8.16sec, accelerator: 3.52ms, total: 8.17sec
  __init__.py:194:compute_gradients, cpu: 8.16sec, accelerator: 903us, total: 8.16sec
    __init__.py:83:allreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec
    __init__.py:86:allreduce, cpu: 8.64ms, accelerator: 903us, total: 9.56ms
  __init__.py:185:compute_gradients, cpu: 3.07ms, accelerator: 2.62ms, total: 5.72ms
train.py:448:<module>, cpu: 138.92ms, accelerator: 0us, total: 138.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_12000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 483us, accelerator: 376464163.72sec, total: 376464163.72sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.17sec, accelerator: 0us, total: 8.17sec (0.00%)
top 3 operation type: ImageSummary, cpu: 341.26ms, accelerator: 0us, total: 341.26ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.23ms, accelerator: 0us, total: 139.23ms
train.py:442:<module>, cpu: 5.67ms, accelerator: 376464163.72sec, total: 376464163.73sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 376464163.72sec, total: 376464163.72sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 376464163.72sec, total: 376464163.72sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 376464163.72sec, total: 376464163.72sec
  train.py:359:image_losses, cpu: 2.52ms, accelerator: 1.70ms, total: 4.23ms
    train.py:322:loss_fn, cpu: 2.51ms, accelerator: 1.70ms, total: 4.22ms
      train.py:342:hfe, cpu: 1.83ms, accelerator: 277us, total: 2.11ms
      train.py:343:hfe, cpu: 390us, accelerator: 869us, total: 1.26ms
  train.py:358:image_losses, cpu: 130us, accelerator: 1.58ms, total: 1.71ms
    train.py:322:loss_fn, cpu: 117us, accelerator: 1.58ms, total: 1.70ms
train.py:511:<module>, cpu: 8.18sec, accelerator: 3.47ms, total: 8.18sec
  __init__.py:194:compute_gradients, cpu: 8.18sec, accelerator: 893us, total: 8.18sec
    __init__.py:83:allreduce, cpu: 8.17sec, accelerator: 0us, total: 8.17sec
    __init__.py:86:allreduce, cpu: 8.50ms, accelerator: 893us, total: 9.41ms
  __init__.py:185:compute_gradients, cpu: 3.04ms, accelerator: 2.57ms, total: 5.65ms
train.py:448:<module>, cpu: 139.24ms, accelerator: 0us, total: 139.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_12250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 478us, accelerator: 368934880.44sec, total: 368934880.44sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec (0.00%)
top 3 operation type: ImageSummary, cpu: 341.24ms, accelerator: 0us, total: 341.24ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.76ms, accelerator: 0us, total: 139.76ms
train.py:442:<module>, cpu: 5.62ms, accelerator: 368934880.45sec, total: 368934880.46sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 368934880.45sec, total: 368934880.45sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 368934880.45sec, total: 368934880.45sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 368934880.45sec, total: 368934880.45sec
  train.py:359:image_losses, cpu: 2.49ms, accelerator: 1.66ms, total: 4.16ms
    train.py:322:loss_fn, cpu: 2.47ms, accelerator: 1.66ms, total: 4.14ms
      train.py:342:hfe, cpu: 1.80ms, accelerator: 272us, total: 2.08ms
      train.py:343:hfe, cpu: 385us, accelerator: 852us, total: 1.24ms
  train.py:358:image_losses, cpu: 129us, accelerator: 1.55ms, total: 1.68ms
    train.py:322:loss_fn, cpu: 116us, accelerator: 1.55ms, total: 1.67ms
train.py:511:<module>, cpu: 8.16sec, accelerator: 3.41ms, total: 8.17sec
  __init__.py:194:compute_gradients, cpu: 8.16sec, accelerator: 878us, total: 8.16sec
    __init__.py:83:allreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec
    __init__.py:86:allreduce, cpu: 8.35ms, accelerator: 878us, total: 9.26ms
  __init__.py:185:compute_gradients, cpu: 3.02ms, accelerator: 2.53ms, total: 5.58ms
train.py:448:<module>, cpu: 139.76ms, accelerator: 0us, total: 139.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_12500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 477us, accelerator: 361700863.18sec, total: 361700863.18sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.16sec, accelerator: 0us, total: 8.16sec (0.00%)
top 3 operation type: ImageSummary, cpu: 340.92ms, accelerator: 0us, total: 340.92ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.94ms, accelerator: 0us, total: 139.94ms
train.py:442:<module>, cpu: 5.58ms, accelerator: 361700863.19sec, total: 361700863.19sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 361700863.18sec, total: 361700863.19sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 361700863.18sec, total: 361700863.19sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 361700863.18sec, total: 361700863.19sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.63ms, total: 4.10ms
    train.py:322:loss_fn, cpu: 2.43ms, accelerator: 1.63ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.77ms, accelerator: 268us, total: 2.04ms
      train.py:343:hfe, cpu: 380us, accelerator: 836us, total: 1.22ms
  train.py:358:image_losses, cpu: 130us, accelerator: 1.52ms, total: 1.65ms
    train.py:322:loss_fn, cpu: 117us, accelerator: 1.52ms, total: 1.64ms
train.py:511:<module>, cpu: 8.17sec, accelerator: 3.36ms, total: 8.17sec
  __init__.py:194:compute_gradients, cpu: 8.17sec, accelerator: 871us, total: 8.17sec
    __init__.py:83:allreduce, cpu: 8.16sec, accelerator: 0us, total: 8.16sec
    __init__.py:86:allreduce, cpu: 8.25ms, accelerator: 871us, total: 9.14ms
  __init__.py:185:compute_gradients, cpu: 3.00ms, accelerator: 2.49ms, total: 5.54ms
train.py:448:<module>, cpu: 139.95ms, accelerator: 0us, total: 139.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_12750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 474us, accelerator: 354745077.35sec, total: 354745077.35sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.17sec, accelerator: 0us, total: 8.17sec (0.00%)
top 3 operation type: ImageSummary, cpu: 339.89ms, accelerator: 0us, total: 339.89ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.40ms, accelerator: 0us, total: 140.40ms
train.py:442:<module>, cpu: 5.55ms, accelerator: 354745077.36sec, total: 354745077.36sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 354745077.35sec, total: 354745077.36sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 354745077.35sec, total: 354745077.36sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 354745077.35sec, total: 354745077.36sec
  train.py:359:image_losses, cpu: 2.43ms, accelerator: 1.61ms, total: 4.05ms
    train.py:322:loss_fn, cpu: 2.42ms, accelerator: 1.61ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.76ms, accelerator: 265us, total: 2.03ms
      train.py:343:hfe, cpu: 379us, accelerator: 822us, total: 1.20ms
  train.py:358:image_losses, cpu: 128us, accelerator: 1.49ms, total: 1.62ms
    train.py:322:loss_fn, cpu: 115us, accelerator: 1.49ms, total: 1.61ms
train.py:511:<module>, cpu: 8.18sec, accelerator: 3.31ms, total: 8.19sec
  __init__.py:194:compute_gradients, cpu: 8.18sec, accelerator: 855us, total: 8.18sec
    __init__.py:83:allreduce, cpu: 8.17sec, accelerator: 0us, total: 8.17sec
    __init__.py:86:allreduce, cpu: 8.13ms, accelerator: 855us, total: 9.02ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.45ms, total: 5.49ms
train.py:448:<module>, cpu: 140.40ms, accelerator: 0us, total: 140.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_13000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 472us, accelerator: 348051774.00sec, total: 348051774.00sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.19sec, accelerator: 0us, total: 8.19sec (0.00%)
top 3 operation type: ImageSummary, cpu: 338.43ms, accelerator: 0us, total: 338.43ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.64ms, accelerator: 0us, total: 140.64ms
train.py:442:<module>, cpu: 5.57ms, accelerator: 348051774.01sec, total: 348051774.02sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 348051774.01sec, total: 348051774.01sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 348051774.01sec, total: 348051774.01sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 348051774.01sec, total: 348051774.01sec
  train.py:359:image_losses, cpu: 2.40ms, accelerator: 1.58ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.38ms, accelerator: 1.58ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.73ms, accelerator: 261us, total: 1.99ms
      train.py:343:hfe, cpu: 374us, accelerator: 806us, total: 1.18ms
  train.py:358:image_losses, cpu: 128us, accelerator: 1.46ms, total: 1.59ms
    train.py:322:loss_fn, cpu: 115us, accelerator: 1.46ms, total: 1.58ms
train.py:511:<module>, cpu: 8.20sec, accelerator: 3.41ms, total: 8.20sec
  __init__.py:194:compute_gradients, cpu: 8.20sec, accelerator: 847us, total: 8.20sec
    __init__.py:83:allreduce, cpu: 8.19sec, accelerator: 0us, total: 8.19sec
    __init__.py:86:allreduce, cpu: 8.10ms, accelerator: 847us, total: 8.97ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.56ms, total: 5.57ms
train.py:448:<module>, cpu: 140.65ms, accelerator: 0us, total: 140.65ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_13250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 471us, accelerator: 341606370.78sec, total: 341606370.78sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.18sec, accelerator: 0us, total: 8.18sec (0.00%)
top 3 operation type: ImageSummary, cpu: 337.63ms, accelerator: 0us, total: 337.63ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.45ms, accelerator: 0us, total: 140.45ms
train.py:442:<module>, cpu: 5.54ms, accelerator: 341606370.79sec, total: 341606370.79sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 341606370.79sec, total: 341606370.79sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 341606370.79sec, total: 341606370.79sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 341606370.79sec, total: 341606370.79sec
  train.py:359:image_losses, cpu: 2.38ms, accelerator: 1.55ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.36ms, accelerator: 1.55ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.71ms, accelerator: 258us, total: 1.97ms
      train.py:343:hfe, cpu: 373us, accelerator: 794us, total: 1.17ms
  train.py:358:image_losses, cpu: 128us, accelerator: 1.44ms, total: 1.56ms
    train.py:322:loss_fn, cpu: 115us, accelerator: 1.44ms, total: 1.55ms
train.py:511:<module>, cpu: 8.19sec, accelerator: 3.36ms, total: 8.20sec
  __init__.py:194:compute_gradients, cpu: 8.19sec, accelerator: 837us, total: 8.19sec
    __init__.py:83:allreduce, cpu: 8.18sec, accelerator: 0us, total: 8.18sec
    __init__.py:86:allreduce, cpu: 7.99ms, accelerator: 837us, total: 8.85ms
  __init__.py:185:compute_gradients, cpu: 3.03ms, accelerator: 2.53ms, total: 5.60ms
train.py:448:<module>, cpu: 140.46ms, accelerator: 0us, total: 140.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_13500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 469us, accelerator: 335395345.86sec, total: 335395345.86sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.18sec, accelerator: 0us, total: 8.18sec (0.00%)
top 3 operation type: ImageSummary, cpu: 339.28ms, accelerator: 0us, total: 339.28ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.51ms, accelerator: 0us, total: 141.51ms
train.py:442:<module>, cpu: 5.50ms, accelerator: 335395345.87sec, total: 335395345.87sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 335395345.86sec, total: 335395345.86sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 335395345.86sec, total: 335395345.86sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 335395345.86sec, total: 335395345.86sec
  train.py:359:image_losses, cpu: 2.34ms, accelerator: 1.53ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.33ms, accelerator: 1.53ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.68ms, accelerator: 255us, total: 1.94ms
      train.py:343:hfe, cpu: 370us, accelerator: 779us, total: 1.15ms
  train.py:358:image_losses, cpu: 126us, accelerator: 1.41ms, total: 1.54ms
    train.py:322:loss_fn, cpu: 113us, accelerator: 1.41ms, total: 1.52ms
train.py:511:<module>, cpu: 8.19sec, accelerator: 3.32ms, total: 8.19sec
  __init__.py:194:compute_gradients, cpu: 8.18sec, accelerator: 828us, total: 8.19sec
    __init__.py:83:allreduce, cpu: 8.18sec, accelerator: 0us, total: 8.18sec
    __init__.py:86:allreduce, cpu: 7.94ms, accelerator: 828us, total: 8.79ms
  __init__.py:185:compute_gradients, cpu: 3.20ms, accelerator: 2.49ms, total: 5.73ms
train.py:448:<module>, cpu: 141.51ms, accelerator: 0us, total: 141.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_13750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 464us, accelerator: 329406143.25sec, total: 329406143.25sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec (0.00%)
top 3 operation type: ImageSummary, cpu: 338.96ms, accelerator: 0us, total: 338.96ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.99ms, accelerator: 0us, total: 141.99ms
train.py:442:<module>, cpu: 5.45ms, accelerator: 329406143.26sec, total: 329406143.27sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 329406143.26sec, total: 329406143.26sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 329406143.26sec, total: 329406143.26sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 329406143.26sec, total: 329406143.26sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.50ms, total: 3.82ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.50ms, total: 3.81ms
      train.py:342:hfe, cpu: 1.66ms, accelerator: 250us, total: 1.91ms
      train.py:343:hfe, cpu: 364us, accelerator: 765us, total: 1.13ms
  train.py:358:image_losses, cpu: 125us, accelerator: 1.39ms, total: 1.51ms
    train.py:322:loss_fn, cpu: 112us, accelerator: 1.39ms, total: 1.50ms
train.py:511:<module>, cpu: 8.16sec, accelerator: 3.27ms, total: 8.17sec
  __init__.py:194:compute_gradients, cpu: 8.16sec, accelerator: 819us, total: 8.16sec
    __init__.py:83:allreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec
    __init__.py:86:allreduce, cpu: 7.84ms, accelerator: 819us, total: 8.68ms
  __init__.py:185:compute_gradients, cpu: 3.26ms, accelerator: 2.46ms, total: 5.76ms
train.py:448:<module>, cpu: 141.99ms, accelerator: 0us, total: 141.99ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_14000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 464us, accelerator: 323627088.11sec, total: 323627088.11sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec (0.00%)
top 3 operation type: ImageSummary, cpu: 339.07ms, accelerator: 0us, total: 339.07ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.87ms, accelerator: 0us, total: 141.87ms
train.py:442:<module>, cpu: 5.43ms, accelerator: 323627088.12sec, total: 323627088.12sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 323627088.11sec, total: 323627088.12sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 323627088.11sec, total: 323627088.12sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 323627088.11sec, total: 323627088.12sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.48ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.48ms, total: 3.76ms
      train.py:342:hfe, cpu: 1.63ms, accelerator: 246us, total: 1.89ms
      train.py:343:hfe, cpu: 363us, accelerator: 754us, total: 1.12ms
  train.py:358:image_losses, cpu: 127us, accelerator: 1.36ms, total: 1.49ms
    train.py:322:loss_fn, cpu: 114us, accelerator: 1.36ms, total: 1.48ms
train.py:511:<module>, cpu: 8.14sec, accelerator: 3.23ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.14sec, accelerator: 810us, total: 8.14sec
    __init__.py:83:allreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec
    __init__.py:86:allreduce, cpu: 7.72ms, accelerator: 810us, total: 8.55ms
  __init__.py:185:compute_gradients, cpu: 3.24ms, accelerator: 2.42ms, total: 5.70ms
train.py:448:<module>, cpu: 141.88ms, accelerator: 0us, total: 141.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_14250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 462us, accelerator: 318047310.72sec, total: 318047310.73sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec (0.00%)
top 3 operation type: ImageSummary, cpu: 339.21ms, accelerator: 0us, total: 339.21ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.23ms, accelerator: 0us, total: 142.23ms
train.py:442:<module>, cpu: 5.44ms, accelerator: 318047310.73sec, total: 318047310.74sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 318047310.73sec, total: 318047310.73sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 318047310.73sec, total: 318047310.73sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 318047310.73sec, total: 318047310.73sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.57ms, total: 3.89ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.57ms, total: 3.87ms
      train.py:342:hfe, cpu: 1.67ms, accelerator: 243us, total: 1.91ms
      train.py:343:hfe, cpu: 361us, accelerator: 820us, total: 1.18ms
  train.py:358:image_losses, cpu: 127us, accelerator: 1.38ms, total: 1.50ms
    train.py:322:loss_fn, cpu: 114us, accelerator: 1.38ms, total: 1.49ms
train.py:511:<module>, cpu: 8.15sec, accelerator: 3.19ms, total: 8.15sec
  __init__.py:194:compute_gradients, cpu: 8.15sec, accelerator: 800us, total: 8.15sec
    __init__.py:83:allreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec
    __init__.py:86:allreduce, cpu: 7.61ms, accelerator: 800us, total: 8.44ms
  __init__.py:185:compute_gradients, cpu: 3.23ms, accelerator: 2.39ms, total: 5.66ms
train.py:448:<module>, cpu: 142.23ms, accelerator: 0us, total: 142.23ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_14500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 460us, accelerator: 312656678.34sec, total: 312656678.34sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 3 operation type: ImageSummary, cpu: 338.93ms, accelerator: 0us, total: 338.93ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.84ms, accelerator: 0us, total: 142.84ms
train.py:442:<module>, cpu: 5.45ms, accelerator: 312656678.35sec, total: 312656678.35sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 312656678.35sec, total: 312656678.35sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 312656678.35sec, total: 312656678.35sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 312656678.35sec, total: 312656678.35sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.54ms, total: 3.86ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.54ms, total: 3.84ms
      train.py:342:hfe, cpu: 1.66ms, accelerator: 240us, total: 1.91ms
      train.py:343:hfe, cpu: 360us, accelerator: 807us, total: 1.17ms
  train.py:358:image_losses, cpu: 129us, accelerator: 1.35ms, total: 1.48ms
    train.py:322:loss_fn, cpu: 116us, accelerator: 1.35ms, total: 1.47ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.15ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 792us, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 7.66ms, accelerator: 792us, total: 8.48ms
  __init__.py:185:compute_gradients, cpu: 3.21ms, accelerator: 2.36ms, total: 5.61ms
train.py:448:<module>, cpu: 142.84ms, accelerator: 0us, total: 142.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_14750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 460us, accelerator: 307445733.70sec, total: 307445733.70sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 337.81ms, accelerator: 0us, total: 337.81ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.47ms, accelerator: 0us, total: 142.47ms
train.py:442:<module>, cpu: 5.41ms, accelerator: 307445733.71sec, total: 307445733.72sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 307445733.71sec, total: 307445733.71sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 307445733.71sec, total: 307445733.71sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 307445733.71sec, total: 307445733.71sec
  train.py:359:image_losses, cpu: 2.28ms, accelerator: 1.69ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.69ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.64ms, accelerator: 322us, total: 1.97ms
      train.py:343:hfe, cpu: 359us, accelerator: 829us, total: 1.19ms
  train.py:358:image_losses, cpu: 128us, accelerator: 1.33ms, total: 1.47ms
    train.py:322:loss_fn, cpu: 115us, accelerator: 1.33ms, total: 1.45ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.32ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 784us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 7.68ms, accelerator: 784us, total: 8.48ms
  __init__.py:185:compute_gradients, cpu: 3.20ms, accelerator: 2.54ms, total: 5.77ms
train.py:448:<module>, cpu: 142.47ms, accelerator: 0us, total: 142.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_15000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 457us, accelerator: 302405639.71sec, total: 302405639.71sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 3 operation type: ImageSummary, cpu: 338.07ms, accelerator: 0us, total: 338.07ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.30ms, accelerator: 0us, total: 142.30ms
train.py:442:<module>, cpu: 5.39ms, accelerator: 302405639.72sec, total: 302405639.72sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 302405639.71sec, total: 302405639.71sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 302405639.71sec, total: 302405639.71sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 302405639.71sec, total: 302405639.71sec
  train.py:359:image_losses, cpu: 2.27ms, accelerator: 1.66ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.25ms, accelerator: 1.66ms, total: 3.93ms
      train.py:342:hfe, cpu: 1.63ms, accelerator: 318us, total: 1.95ms
      train.py:343:hfe, cpu: 357us, accelerator: 815us, total: 1.18ms
  train.py:358:image_losses, cpu: 128us, accelerator: 1.31ms, total: 1.44ms
    train.py:322:loss_fn, cpu: 115us, accelerator: 1.31ms, total: 1.43ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.28ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 777us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 7.75ms, accelerator: 777us, total: 8.55ms
  __init__.py:185:compute_gradients, cpu: 3.32ms, accelerator: 2.50ms, total: 5.86ms
train.py:448:<module>, cpu: 142.30ms, accelerator: 0us, total: 142.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_15250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 456us, accelerator: 297528129.39sec, total: 297528129.39sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 3 operation type: ImageSummary, cpu: 337.88ms, accelerator: 0us, total: 337.88ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.71ms, accelerator: 0us, total: 142.71ms
train.py:442:<module>, cpu: 5.45ms, accelerator: 297528129.40sec, total: 297528129.40sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 297528129.39sec, total: 297528129.40sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 297528129.39sec, total: 297528129.40sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 297528129.39sec, total: 297528129.40sec
  train.py:359:image_losses, cpu: 2.33ms, accelerator: 1.64ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.64ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.70ms, accelerator: 315us, total: 2.01ms
      train.py:343:hfe, cpu: 354us, accelerator: 803us, total: 1.16ms
  train.py:358:image_losses, cpu: 128us, accelerator: 1.29ms, total: 1.42ms
    train.py:322:loss_fn, cpu: 115us, accelerator: 1.29ms, total: 1.41ms
train.py:511:<module>, cpu: 8.13sec, accelerator: 3.42ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 950us, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 7.77ms, accelerator: 950us, total: 8.75ms
  __init__.py:185:compute_gradients, cpu: 3.29ms, accelerator: 2.48ms, total: 5.81ms
train.py:448:<module>, cpu: 142.72ms, accelerator: 0us, total: 142.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2062.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_15500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 453us, accelerator: 292805460.67sec, total: 292805460.67sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec (0.00%)
top 3 operation type: ImageSummary, cpu: 338.47ms, accelerator: 0us, total: 338.47ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.06ms, accelerator: 0us, total: 143.06ms
train.py:442:<module>, cpu: 5.40ms, accelerator: 292805460.68sec, total: 292805460.68sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 292805460.67sec, total: 292805460.68sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 292805460.67sec, total: 292805460.68sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 292805460.67sec, total: 292805460.68sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.62ms, total: 3.93ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.62ms, total: 3.91ms
      train.py:342:hfe, cpu: 1.67ms, accelerator: 311us, total: 1.99ms
      train.py:343:hfe, cpu: 353us, accelerator: 793us, total: 1.15ms
  train.py:358:image_losses, cpu: 126us, accelerator: 1.27ms, total: 1.40ms
    train.py:322:loss_fn, cpu: 113us, accelerator: 1.27ms, total: 1.39ms
train.py:511:<module>, cpu: 8.14sec, accelerator: 3.39ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.14sec, accelerator: 941us, total: 8.14sec
    __init__.py:83:allreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec
    __init__.py:86:allreduce, cpu: 7.73ms, accelerator: 941us, total: 8.70ms
  __init__.py:185:compute_gradients, cpu: 3.27ms, accelerator: 2.44ms, total: 5.75ms
train.py:448:<module>, cpu: 143.07ms, accelerator: 0us, total: 143.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_15750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 452us, accelerator: 288230375.34sec, total: 288230375.34sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec (0.00%)
top 3 operation type: ImageSummary, cpu: 338.78ms, accelerator: 0us, total: 338.78ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.73ms, accelerator: 0us, total: 142.73ms
train.py:442:<module>, cpu: 5.41ms, accelerator: 288230375.35sec, total: 288230375.36sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 288230375.35sec, total: 288230375.35sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 288230375.35sec, total: 288230375.35sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 288230375.35sec, total: 288230375.35sec
  train.py:359:image_losses, cpu: 2.30ms, accelerator: 1.60ms, total: 3.90ms
    train.py:322:loss_fn, cpu: 2.28ms, accelerator: 1.60ms, total: 3.88ms
      train.py:342:hfe, cpu: 1.65ms, accelerator: 308us, total: 1.96ms
      train.py:343:hfe, cpu: 360us, accelerator: 781us, total: 1.14ms
  train.py:358:image_losses, cpu: 129us, accelerator: 1.25ms, total: 1.38ms
    train.py:322:loss_fn, cpu: 117us, accelerator: 1.25ms, total: 1.37ms
train.py:511:<module>, cpu: 8.16sec, accelerator: 3.34ms, total: 8.17sec
  __init__.py:194:compute_gradients, cpu: 8.16sec, accelerator: 929us, total: 8.16sec
    __init__.py:83:allreduce, cpu: 8.15sec, accelerator: 0us, total: 8.15sec
    __init__.py:86:allreduce, cpu: 7.75ms, accelerator: 929us, total: 8.71ms
  __init__.py:185:compute_gradients, cpu: 3.25ms, accelerator: 2.41ms, total: 5.71ms
train.py:448:<module>, cpu: 142.74ms, accelerator: 0us, total: 142.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_16000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 455us, accelerator: 283796061.88sec, total: 283796061.88sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.19sec, accelerator: 0us, total: 8.19sec (0.00%)
top 3 operation type: ImageSummary, cpu: 340.72ms, accelerator: 0us, total: 340.72ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.32ms, accelerator: 0us, total: 143.32ms
train.py:442:<module>, cpu: 5.41ms, accelerator: 283796061.89sec, total: 283796061.89sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 283796061.88sec, total: 283796061.89sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 283796061.88sec, total: 283796061.89sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 283796061.88sec, total: 283796061.89sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.57ms, total: 3.87ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.57ms, total: 3.85ms
      train.py:342:hfe, cpu: 1.63ms, accelerator: 304us, total: 1.94ms
      train.py:343:hfe, cpu: 374us, accelerator: 769us, total: 1.15ms
  train.py:358:image_losses, cpu: 128us, accelerator: 1.23ms, total: 1.36ms
    train.py:322:loss_fn, cpu: 116us, accelerator: 1.23ms, total: 1.35ms
train.py:511:<module>, cpu: 8.20sec, accelerator: 3.32ms, total: 8.20sec
  __init__.py:194:compute_gradients, cpu: 8.19sec, accelerator: 931us, total: 8.19sec
    __init__.py:83:allreduce, cpu: 8.19sec, accelerator: 0us, total: 8.19sec
    __init__.py:86:allreduce, cpu: 7.66ms, accelerator: 931us, total: 8.61ms
  __init__.py:185:compute_gradients, cpu: 3.29ms, accelerator: 2.39ms, total: 5.71ms
train.py:448:<module>, cpu: 143.33ms, accelerator: 0us, total: 143.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_16250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 454us, accelerator: 279496121.55sec, total: 279496121.55sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.16sec, accelerator: 0us, total: 8.16sec (0.00%)
top 3 operation type: ImageSummary, cpu: 341.08ms, accelerator: 0us, total: 341.08ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.82ms, accelerator: 0us, total: 143.82ms
train.py:442:<module>, cpu: 5.59ms, accelerator: 279496121.56sec, total: 279496121.56sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 279496121.55sec, total: 279496121.56sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 279496121.55sec, total: 279496121.56sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 279496121.55sec, total: 279496121.56sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.55ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.45ms, accelerator: 1.55ms, total: 4.02ms
      train.py:342:hfe, cpu: 1.82ms, accelerator: 301us, total: 2.12ms
      train.py:343:hfe, cpu: 371us, accelerator: 760us, total: 1.13ms
  train.py:358:image_losses, cpu: 128us, accelerator: 1.22ms, total: 1.34ms
    train.py:322:loss_fn, cpu: 116us, accelerator: 1.22ms, total: 1.33ms
train.py:511:<module>, cpu: 8.17sec, accelerator: 3.48ms, total: 8.18sec
  __init__.py:194:compute_gradients, cpu: 8.17sec, accelerator: 922us, total: 8.17sec
    __init__.py:83:allreduce, cpu: 8.16sec, accelerator: 0us, total: 8.16sec
    __init__.py:86:allreduce, cpu: 7.78ms, accelerator: 922us, total: 8.73ms
  __init__.py:185:compute_gradients, cpu: 3.26ms, accelerator: 2.56ms, total: 5.86ms
train.py:448:<module>, cpu: 143.82ms, accelerator: 0us, total: 143.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_16500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 451us, accelerator: 275324537.64sec, total: 275324537.64sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec (0.00%)
top 3 operation type: ImageSummary, cpu: 341.07ms, accelerator: 0us, total: 341.07ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.61ms, accelerator: 0us, total: 143.61ms
train.py:442:<module>, cpu: 5.56ms, accelerator: 275324537.65sec, total: 275324537.66sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 275324537.65sec, total: 275324537.65sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 275324537.65sec, total: 275324537.65sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 275324537.65sec, total: 275324537.65sec
  train.py:359:image_losses, cpu: 2.44ms, accelerator: 1.56ms, total: 4.02ms
    train.py:322:loss_fn, cpu: 2.43ms, accelerator: 1.56ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.80ms, accelerator: 296us, total: 2.10ms
      train.py:343:hfe, cpu: 368us, accelerator: 781us, total: 1.15ms
  train.py:358:image_losses, cpu: 127us, accelerator: 1.20ms, total: 1.33ms
    train.py:322:loss_fn, cpu: 115us, accelerator: 1.20ms, total: 1.32ms
train.py:511:<module>, cpu: 8.15sec, accelerator: 3.44ms, total: 8.16sec
  __init__.py:194:compute_gradients, cpu: 8.15sec, accelerator: 914us, total: 8.15sec
    __init__.py:83:allreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec
    __init__.py:86:allreduce, cpu: 7.89ms, accelerator: 914us, total: 8.83ms
  __init__.py:185:compute_gradients, cpu: 3.25ms, accelerator: 2.53ms, total: 5.83ms
train.py:448:<module>, cpu: 143.61ms, accelerator: 0us, total: 143.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_16750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 450us, accelerator: 271275647.38sec, total: 271275647.38sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec (0.00%)
top 3 operation type: ImageSummary, cpu: 341.67ms, accelerator: 0us, total: 341.67ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.69ms, accelerator: 0us, total: 143.69ms
train.py:442:<module>, cpu: 5.53ms, accelerator: 271275647.39sec, total: 271275647.40sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 271275647.39sec, total: 271275647.39sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 271275647.39sec, total: 271275647.39sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 271275647.39sec, total: 271275647.39sec
  train.py:359:image_losses, cpu: 2.42ms, accelerator: 1.59ms, total: 4.03ms
    train.py:322:loss_fn, cpu: 2.40ms, accelerator: 1.59ms, total: 4.01ms
      train.py:342:hfe, cpu: 1.78ms, accelerator: 292us, total: 2.07ms
      train.py:343:hfe, cpu: 367us, accelerator: 791us, total: 1.16ms
  train.py:358:image_losses, cpu: 126us, accelerator: 1.20ms, total: 1.32ms
    train.py:322:loss_fn, cpu: 114us, accelerator: 1.20ms, total: 1.31ms
train.py:511:<module>, cpu: 8.14sec, accelerator: 3.41ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.14sec, accelerator: 904us, total: 8.14sec
    __init__.py:83:allreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec
    __init__.py:86:allreduce, cpu: 7.80ms, accelerator: 904us, total: 8.73ms
  __init__.py:185:compute_gradients, cpu: 3.23ms, accelerator: 2.50ms, total: 5.78ms
train.py:448:<module>, cpu: 143.70ms, accelerator: 0us, total: 143.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_17000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 449us, accelerator: 267344116.26sec, total: 267344116.26sec (100.00%)
top 2 operation type: HorovodAllreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec (0.00%)
top 3 operation type: ImageSummary, cpu: 341.36ms, accelerator: 0us, total: 341.36ms (0.00%)
top 1 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.52ms, accelerator: 0us, total: 143.52ms
train.py:442:<module>, cpu: 5.58ms, accelerator: 267344116.27sec, total: 267344116.28sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 267344116.27sec, total: 267344116.27sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 267344116.27sec, total: 267344116.27sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 267344116.27sec, total: 267344116.27sec
  train.py:359:image_losses, cpu: 2.47ms, accelerator: 1.57ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.57ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.77ms, accelerator: 290us, total: 2.07ms
      train.py:343:hfe, cpu: 374us, accelerator: 781us, total: 1.16ms
  train.py:358:image_losses, cpu: 128us, accelerator: 1.18ms, total: 1.31ms
    train.py:322:loss_fn, cpu: 116us, accelerator: 1.18ms, total: 1.30ms
train.py:511:<module>, cpu: 8.14sec, accelerator: 3.53ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.14sec, accelerator: 899us, total: 8.14sec
    __init__.py:83:allreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec
    __init__.py:86:allreduce, cpu: 7.87ms, accelerator: 899us, total: 8.78ms
  __init__.py:185:compute_gradients, cpu: 3.22ms, accelerator: 2.63ms, total: 5.89ms
train.py:448:<module>, cpu: 143.52ms, accelerator: 0us, total: 143.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_17250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 447us, accelerator: 263524914.60sec, total: 263524914.60sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 263524914.60sec, total: 263524914.60sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.99ms, accelerator: 0us, total: 143.99ms
train.py:442:<module>, cpu: 5.63ms, accelerator: 263524914.61sec, total: 263524914.62sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 263524914.61sec, total: 263524914.61sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 263524914.61sec, total: 263524914.61sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 263524914.61sec, total: 263524914.61sec
  train.py:359:image_losses, cpu: 2.52ms, accelerator: 1.55ms, total: 4.09ms
    train.py:322:loss_fn, cpu: 2.51ms, accelerator: 1.55ms, total: 4.08ms
      train.py:342:hfe, cpu: 1.83ms, accelerator: 287us, total: 2.12ms
      train.py:343:hfe, cpu: 372us, accelerator: 771us, total: 1.15ms
  train.py:358:image_losses, cpu: 127us, accelerator: 1.16ms, total: 1.29ms
    train.py:322:loss_fn, cpu: 115us, accelerator: 1.16ms, total: 1.28ms
train.py:441:<module> (gradient), cpu: 4.32ms, accelerator: 263524914.60sec, total: 263524914.61sec
train.py:511:<module>, cpu: 8.15sec, accelerator: 3.56ms, total: 8.15sec
  __init__.py:194:compute_gradients, cpu: 8.14sec, accelerator: 890us, total: 8.14sec
    __init__.py:83:allreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec
    __init__.py:86:allreduce, cpu: 7.88ms, accelerator: 890us, total: 8.79ms
  __init__.py:185:compute_gradients, cpu: 3.20ms, accelerator: 2.67ms, total: 5.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_17500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 446us, accelerator: 259813296.09sec, total: 259813296.09sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 259813296.08sec, total: 259813296.08sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.41ms, accelerator: 0us, total: 143.41ms
train.py:442:<module>, cpu: 5.60ms, accelerator: 259813296.09sec, total: 259813296.10sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 259813296.09sec, total: 259813296.09sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 259813296.09sec, total: 259813296.09sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 259813296.09sec, total: 259813296.09sec
  train.py:359:image_losses, cpu: 2.50ms, accelerator: 1.54ms, total: 4.04ms
    train.py:322:loss_fn, cpu: 2.48ms, accelerator: 1.54ms, total: 4.03ms
      train.py:342:hfe, cpu: 1.81ms, accelerator: 284us, total: 2.10ms
      train.py:343:hfe, cpu: 369us, accelerator: 762us, total: 1.14ms
  train.py:358:image_losses, cpu: 127us, accelerator: 1.15ms, total: 1.27ms
    train.py:322:loss_fn, cpu: 115us, accelerator: 1.15ms, total: 1.26ms
train.py:441:<module> (gradient), cpu: 4.32ms, accelerator: 259813296.09sec, total: 259813296.09sec
train.py:511:<module>, cpu: 8.14sec, accelerator: 3.53ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.13sec, accelerator: 882us, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 7.81ms, accelerator: 882us, total: 8.71ms
  __init__.py:185:compute_gradients, cpu: 3.19ms, accelerator: 2.64ms, total: 5.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2133.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_17750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 445us, accelerator: 256204778.08sec, total: 256204778.08sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 256204778.08sec, total: 256204778.08sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.92ms, accelerator: 0us, total: 143.92ms
train.py:442:<module>, cpu: 5.64ms, accelerator: 256204778.09sec, total: 256204778.10sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 256204778.09sec, total: 256204778.09sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 256204778.09sec, total: 256204778.09sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 256204778.09sec, total: 256204778.09sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.52ms, total: 4.08ms
    train.py:322:loss_fn, cpu: 2.54ms, accelerator: 1.52ms, total: 4.06ms
      train.py:342:hfe, cpu: 1.79ms, accelerator: 280us, total: 2.07ms
      train.py:343:hfe, cpu: 368us, accelerator: 751us, total: 1.12ms
  train.py:358:image_losses, cpu: 125us, accelerator: 1.13ms, total: 1.26ms
    train.py:322:loss_fn, cpu: 113us, accelerator: 1.13ms, total: 1.25ms
train.py:441:<module> (gradient), cpu: 4.32ms, accelerator: 256204778.08sec, total: 256204778.09sec
train.py:511:<module>, cpu: 8.15sec, accelerator: 3.78ms, total: 8.15sec
  __init__.py:194:compute_gradients, cpu: 8.15sec, accelerator: 871us, total: 8.15sec
    __init__.py:83:allreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec
    __init__.py:86:allreduce, cpu: 7.72ms, accelerator: 871us, total: 8.62ms
  __init__.py:185:compute_gradients, cpu: 3.17ms, accelerator: 2.91ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_18000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 443us, accelerator: 252695123.59sec, total: 252695123.59sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 252695123.59sec, total: 252695123.59sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.35ms, accelerator: 0us, total: 143.35ms
train.py:442:<module>, cpu: 5.63ms, accelerator: 252695123.60sec, total: 252695123.60sec
  train.py:360:image_losses, cpu: 2.75ms, accelerator: 252695123.60sec, total: 252695123.60sec
    train.py:322:loss_fn, cpu: 2.74ms, accelerator: 252695123.60sec, total: 252695123.60sec
      train.py:349:msssim, cpu: 2.69ms, accelerator: 252695123.60sec, total: 252695123.60sec
  train.py:359:image_losses, cpu: 2.55ms, accelerator: 1.50ms, total: 4.06ms
    train.py:322:loss_fn, cpu: 2.53ms, accelerator: 1.50ms, total: 4.04ms
      train.py:342:hfe, cpu: 1.79ms, accelerator: 279us, total: 2.07ms
      train.py:343:hfe, cpu: 365us, accelerator: 741us, total: 1.11ms
  train.py:358:image_losses, cpu: 125us, accelerator: 1.12ms, total: 1.24ms
    train.py:322:loss_fn, cpu: 113us, accelerator: 1.12ms, total: 1.23ms
train.py:441:<module> (gradient), cpu: 4.34ms, accelerator: 252695123.59sec, total: 252695123.59sec
train.py:511:<module>, cpu: 8.14sec, accelerator: 3.73ms, total: 8.15sec
  __init__.py:194:compute_gradients, cpu: 8.14sec, accelerator: 861us, total: 8.14sec
    __init__.py:83:allreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec
    __init__.py:86:allreduce, cpu: 7.66ms, accelerator: 861us, total: 8.54ms
  __init__.py:185:compute_gradients, cpu: 3.15ms, accelerator: 2.87ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_18250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 440us, accelerator: 249280324.62sec, total: 249280324.62sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.35ms, accelerator: 249280324.62sec, total: 249280324.62sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.13ms, accelerator: 0us, total: 143.13ms
train.py:442:<module>, cpu: 5.60ms, accelerator: 249280324.63sec, total: 249280324.64sec
  train.py:360:image_losses, cpu: 2.74ms, accelerator: 249280324.63sec, total: 249280324.63sec
    train.py:322:loss_fn, cpu: 2.73ms, accelerator: 249280324.63sec, total: 249280324.63sec
      train.py:349:msssim, cpu: 2.68ms, accelerator: 249280324.63sec, total: 249280324.63sec
  train.py:359:image_losses, cpu: 2.52ms, accelerator: 1.48ms, total: 4.01ms
    train.py:322:loss_fn, cpu: 2.51ms, accelerator: 1.48ms, total: 4.00ms
      train.py:342:hfe, cpu: 1.77ms, accelerator: 275us, total: 2.04ms
      train.py:343:hfe, cpu: 362us, accelerator: 731us, total: 1.10ms
  train.py:358:image_losses, cpu: 124us, accelerator: 1.10ms, total: 1.23ms
    train.py:322:loss_fn, cpu: 112us, accelerator: 1.10ms, total: 1.22ms
train.py:441:<module> (gradient), cpu: 4.37ms, accelerator: 249280324.62sec, total: 249280324.63sec
train.py:511:<module>, cpu: 8.13sec, accelerator: 3.70ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.13sec, accelerator: 854us, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 7.61ms, accelerator: 854us, total: 8.49ms
  __init__.py:185:compute_gradients, cpu: 3.19ms, accelerator: 2.84ms, total: 6.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_18500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 438us, accelerator: 245956586.96sec, total: 245956586.96sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 245956586.96sec, total: 245956586.96sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.00ms, accelerator: 0us, total: 143.00ms
train.py:442:<module>, cpu: 5.58ms, accelerator: 245956586.97sec, total: 245956586.98sec
  train.py:360:image_losses, cpu: 2.74ms, accelerator: 245956586.97sec, total: 245956586.97sec
    train.py:322:loss_fn, cpu: 2.73ms, accelerator: 245956586.97sec, total: 245956586.97sec
      train.py:349:msssim, cpu: 2.68ms, accelerator: 245956586.97sec, total: 245956586.97sec
  train.py:359:image_losses, cpu: 2.51ms, accelerator: 1.46ms, total: 3.98ms
    train.py:322:loss_fn, cpu: 2.49ms, accelerator: 1.46ms, total: 3.96ms
      train.py:342:hfe, cpu: 1.75ms, accelerator: 272us, total: 2.03ms
      train.py:343:hfe, cpu: 360us, accelerator: 722us, total: 1.09ms
  train.py:358:image_losses, cpu: 124us, accelerator: 1.09ms, total: 1.21ms
    train.py:322:loss_fn, cpu: 112us, accelerator: 1.09ms, total: 1.20ms
train.py:441:<module> (gradient), cpu: 4.36ms, accelerator: 245956586.96sec, total: 245956586.97sec
train.py:511:<module>, cpu: 8.15sec, accelerator: 3.95ms, total: 8.15sec
  __init__.py:194:compute_gradients, cpu: 8.15sec, accelerator: 847us, total: 8.15sec
    __init__.py:83:allreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec
    __init__.py:86:allreduce, cpu: 7.59ms, accelerator: 847us, total: 8.46ms
  __init__.py:185:compute_gradients, cpu: 3.17ms, accelerator: 3.10ms, total: 6.31ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2075.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_18750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 444us, accelerator: 242720316.08sec, total: 242720316.08sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 242720316.08sec, total: 242720316.08sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.63ms, accelerator: 0us, total: 143.63ms
train.py:442:<module>, cpu: 5.62ms, accelerator: 242720316.09sec, total: 242720316.09sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 242720316.09sec, total: 242720316.09sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 242720316.09sec, total: 242720316.09sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 242720316.09sec, total: 242720316.09sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.45ms, total: 3.94ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.45ms, total: 3.92ms
      train.py:342:hfe, cpu: 1.73ms, accelerator: 270us, total: 2.00ms
      train.py:343:hfe, cpu: 358us, accelerator: 715us, total: 1.08ms
  train.py:358:image_losses, cpu: 125us, accelerator: 1.07ms, total: 1.20ms
    train.py:322:loss_fn, cpu: 113us, accelerator: 1.07ms, total: 1.19ms
train.py:441:<module> (gradient), cpu: 4.34ms, accelerator: 242720316.08sec, total: 242720316.08sec
train.py:511:<module>, cpu: 8.15sec, accelerator: 3.92ms, total: 8.16sec
  __init__.py:194:compute_gradients, cpu: 8.15sec, accelerator: 840us, total: 8.15sec
    __init__.py:83:allreduce, cpu: 8.14sec, accelerator: 0us, total: 8.14sec
    __init__.py:86:allreduce, cpu: 7.50ms, accelerator: 840us, total: 8.37ms
  __init__.py:185:compute_gradients, cpu: 3.15ms, accelerator: 3.08ms, total: 6.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_19000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 444us, accelerator: 239568104.18sec, total: 239568104.18sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 239568104.18sec, total: 239568104.18sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.23ms, accelerator: 0us, total: 143.23ms
train.py:442:<module>, cpu: 5.62ms, accelerator: 239568104.19sec, total: 239568104.20sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 239568104.19sec, total: 239568104.19sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 239568104.19sec, total: 239568104.19sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 239568104.19sec, total: 239568104.19sec
  train.py:359:image_losses, cpu: 2.48ms, accelerator: 1.43ms, total: 3.91ms
    train.py:322:loss_fn, cpu: 2.46ms, accelerator: 1.43ms, total: 3.90ms
      train.py:342:hfe, cpu: 1.71ms, accelerator: 267us, total: 1.98ms
      train.py:343:hfe, cpu: 358us, accelerator: 706us, total: 1.07ms
  train.py:358:image_losses, cpu: 124us, accelerator: 1.06ms, total: 1.18ms
    train.py:322:loss_fn, cpu: 112us, accelerator: 1.06ms, total: 1.17ms
train.py:441:<module> (gradient), cpu: 4.34ms, accelerator: 239568104.18sec, total: 239568104.19sec
train.py:511:<module>, cpu: 8.14sec, accelerator: 3.87ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.13sec, accelerator: 833us, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 7.57ms, accelerator: 833us, total: 8.44ms
  __init__.py:185:compute_gradients, cpu: 3.22ms, accelerator: 3.04ms, total: 6.30ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_19250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 443us, accelerator: 236496718.23sec, total: 236496718.23sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 236496718.23sec, total: 236496718.23sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.40ms, accelerator: 0us, total: 143.40ms
train.py:442:<module>, cpu: 5.59ms, accelerator: 236496718.24sec, total: 236496718.25sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 236496718.24sec, total: 236496718.24sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 236496718.24sec, total: 236496718.24sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 236496718.24sec, total: 236496718.24sec
  train.py:359:image_losses, cpu: 2.45ms, accelerator: 1.42ms, total: 3.88ms
    train.py:322:loss_fn, cpu: 2.44ms, accelerator: 1.42ms, total: 3.86ms
      train.py:342:hfe, cpu: 1.70ms, accelerator: 264us, total: 1.97ms
      train.py:343:hfe, cpu: 355us, accelerator: 698us, total: 1.06ms
  train.py:358:image_losses, cpu: 123us, accelerator: 1.04ms, total: 1.17ms
    train.py:322:loss_fn, cpu: 111us, accelerator: 1.04ms, total: 1.16ms
train.py:441:<module> (gradient), cpu: 4.34ms, accelerator: 236496718.23sec, total: 236496718.24sec
train.py:511:<module>, cpu: 8.12sec, accelerator: 3.91ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 825us, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 7.53ms, accelerator: 825us, total: 8.38ms
  __init__.py:185:compute_gradients, cpu: 3.23ms, accelerator: 3.09ms, total: 6.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_19500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 441us, accelerator: 233503088.89sec, total: 233503088.89sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.34ms, accelerator: 233503088.88sec, total: 233503088.88sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.91ms, accelerator: 0us, total: 143.91ms
train.py:442:<module>, cpu: 5.56ms, accelerator: 233503088.90sec, total: 233503088.90sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 233503088.89sec, total: 233503088.90sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 233503088.89sec, total: 233503088.90sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 233503088.89sec, total: 233503088.90sec
  train.py:359:image_losses, cpu: 2.43ms, accelerator: 1.40ms, total: 3.84ms
    train.py:322:loss_fn, cpu: 2.41ms, accelerator: 1.40ms, total: 3.82ms
      train.py:342:hfe, cpu: 1.68ms, accelerator: 261us, total: 1.95ms
      train.py:343:hfe, cpu: 353us, accelerator: 689us, total: 1.05ms
  train.py:358:image_losses, cpu: 122us, accelerator: 1.03ms, total: 1.16ms
    train.py:322:loss_fn, cpu: 110us, accelerator: 1.03ms, total: 1.15ms
train.py:441:<module> (gradient), cpu: 4.33ms, accelerator: 233503088.89sec, total: 233503088.89sec
train.py:511:<module>, cpu: 8.12sec, accelerator: 4.05ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 817us, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 7.54ms, accelerator: 817us, total: 8.38ms
  __init__.py:185:compute_gradients, cpu: 3.21ms, accelerator: 3.23ms, total: 6.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_19750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 442us, accelerator: 230584300.28sec, total: 230584300.28sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 230584300.27sec, total: 230584300.27sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.41ms, accelerator: 0us, total: 143.41ms
train.py:442:<module>, cpu: 5.54ms, accelerator: 230584300.28sec, total: 230584300.29sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 230584300.28sec, total: 230584300.28sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 230584300.28sec, total: 230584300.28sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 230584300.28sec, total: 230584300.28sec
  train.py:359:image_losses, cpu: 2.41ms, accelerator: 1.38ms, total: 3.81ms
    train.py:322:loss_fn, cpu: 2.39ms, accelerator: 1.38ms, total: 3.79ms
      train.py:342:hfe, cpu: 1.66ms, accelerator: 259us, total: 1.93ms
      train.py:343:hfe, cpu: 352us, accelerator: 682us, total: 1.04ms
  train.py:358:image_losses, cpu: 122us, accelerator: 1.02ms, total: 1.14ms
    train.py:322:loss_fn, cpu: 110us, accelerator: 1.02ms, total: 1.13ms
train.py:441:<module> (gradient), cpu: 4.32ms, accelerator: 230584300.28sec, total: 230584300.28sec
train.py:511:<module>, cpu: 8.12sec, accelerator: 4.03ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 811us, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 7.46ms, accelerator: 811us, total: 8.30ms
  __init__.py:185:compute_gradients, cpu: 3.35ms, accelerator: 3.22ms, total: 6.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_20000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 440us, accelerator: 227737580.52sec, total: 227737580.52sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 227737580.52sec, total: 227737580.52sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.03ms, accelerator: 0us, total: 143.03ms
train.py:442:<module>, cpu: 5.59ms, accelerator: 227737580.53sec, total: 227737580.53sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 227737580.52sec, total: 227737580.53sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 227737580.52sec, total: 227737580.53sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 227737580.52sec, total: 227737580.53sec
  train.py:359:image_losses, cpu: 2.39ms, accelerator: 1.37ms, total: 3.77ms
    train.py:322:loss_fn, cpu: 2.37ms, accelerator: 1.37ms, total: 3.75ms
      train.py:342:hfe, cpu: 1.64ms, accelerator: 258us, total: 1.91ms
      train.py:343:hfe, cpu: 351us, accelerator: 676us, total: 1.03ms
  train.py:358:image_losses, cpu: 122us, accelerator: 1.01ms, total: 1.13ms
    train.py:322:loss_fn, cpu: 110us, accelerator: 1.01ms, total: 1.12ms
train.py:441:<module> (gradient), cpu: 4.32ms, accelerator: 227737580.52sec, total: 227737580.52sec
train.py:511:<module>, cpu: 8.12sec, accelerator: 4.01ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 807us, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 7.44ms, accelerator: 807us, total: 8.28ms
  __init__.py:185:compute_gradients, cpu: 3.34ms, accelerator: 3.20ms, total: 6.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_20250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 437us, accelerator: 224960292.95sec, total: 224960292.95sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 224960292.95sec, total: 224960292.95sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.67ms, accelerator: 0us, total: 142.67ms
train.py:442:<module>, cpu: 5.56ms, accelerator: 224960292.96sec, total: 224960292.97sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 224960292.96sec, total: 224960292.96sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 224960292.96sec, total: 224960292.96sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 224960292.96sec, total: 224960292.96sec
  train.py:359:image_losses, cpu: 2.36ms, accelerator: 1.35ms, total: 3.73ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.35ms, total: 3.71ms
      train.py:342:hfe, cpu: 1.63ms, accelerator: 255us, total: 1.89ms
      train.py:343:hfe, cpu: 347us, accelerator: 667us, total: 1.02ms
  train.py:358:image_losses, cpu: 122us, accelerator: 996us, total: 1.12ms
    train.py:322:loss_fn, cpu: 110us, accelerator: 996us, total: 1.11ms
train.py:441:<module> (gradient), cpu: 4.31ms, accelerator: 224960292.95sec, total: 224960292.96sec
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.98ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 812us, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 7.39ms, accelerator: 812us, total: 8.23ms
  __init__.py:185:compute_gradients, cpu: 3.33ms, accelerator: 3.17ms, total: 6.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_20500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 437us, accelerator: 222249927.98sec, total: 222249927.98sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 222249927.97sec, total: 222249927.97sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.92ms, accelerator: 0us, total: 142.92ms
train.py:442:<module>, cpu: 5.57ms, accelerator: 222249927.98sec, total: 222249927.99sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 222249927.98sec, total: 222249927.98sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 222249927.98sec, total: 222249927.98sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 222249927.98sec, total: 222249927.98sec
  train.py:359:image_losses, cpu: 2.37ms, accelerator: 1.34ms, total: 3.72ms
    train.py:322:loss_fn, cpu: 2.35ms, accelerator: 1.34ms, total: 3.70ms
      train.py:342:hfe, cpu: 1.62ms, accelerator: 253us, total: 1.88ms
      train.py:343:hfe, cpu: 363us, accelerator: 660us, total: 1.03ms
  train.py:358:image_losses, cpu: 123us, accelerator: 984us, total: 1.11ms
    train.py:322:loss_fn, cpu: 111us, accelerator: 984us, total: 1.10ms
train.py:441:<module> (gradient), cpu: 4.31ms, accelerator: 222249927.98sec, total: 222249927.98sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.95ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 807us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 7.43ms, accelerator: 807us, total: 8.26ms
  __init__.py:185:compute_gradients, cpu: 3.31ms, accelerator: 3.14ms, total: 6.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_20750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 436us, accelerator: 219604095.50sec, total: 219604095.50sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 219604095.50sec, total: 219604095.50sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.57ms, accelerator: 0us, total: 142.57ms
train.py:442:<module>, cpu: 5.54ms, accelerator: 219604095.51sec, total: 219604095.51sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 219604095.51sec, total: 219604095.51sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 219604095.51sec, total: 219604095.51sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 219604095.51sec, total: 219604095.51sec
  train.py:359:image_losses, cpu: 2.34ms, accelerator: 1.33ms, total: 3.69ms
    train.py:322:loss_fn, cpu: 2.33ms, accelerator: 1.33ms, total: 3.67ms
      train.py:342:hfe, cpu: 1.60ms, accelerator: 251us, total: 1.86ms
      train.py:343:hfe, cpu: 359us, accelerator: 653us, total: 1.02ms
  train.py:358:image_losses, cpu: 123us, accelerator: 973us, total: 1.10ms
    train.py:322:loss_fn, cpu: 111us, accelerator: 973us, total: 1.08ms
train.py:441:<module> (gradient), cpu: 4.29ms, accelerator: 219604095.50sec, total: 219604095.51sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.92ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 812us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 7.37ms, accelerator: 812us, total: 8.21ms
  __init__.py:185:compute_gradients, cpu: 3.30ms, accelerator: 3.11ms, total: 6.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_21000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 436us, accelerator: 217020517.91sec, total: 217020517.91sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 217020517.90sec, total: 217020517.90sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.64ms, accelerator: 0us, total: 142.64ms
train.py:442:<module>, cpu: 5.53ms, accelerator: 217020517.91sec, total: 217020517.92sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 217020517.91sec, total: 217020517.91sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 217020517.91sec, total: 217020517.91sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 217020517.91sec, total: 217020517.91sec
  train.py:359:image_losses, cpu: 2.34ms, accelerator: 1.31ms, total: 3.67ms
    train.py:322:loss_fn, cpu: 2.33ms, accelerator: 1.31ms, total: 3.66ms
      train.py:342:hfe, cpu: 1.60ms, accelerator: 249us, total: 1.85ms
      train.py:343:hfe, cpu: 360us, accelerator: 647us, total: 1.01ms
  train.py:358:image_losses, cpu: 123us, accelerator: 962us, total: 1.09ms
    train.py:322:loss_fn, cpu: 111us, accelerator: 962us, total: 1.07ms
train.py:441:<module> (gradient), cpu: 4.28ms, accelerator: 217020517.91sec, total: 217020517.91sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.88ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 804us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 7.30ms, accelerator: 804us, total: 8.13ms
  __init__.py:185:compute_gradients, cpu: 3.28ms, accelerator: 3.08ms, total: 6.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_21250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 435us, accelerator: 214497023.51sec, total: 214497023.51sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 214497023.51sec, total: 214497023.51sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.72ms, accelerator: 0us, total: 142.72ms
train.py:442:<module>, cpu: 5.50ms, accelerator: 214497023.52sec, total: 214497023.53sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 214497023.52sec, total: 214497023.52sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 214497023.52sec, total: 214497023.52sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 214497023.52sec, total: 214497023.52sec
  train.py:359:image_losses, cpu: 2.32ms, accelerator: 1.30ms, total: 3.63ms
    train.py:322:loss_fn, cpu: 2.31ms, accelerator: 1.30ms, total: 3.62ms
      train.py:342:hfe, cpu: 1.58ms, accelerator: 246us, total: 1.83ms
      train.py:343:hfe, cpu: 358us, accelerator: 639us, total: 1.00ms
  train.py:358:image_losses, cpu: 124us, accelerator: 951us, total: 1.07ms
    train.py:322:loss_fn, cpu: 112us, accelerator: 951us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.28ms, accelerator: 214497023.51sec, total: 214497023.52sec
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.84ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 798us, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 7.38ms, accelerator: 798us, total: 8.20ms
  __init__.py:185:compute_gradients, cpu: 3.31ms, accelerator: 3.04ms, total: 6.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_21500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 434us, accelerator: 212031540.48sec, total: 212031540.48sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.33ms, accelerator: 212031540.48sec, total: 212031540.48sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.35ms, accelerator: 0us, total: 142.35ms
train.py:442:<module>, cpu: 5.49ms, accelerator: 212031540.49sec, total: 212031540.50sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 212031540.49sec, total: 212031540.49sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 212031540.49sec, total: 212031540.49sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 212031540.49sec, total: 212031540.49sec
  train.py:359:image_losses, cpu: 2.31ms, accelerator: 1.29ms, total: 3.61ms
    train.py:322:loss_fn, cpu: 2.29ms, accelerator: 1.29ms, total: 3.59ms
      train.py:342:hfe, cpu: 1.57ms, accelerator: 245us, total: 1.82ms
  train.py:358:image_losses, cpu: 124us, accelerator: 940us, total: 1.06ms
    train.py:322:loss_fn, cpu: 112us, accelerator: 940us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.28ms, accelerator: 212031540.48sec, total: 212031540.49sec
train.py:511:<module>, cpu: 8.08sec, accelerator: 3.81ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 791us, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 7.33ms, accelerator: 791us, total: 8.14ms
  __init__.py:185:compute_gradients, cpu: 3.30ms, accelerator: 3.02ms, total: 6.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_21750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 432us, accelerator: 209622091.16sec, total: 209622091.16sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 209622091.16sec, total: 209622091.16sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.62ms, accelerator: 0us, total: 142.62ms
train.py:442:<module>, cpu: 5.47ms, accelerator: 209622091.17sec, total: 209622091.17sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 209622091.17sec, total: 209622091.17sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 209622091.17sec, total: 209622091.17sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 209622091.16sec, total: 209622091.17sec
  train.py:359:image_losses, cpu: 2.29ms, accelerator: 1.34ms, total: 3.64ms
    train.py:322:loss_fn, cpu: 2.27ms, accelerator: 1.34ms, total: 3.63ms
      train.py:342:hfe, cpu: 1.56ms, accelerator: 243us, total: 1.81ms
      train.py:343:hfe, cpu: 354us, accelerator: 686us, total: 1.04ms
  train.py:358:image_losses, cpu: 122us, accelerator: 959us, total: 1.08ms
    train.py:322:loss_fn, cpu: 110us, accelerator: 959us, total: 1.07ms
train.py:441:<module> (gradient), cpu: 4.27ms, accelerator: 209622091.16sec, total: 209622091.16sec
train.py:511:<module>, cpu: 8.12sec, accelerator: 4.00ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 978us, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 7.36ms, accelerator: 978us, total: 8.37ms
  __init__.py:185:compute_gradients, cpu: 3.28ms, accelerator: 3.02ms, total: 6.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_22000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 432us, accelerator: 207266786.76sec, total: 207266786.77sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 207266786.76sec, total: 207266786.76sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.79ms, accelerator: 0us, total: 142.79ms
train.py:442:<module>, cpu: 5.45ms, accelerator: 207266786.77sec, total: 207266786.78sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 207266786.77sec, total: 207266786.77sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 207266786.77sec, total: 207266786.77sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 207266786.77sec, total: 207266786.77sec
  train.py:359:image_losses, cpu: 2.27ms, accelerator: 1.33ms, total: 3.61ms
    train.py:322:loss_fn, cpu: 2.26ms, accelerator: 1.33ms, total: 3.59ms
      train.py:342:hfe, cpu: 1.54ms, accelerator: 241us, total: 1.79ms
      train.py:343:hfe, cpu: 354us, accelerator: 678us, total: 1.03ms
  train.py:358:image_losses, cpu: 122us, accelerator: 949us, total: 1.07ms
    train.py:322:loss_fn, cpu: 110us, accelerator: 949us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.26ms, accelerator: 207266786.77sec, total: 207266786.77sec
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.96ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 968us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 7.29ms, accelerator: 968us, total: 8.29ms
  __init__.py:185:compute_gradients, cpu: 3.28ms, accelerator: 2.99ms, total: 6.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_22250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 430us, accelerator: 204963822.47sec, total: 204963822.47sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 204963822.46sec, total: 204963822.47sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.85ms, accelerator: 0us, total: 142.85ms
train.py:442:<module>, cpu: 5.42ms, accelerator: 204963822.48sec, total: 204963822.48sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 204963822.47sec, total: 204963822.48sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 204963822.47sec, total: 204963822.48sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 204963822.47sec, total: 204963822.48sec
  train.py:359:image_losses, cpu: 2.25ms, accelerator: 1.31ms, total: 3.58ms
    train.py:322:loss_fn, cpu: 2.23ms, accelerator: 1.31ms, total: 3.56ms
      train.py:342:hfe, cpu: 1.53ms, accelerator: 235us, total: 1.77ms
      train.py:343:hfe, cpu: 349us, accelerator: 674us, total: 1.03ms
  train.py:358:image_losses, cpu: 122us, accelerator: 938us, total: 1.06ms
    train.py:322:loss_fn, cpu: 110us, accelerator: 938us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.27ms, accelerator: 204963822.47sec, total: 204963822.47sec
train.py:511:<module>, cpu: 8.08sec, accelerator: 3.93ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 964us, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 7.25ms, accelerator: 964us, total: 8.23ms
  __init__.py:185:compute_gradients, cpu: 3.33ms, accelerator: 2.96ms, total: 6.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_22500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 429us, accelerator: 202711472.77sec, total: 202711472.77sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 202711472.77sec, total: 202711472.77sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.26ms, accelerator: 0us, total: 143.26ms
train.py:442:<module>, cpu: 5.39ms, accelerator: 202711472.78sec, total: 202711472.78sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 202711472.77sec, total: 202711472.78sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 202711472.77sec, total: 202711472.78sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 202711472.77sec, total: 202711472.78sec
  train.py:359:image_losses, cpu: 2.23ms, accelerator: 1.30ms, total: 3.55ms
    train.py:322:loss_fn, cpu: 2.22ms, accelerator: 1.30ms, total: 3.53ms
      train.py:342:hfe, cpu: 1.52ms, accelerator: 235us, total: 1.76ms
      train.py:343:hfe, cpu: 349us, accelerator: 665us, total: 1.02ms
  train.py:358:image_losses, cpu: 121us, accelerator: 929us, total: 1.05ms
    train.py:322:loss_fn, cpu: 109us, accelerator: 929us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.27ms, accelerator: 202711472.77sec, total: 202711472.78sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.96ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.02ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 7.18ms, accelerator: 1.02ms, total: 8.23ms
  __init__.py:185:compute_gradients, cpu: 3.31ms, accelerator: 2.94ms, total: 6.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_22750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 427us, accelerator: 200508087.20sec, total: 200508087.20sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.32ms, accelerator: 200508087.19sec, total: 200508087.19sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.72ms, accelerator: 0us, total: 142.72ms
train.py:442:<module>, cpu: 5.38ms, accelerator: 200508087.20sec, total: 200508087.21sec
  train.py:360:image_losses, cpu: 2.75ms, accelerator: 200508087.20sec, total: 200508087.20sec
    train.py:322:loss_fn, cpu: 2.74ms, accelerator: 200508087.20sec, total: 200508087.20sec
      train.py:349:msssim, cpu: 2.69ms, accelerator: 200508087.20sec, total: 200508087.20sec
  train.py:359:image_losses, cpu: 2.22ms, accelerator: 1.29ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.21ms, accelerator: 1.29ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.51ms, accelerator: 234us, total: 1.74ms
      train.py:343:hfe, cpu: 351us, accelerator: 659us, total: 1.01ms
  train.py:358:image_losses, cpu: 123us, accelerator: 919us, total: 1.04ms
    train.py:322:loss_fn, cpu: 111us, accelerator: 919us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.27ms, accelerator: 200508087.20sec, total: 200508087.20sec
train.py:511:<module>, cpu: 8.12sec, accelerator: 3.93ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.02ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 7.19ms, accelerator: 1.02ms, total: 8.23ms
  __init__.py:185:compute_gradients, cpu: 3.29ms, accelerator: 2.91ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_23000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 429us, accelerator: 198352086.26sec, total: 198352086.26sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.31ms, accelerator: 198352086.26sec, total: 198352086.26sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.70ms, accelerator: 0us, total: 142.70ms
train.py:442:<module>, cpu: 5.38ms, accelerator: 198352086.27sec, total: 198352086.27sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 198352086.26sec, total: 198352086.27sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 198352086.26sec, total: 198352086.27sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 198352086.26sec, total: 198352086.27sec
  train.py:359:image_losses, cpu: 2.21ms, accelerator: 1.28ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.20ms, accelerator: 1.28ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.49ms, accelerator: 231us, total: 1.73ms
      train.py:343:hfe, cpu: 353us, accelerator: 651us, total: 1.01ms
  train.py:358:image_losses, cpu: 124us, accelerator: 909us, total: 1.03ms
    train.py:322:loss_fn, cpu: 112us, accelerator: 909us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 198352086.26sec, total: 198352086.26sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.89ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.00ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 7.14ms, accelerator: 1.00ms, total: 8.17ms
  __init__.py:185:compute_gradients, cpu: 3.28ms, accelerator: 2.89ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_23250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 427us, accelerator: 196241957.68sec, total: 196241957.68sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.31ms, accelerator: 196241957.68sec, total: 196241957.68sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.94ms, accelerator: 0us, total: 142.94ms
train.py:442:<module>, cpu: 5.36ms, accelerator: 196241957.69sec, total: 196241957.69sec
  train.py:360:image_losses, cpu: 2.75ms, accelerator: 196241957.69sec, total: 196241957.69sec
    train.py:322:loss_fn, cpu: 2.74ms, accelerator: 196241957.69sec, total: 196241957.69sec
      train.py:349:msssim, cpu: 2.69ms, accelerator: 196241957.69sec, total: 196241957.69sec
  train.py:359:image_losses, cpu: 2.21ms, accelerator: 1.30ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.30ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.48ms, accelerator: 245us, total: 1.73ms
      train.py:343:hfe, cpu: 354us, accelerator: 657us, total: 1.02ms
  train.py:358:image_losses, cpu: 125us, accelerator: 901us, total: 1.03ms
    train.py:322:loss_fn, cpu: 113us, accelerator: 901us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 196241957.68sec, total: 196241957.69sec
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.93ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 998us, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 7.13ms, accelerator: 998us, total: 8.15ms
  __init__.py:185:compute_gradients, cpu: 3.26ms, accelerator: 2.94ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_23500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 427us, accelerator: 194176252.86sec, total: 194176252.86sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.31ms, accelerator: 194176252.86sec, total: 194176252.86sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.35ms, accelerator: 0us, total: 143.35ms
train.py:442:<module>, cpu: 5.34ms, accelerator: 194176252.87sec, total: 194176252.88sec
  train.py:360:image_losses, cpu: 2.75ms, accelerator: 194176252.87sec, total: 194176252.87sec
    train.py:322:loss_fn, cpu: 2.74ms, accelerator: 194176252.87sec, total: 194176252.87sec
      train.py:349:msssim, cpu: 2.69ms, accelerator: 194176252.87sec, total: 194176252.87sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.29ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.29ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.47ms, accelerator: 242us, total: 1.72ms
      train.py:343:hfe, cpu: 354us, accelerator: 650us, total: 1.01ms
  train.py:358:image_losses, cpu: 125us, accelerator: 892us, total: 1.02ms
    train.py:322:loss_fn, cpu: 113us, accelerator: 892us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 194176252.86sec, total: 194176252.87sec
train.py:511:<module>, cpu: 8.12sec, accelerator: 3.92ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 991us, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 7.07ms, accelerator: 991us, total: 8.08ms
  __init__.py:185:compute_gradients, cpu: 3.25ms, accelerator: 2.93ms, total: 6.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_23750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 424us, accelerator: 192153583.56sec, total: 192153583.56sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.30ms, accelerator: 192153583.56sec, total: 192153583.56sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.56ms, accelerator: 0us, total: 143.56ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 192153583.57sec, total: 192153583.58sec
  train.py:360:image_losses, cpu: 2.74ms, accelerator: 192153583.57sec, total: 192153583.57sec
    train.py:322:loss_fn, cpu: 2.73ms, accelerator: 192153583.57sec, total: 192153583.57sec
      train.py:349:msssim, cpu: 2.68ms, accelerator: 192153583.57sec, total: 192153583.57sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.31ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.31ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.46ms, accelerator: 241us, total: 1.71ms
      train.py:343:hfe, cpu: 352us, accelerator: 670us, total: 1.03ms
  train.py:358:image_losses, cpu: 125us, accelerator: 888us, total: 1.01ms
    train.py:322:loss_fn, cpu: 113us, accelerator: 888us, total: 1.00ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 192153583.56sec, total: 192153583.57sec
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.97ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.05ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 7.09ms, accelerator: 1.05ms, total: 8.17ms
  __init__.py:185:compute_gradients, cpu: 3.23ms, accelerator: 2.92ms, total: 6.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_24000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 423us, accelerator: 190172618.78sec, total: 190172618.78sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.30ms, accelerator: 190172618.78sec, total: 190172618.78sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.35ms, accelerator: 0us, total: 143.35ms
train.py:442:<module>, cpu: 5.30ms, accelerator: 190172618.79sec, total: 190172618.80sec
  train.py:360:image_losses, cpu: 2.74ms, accelerator: 190172618.79sec, total: 190172618.79sec
    train.py:322:loss_fn, cpu: 2.73ms, accelerator: 190172618.79sec, total: 190172618.79sec
      train.py:349:msssim, cpu: 2.68ms, accelerator: 190172618.79sec, total: 190172618.79sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.30ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.30ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.45ms, accelerator: 240us, total: 1.70ms
      train.py:343:hfe, cpu: 351us, accelerator: 664us, total: 1.02ms
  train.py:358:image_losses, cpu: 125us, accelerator: 879us, total: 1.00ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 190172618.79sec, total: 190172618.79sec
train.py:511:<module>, cpu: 8.12sec, accelerator: 3.93ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 1.04ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 7.05ms, accelerator: 1.04ms, total: 8.11ms
  __init__.py:185:compute_gradients, cpu: 3.22ms, accelerator: 2.89ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_24250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 423us, accelerator: 188232081.86sec, total: 188232081.86sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.30ms, accelerator: 188232081.86sec, total: 188232081.86sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.43ms, accelerator: 0us, total: 143.43ms
train.py:442:<module>, cpu: 5.29ms, accelerator: 188232081.87sec, total: 188232081.87sec
  train.py:360:image_losses, cpu: 2.74ms, accelerator: 188232081.86sec, total: 188232081.87sec
    train.py:322:loss_fn, cpu: 2.72ms, accelerator: 188232081.86sec, total: 188232081.87sec
      train.py:349:msssim, cpu: 2.67ms, accelerator: 188232081.86sec, total: 188232081.87sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.29ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.29ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.44ms, accelerator: 238us, total: 1.68ms
      train.py:343:hfe, cpu: 350us, accelerator: 657us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 188232081.86sec, total: 188232081.86sec
train.py:511:<module>, cpu: 8.14sec, accelerator: 3.91ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.13sec, accelerator: 1.03ms, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 7.06ms, accelerator: 1.03ms, total: 8.11ms
  __init__.py:185:compute_gradients, cpu: 3.20ms, accelerator: 2.88ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_24500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 421us, accelerator: 186330747.70sec, total: 186330747.70sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.30ms, accelerator: 186330747.69sec, total: 186330747.70sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.02ms, accelerator: 0us, total: 143.02ms
train.py:442:<module>, cpu: 5.26ms, accelerator: 186330747.70sec, total: 186330747.71sec
  train.py:360:image_losses, cpu: 2.73ms, accelerator: 186330747.70sec, total: 186330747.71sec
    train.py:322:loss_fn, cpu: 2.72ms, accelerator: 186330747.70sec, total: 186330747.71sec
      train.py:349:msssim, cpu: 2.67ms, accelerator: 186330747.70sec, total: 186330747.71sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.28ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.28ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.43ms, accelerator: 237us, total: 1.67ms
      train.py:343:hfe, cpu: 350us, accelerator: 652us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 186330747.70sec, total: 186330747.70sec
train.py:511:<module>, cpu: 8.13sec, accelerator: 3.88ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.13sec, accelerator: 1.03ms, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 7.10ms, accelerator: 1.03ms, total: 8.15ms
  __init__.py:185:compute_gradients, cpu: 3.19ms, accelerator: 2.85ms, total: 6.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_24750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 421us, accelerator: 184467440.22sec, total: 184467440.22sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.30ms, accelerator: 184467440.22sec, total: 184467440.22sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.78ms, accelerator: 0us, total: 142.78ms
train.py:442:<module>, cpu: 5.25ms, accelerator: 184467440.23sec, total: 184467440.23sec
  train.py:360:image_losses, cpu: 2.73ms, accelerator: 184467440.23sec, total: 184467440.23sec
    train.py:322:loss_fn, cpu: 2.71ms, accelerator: 184467440.23sec, total: 184467440.23sec
      train.py:349:msssim, cpu: 2.66ms, accelerator: 184467440.23sec, total: 184467440.23sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.27ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.27ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.42ms, accelerator: 234us, total: 1.66ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 184467440.22sec, total: 184467440.23sec
train.py:511:<module>, cpu: 8.14sec, accelerator: 3.85ms, total: 8.14sec
  __init__.py:194:compute_gradients, cpu: 8.13sec, accelerator: 1.02ms, total: 8.14sec
    __init__.py:83:allreduce, cpu: 8.13sec, accelerator: 0us, total: 8.13sec
    __init__.py:86:allreduce, cpu: 7.04ms, accelerator: 1.02ms, total: 8.09ms
  __init__.py:185:compute_gradients, cpu: 3.18ms, accelerator: 2.83ms, total: 6.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_25000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 420us, accelerator: 182641029.92sec, total: 182641029.92sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.30ms, accelerator: 182641029.92sec, total: 182641029.92sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.00ms, accelerator: 0us, total: 143.00ms
train.py:442:<module>, cpu: 5.22ms, accelerator: 182641029.93sec, total: 182641029.93sec
  train.py:360:image_losses, cpu: 2.72ms, accelerator: 182641029.93sec, total: 182641029.93sec
    train.py:322:loss_fn, cpu: 2.71ms, accelerator: 182641029.93sec, total: 182641029.93sec
      train.py:349:msssim, cpu: 2.66ms, accelerator: 182641029.93sec, total: 182641029.93sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.26ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.26ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.41ms, accelerator: 232us, total: 1.64ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 182641029.92sec, total: 182641029.93sec
train.py:511:<module>, cpu: 8.13sec, accelerator: 3.93ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 1.01ms, total: 8.13sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 6.99ms, accelerator: 1.01ms, total: 8.03ms
  __init__.py:185:compute_gradients, cpu: 3.23ms, accelerator: 2.92ms, total: 6.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_25250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 419us, accelerator: 180850431.59sec, total: 180850431.59sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 180850431.59sec, total: 180850431.59sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.01ms, accelerator: 0us, total: 143.01ms
train.py:442:<module>, cpu: 5.21ms, accelerator: 180850431.60sec, total: 180850431.60sec
  train.py:360:image_losses, cpu: 2.72ms, accelerator: 180850431.59sec, total: 180850431.60sec
    train.py:322:loss_fn, cpu: 2.71ms, accelerator: 180850431.59sec, total: 180850431.60sec
      train.py:349:msssim, cpu: 2.65ms, accelerator: 180850431.59sec, total: 180850431.60sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.25ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.25ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.40ms, accelerator: 231us, total: 1.64ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 180850431.59sec, total: 180850431.59sec
train.py:511:<module>, cpu: 8.12sec, accelerator: 3.90ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 1.00ms, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 7.19ms, accelerator: 1.00ms, total: 8.22ms
  __init__.py:185:compute_gradients, cpu: 3.24ms, accelerator: 2.90ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_25500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 419us, accelerator: 179094602.16sec, total: 179094602.16sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 179094602.15sec, total: 179094602.15sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.94ms, accelerator: 0us, total: 142.94ms
train.py:442:<module>, cpu: 5.21ms, accelerator: 179094602.16sec, total: 179094602.17sec
  train.py:360:image_losses, cpu: 2.71ms, accelerator: 179094602.16sec, total: 179094602.16sec
    train.py:322:loss_fn, cpu: 2.70ms, accelerator: 179094602.16sec, total: 179094602.16sec
      train.py:349:msssim, cpu: 2.65ms, accelerator: 179094602.16sec, total: 179094602.16sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.34ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.34ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 277us, total: 1.67ms
      train.py:343:hfe, cpu: 342us, accelerator: 668us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 179094602.16sec, total: 179094602.16sec
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.01ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.00ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 7.14ms, accelerator: 1.00ms, total: 8.17ms
  __init__.py:185:compute_gradients, cpu: 3.22ms, accelerator: 3.01ms, total: 6.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_25750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 418us, accelerator: 177372538.67sec, total: 177372538.67sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 177372538.67sec, total: 177372538.67sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.04ms, accelerator: 0us, total: 143.04ms
train.py:442:<module>, cpu: 5.21ms, accelerator: 177372538.68sec, total: 177372538.69sec
  train.py:360:image_losses, cpu: 2.71ms, accelerator: 177372538.68sec, total: 177372538.68sec
    train.py:322:loss_fn, cpu: 2.70ms, accelerator: 177372538.68sec, total: 177372538.68sec
      train.py:349:msssim, cpu: 2.65ms, accelerator: 177372538.68sec, total: 177372538.68sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.33ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.33ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 275us, total: 1.66ms
      train.py:343:hfe, cpu: 341us, accelerator: 662us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 177372538.67sec, total: 177372538.68sec
train.py:511:<module>, cpu: 8.13sec, accelerator: 3.99ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 996us, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 7.08ms, accelerator: 996us, total: 8.10ms
  __init__.py:185:compute_gradients, cpu: 3.21ms, accelerator: 2.99ms, total: 6.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_26000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 418us, accelerator: 175683276.40sec, total: 175683276.40sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.30ms, accelerator: 175683276.40sec, total: 175683276.40sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.38ms, accelerator: 0us, total: 143.38ms
train.py:442:<module>, cpu: 5.19ms, accelerator: 175683276.41sec, total: 175683276.41sec
  train.py:360:image_losses, cpu: 2.71ms, accelerator: 175683276.41sec, total: 175683276.41sec
    train.py:322:loss_fn, cpu: 2.70ms, accelerator: 175683276.41sec, total: 175683276.41sec
      train.py:349:msssim, cpu: 2.65ms, accelerator: 175683276.41sec, total: 175683276.41sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.32ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.32ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 274us, total: 1.65ms
      train.py:343:hfe, cpu: 340us, accelerator: 657us, total: 1.00ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 175683276.40sec, total: 175683276.41sec
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.95ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 987us, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 7.04ms, accelerator: 987us, total: 8.05ms
  __init__.py:185:compute_gradients, cpu: 3.20ms, accelerator: 2.97ms, total: 6.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_26250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 418us, accelerator: 174025887.00sec, total: 174025887.00sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.30ms, accelerator: 174025887.00sec, total: 174025887.00sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.12ms, accelerator: 0us, total: 143.12ms
train.py:442:<module>, cpu: 5.19ms, accelerator: 174025887.01sec, total: 174025887.01sec
  train.py:360:image_losses, cpu: 2.72ms, accelerator: 174025887.01sec, total: 174025887.01sec
    train.py:322:loss_fn, cpu: 2.70ms, accelerator: 174025887.01sec, total: 174025887.01sec
      train.py:349:msssim, cpu: 2.65ms, accelerator: 174025887.01sec, total: 174025887.01sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.31ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.31ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 272us, total: 1.66ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 174025887.00sec, total: 174025887.01sec
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.93ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 982us, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 6.99ms, accelerator: 982us, total: 7.99ms
  __init__.py:185:compute_gradients, cpu: 3.20ms, accelerator: 2.94ms, total: 6.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_26500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 418us, accelerator: 172399476.84sec, total: 172399476.84sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 172399476.84sec, total: 172399476.84sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.32ms, accelerator: 0us, total: 143.32ms
train.py:442:<module>, cpu: 5.21ms, accelerator: 172399476.85sec, total: 172399476.85sec
  train.py:360:image_losses, cpu: 2.71ms, accelerator: 172399476.85sec, total: 172399476.85sec
    train.py:322:loss_fn, cpu: 2.70ms, accelerator: 172399476.85sec, total: 172399476.85sec
      train.py:349:msssim, cpu: 2.65ms, accelerator: 172399476.85sec, total: 172399476.85sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.30ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.30ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.40ms, accelerator: 271us, total: 1.67ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 172399476.84sec, total: 172399476.85sec
train.py:511:<module>, cpu: 8.12sec, accelerator: 3.90ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 975us, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 6.93ms, accelerator: 975us, total: 7.94ms
  __init__.py:185:compute_gradients, cpu: 3.20ms, accelerator: 2.92ms, total: 6.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_26750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 416us, accelerator: 170803185.39sec, total: 170803185.39sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 170803185.39sec, total: 170803185.39sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.44ms, accelerator: 0us, total: 143.44ms
train.py:442:<module>, cpu: 5.18ms, accelerator: 170803185.40sec, total: 170803185.40sec
  train.py:360:image_losses, cpu: 2.71ms, accelerator: 170803185.39sec, total: 170803185.40sec
    train.py:322:loss_fn, cpu: 2.69ms, accelerator: 170803185.39sec, total: 170803185.40sec
      train.py:349:msssim, cpu: 2.64ms, accelerator: 170803185.39sec, total: 170803185.40sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.29ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.29ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.39ms, accelerator: 269us, total: 1.66ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 170803185.39sec, total: 170803185.40sec
train.py:511:<module>, cpu: 8.13sec, accelerator: 3.87ms, total: 8.13sec
  __init__.py:194:compute_gradients, cpu: 8.12sec, accelerator: 967us, total: 8.12sec
    __init__.py:83:allreduce, cpu: 8.12sec, accelerator: 0us, total: 8.12sec
    __init__.py:86:allreduce, cpu: 6.89ms, accelerator: 967us, total: 7.89ms
  __init__.py:185:compute_gradients, cpu: 3.18ms, accelerator: 2.90ms, total: 6.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_27000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 415us, accelerator: 169236183.69sec, total: 169236183.69sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 169236183.69sec, total: 169236183.69sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.57ms, accelerator: 0us, total: 143.57ms
train.py:442:<module>, cpu: 5.17ms, accelerator: 169236183.70sec, total: 169236183.70sec
  train.py:360:image_losses, cpu: 2.70ms, accelerator: 169236183.69sec, total: 169236183.70sec
    train.py:322:loss_fn, cpu: 2.69ms, accelerator: 169236183.69sec, total: 169236183.70sec
      train.py:349:msssim, cpu: 2.64ms, accelerator: 169236183.69sec, total: 169236183.70sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.28ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.28ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 267us, total: 1.65ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 169236183.69sec, total: 169236183.69sec
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.84ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 961us, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 6.86ms, accelerator: 961us, total: 7.84ms
  __init__.py:185:compute_gradients, cpu: 3.17ms, accelerator: 2.88ms, total: 6.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_27250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 415us, accelerator: 167697672.93sec, total: 167697672.93sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 167697672.93sec, total: 167697672.93sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.52ms, accelerator: 0us, total: 143.52ms
train.py:442:<module>, cpu: 5.26ms, accelerator: 167697672.94sec, total: 167697672.94sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 167697672.93sec, total: 167697672.94sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 167697672.93sec, total: 167697672.94sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 167697672.93sec, total: 167697672.94sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.33ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.33ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.38ms, accelerator: 265us, total: 1.65ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 167697672.93sec, total: 167697672.93sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.81ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 956us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.83ms, accelerator: 956us, total: 7.82ms
  __init__.py:185:compute_gradients, cpu: 3.16ms, accelerator: 2.85ms, total: 6.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_27500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 415us, accelerator: 166186883.08sec, total: 166186883.08sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 166186883.08sec, total: 166186883.08sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.68ms, accelerator: 0us, total: 143.68ms
train.py:442:<module>, cpu: 5.26ms, accelerator: 166186883.09sec, total: 166186883.09sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 166186883.09sec, total: 166186883.09sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 166186883.09sec, total: 166186883.09sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 166186883.09sec, total: 166186883.09sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.32ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.32ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 264us, total: 1.64ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 166186883.08sec, total: 166186883.09sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.78ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 949us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.88ms, accelerator: 949us, total: 7.85ms
  __init__.py:185:compute_gradients, cpu: 3.16ms, accelerator: 2.83ms, total: 6.03ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_27750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 414us, accelerator: 164703071.63sec, total: 164703071.63sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 164703071.62sec, total: 164703071.62sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.86ms, accelerator: 0us, total: 143.86ms
train.py:442:<module>, cpu: 5.27ms, accelerator: 164703071.63sec, total: 164703071.64sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 164703071.63sec, total: 164703071.63sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 164703071.63sec, total: 164703071.63sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 164703071.63sec, total: 164703071.63sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.31ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.31ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.37ms, accelerator: 263us, total: 1.63ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 164703071.63sec, total: 164703071.63sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.76ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 943us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.89ms, accelerator: 943us, total: 7.85ms
  __init__.py:185:compute_gradients, cpu: 3.15ms, accelerator: 2.82ms, total: 6.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_28000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 427us, accelerator: 163245522.32sec, total: 163245522.32sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 163245522.32sec, total: 163245522.32sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 144.20ms, accelerator: 0us, total: 144.20ms
train.py:442:<module>, cpu: 5.27ms, accelerator: 163245522.33sec, total: 163245522.33sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 163245522.32sec, total: 163245522.33sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 163245522.32sec, total: 163245522.33sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 163245522.32sec, total: 163245522.33sec
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.30ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.30ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 260us, total: 1.62ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 163245522.32sec, total: 163245522.32sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.74ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 939us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.87ms, accelerator: 939us, total: 7.83ms
  __init__.py:185:compute_gradients, cpu: 3.14ms, accelerator: 2.80ms, total: 5.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_28250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 425us, accelerator: 161813544.05sec, total: 161813544.05sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 161813544.05sec, total: 161813544.05sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 144.02ms, accelerator: 0us, total: 144.02ms
train.py:442:<module>, cpu: 5.27ms, accelerator: 161813544.06sec, total: 161813544.07sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 161813544.06sec, total: 161813544.06sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 161813544.06sec, total: 161813544.06sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 161813544.06sec, total: 161813544.06sec
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.29ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.29ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 259us, total: 1.63ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 161813544.05sec, total: 161813544.06sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.72ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 935us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.85ms, accelerator: 935us, total: 7.80ms
  __init__.py:185:compute_gradients, cpu: 3.15ms, accelerator: 2.78ms, total: 5.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_28500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 425us, accelerator: 160406469.76sec, total: 160406469.76sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 160406469.75sec, total: 160406469.76sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.80ms, accelerator: 0us, total: 143.80ms
train.py:442:<module>, cpu: 5.25ms, accelerator: 160406469.76sec, total: 160406469.77sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 160406469.76sec, total: 160406469.76sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 160406469.76sec, total: 160406469.76sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 160406469.76sec, total: 160406469.76sec
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.28ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.28ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.36ms, accelerator: 255us, total: 1.62ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 160406469.76sec, total: 160406469.76sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.69ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 928us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.80ms, accelerator: 928us, total: 7.76ms
  __init__.py:185:compute_gradients, cpu: 3.13ms, accelerator: 2.76ms, total: 5.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_28750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 424us, accelerator: 159023655.36sec, total: 159023655.36sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 159023655.36sec, total: 159023655.36sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.93ms, accelerator: 0us, total: 143.93ms
train.py:442:<module>, cpu: 5.27ms, accelerator: 159023655.37sec, total: 159023655.37sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 159023655.37sec, total: 159023655.37sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 159023655.37sec, total: 159023655.37sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 159023655.37sec, total: 159023655.37sec
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.27ms, total: 3.31ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.27ms, total: 3.30ms
      train.py:342:hfe, cpu: 1.35ms, accelerator: 254us, total: 1.61ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 159023655.36sec, total: 159023655.37sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.77ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.03ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.76ms, accelerator: 1.03ms, total: 7.81ms
  __init__.py:185:compute_gradients, cpu: 3.16ms, accelerator: 2.74ms, total: 5.93ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_29000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 423us, accelerator: 157664478.82sec, total: 157664478.82sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 157664478.82sec, total: 157664478.82sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.60ms, accelerator: 0us, total: 143.60ms
train.py:442:<module>, cpu: 5.24ms, accelerator: 157664478.83sec, total: 157664478.83sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 157664478.83sec, total: 157664478.83sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 157664478.83sec, total: 157664478.83sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 157664478.83sec, total: 157664478.83sec
  train.py:359:image_losses, cpu: 2.02ms, accelerator: 1.26ms, total: 3.29ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.26ms, total: 3.28ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 252us, total: 1.60ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 157664478.82sec, total: 157664478.83sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.76ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.02ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.73ms, accelerator: 1.02ms, total: 7.77ms
  __init__.py:185:compute_gradients, cpu: 3.15ms, accelerator: 2.74ms, total: 5.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_29250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 423us, accelerator: 156328339.17sec, total: 156328339.17sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 156328339.17sec, total: 156328339.17sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.64ms, accelerator: 0us, total: 143.64ms
train.py:442:<module>, cpu: 5.24ms, accelerator: 156328339.18sec, total: 156328339.18sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 156328339.17sec, total: 156328339.18sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 156328339.17sec, total: 156328339.18sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 156328339.17sec, total: 156328339.18sec
  train.py:359:image_losses, cpu: 2.02ms, accelerator: 1.25ms, total: 3.28ms
    train.py:322:loss_fn, cpu: 2.00ms, accelerator: 1.25ms, total: 3.26ms
      train.py:342:hfe, cpu: 1.34ms, accelerator: 251us, total: 1.59ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 156328339.17sec, total: 156328339.18sec
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.74ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.02ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 6.73ms, accelerator: 1.02ms, total: 7.76ms
  __init__.py:185:compute_gradients, cpu: 3.14ms, accelerator: 2.72ms, total: 5.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_29500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 422us, accelerator: 155014655.65sec, total: 155014655.65sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 155014655.65sec, total: 155014655.65sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.30ms, accelerator: 0us, total: 143.30ms
train.py:442:<module>, cpu: 5.22ms, accelerator: 155014655.65sec, total: 155014655.66sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 155014655.65sec, total: 155014655.65sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 155014655.65sec, total: 155014655.65sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 155014655.65sec, total: 155014655.65sec
  train.py:359:image_losses, cpu: 2.01ms, accelerator: 1.24ms, total: 3.26ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.24ms, total: 3.24ms
      train.py:342:hfe, cpu: 1.33ms, accelerator: 251us, total: 1.58ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 155014655.65sec, total: 155014655.65sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.72ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.01ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.71ms, accelerator: 1.01ms, total: 7.75ms
  __init__.py:185:compute_gradients, cpu: 3.15ms, accelerator: 2.71ms, total: 5.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_29750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 423us, accelerator: 153722866.85sec, total: 153722866.85sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 153722866.85sec, total: 153722866.85sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.10ms, accelerator: 0us, total: 143.10ms
train.py:442:<module>, cpu: 5.21ms, accelerator: 153722866.86sec, total: 153722866.86sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 153722866.86sec, total: 153722866.86sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 153722866.86sec, total: 153722866.86sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 153722866.86sec, total: 153722866.86sec
  train.py:359:image_losses, cpu: 2.00ms, accelerator: 1.23ms, total: 3.24ms
    train.py:322:loss_fn, cpu: 1.98ms, accelerator: 1.23ms, total: 3.22ms
      train.py:342:hfe, cpu: 1.32ms, accelerator: 250us, total: 1.57ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 153722866.85sec, total: 153722866.86sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.70ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.00ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.68ms, accelerator: 1.00ms, total: 7.70ms
  __init__.py:185:compute_gradients, cpu: 3.14ms, accelerator: 2.70ms, total: 5.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_30000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 421us, accelerator: 152452429.93sec, total: 152452429.93sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 152452429.93sec, total: 152452429.93sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.85ms, accelerator: 0us, total: 142.85ms
train.py:442:<module>, cpu: 5.19ms, accelerator: 152452429.94sec, total: 152452429.95sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 152452429.94sec, total: 152452429.94sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 152452429.94sec, total: 152452429.94sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 152452429.94sec, total: 152452429.94sec
  train.py:359:image_losses, cpu: 1.99ms, accelerator: 1.22ms, total: 3.22ms
    train.py:322:loss_fn, cpu: 1.97ms, accelerator: 1.22ms, total: 3.20ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 246us, total: 1.56ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 152452429.94sec, total: 152452429.94sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.67ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 996us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.64ms, accelerator: 996us, total: 7.66ms
  __init__.py:185:compute_gradients, cpu: 3.13ms, accelerator: 2.68ms, total: 5.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_30250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 422us, accelerator: 151202819.85sec, total: 151202819.85sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 151202819.85sec, total: 151202819.85sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 143.00ms, accelerator: 0us, total: 143.00ms
train.py:442:<module>, cpu: 5.18ms, accelerator: 151202819.86sec, total: 151202819.86sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 151202819.86sec, total: 151202819.86sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 151202819.86sec, total: 151202819.86sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 151202819.86sec, total: 151202819.86sec
  train.py:359:image_losses, cpu: 1.98ms, accelerator: 1.21ms, total: 3.20ms
    train.py:322:loss_fn, cpu: 1.96ms, accelerator: 1.21ms, total: 3.19ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 245us, total: 1.55ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 151202819.85sec, total: 151202819.86sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.65ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 991us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.60ms, accelerator: 991us, total: 7.62ms
  __init__.py:185:compute_gradients, cpu: 3.12ms, accelerator: 2.66ms, total: 5.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_30500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 421us, accelerator: 149973528.63sec, total: 149973528.64sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 149973528.63sec, total: 149973528.63sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.61ms, accelerator: 0us, total: 142.61ms
train.py:442:<module>, cpu: 5.20ms, accelerator: 149973528.64sec, total: 149973528.65sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 149973528.64sec, total: 149973528.64sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 149973528.64sec, total: 149973528.64sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 149973528.64sec, total: 149973528.64sec
  train.py:359:image_losses, cpu: 1.99ms, accelerator: 1.20ms, total: 3.20ms
    train.py:322:loss_fn, cpu: 1.97ms, accelerator: 1.20ms, total: 3.18ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 243us, total: 1.56ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 149973528.64sec, total: 149973528.64sec
train.py:511:<module>, cpu: 8.08sec, accelerator: 3.63ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 987us, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 6.57ms, accelerator: 987us, total: 7.58ms
  __init__.py:185:compute_gradients, cpu: 3.11ms, accelerator: 2.65ms, total: 5.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_30750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 421us, accelerator: 148764064.69sec, total: 148764064.69sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 148764064.69sec, total: 148764064.69sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.25ms, accelerator: 0us, total: 142.25ms
train.py:442:<module>, cpu: 5.19ms, accelerator: 148764064.70sec, total: 148764064.71sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 148764064.70sec, total: 148764064.70sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 148764064.70sec, total: 148764064.70sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 148764064.70sec, total: 148764064.70sec
  train.py:359:image_losses, cpu: 1.98ms, accelerator: 1.20ms, total: 3.18ms
    train.py:322:loss_fn, cpu: 1.96ms, accelerator: 1.20ms, total: 3.17ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 243us, total: 1.55ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 148764064.70sec, total: 148764064.70sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.61ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 981us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.64ms, accelerator: 981us, total: 7.65ms
  __init__.py:185:compute_gradients, cpu: 3.10ms, accelerator: 2.63ms, total: 5.77ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2132.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_31000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 420us, accelerator: 147573952.18sec, total: 147573952.18sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 147573952.17sec, total: 147573952.18sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.35ms, accelerator: 0us, total: 142.35ms
train.py:442:<module>, cpu: 5.22ms, accelerator: 147573952.18sec, total: 147573952.19sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 147573952.18sec, total: 147573952.18sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 147573952.18sec, total: 147573952.18sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 147573952.18sec, total: 147573952.18sec
  train.py:359:image_losses, cpu: 2.01ms, accelerator: 1.19ms, total: 3.21ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.19ms, total: 3.19ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 241us, total: 1.54ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 147573952.18sec, total: 147573952.18sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.59ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 976us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.60ms, accelerator: 976us, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.10ms, accelerator: 2.61ms, total: 5.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_31250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 420us, accelerator: 146402730.33sec, total: 146402730.33sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 146402730.33sec, total: 146402730.33sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.07ms, accelerator: 0us, total: 142.07ms
train.py:442:<module>, cpu: 5.21ms, accelerator: 146402730.34sec, total: 146402730.35sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 146402730.34sec, total: 146402730.34sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 146402730.34sec, total: 146402730.34sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 146402730.34sec, total: 146402730.34sec
  train.py:359:image_losses, cpu: 2.00ms, accelerator: 1.18ms, total: 3.19ms
    train.py:322:loss_fn, cpu: 1.98ms, accelerator: 1.18ms, total: 3.17ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 240us, total: 1.53ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 146402730.34sec, total: 146402730.34sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.56ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 972us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.59ms, accelerator: 972us, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.09ms, accelerator: 2.59ms, total: 5.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_31500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 420us, accelerator: 145249952.93sec, total: 145249952.93sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 145249952.93sec, total: 145249952.93sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.43ms, accelerator: 0us, total: 142.43ms
train.py:442:<module>, cpu: 5.20ms, accelerator: 145249952.94sec, total: 145249952.94sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 145249952.93sec, total: 145249952.94sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 145249952.93sec, total: 145249952.94sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 145249952.93sec, total: 145249952.94sec
  train.py:359:image_losses, cpu: 1.99ms, accelerator: 1.17ms, total: 3.18ms
    train.py:322:loss_fn, cpu: 1.98ms, accelerator: 1.17ms, total: 3.16ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 239us, total: 1.53ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 145249952.93sec, total: 145249952.94sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.55ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 974us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.68ms, accelerator: 974us, total: 7.68ms
  __init__.py:185:compute_gradients, cpu: 3.08ms, accelerator: 2.57ms, total: 5.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_31750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 418us, accelerator: 144115187.67sec, total: 144115187.67sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 144115187.67sec, total: 144115187.67sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.29ms, accelerator: 0us, total: 142.29ms
train.py:442:<module>, cpu: 5.18ms, accelerator: 144115187.68sec, total: 144115187.68sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 144115187.68sec, total: 144115187.68sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 144115187.68sec, total: 144115187.68sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 144115187.68sec, total: 144115187.68sec
  train.py:359:image_losses, cpu: 1.98ms, accelerator: 1.21ms, total: 3.21ms
    train.py:322:loss_fn, cpu: 1.97ms, accelerator: 1.21ms, total: 3.19ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 238us, total: 1.52ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 144115187.67sec, total: 144115187.68sec
train.py:511:<module>, cpu: 8.08sec, accelerator: 3.54ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 966us, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 6.65ms, accelerator: 966us, total: 7.64ms
  __init__.py:185:compute_gradients, cpu: 3.10ms, accelerator: 2.57ms, total: 5.72ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_32000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 418us, accelerator: 142998015.67sec, total: 142998015.68sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 142998015.67sec, total: 142998015.67sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.00ms, accelerator: 0us, total: 142.00ms
train.py:442:<module>, cpu: 5.17ms, accelerator: 142998015.68sec, total: 142998015.69sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 142998015.68sec, total: 142998015.68sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 142998015.68sec, total: 142998015.68sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 142998015.68sec, total: 142998015.68sec
  train.py:359:image_losses, cpu: 1.98ms, accelerator: 1.20ms, total: 3.19ms
    train.py:322:loss_fn, cpu: 1.96ms, accelerator: 1.20ms, total: 3.17ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 234us, total: 1.51ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 142998015.68sec, total: 142998015.68sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.52ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 962us, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.62ms, accelerator: 962us, total: 7.61ms
  __init__.py:185:compute_gradients, cpu: 3.10ms, accelerator: 2.56ms, total: 5.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_32250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 417us, accelerator: 141898030.94sec, total: 141898030.94sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 141898030.94sec, total: 141898030.94sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.73ms, accelerator: 0us, total: 141.73ms
train.py:442:<module>, cpu: 5.16ms, accelerator: 141898030.95sec, total: 141898030.95sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 141898030.94sec, total: 141898030.95sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 141898030.94sec, total: 141898030.95sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 141898030.94sec, total: 141898030.95sec
  train.py:359:image_losses, cpu: 1.97ms, accelerator: 1.19ms, total: 3.17ms
    train.py:322:loss_fn, cpu: 1.95ms, accelerator: 1.19ms, total: 3.15ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 232us, total: 1.51ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 141898030.94sec, total: 141898030.94sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.50ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 954us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.61ms, accelerator: 954us, total: 7.59ms
  __init__.py:185:compute_gradients, cpu: 3.08ms, accelerator: 2.54ms, total: 5.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_32500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 416us, accelerator: 140814839.86sec, total: 140814839.86sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 140814839.86sec, total: 140814839.86sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.25ms, accelerator: 0us, total: 142.25ms
train.py:442:<module>, cpu: 5.16ms, accelerator: 140814839.87sec, total: 140814839.87sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 140814839.87sec, total: 140814839.87sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 140814839.87sec, total: 140814839.87sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 140814839.87sec, total: 140814839.87sec
  train.py:359:image_losses, cpu: 1.97ms, accelerator: 1.19ms, total: 3.17ms
    train.py:322:loss_fn, cpu: 1.96ms, accelerator: 1.19ms, total: 3.15ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 232us, total: 1.51ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 140814839.86sec, total: 140814839.87sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.48ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 950us, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.58ms, accelerator: 950us, total: 7.56ms
  __init__.py:185:compute_gradients, cpu: 3.08ms, accelerator: 2.53ms, total: 5.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_32750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 416us, accelerator: 139748060.77sec, total: 139748060.77sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 139748060.77sec, total: 139748060.77sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.35ms, accelerator: 0us, total: 142.35ms
train.py:442:<module>, cpu: 5.15ms, accelerator: 139748060.78sec, total: 139748060.78sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 139748060.78sec, total: 139748060.78sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 139748060.78sec, total: 139748060.78sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 139748060.78sec, total: 139748060.78sec
  train.py:359:image_losses, cpu: 1.97ms, accelerator: 1.18ms, total: 3.15ms
    train.py:322:loss_fn, cpu: 1.95ms, accelerator: 1.18ms, total: 3.14ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 231us, total: 1.50ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 139748060.77sec, total: 139748060.78sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.46ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 947us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.54ms, accelerator: 947us, total: 7.51ms
  __init__.py:185:compute_gradients, cpu: 3.07ms, accelerator: 2.51ms, total: 5.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_33000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 414us, accelerator: 138697323.47sec, total: 138697323.47sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 138697323.47sec, total: 138697323.47sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.39ms, accelerator: 0us, total: 142.39ms
train.py:442:<module>, cpu: 5.14ms, accelerator: 138697323.48sec, total: 138697323.49sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 138697323.48sec, total: 138697323.48sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 138697323.48sec, total: 138697323.48sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 138697323.48sec, total: 138697323.48sec
  train.py:359:image_losses, cpu: 1.96ms, accelerator: 1.26ms, total: 3.22ms
    train.py:322:loss_fn, cpu: 1.94ms, accelerator: 1.26ms, total: 3.21ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 231us, total: 1.49ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 138697323.48sec, total: 138697323.48sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.45ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 940us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.52ms, accelerator: 940us, total: 7.48ms
  __init__.py:185:compute_gradients, cpu: 3.06ms, accelerator: 2.51ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_33250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 413us, accelerator: 137662268.82sec, total: 137662268.82sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 137662268.82sec, total: 137662268.82sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.60ms, accelerator: 0us, total: 142.60ms
train.py:442:<module>, cpu: 5.12ms, accelerator: 137662268.83sec, total: 137662268.83sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 137662268.83sec, total: 137662268.83sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 137662268.83sec, total: 137662268.83sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 137662268.83sec, total: 137662268.83sec
  train.py:359:image_losses, cpu: 1.95ms, accelerator: 1.29ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 1.93ms, accelerator: 1.29ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 229us, total: 1.49ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 137662268.82sec, total: 137662268.83sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.46ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 937us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.47ms, accelerator: 937us, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 3.06ms, accelerator: 2.53ms, total: 5.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_33500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 413us, accelerator: 136642548.31sec, total: 136642548.31sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 136642548.31sec, total: 136642548.31sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.32ms, accelerator: 0us, total: 142.32ms
train.py:442:<module>, cpu: 5.13ms, accelerator: 136642548.32sec, total: 136642548.32sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 136642548.32sec, total: 136642548.32sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 136642548.32sec, total: 136642548.32sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 136642548.32sec, total: 136642548.32sec
  train.py:359:image_losses, cpu: 1.94ms, accelerator: 1.28ms, total: 3.24ms
    train.py:322:loss_fn, cpu: 1.92ms, accelerator: 1.28ms, total: 3.22ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 227us, total: 1.48ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 136642548.31sec, total: 136642548.32sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.53ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 933us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.47ms, accelerator: 933us, total: 7.42ms
  __init__.py:185:compute_gradients, cpu: 3.06ms, accelerator: 2.60ms, total: 5.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_33750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 413us, accelerator: 135637823.69sec, total: 135637823.69sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 135637823.69sec, total: 135637823.69sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.42ms, accelerator: 0us, total: 142.42ms
train.py:442:<module>, cpu: 5.22ms, accelerator: 135637823.70sec, total: 135637823.70sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 135637823.70sec, total: 135637823.70sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 135637823.70sec, total: 135637823.70sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 135637823.70sec, total: 135637823.70sec
  train.py:359:image_losses, cpu: 1.98ms, accelerator: 1.28ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 1.96ms, accelerator: 1.28ms, total: 3.25ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 227us, total: 1.52ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 135637823.69sec, total: 135637823.70sec
train.py:511:<module>, cpu: 8.08sec, accelerator: 3.52ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 929us, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.49ms, accelerator: 929us, total: 7.45ms
  __init__.py:185:compute_gradients, cpu: 3.04ms, accelerator: 2.60ms, total: 5.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_34000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 412us, accelerator: 134647766.58sec, total: 134647766.58sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 134647766.58sec, total: 134647766.58sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.17ms, accelerator: 0us, total: 142.17ms
train.py:442:<module>, cpu: 5.25ms, accelerator: 134647766.59sec, total: 134647766.60sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 134647766.59sec, total: 134647766.59sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 134647766.59sec, total: 134647766.59sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 134647766.59sec, total: 134647766.59sec
  train.py:359:image_losses, cpu: 2.01ms, accelerator: 1.27ms, total: 3.29ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.27ms, total: 3.27ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 226us, total: 1.51ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 134647766.59sec, total: 134647766.59sec
train.py:511:<module>, cpu: 8.08sec, accelerator: 3.50ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 924us, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 6.46ms, accelerator: 924us, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 3.04ms, accelerator: 2.58ms, total: 5.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_34250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 411us, accelerator: 133672058.13sec, total: 133672058.13sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 133672058.13sec, total: 133672058.13sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.38ms, accelerator: 0us, total: 142.38ms
train.py:442:<module>, cpu: 5.39ms, accelerator: 133672058.14sec, total: 133672058.14sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 133672058.14sec, total: 133672058.14sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 133672058.14sec, total: 133672058.14sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 133672058.14sec, total: 133672058.14sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.26ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.26ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 226us, total: 1.53ms
      train.py:343:hfe, cpu: 479us, accelerator: 618us, total: 1.10ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 133672058.13sec, total: 133672058.14sec
train.py:511:<module>, cpu: 8.07sec, accelerator: 3.59ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 920us, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 6.51ms, accelerator: 920us, total: 7.46ms
  __init__.py:185:compute_gradients, cpu: 3.03ms, accelerator: 2.67ms, total: 5.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_34500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 411us, accelerator: 132710388.65sec, total: 132710388.65sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 132710388.65sec, total: 132710388.65sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.01ms, accelerator: 0us, total: 142.01ms
train.py:442:<module>, cpu: 5.39ms, accelerator: 132710388.65sec, total: 132710388.66sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 132710388.65sec, total: 132710388.66sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 132710388.65sec, total: 132710388.66sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 132710388.65sec, total: 132710388.65sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.25ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.25ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 223us, total: 1.52ms
      train.py:343:hfe, cpu: 486us, accelerator: 614us, total: 1.10ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 132710388.65sec, total: 132710388.65sec
train.py:511:<module>, cpu: 8.08sec, accelerator: 3.58ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 918us, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 6.48ms, accelerator: 918us, total: 7.42ms
  __init__.py:185:compute_gradients, cpu: 3.03ms, accelerator: 2.66ms, total: 5.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2116.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_34750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 410us, accelerator: 131762457.30sec, total: 131762457.30sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 131762457.30sec, total: 131762457.30sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 142.13ms, accelerator: 0us, total: 142.13ms
train.py:442:<module>, cpu: 5.38ms, accelerator: 131762457.31sec, total: 131762457.31sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 131762457.30sec, total: 131762457.31sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 131762457.30sec, total: 131762457.31sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 131762457.30sec, total: 131762457.31sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.25ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.25ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 222us, total: 1.52ms
      train.py:343:hfe, cpu: 484us, accelerator: 611us, total: 1.10ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 131762457.30sec, total: 131762457.31sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.57ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 927us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.44ms, accelerator: 927us, total: 7.39ms
  __init__.py:185:compute_gradients, cpu: 3.02ms, accelerator: 2.64ms, total: 5.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2123.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_35000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 412us, accelerator: 130827971.79sec, total: 130827971.79sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 130827971.79sec, total: 130827971.79sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.92ms, accelerator: 0us, total: 141.92ms
train.py:442:<module>, cpu: 5.37ms, accelerator: 130827971.79sec, total: 130827971.80sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 130827971.79sec, total: 130827971.79sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 130827971.79sec, total: 130827971.79sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 130827971.79sec, total: 130827971.79sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.27ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.27ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 244us, total: 1.54ms
      train.py:343:hfe, cpu: 482us, accelerator: 611us, total: 1.10ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 130827971.79sec, total: 130827971.79sec
train.py:511:<module>, cpu: 8.10sec, accelerator: 3.55ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 918us, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 6.59ms, accelerator: 918us, total: 7.54ms
  __init__.py:185:compute_gradients, cpu: 3.01ms, accelerator: 2.63ms, total: 5.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_35250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 411us, accelerator: 129906648.04sec, total: 129906648.04sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 129906648.04sec, total: 129906648.04sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.86ms, accelerator: 0us, total: 141.86ms
train.py:442:<module>, cpu: 5.35ms, accelerator: 129906648.05sec, total: 129906648.05sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 129906648.05sec, total: 129906648.05sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 129906648.05sec, total: 129906648.05sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 129906648.05sec, total: 129906648.05sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.28ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 243us, total: 1.53ms
      train.py:343:hfe, cpu: 480us, accelerator: 608us, total: 1.09ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 129906648.04sec, total: 129906648.05sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.54ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 916us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.59ms, accelerator: 916us, total: 7.53ms
  __init__.py:185:compute_gradients, cpu: 3.01ms, accelerator: 2.62ms, total: 5.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_35500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 410us, accelerator: 128998209.94sec, total: 128998209.95sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 128998209.94sec, total: 128998209.94sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.83ms, accelerator: 0us, total: 141.83ms
train.py:442:<module>, cpu: 5.34ms, accelerator: 128998209.95sec, total: 128998209.96sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 128998209.95sec, total: 128998209.95sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 128998209.95sec, total: 128998209.95sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 128998209.95sec, total: 128998209.95sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 242us, total: 1.52ms
      train.py:343:hfe, cpu: 477us, accelerator: 606us, total: 1.09ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 128998209.95sec, total: 128998209.95sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.52ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 912us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.56ms, accelerator: 912us, total: 7.49ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.61ms, total: 5.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_35750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 410us, accelerator: 128102389.04sec, total: 128102389.04sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 128102389.04sec, total: 128102389.04sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.73ms, accelerator: 0us, total: 141.73ms
train.py:442:<module>, cpu: 5.38ms, accelerator: 128102389.05sec, total: 128102389.05sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 128102389.05sec, total: 128102389.05sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 128102389.05sec, total: 128102389.05sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 128102389.05sec, total: 128102389.05sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.27ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.27ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 240us, total: 1.52ms
      train.py:343:hfe, cpu: 479us, accelerator: 604us, total: 1.09ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 128102389.04sec, total: 128102389.05sec
train.py:511:<module>, cpu: 8.08sec, accelerator: 3.50ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 905us, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 6.53ms, accelerator: 905us, total: 7.46ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.59ms, total: 5.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_36000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 409us, accelerator: 127218924.29sec, total: 127218924.29sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 127218924.29sec, total: 127218924.29sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.55ms, accelerator: 0us, total: 141.55ms
train.py:442:<module>, cpu: 5.38ms, accelerator: 127218924.30sec, total: 127218924.30sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 127218924.29sec, total: 127218924.30sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 127218924.29sec, total: 127218924.30sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 127218924.29sec, total: 127218924.30sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.26ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.26ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 239us, total: 1.51ms
      train.py:343:hfe, cpu: 482us, accelerator: 602us, total: 1.08ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 127218924.29sec, total: 127218924.30sec
train.py:511:<module>, cpu: 8.08sec, accelerator: 3.48ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 902us, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 6.50ms, accelerator: 902us, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.58ms, total: 5.61ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_36250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 420us, accelerator: 126347561.80sec, total: 126347561.80sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 126347561.79sec, total: 126347561.79sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.28ms, accelerator: 0us, total: 141.28ms
train.py:442:<module>, cpu: 5.40ms, accelerator: 126347561.80sec, total: 126347561.81sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 126347561.80sec, total: 126347561.80sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 126347561.80sec, total: 126347561.80sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 126347561.80sec, total: 126347561.80sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.25ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.25ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 238us, total: 1.53ms
      train.py:343:hfe, cpu: 481us, accelerator: 596us, total: 1.08ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 126347561.80sec, total: 126347561.80sec
train.py:511:<module>, cpu: 8.09sec, accelerator: 3.54ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 978us, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 6.47ms, accelerator: 978us, total: 7.48ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.57ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_36500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 419us, accelerator: 125488054.57sec, total: 125488054.57sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 125488054.57sec, total: 125488054.57sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.48ms, accelerator: 0us, total: 141.48ms
train.py:442:<module>, cpu: 5.38ms, accelerator: 125488054.58sec, total: 125488054.58sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 125488054.58sec, total: 125488054.58sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 125488054.58sec, total: 125488054.58sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 125488054.58sec, total: 125488054.58sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.25ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.25ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 238us, total: 1.52ms
      train.py:343:hfe, cpu: 480us, accelerator: 592us, total: 1.08ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 125488054.57sec, total: 125488054.58sec
train.py:511:<module>, cpu: 8.07sec, accelerator: 3.53ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 976us, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 6.45ms, accelerator: 976us, total: 7.44ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.55ms, total: 5.57ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_36750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 421us, accelerator: 124640162.31sec, total: 124640162.31sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 124640162.31sec, total: 124640162.31sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.38ms, accelerator: 0us, total: 141.38ms
train.py:442:<module>, cpu: 5.39ms, accelerator: 124640162.32sec, total: 124640162.32sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 124640162.32sec, total: 124640162.32sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 124640162.32sec, total: 124640162.32sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 124640162.32sec, total: 124640162.32sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.24ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.24ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 234us, total: 1.52ms
      train.py:343:hfe, cpu: 479us, accelerator: 589us, total: 1.07ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 124640162.31sec, total: 124640162.32sec
train.py:511:<module>, cpu: 8.07sec, accelerator: 3.50ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 970us, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 6.41ms, accelerator: 970us, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.54ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_37000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 419us, accelerator: 123803651.15sec, total: 123803651.16sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 123803651.15sec, total: 123803651.15sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.16ms, accelerator: 0us, total: 141.16ms
train.py:442:<module>, cpu: 5.38ms, accelerator: 123803651.16sec, total: 123803651.17sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 123803651.16sec, total: 123803651.16sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 123803651.16sec, total: 123803651.16sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 123803651.16sec, total: 123803651.16sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.23ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.23ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 234us, total: 1.51ms
      train.py:343:hfe, cpu: 478us, accelerator: 585us, total: 1.07ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 123803651.16sec, total: 123803651.16sec
train.py:511:<module>, cpu: 8.06sec, accelerator: 3.49ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 966us, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 6.44ms, accelerator: 966us, total: 7.43ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.52ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_37250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 421us, accelerator: 122978293.48sec, total: 122978293.48sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 122978293.48sec, total: 122978293.48sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.20ms, accelerator: 0us, total: 141.20ms
train.py:442:<module>, cpu: 5.38ms, accelerator: 122978293.49sec, total: 122978293.49sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 122978293.48sec, total: 122978293.49sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 122978293.48sec, total: 122978293.49sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 122978293.48sec, total: 122978293.49sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.23ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.23ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 233us, total: 1.50ms
      train.py:343:hfe, cpu: 476us, accelerator: 583us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 122978293.48sec, total: 122978293.49sec
train.py:511:<module>, cpu: 8.07sec, accelerator: 3.48ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 965us, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 6.42ms, accelerator: 965us, total: 7.41ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.51ms, total: 5.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_37500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 421us, accelerator: 122163867.70sec, total: 122163867.70sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 122163867.69sec, total: 122163867.70sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.29ms, accelerator: 0us, total: 141.29ms
train.py:442:<module>, cpu: 5.36ms, accelerator: 122163867.70sec, total: 122163867.71sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 122163867.70sec, total: 122163867.70sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 122163867.70sec, total: 122163867.70sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 122163867.70sec, total: 122163867.70sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.22ms, total: 3.32ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.22ms, total: 3.30ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 231us, total: 1.50ms
      train.py:343:hfe, cpu: 474us, accelerator: 579us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 122163867.70sec, total: 122163867.70sec
train.py:511:<module>, cpu: 8.07sec, accelerator: 3.58ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 957us, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 6.39ms, accelerator: 957us, total: 7.37ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.62ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_37750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 420us, accelerator: 121360158.04sec, total: 121360158.04sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 121360158.04sec, total: 121360158.04sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.37ms, accelerator: 0us, total: 141.37ms
train.py:442:<module>, cpu: 5.35ms, accelerator: 121360158.05sec, total: 121360158.05sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 121360158.04sec, total: 121360158.05sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 121360158.04sec, total: 121360158.05sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 121360158.04sec, total: 121360158.05sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.21ms, total: 3.30ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.21ms, total: 3.29ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 231us, total: 1.49ms
      train.py:343:hfe, cpu: 471us, accelerator: 575us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 121360158.04sec, total: 121360158.05sec
train.py:511:<module>, cpu: 8.06sec, accelerator: 3.56ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 953us, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 6.36ms, accelerator: 953us, total: 7.34ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.61ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_38000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 419us, accelerator: 120566954.39sec, total: 120566954.39sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 120566954.39sec, total: 120566954.39sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.20ms, accelerator: 0us, total: 141.20ms
train.py:442:<module>, cpu: 5.34ms, accelerator: 120566954.40sec, total: 120566954.40sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 120566954.40sec, total: 120566954.40sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 120566954.40sec, total: 120566954.40sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 120566954.40sec, total: 120566954.40sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.21ms, total: 3.29ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.21ms, total: 3.27ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 230us, total: 1.48ms
      train.py:343:hfe, cpu: 471us, accelerator: 573us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 120566954.39sec, total: 120566954.40sec
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.54ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 948us, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 6.33ms, accelerator: 948us, total: 7.31ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.59ms, total: 5.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_38250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 419us, accelerator: 119784052.09sec, total: 119784052.09sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 119784052.09sec, total: 119784052.09sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.94ms, accelerator: 0us, total: 140.94ms
train.py:442:<module>, cpu: 5.35ms, accelerator: 119784052.10sec, total: 119784052.10sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 119784052.10sec, total: 119784052.10sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 119784052.10sec, total: 119784052.10sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 119784052.10sec, total: 119784052.10sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.20ms, total: 3.30ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.20ms, total: 3.28ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 229us, total: 1.47ms
      train.py:343:hfe, cpu: 469us, accelerator: 569us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 119784052.09sec, total: 119784052.10sec
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.52ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 944us, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 6.31ms, accelerator: 944us, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.58ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_38500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 418us, accelerator: 119011251.76sec, total: 119011251.76sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 119011251.75sec, total: 119011251.76sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.71ms, accelerator: 0us, total: 140.71ms
train.py:442:<module>, cpu: 5.34ms, accelerator: 119011251.76sec, total: 119011251.77sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 119011251.76sec, total: 119011251.76sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 119011251.76sec, total: 119011251.76sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 119011251.76sec, total: 119011251.76sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.20ms, total: 3.29ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.20ms, total: 3.27ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 229us, total: 1.47ms
      train.py:343:hfe, cpu: 465us, accelerator: 566us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 119011251.76sec, total: 119011251.76sec
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.50ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 939us, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 6.29ms, accelerator: 939us, total: 7.25ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.56ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_38750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 416us, accelerator: 118248359.12sec, total: 118248359.12sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 118248359.11sec, total: 118248359.12sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.63ms, accelerator: 0us, total: 140.63ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 118248359.12sec, total: 118248359.13sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 118248359.12sec, total: 118248359.12sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 118248359.12sec, total: 118248359.12sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 118248359.12sec, total: 118248359.12sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.21ms, total: 3.29ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.21ms, total: 3.27ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 228us, total: 1.46ms
      train.py:343:hfe, cpu: 463us, accelerator: 576us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 118248359.12sec, total: 118248359.12sec
train.py:511:<module>, cpu: 8.06sec, accelerator: 3.62ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.06ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 6.25ms, accelerator: 1.06ms, total: 7.34ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.57ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2066.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_39000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 416us, accelerator: 117495184.85sec, total: 117495184.85sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 117495184.85sec, total: 117495184.85sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.81ms, accelerator: 0us, total: 140.81ms
train.py:442:<module>, cpu: 5.34ms, accelerator: 117495184.86sec, total: 117495184.87sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 117495184.86sec, total: 117495184.86sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 117495184.86sec, total: 117495184.86sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 117495184.86sec, total: 117495184.86sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.19ms, total: 3.30ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.19ms, total: 3.29ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 225us, total: 1.49ms
      train.py:343:hfe, cpu: 461us, accelerator: 569us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 117495184.86sec, total: 117495184.86sec
train.py:511:<module>, cpu: 8.06sec, accelerator: 3.60ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.05ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 6.23ms, accelerator: 1.05ms, total: 7.31ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.55ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_39250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 416us, accelerator: 116751544.44sec, total: 116751544.44sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 116751544.44sec, total: 116751544.44sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.83ms, accelerator: 0us, total: 140.83ms
train.py:442:<module>, cpu: 5.33ms, accelerator: 116751544.45sec, total: 116751544.46sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 116751544.45sec, total: 116751544.45sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 116751544.45sec, total: 116751544.45sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 116751544.45sec, total: 116751544.45sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.19ms, total: 3.29ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.19ms, total: 3.27ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 224us, total: 1.48ms
      train.py:343:hfe, cpu: 460us, accelerator: 568us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 116751544.45sec, total: 116751544.45sec
train.py:511:<module>, cpu: 8.06sec, accelerator: 3.73ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.04ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 6.21ms, accelerator: 1.04ms, total: 7.28ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.69ms, total: 5.66ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_39500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 414us, accelerator: 116017258.00sec, total: 116017258.00sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 116017258.00sec, total: 116017258.00sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.90ms, accelerator: 0us, total: 140.90ms
train.py:442:<module>, cpu: 5.31ms, accelerator: 116017258.01sec, total: 116017258.01sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 116017258.00sec, total: 116017258.01sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 116017258.00sec, total: 116017258.01sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 116017258.00sec, total: 116017258.01sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.18ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.18ms, total: 3.25ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 223us, total: 1.47ms
      train.py:343:hfe, cpu: 457us, accelerator: 565us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 116017258.00sec, total: 116017258.01sec
train.py:511:<module>, cpu: 8.06sec, accelerator: 3.71ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.04ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 6.17ms, accelerator: 1.04ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.67ms, total: 5.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_39750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 413us, accelerator: 115292150.14sec, total: 115292150.14sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 115292150.14sec, total: 115292150.14sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.63ms, accelerator: 0us, total: 140.63ms
train.py:442:<module>, cpu: 5.30ms, accelerator: 115292150.14sec, total: 115292150.15sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 115292150.14sec, total: 115292150.15sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 115292150.14sec, total: 115292150.15sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 115292150.14sec, total: 115292150.14sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.21ms, total: 3.29ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.21ms, total: 3.28ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 236us, total: 1.48ms
      train.py:343:hfe, cpu: 456us, accelerator: 579us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 115292150.14sec, total: 115292150.14sec
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.72ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.04ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 6.14ms, accelerator: 1.04ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.68ms, total: 5.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_40000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 413us, accelerator: 114576049.83sec, total: 114576049.83sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 114576049.83sec, total: 114576049.83sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.96ms, accelerator: 0us, total: 140.96ms
train.py:442:<module>, cpu: 5.29ms, accelerator: 114576049.83sec, total: 114576049.84sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 114576049.83sec, total: 114576049.83sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 114576049.83sec, total: 114576049.83sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 114576049.83sec, total: 114576049.83sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.21ms, total: 3.28ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.21ms, total: 3.27ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 235us, total: 1.48ms
      train.py:343:hfe, cpu: 454us, accelerator: 577us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 114576049.83sec, total: 114576049.83sec
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.69ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.03ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 6.12ms, accelerator: 1.03ms, total: 7.18ms
  __init__.py:185:compute_gradients, cpu: 2.92ms, accelerator: 2.66ms, total: 5.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2138.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_40250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 414us, accelerator: 113868790.26sec, total: 113868790.26sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 113868790.26sec, total: 113868790.26sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 141.13ms, accelerator: 0us, total: 141.13ms
train.py:442:<module>, cpu: 5.29ms, accelerator: 113868790.27sec, total: 113868790.27sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 113868790.26sec, total: 113868790.27sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 113868790.26sec, total: 113868790.27sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 113868790.26sec, total: 113868790.27sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.20ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.20ms, total: 3.25ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 235us, total: 1.47ms
      train.py:343:hfe, cpu: 453us, accelerator: 573us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 113868790.26sec, total: 113868790.27sec
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.75ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.11ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 6.09ms, accelerator: 1.11ms, total: 7.22ms
  __init__.py:185:compute_gradients, cpu: 2.91ms, accelerator: 2.65ms, total: 5.60ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_40500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 413us, accelerator: 113170208.72sec, total: 113170208.72sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 113170208.72sec, total: 113170208.72sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.88ms, accelerator: 0us, total: 140.88ms
train.py:442:<module>, cpu: 5.27ms, accelerator: 113170208.73sec, total: 113170208.74sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 113170208.73sec, total: 113170208.73sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 113170208.73sec, total: 113170208.73sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 113170208.73sec, total: 113170208.73sec
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.20ms, total: 3.26ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.20ms, total: 3.24ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 234us, total: 1.47ms
      train.py:343:hfe, cpu: 451us, accelerator: 570us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 113170208.73sec, total: 113170208.73sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.74ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.10ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 6.06ms, accelerator: 1.10ms, total: 7.19ms
  __init__.py:185:compute_gradients, cpu: 2.90ms, accelerator: 2.64ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_40750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 414us, accelerator: 112480146.48sec, total: 112480146.48sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 112480146.48sec, total: 112480146.48sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.77ms, accelerator: 0us, total: 140.77ms
train.py:442:<module>, cpu: 5.27ms, accelerator: 112480146.48sec, total: 112480146.49sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 112480146.48sec, total: 112480146.48sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 112480146.48sec, total: 112480146.48sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 112480146.48sec, total: 112480146.48sec
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.19ms, total: 3.24ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.19ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 233us, total: 1.46ms
      train.py:343:hfe, cpu: 450us, accelerator: 567us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 112480146.48sec, total: 112480146.48sec
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.92ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.29ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 6.04ms, accelerator: 1.29ms, total: 7.36ms
  __init__.py:185:compute_gradients, cpu: 2.90ms, accelerator: 2.62ms, total: 5.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_41000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 414us, accelerator: 111798448.62sec, total: 111798448.62sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 111798448.62sec, total: 111798448.62sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.82ms, accelerator: 0us, total: 140.82ms
train.py:442:<module>, cpu: 5.26ms, accelerator: 111798448.63sec, total: 111798448.63sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 111798448.62sec, total: 111798448.63sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 111798448.62sec, total: 111798448.63sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 111798448.62sec, total: 111798448.63sec
  train.py:359:image_losses, cpu: 2.03ms, accelerator: 1.20ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.20ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 244us, total: 1.46ms
      train.py:343:hfe, cpu: 448us, accelerator: 570us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 111798448.62sec, total: 111798448.62sec
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.93ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.29ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 6.01ms, accelerator: 1.29ms, total: 7.32ms
  __init__.py:185:compute_gradients, cpu: 2.90ms, accelerator: 2.64ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_41250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 414us, accelerator: 111124963.99sec, total: 111124963.99sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 111124963.99sec, total: 111124963.99sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.61ms, accelerator: 0us, total: 140.61ms
train.py:442:<module>, cpu: 5.25ms, accelerator: 111124963.99sec, total: 111124964.00sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 111124963.99sec, total: 111124964.00sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 111124963.99sec, total: 111124964.00sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 111124963.99sec, total: 111124964.00sec
  train.py:359:image_losses, cpu: 2.03ms, accelerator: 1.20ms, total: 3.24ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.20ms, total: 3.22ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 242us, total: 1.46ms
      train.py:343:hfe, cpu: 448us, accelerator: 565us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 111124963.99sec, total: 111124963.99sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.91ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.28ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.99ms, accelerator: 1.28ms, total: 7.29ms
  __init__.py:185:compute_gradients, cpu: 2.89ms, accelerator: 2.63ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_41500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 412us, accelerator: 110459545.04sec, total: 110459545.04sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 110459545.04sec, total: 110459545.04sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.41ms, accelerator: 0us, total: 140.41ms
train.py:442:<module>, cpu: 5.24ms, accelerator: 110459545.05sec, total: 110459545.05sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 110459545.05sec, total: 110459545.05sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 110459545.05sec, total: 110459545.05sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 110459545.05sec, total: 110459545.05sec
  train.py:359:image_losses, cpu: 2.02ms, accelerator: 1.19ms, total: 3.22ms
    train.py:322:loss_fn, cpu: 2.00ms, accelerator: 1.19ms, total: 3.20ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 241us, total: 1.45ms
      train.py:343:hfe, cpu: 447us, accelerator: 563us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 110459545.04sec, total: 110459545.05sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.91ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.28ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.97ms, accelerator: 1.28ms, total: 7.27ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.63ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_41750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 412us, accelerator: 109802047.75sec, total: 109802047.75sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 109802047.75sec, total: 109802047.75sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.58ms, accelerator: 0us, total: 140.58ms
train.py:442:<module>, cpu: 5.22ms, accelerator: 109802047.76sec, total: 109802047.76sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 109802047.75sec, total: 109802047.76sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 109802047.75sec, total: 109802047.76sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 109802047.75sec, total: 109802047.76sec
  train.py:359:image_losses, cpu: 2.01ms, accelerator: 1.19ms, total: 3.21ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.19ms, total: 3.19ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 241us, total: 1.44ms
      train.py:343:hfe, cpu: 446us, accelerator: 560us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.14ms, accelerator: 109802047.75sec, total: 109802047.76sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.89ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.27ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.95ms, accelerator: 1.27ms, total: 7.24ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.62ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_42000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 412us, accelerator: 109152331.49sec, total: 109152331.49sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 109152331.49sec, total: 109152331.49sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.62ms, accelerator: 0us, total: 140.62ms
train.py:442:<module>, cpu: 5.29ms, accelerator: 109152331.50sec, total: 109152331.50sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 109152331.50sec, total: 109152331.50sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 109152331.50sec, total: 109152331.50sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 109152331.50sec, total: 109152331.50sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.18ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.18ms, total: 3.25ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 239us, total: 1.44ms
      train.py:343:hfe, cpu: 445us, accelerator: 558us, total: 1.00ms
train.py:441:<module> (gradient), cpu: 4.14ms, accelerator: 109152331.49sec, total: 109152331.50sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.88ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.26ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.92ms, accelerator: 1.26ms, total: 7.21ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.61ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_42250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 412us, accelerator: 108510258.95sec, total: 108510258.95sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 108510258.95sec, total: 108510258.95sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.81ms, accelerator: 0us, total: 140.81ms
train.py:442:<module>, cpu: 5.28ms, accelerator: 108510258.96sec, total: 108510258.97sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 108510258.96sec, total: 108510258.96sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 108510258.96sec, total: 108510258.96sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 108510258.96sec, total: 108510258.96sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.17ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.17ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 238us, total: 1.43ms
      train.py:343:hfe, cpu: 442us, accelerator: 553us, total: 1.00ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 108510258.96sec, total: 108510258.96sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.86ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.26ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.90ms, accelerator: 1.26ms, total: 7.19ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.60ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_42500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 411us, accelerator: 107875696.04sec, total: 107875696.04sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 107875696.03sec, total: 107875696.04sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.69ms, accelerator: 0us, total: 140.69ms
train.py:442:<module>, cpu: 5.28ms, accelerator: 107875696.04sec, total: 107875696.05sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 107875696.04sec, total: 107875696.04sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 107875696.04sec, total: 107875696.04sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 107875696.04sec, total: 107875696.04sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.17ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.17ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 238us, total: 1.44ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 107875696.04sec, total: 107875696.04sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.85ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.26ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.88ms, accelerator: 1.26ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.59ms, total: 5.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_42750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 411us, accelerator: 107248511.76sec, total: 107248511.76sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 107248511.76sec, total: 107248511.76sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.78ms, accelerator: 0us, total: 140.78ms
train.py:442:<module>, cpu: 5.28ms, accelerator: 107248511.76sec, total: 107248511.77sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 107248511.76sec, total: 107248511.76sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 107248511.76sec, total: 107248511.76sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 107248511.76sec, total: 107248511.76sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.16ms, total: 3.24ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.16ms, total: 3.22ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 237us, total: 1.43ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 107248511.76sec, total: 107248511.76sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.83ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 1.25ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.89ms, accelerator: 1.25ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.58ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_43000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 411us, accelerator: 106628578.16sec, total: 106628578.16sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 106628578.16sec, total: 106628578.16sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.68ms, accelerator: 0us, total: 140.68ms
train.py:442:<module>, cpu: 5.27ms, accelerator: 106628578.17sec, total: 106628578.17sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 106628578.17sec, total: 106628578.17sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 106628578.17sec, total: 106628578.17sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 106628578.17sec, total: 106628578.17sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.16ms, total: 3.23ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.16ms, total: 3.21ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 235us, total: 1.43ms
train.py:441:<module> (gradient), cpu: 4.12ms, accelerator: 106628578.16sec, total: 106628578.17sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.82ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 1.25ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.89ms, accelerator: 1.25ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.57ms, total: 5.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_43250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 410us, accelerator: 106015770.24sec, total: 106015770.24sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 106015770.24sec, total: 106015770.24sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.78ms, accelerator: 0us, total: 140.78ms
train.py:442:<module>, cpu: 5.26ms, accelerator: 106015770.25sec, total: 106015770.25sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 106015770.25sec, total: 106015770.25sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 106015770.25sec, total: 106015770.25sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 106015770.25sec, total: 106015770.25sec
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.16ms, total: 3.21ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.16ms, total: 3.19ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 235us, total: 1.42ms
train.py:441:<module> (gradient), cpu: 4.12ms, accelerator: 106015770.24sec, total: 106015770.25sec
train.py:511:<module>, cpu: 8.01sec, accelerator: 3.80ms, total: 8.01sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 1.24ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec
    __init__.py:86:allreduce, cpu: 5.87ms, accelerator: 1.24ms, total: 7.13ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.56ms, total: 5.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_43500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 409us, accelerator: 105409965.84sec, total: 105409965.84sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 105409965.84sec, total: 105409965.84sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.85ms, accelerator: 0us, total: 140.85ms
train.py:442:<module>, cpu: 5.25ms, accelerator: 105409965.85sec, total: 105409965.85sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 105409965.84sec, total: 105409965.85sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 105409965.84sec, total: 105409965.85sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 105409965.84sec, total: 105409965.85sec
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.15ms, total: 3.21ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.15ms, total: 3.19ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 234us, total: 1.42ms
train.py:441:<module> (gradient), cpu: 4.12ms, accelerator: 105409965.84sec, total: 105409965.85sec
train.py:511:<module>, cpu: 8.01sec, accelerator: 3.78ms, total: 8.01sec
  __init__.py:194:compute_gradients, cpu: 8.00sec, accelerator: 1.23ms, total: 8.00sec
    __init__.py:83:allreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec
    __init__.py:86:allreduce, cpu: 5.85ms, accelerator: 1.23ms, total: 7.11ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.55ms, total: 5.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_43750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 409us, accelerator: 104811045.58sec, total: 104811045.58sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 104811045.58sec, total: 104811045.58sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.99sec, accelerator: 0us, total: 7.99sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.67ms, accelerator: 0us, total: 140.67ms
train.py:442:<module>, cpu: 5.26ms, accelerator: 104811045.59sec, total: 104811045.59sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 104811045.58sec, total: 104811045.59sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 104811045.58sec, total: 104811045.59sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 104811045.58sec, total: 104811045.59sec
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.14ms, total: 3.21ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.14ms, total: 3.19ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 233us, total: 1.43ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 104811045.58sec, total: 104811045.59sec
train.py:511:<module>, cpu: 8.00sec, accelerator: 3.76ms, total: 8.00sec
  __init__.py:194:compute_gradients, cpu: 8.00sec, accelerator: 1.22ms, total: 8.00sec
    __init__.py:83:allreduce, cpu: 7.99sec, accelerator: 0us, total: 7.99sec
    __init__.py:86:allreduce, cpu: 5.83ms, accelerator: 1.22ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.54ms, total: 5.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_44000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 408us, accelerator: 104218892.78sec, total: 104218892.78sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 104218892.78sec, total: 104218892.78sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.99sec, accelerator: 0us, total: 7.99sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.70ms, accelerator: 0us, total: 140.70ms
train.py:442:<module>, cpu: 5.31ms, accelerator: 104218892.79sec, total: 104218892.79sec
  train.py:360:image_losses, cpu: 2.76ms, accelerator: 104218892.78sec, total: 104218892.79sec
    train.py:322:loss_fn, cpu: 2.75ms, accelerator: 104218892.78sec, total: 104218892.79sec
      train.py:349:msssim, cpu: 2.70ms, accelerator: 104218892.78sec, total: 104218892.79sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.14ms, total: 3.26ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.14ms, total: 3.24ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 234us, total: 1.42ms
      train.py:343:hfe, cpu: 501us, accelerator: 536us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 104218892.78sec, total: 104218892.79sec
train.py:511:<module>, cpu: 8.00sec, accelerator: 3.74ms, total: 8.00sec
  __init__.py:194:compute_gradients, cpu: 7.99sec, accelerator: 1.22ms, total: 7.99sec
    __init__.py:83:allreduce, cpu: 7.99sec, accelerator: 0us, total: 7.99sec
    __init__.py:86:allreduce, cpu: 5.81ms, accelerator: 1.22ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.52ms, total: 5.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_44250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 103633393.38sec, total: 103633393.38sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 103633393.38sec, total: 103633393.38sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 7.99sec, accelerator: 0us, total: 7.99sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.56ms, accelerator: 0us, total: 140.56ms
train.py:442:<module>, cpu: 5.30ms, accelerator: 103633393.39sec, total: 103633393.39sec
  train.py:360:image_losses, cpu: 2.75ms, accelerator: 103633393.39sec, total: 103633393.39sec
    train.py:322:loss_fn, cpu: 2.74ms, accelerator: 103633393.39sec, total: 103633393.39sec
      train.py:349:msssim, cpu: 2.69ms, accelerator: 103633393.39sec, total: 103633393.39sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.13ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.13ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 231us, total: 1.42ms
      train.py:343:hfe, cpu: 500us, accelerator: 534us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 103633393.38sec, total: 103633393.39sec
train.py:511:<module>, cpu: 7.99sec, accelerator: 3.80ms, total: 8.00sec
  __init__.py:194:compute_gradients, cpu: 7.99sec, accelerator: 1.22ms, total: 7.99sec
    __init__.py:83:allreduce, cpu: 7.99sec, accelerator: 0us, total: 7.99sec
    __init__.py:86:allreduce, cpu: 5.78ms, accelerator: 1.22ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.58ms, total: 5.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_44500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 103054435.88sec, total: 103054435.88sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 103054435.88sec, total: 103054435.88sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.59ms, accelerator: 0us, total: 140.59ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 103054435.88sec, total: 103054435.89sec
  train.py:360:image_losses, cpu: 2.75ms, accelerator: 103054435.88sec, total: 103054435.88sec
    train.py:322:loss_fn, cpu: 2.74ms, accelerator: 103054435.88sec, total: 103054435.88sec
      train.py:349:msssim, cpu: 2.69ms, accelerator: 103054435.88sec, total: 103054435.88sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.12ms, total: 3.26ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.12ms, total: 3.24ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 231us, total: 1.43ms
      train.py:343:hfe, cpu: 500us, accelerator: 529us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 103054435.88sec, total: 103054435.88sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.79ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.21ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.76ms, accelerator: 1.21ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.57ms, total: 5.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_44750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 102481911.23sec, total: 102481911.23sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 102481911.23sec, total: 102481911.23sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.43ms, accelerator: 0us, total: 140.43ms
train.py:442:<module>, cpu: 5.31ms, accelerator: 102481911.24sec, total: 102481911.25sec
  train.py:360:image_losses, cpu: 2.75ms, accelerator: 102481911.24sec, total: 102481911.24sec
    train.py:322:loss_fn, cpu: 2.74ms, accelerator: 102481911.24sec, total: 102481911.24sec
      train.py:349:msssim, cpu: 2.69ms, accelerator: 102481911.24sec, total: 102481911.24sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.12ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.12ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 230us, total: 1.43ms
      train.py:343:hfe, cpu: 499us, accelerator: 529us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 102481911.24sec, total: 102481911.24sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.77ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.21ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.74ms, accelerator: 1.21ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.56ms, total: 5.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_45000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 409us, accelerator: 101915712.83sec, total: 101915712.83sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 101915712.83sec, total: 101915712.83sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.37ms, accelerator: 0us, total: 140.37ms
train.py:442:<module>, cpu: 5.35ms, accelerator: 101915712.84sec, total: 101915712.84sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 101915712.83sec, total: 101915712.84sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 101915712.83sec, total: 101915712.84sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 101915712.83sec, total: 101915712.84sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.14ms, total: 3.26ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.14ms, total: 3.24ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 228us, total: 1.42ms
      train.py:343:hfe, cpu: 497us, accelerator: 535us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 101915712.83sec, total: 101915712.84sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.77ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.20ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.80ms, accelerator: 1.20ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.83ms, accelerator: 2.56ms, total: 5.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_45250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 408us, accelerator: 101355736.39sec, total: 101355736.39sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 101355736.38sec, total: 101355736.39sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.39ms, accelerator: 0us, total: 140.39ms
train.py:442:<module>, cpu: 5.34ms, accelerator: 101355736.39sec, total: 101355736.40sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 101355736.39sec, total: 101355736.39sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 101355736.39sec, total: 101355736.39sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 101355736.39sec, total: 101355736.39sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.13ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.13ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 228us, total: 1.42ms
      train.py:343:hfe, cpu: 498us, accelerator: 534us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 101355736.39sec, total: 101355736.39sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.75ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.20ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.79ms, accelerator: 1.20ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.55ms, total: 5.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_45500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 408us, accelerator: 100801879.90sec, total: 100801879.90sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 100801879.90sec, total: 100801879.90sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.23ms, accelerator: 0us, total: 140.23ms
train.py:442:<module>, cpu: 5.33ms, accelerator: 100801879.91sec, total: 100801879.91sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 100801879.91sec, total: 100801879.91sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 100801879.91sec, total: 100801879.91sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 100801879.91sec, total: 100801879.91sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.13ms, total: 3.24ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.13ms, total: 3.22ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 227us, total: 1.41ms
      train.py:343:hfe, cpu: 495us, accelerator: 530us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 100801879.90sec, total: 100801879.91sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.81ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.20ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.79ms, accelerator: 1.20ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.61ms, total: 5.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_45750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 408us, accelerator: 100254043.60sec, total: 100254043.60sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 100254043.60sec, total: 100254043.60sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.24ms, accelerator: 0us, total: 140.24ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 100254043.60sec, total: 100254043.61sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 100254043.60sec, total: 100254043.61sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 100254043.60sec, total: 100254043.61sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 100254043.60sec, total: 100254043.61sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.12ms, total: 3.22ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.12ms, total: 3.20ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 227us, total: 1.41ms
      train.py:343:hfe, cpu: 493us, accelerator: 528us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 100254043.60sec, total: 100254043.60sec
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.79ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.20ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.82ms, accelerator: 1.20ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.59ms, total: 5.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_46000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 408us, accelerator: 99712129.85sec, total: 99712129.85sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 99712129.85sec, total: 99712129.85sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.14ms, accelerator: 0us, total: 140.14ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 99712129.86sec, total: 99712129.86sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 99712129.85sec, total: 99712129.86sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 99712129.85sec, total: 99712129.86sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 99712129.85sec, total: 99712129.86sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.11ms, total: 3.21ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.11ms, total: 3.20ms
      train.py:342:hfe, cpu: 1.17ms, accelerator: 226us, total: 1.40ms
      train.py:343:hfe, cpu: 494us, accelerator: 524us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 99712129.85sec, total: 99712129.86sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.77ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.19ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.81ms, accelerator: 1.19ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.58ms, total: 5.47ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_46250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 99176043.13sec, total: 99176043.13sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 408us, accelerator: 99176043.13sec, total: 99176043.13sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.11ms, accelerator: 0us, total: 140.11ms
train.py:442:<module>, cpu: 5.36ms, accelerator: 99176043.14sec, total: 99176043.14sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 99176043.13sec, total: 99176043.14sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 99176043.13sec, total: 99176043.14sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 99176043.13sec, total: 99176043.14sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.11ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.11ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 224us, total: 1.44ms
      train.py:343:hfe, cpu: 492us, accelerator: 523us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 99176043.13sec, total: 99176043.14sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.79ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.19ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.79ms, accelerator: 1.19ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.61ms, total: 5.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_46500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 98645689.96sec, total: 98645689.96sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 98645689.96sec, total: 98645689.96sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.05ms, accelerator: 0us, total: 140.05ms
train.py:442:<module>, cpu: 5.35ms, accelerator: 98645689.96sec, total: 98645689.97sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 98645689.96sec, total: 98645689.96sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 98645689.96sec, total: 98645689.96sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 98645689.96sec, total: 98645689.96sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.15ms, total: 3.28ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.15ms, total: 3.27ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 223us, total: 1.44ms
      train.py:343:hfe, cpu: 493us, accelerator: 545us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 98645689.96sec, total: 98645689.96sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.84ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.21ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.79ms, accelerator: 1.21ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.62ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_46750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 98120978.84sec, total: 98120978.84sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 98120978.84sec, total: 98120978.84sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.28ms, accelerator: 0us, total: 140.28ms
train.py:442:<module>, cpu: 5.34ms, accelerator: 98120978.85sec, total: 98120978.85sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 98120978.85sec, total: 98120978.85sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 98120978.85sec, total: 98120978.85sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 98120978.85sec, total: 98120978.85sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.16ms, total: 3.29ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.16ms, total: 3.27ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 222us, total: 1.43ms
      train.py:343:hfe, cpu: 492us, accelerator: 547us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 98120978.84sec, total: 98120978.85sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.82ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.21ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.77ms, accelerator: 1.21ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.83ms, accelerator: 2.61ms, total: 5.49ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_47000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 408us, accelerator: 97601820.22sec, total: 97601820.22sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 97601820.22sec, total: 97601820.22sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.31ms, accelerator: 0us, total: 140.31ms
train.py:442:<module>, cpu: 5.34ms, accelerator: 97601820.23sec, total: 97601820.23sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 97601820.23sec, total: 97601820.23sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 97601820.23sec, total: 97601820.23sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 97601820.23sec, total: 97601820.23sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.16ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.16ms, total: 3.26ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 220us, total: 1.43ms
      train.py:343:hfe, cpu: 491us, accelerator: 544us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 97601820.22sec, total: 97601820.23sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.80ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.21ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.75ms, accelerator: 1.21ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.60ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_47250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 408us, accelerator: 97088126.43sec, total: 97088126.43sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 97088126.43sec, total: 97088126.43sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.16ms, accelerator: 0us, total: 140.16ms
train.py:442:<module>, cpu: 5.33ms, accelerator: 97088126.44sec, total: 97088126.44sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 97088126.44sec, total: 97088126.44sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 97088126.44sec, total: 97088126.44sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 97088126.44sec, total: 97088126.44sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.15ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.15ms, total: 3.25ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 220us, total: 1.42ms
      train.py:343:hfe, cpu: 487us, accelerator: 542us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 97088126.43sec, total: 97088126.44sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.79ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.20ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.72ms, accelerator: 1.20ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.58ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_47500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 409us, accelerator: 96579811.63sec, total: 96579811.63sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 96579811.63sec, total: 96579811.63sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.94ms, accelerator: 0us, total: 139.94ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 96579811.64sec, total: 96579811.65sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 96579811.64sec, total: 96579811.64sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 96579811.64sec, total: 96579811.64sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 96579811.64sec, total: 96579811.64sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.15ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.15ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 220us, total: 1.42ms
      train.py:343:hfe, cpu: 485us, accelerator: 540us, total: 1.03ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 96579811.64sec, total: 96579811.64sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.77ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.20ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.70ms, accelerator: 1.20ms, total: 6.92ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.57ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_47750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 409us, accelerator: 96076791.78sec, total: 96076791.78sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 96076791.78sec, total: 96076791.78sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.84ms, accelerator: 0us, total: 139.84ms
train.py:442:<module>, cpu: 5.31ms, accelerator: 96076791.79sec, total: 96076791.79sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 96076791.79sec, total: 96076791.79sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 96076791.79sec, total: 96076791.79sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 96076791.79sec, total: 96076791.79sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.14ms, total: 3.24ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.14ms, total: 3.22ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 218us, total: 1.41ms
      train.py:343:hfe, cpu: 485us, accelerator: 538us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 96076791.78sec, total: 96076791.79sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.75ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.19ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.68ms, accelerator: 1.19ms, total: 6.90ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.56ms, total: 5.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_48000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 409us, accelerator: 95578984.57sec, total: 95578984.57sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 95578984.57sec, total: 95578984.57sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.68ms, accelerator: 0us, total: 139.68ms
train.py:442:<module>, cpu: 5.31ms, accelerator: 95578984.58sec, total: 95578984.58sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 95578984.57sec, total: 95578984.58sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 95578984.57sec, total: 95578984.58sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 95578984.57sec, total: 95578984.58sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.13ms, total: 3.23ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.13ms, total: 3.21ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 218us, total: 1.41ms
      train.py:343:hfe, cpu: 484us, accelerator: 534us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 95578984.57sec, total: 95578984.58sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.74ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.19ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.66ms, accelerator: 1.19ms, total: 6.88ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.55ms, total: 5.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_48250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 408us, accelerator: 95086309.39sec, total: 95086309.39sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 95086309.39sec, total: 95086309.39sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.74ms, accelerator: 0us, total: 139.74ms
train.py:442:<module>, cpu: 5.29ms, accelerator: 95086309.40sec, total: 95086309.40sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 95086309.40sec, total: 95086309.40sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 95086309.40sec, total: 95086309.40sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 95086309.40sec, total: 95086309.40sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.13ms, total: 3.21ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.13ms, total: 3.20ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 218us, total: 1.40ms
      train.py:343:hfe, cpu: 483us, accelerator: 531us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 95086309.39sec, total: 95086309.40sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.72ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.18ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.65ms, accelerator: 1.18ms, total: 6.85ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.54ms, total: 5.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_48500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 408us, accelerator: 94598687.29sec, total: 94598687.29sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 94598687.29sec, total: 94598687.29sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.80ms, accelerator: 0us, total: 139.80ms
train.py:442:<module>, cpu: 5.28ms, accelerator: 94598687.30sec, total: 94598687.30sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 94598687.30sec, total: 94598687.30sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 94598687.30sec, total: 94598687.30sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 94598687.30sec, total: 94598687.30sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.13ms, total: 3.20ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.13ms, total: 3.18ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 217us, total: 1.39ms
      train.py:343:hfe, cpu: 481us, accelerator: 529us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 94598687.29sec, total: 94598687.30sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.71ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.18ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.18ms, total: 6.84ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.53ms, total: 5.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_48750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 94116040.93sec, total: 94116040.93sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 94116040.93sec, total: 94116040.93sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.87ms, accelerator: 0us, total: 139.87ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 94116040.94sec, total: 94116040.94sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 94116040.93sec, total: 94116040.94sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 94116040.93sec, total: 94116040.94sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 94116040.93sec, total: 94116040.94sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.12ms, total: 3.19ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.12ms, total: 3.18ms
      train.py:342:hfe, cpu: 1.17ms, accelerator: 216us, total: 1.39ms
      train.py:343:hfe, cpu: 484us, accelerator: 528us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 94116040.93sec, total: 94116040.94sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.81ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.17ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.62ms, accelerator: 1.17ms, total: 6.82ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.64ms, total: 5.56ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_49000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 93638294.53sec, total: 93638294.53sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 93638294.53sec, total: 93638294.53sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.02ms, accelerator: 0us, total: 140.02ms
train.py:442:<module>, cpu: 5.30ms, accelerator: 93638294.53sec, total: 93638294.54sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 93638294.53sec, total: 93638294.54sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 93638294.53sec, total: 93638294.54sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 93638294.53sec, total: 93638294.54sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.12ms, total: 3.18ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.12ms, total: 3.17ms
      train.py:342:hfe, cpu: 1.17ms, accelerator: 215us, total: 1.39ms
      train.py:343:hfe, cpu: 482us, accelerator: 525us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 93638294.53sec, total: 93638294.53sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.79ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.17ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.70ms, accelerator: 1.17ms, total: 6.89ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.63ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2130.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_49250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 93165373.85sec, total: 93165373.85sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 93165373.85sec, total: 93165373.85sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 140.05ms, accelerator: 0us, total: 140.05ms
train.py:442:<module>, cpu: 5.30ms, accelerator: 93165373.85sec, total: 93165373.86sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 93165373.85sec, total: 93165373.86sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 93165373.85sec, total: 93165373.86sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 93165373.85sec, total: 93165373.86sec
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.11ms, total: 3.17ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.11ms, total: 3.15ms
      train.py:342:hfe, cpu: 1.16ms, accelerator: 214us, total: 1.38ms
      train.py:343:hfe, cpu: 480us, accelerator: 523us, total: 1.01ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 93165373.85sec, total: 93165373.86sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.78ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.16ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.68ms, accelerator: 1.16ms, total: 6.86ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.62ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_49500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 92697206.14sec, total: 92697206.14sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 92697206.14sec, total: 92697206.14sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.88ms, accelerator: 0us, total: 139.88ms
train.py:442:<module>, cpu: 5.29ms, accelerator: 92697206.15sec, total: 92697206.15sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 92697206.15sec, total: 92697206.15sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 92697206.15sec, total: 92697206.15sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 92697206.15sec, total: 92697206.15sec
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.14ms, total: 3.18ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.14ms, total: 3.17ms
      train.py:342:hfe, cpu: 1.16ms, accelerator: 213us, total: 1.37ms
      train.py:343:hfe, cpu: 478us, accelerator: 542us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 92697206.14sec, total: 92697206.15sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.88ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.27ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.68ms, accelerator: 1.27ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.62ms, total: 5.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_49750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 92233720.11sec, total: 92233720.11sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 92233720.11sec, total: 92233720.11sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.86ms, accelerator: 0us, total: 139.86ms
train.py:442:<module>, cpu: 5.29ms, accelerator: 92233720.12sec, total: 92233720.12sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 92233720.11sec, total: 92233720.12sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 92233720.11sec, total: 92233720.12sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 92233720.11sec, total: 92233720.12sec
  train.py:359:image_losses, cpu: 2.04ms, accelerator: 1.13ms, total: 3.18ms
    train.py:322:loss_fn, cpu: 2.02ms, accelerator: 1.13ms, total: 3.16ms
      train.py:342:hfe, cpu: 1.16ms, accelerator: 213us, total: 1.37ms
      train.py:343:hfe, cpu: 478us, accelerator: 540us, total: 1.02ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 92233720.11sec, total: 92233720.12sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.87ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.26ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.66ms, accelerator: 1.26ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.61ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_50000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 91774845.88sec, total: 91774845.88sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 91774845.88sec, total: 91774845.88sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.67ms, accelerator: 0us, total: 139.67ms
train.py:442:<module>, cpu: 5.28ms, accelerator: 91774845.89sec, total: 91774845.89sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 91774845.89sec, total: 91774845.89sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 91774845.89sec, total: 91774845.89sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 91774845.89sec, total: 91774845.89sec
  train.py:359:image_losses, cpu: 2.03ms, accelerator: 1.18ms, total: 3.22ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.18ms, total: 3.21ms
      train.py:342:hfe, cpu: 1.15ms, accelerator: 222us, total: 1.38ms
      train.py:343:hfe, cpu: 477us, accelerator: 569us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 91774845.88sec, total: 91774845.89sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.86ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 1.25ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.65ms, accelerator: 1.25ms, total: 6.93ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.61ms, total: 5.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_50250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 91320514.96sec, total: 91320514.96sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 91320514.96sec, total: 91320514.96sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.75ms, accelerator: 0us, total: 139.75ms
train.py:442:<module>, cpu: 5.27ms, accelerator: 91320514.97sec, total: 91320514.97sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 91320514.97sec, total: 91320514.97sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 91320514.97sec, total: 91320514.97sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 91320514.96sec, total: 91320514.97sec
  train.py:359:image_losses, cpu: 2.03ms, accelerator: 1.18ms, total: 3.21ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.18ms, total: 3.19ms
      train.py:342:hfe, cpu: 1.15ms, accelerator: 222us, total: 1.37ms
      train.py:343:hfe, cpu: 478us, accelerator: 568us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 91320514.96sec, total: 91320514.97sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.85ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.25ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.71ms, accelerator: 1.25ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.60ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_50500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 90870660.21sec, total: 90870660.21sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 90870660.21sec, total: 90870660.21sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.75ms, accelerator: 0us, total: 139.75ms
train.py:442:<module>, cpu: 5.28ms, accelerator: 90870660.21sec, total: 90870660.22sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 90870660.21sec, total: 90870660.21sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 90870660.21sec, total: 90870660.21sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 90870660.21sec, total: 90870660.21sec
  train.py:359:image_losses, cpu: 2.03ms, accelerator: 1.17ms, total: 3.21ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.17ms, total: 3.19ms
      train.py:342:hfe, cpu: 1.14ms, accelerator: 218us, total: 1.37ms
      train.py:343:hfe, cpu: 480us, accelerator: 565us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 90870660.21sec, total: 90870660.21sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.84ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.25ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.71ms, accelerator: 1.25ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.59ms, total: 5.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_50750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 90425215.79sec, total: 90425215.80sec (50.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 90425215.79sec, total: 90425215.80sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.83ms, accelerator: 0us, total: 139.83ms
train.py:442:<module>, cpu: 5.28ms, accelerator: 90425215.80sec, total: 90425215.81sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 90425215.80sec, total: 90425215.80sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 90425215.80sec, total: 90425215.80sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 90425215.80sec, total: 90425215.80sec
  train.py:359:image_losses, cpu: 2.03ms, accelerator: 1.20ms, total: 3.23ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.20ms, total: 3.22ms
      train.py:342:hfe, cpu: 1.15ms, accelerator: 218us, total: 1.37ms
      train.py:343:hfe, cpu: 479us, accelerator: 577us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 90425215.80sec, total: 90425215.80sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.84ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.24ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.70ms, accelerator: 1.24ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.60ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_51000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 89984117.18sec, total: 89984117.18sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 89984117.18sec, total: 89984117.18sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.69ms, accelerator: 0us, total: 139.69ms
train.py:442:<module>, cpu: 5.27ms, accelerator: 89984117.19sec, total: 89984117.19sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 89984117.19sec, total: 89984117.19sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 89984117.19sec, total: 89984117.19sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 89984117.19sec, total: 89984117.19sec
  train.py:359:image_losses, cpu: 2.03ms, accelerator: 1.24ms, total: 3.28ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.24ms, total: 3.26ms
      train.py:342:hfe, cpu: 1.14ms, accelerator: 267us, total: 1.42ms
      train.py:343:hfe, cpu: 475us, accelerator: 574us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 89984117.18sec, total: 89984117.19sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.83ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.23ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.73ms, accelerator: 1.23ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.60ms, total: 5.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_51250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 89547301.08sec, total: 89547301.08sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 89547301.08sec, total: 89547301.08sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.71ms, accelerator: 0us, total: 139.71ms
train.py:442:<module>, cpu: 5.27ms, accelerator: 89547301.08sec, total: 89547301.09sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 89547301.08sec, total: 89547301.09sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 89547301.08sec, total: 89547301.09sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 89547301.08sec, total: 89547301.09sec
  train.py:359:image_losses, cpu: 2.03ms, accelerator: 1.23ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.23ms, total: 3.25ms
      train.py:342:hfe, cpu: 1.15ms, accelerator: 266us, total: 1.42ms
      train.py:343:hfe, cpu: 474us, accelerator: 571us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 89547301.08sec, total: 89547301.08sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.84ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.23ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.71ms, accelerator: 1.23ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.60ms, total: 5.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_51500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 89114705.42sec, total: 89114705.42sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 89114705.42sec, total: 89114705.42sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.86ms, accelerator: 0us, total: 139.86ms
train.py:442:<module>, cpu: 5.26ms, accelerator: 89114705.43sec, total: 89114705.43sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 89114705.42sec, total: 89114705.43sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 89114705.42sec, total: 89114705.43sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 89114705.42sec, total: 89114705.43sec
  train.py:359:image_losses, cpu: 2.02ms, accelerator: 1.25ms, total: 3.29ms
    train.py:322:loss_fn, cpu: 2.00ms, accelerator: 1.25ms, total: 3.27ms
      train.py:342:hfe, cpu: 1.14ms, accelerator: 265us, total: 1.41ms
      train.py:343:hfe, cpu: 473us, accelerator: 587us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 89114705.42sec, total: 89114705.43sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.94ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.33ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.69ms, accelerator: 1.33ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.61ms, total: 5.52ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_51750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 88686269.34sec, total: 88686269.34sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 88686269.34sec, total: 88686269.34sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.76ms, accelerator: 0us, total: 139.76ms
train.py:442:<module>, cpu: 5.26ms, accelerator: 88686269.34sec, total: 88686269.35sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 88686269.34sec, total: 88686269.34sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 88686269.34sec, total: 88686269.34sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 88686269.34sec, total: 88686269.34sec
  train.py:359:image_losses, cpu: 2.02ms, accelerator: 1.25ms, total: 3.28ms
    train.py:322:loss_fn, cpu: 2.00ms, accelerator: 1.25ms, total: 3.26ms
      train.py:342:hfe, cpu: 1.14ms, accelerator: 265us, total: 1.41ms
      train.py:343:hfe, cpu: 472us, accelerator: 584us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 88686269.34sec, total: 88686269.34sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.92ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.32ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.68ms, accelerator: 1.32ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.60ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_52000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 88261933.12sec, total: 88261933.12sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 407us, accelerator: 88261933.12sec, total: 88261933.12sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.82ms, accelerator: 0us, total: 139.82ms
train.py:442:<module>, cpu: 5.25ms, accelerator: 88261933.13sec, total: 88261933.13sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 88261933.12sec, total: 88261933.13sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 88261933.12sec, total: 88261933.13sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 88261933.12sec, total: 88261933.13sec
  train.py:359:image_losses, cpu: 2.01ms, accelerator: 1.24ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 2.00ms, accelerator: 1.24ms, total: 3.25ms
      train.py:342:hfe, cpu: 1.14ms, accelerator: 264us, total: 1.41ms
      train.py:343:hfe, cpu: 471us, accelerator: 583us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 88261933.12sec, total: 88261933.13sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.91ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.32ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.67ms, accelerator: 1.32ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.59ms, total: 5.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_52250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 87841638.20sec, total: 87841638.20sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 87841638.20sec, total: 87841638.20sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.69ms, accelerator: 0us, total: 139.69ms
train.py:442:<module>, cpu: 5.25ms, accelerator: 87841638.21sec, total: 87841638.21sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 87841638.20sec, total: 87841638.21sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 87841638.20sec, total: 87841638.21sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 87841638.20sec, total: 87841638.21sec
  train.py:359:image_losses, cpu: 2.01ms, accelerator: 1.27ms, total: 3.28ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.27ms, total: 3.27ms
      train.py:342:hfe, cpu: 1.14ms, accelerator: 263us, total: 1.40ms
      train.py:343:hfe, cpu: 470us, accelerator: 583us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 87841638.20sec, total: 87841638.21sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.93ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.32ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.65ms, accelerator: 1.32ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.62ms, total: 5.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_52500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 87425327.12sec, total: 87425327.12sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 405us, accelerator: 87425327.12sec, total: 87425327.12sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.54ms, accelerator: 0us, total: 139.54ms
train.py:442:<module>, cpu: 5.24ms, accelerator: 87425327.13sec, total: 87425327.13sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 87425327.12sec, total: 87425327.13sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 87425327.12sec, total: 87425327.13sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 87425327.12sec, total: 87425327.13sec
  train.py:359:image_losses, cpu: 2.00ms, accelerator: 1.26ms, total: 3.28ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.26ms, total: 3.26ms
      train.py:342:hfe, cpu: 1.14ms, accelerator: 263us, total: 1.40ms
      train.py:343:hfe, cpu: 470us, accelerator: 580us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 87425327.12sec, total: 87425327.13sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.91ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.31ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.31ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.60ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_52750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 87012943.50sec, total: 87012943.50sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 404us, accelerator: 87012943.50sec, total: 87012943.50sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.53ms, accelerator: 0us, total: 139.53ms
train.py:442:<module>, cpu: 5.24ms, accelerator: 87012943.51sec, total: 87012943.51sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 87012943.50sec, total: 87012943.51sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 87012943.50sec, total: 87012943.51sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 87012943.50sec, total: 87012943.51sec
  train.py:359:image_losses, cpu: 2.00ms, accelerator: 1.26ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 1.99ms, accelerator: 1.26ms, total: 3.26ms
      train.py:342:hfe, cpu: 1.13ms, accelerator: 262us, total: 1.40ms
      train.py:343:hfe, cpu: 471us, accelerator: 577us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 87012943.50sec, total: 87012943.51sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.89ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.30ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.30ms, total: 6.93ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.59ms, total: 5.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_53000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 86604432.03sec, total: 86604432.03sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 405us, accelerator: 86604432.03sec, total: 86604432.03sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.43ms, accelerator: 0us, total: 139.43ms
train.py:442:<module>, cpu: 5.23ms, accelerator: 86604432.04sec, total: 86604432.04sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 86604432.03sec, total: 86604432.04sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 86604432.03sec, total: 86604432.04sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 86604432.03sec, total: 86604432.04sec
  train.py:359:image_losses, cpu: 2.00ms, accelerator: 1.25ms, total: 3.26ms
    train.py:322:loss_fn, cpu: 1.98ms, accelerator: 1.25ms, total: 3.24ms
      train.py:342:hfe, cpu: 1.13ms, accelerator: 260us, total: 1.39ms
      train.py:343:hfe, cpu: 468us, accelerator: 574us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 86604432.03sec, total: 86604432.04sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.94ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.35ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 1.35ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.58ms, total: 5.48ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_53250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 86199738.42sec, total: 86199738.42sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 404us, accelerator: 86199738.42sec, total: 86199738.42sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.53ms, accelerator: 0us, total: 139.53ms
train.py:442:<module>, cpu: 5.22ms, accelerator: 86199738.43sec, total: 86199738.43sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 86199738.43sec, total: 86199738.43sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 86199738.43sec, total: 86199738.43sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 86199738.43sec, total: 86199738.43sec
  train.py:359:image_losses, cpu: 1.99ms, accelerator: 1.25ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 1.97ms, accelerator: 1.25ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.12ms, accelerator: 259us, total: 1.39ms
      train.py:343:hfe, cpu: 466us, accelerator: 574us, total: 1.04ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 86199738.42sec, total: 86199738.43sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.92ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.34ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.58ms, accelerator: 1.34ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.58ms, total: 5.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_53500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 85798809.40sec, total: 85798809.41sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 404us, accelerator: 85798809.41sec, total: 85798809.41sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.44ms, accelerator: 0us, total: 139.44ms
train.py:442:<module>, cpu: 5.24ms, accelerator: 85798809.41sec, total: 85798809.42sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 85798809.41sec, total: 85798809.41sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 85798809.41sec, total: 85798809.41sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 85798809.41sec, total: 85798809.41sec
  train.py:359:image_losses, cpu: 1.99ms, accelerator: 1.27ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 1.97ms, accelerator: 1.27ms, total: 3.26ms
      train.py:342:hfe, cpu: 1.12ms, accelerator: 263us, total: 1.39ms
      train.py:343:hfe, cpu: 466us, accelerator: 589us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 85798809.41sec, total: 85798809.41sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.93ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.36ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.57ms, accelerator: 1.36ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.57ms, total: 5.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_53750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 85401592.69sec, total: 85401592.70sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 85401592.70sec, total: 85401592.70sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.46ms, accelerator: 0us, total: 139.46ms
train.py:442:<module>, cpu: 5.24ms, accelerator: 85401592.70sec, total: 85401592.71sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 85401592.70sec, total: 85401592.70sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 85401592.70sec, total: 85401592.70sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 85401592.70sec, total: 85401592.70sec
  train.py:359:image_losses, cpu: 1.99ms, accelerator: 1.27ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 1.98ms, accelerator: 1.27ms, total: 3.26ms
      train.py:342:hfe, cpu: 1.13ms, accelerator: 262us, total: 1.40ms
      train.py:343:hfe, cpu: 465us, accelerator: 587us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 85401592.70sec, total: 85401592.70sec
train.py:511:<module>, cpu: 8.01sec, accelerator: 3.95ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 1.35ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.57ms, accelerator: 1.35ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.59ms, total: 5.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_54000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 85008036.97sec, total: 85008036.97sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 85008036.97sec, total: 85008036.97sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.37ms, accelerator: 0us, total: 139.37ms
train.py:442:<module>, cpu: 5.28ms, accelerator: 85008036.97sec, total: 85008036.98sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 85008036.97sec, total: 85008036.98sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 85008036.97sec, total: 85008036.98sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 85008036.97sec, total: 85008036.98sec
  train.py:359:image_losses, cpu: 2.00ms, accelerator: 1.26ms, total: 3.27ms
    train.py:322:loss_fn, cpu: 1.98ms, accelerator: 1.26ms, total: 3.26ms
      train.py:342:hfe, cpu: 1.13ms, accelerator: 261us, total: 1.40ms
      train.py:343:hfe, cpu: 466us, accelerator: 584us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.14ms, accelerator: 85008036.97sec, total: 85008036.97sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.94ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.35ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.56ms, accelerator: 1.35ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.59ms, total: 5.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_54250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 84618091.84sec, total: 84618091.85sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 404us, accelerator: 84618091.84sec, total: 84618091.85sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.43ms, accelerator: 0us, total: 139.43ms
train.py:442:<module>, cpu: 5.26ms, accelerator: 84618091.85sec, total: 84618091.86sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 84618091.85sec, total: 84618091.85sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 84618091.85sec, total: 84618091.85sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 84618091.85sec, total: 84618091.85sec
  train.py:359:image_losses, cpu: 1.99ms, accelerator: 1.26ms, total: 3.26ms
    train.py:322:loss_fn, cpu: 1.97ms, accelerator: 1.26ms, total: 3.24ms
      train.py:342:hfe, cpu: 1.13ms, accelerator: 259us, total: 1.39ms
      train.py:343:hfe, cpu: 465us, accelerator: 582us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.14ms, accelerator: 84618091.85sec, total: 84618091.85sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.92ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.34ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.55ms, accelerator: 1.34ms, total: 6.91ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.58ms, total: 5.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_54500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 84231707.86sec, total: 84231707.86sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 84231707.86sec, total: 84231707.86sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.44ms, accelerator: 0us, total: 139.44ms
train.py:442:<module>, cpu: 5.26ms, accelerator: 84231707.87sec, total: 84231707.88sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 84231707.87sec, total: 84231707.87sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 84231707.87sec, total: 84231707.87sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 84231707.87sec, total: 84231707.87sec
  train.py:359:image_losses, cpu: 1.98ms, accelerator: 1.25ms, total: 3.25ms
    train.py:322:loss_fn, cpu: 1.97ms, accelerator: 1.25ms, total: 3.23ms
      train.py:342:hfe, cpu: 1.12ms, accelerator: 259us, total: 1.39ms
      train.py:343:hfe, cpu: 463us, accelerator: 580us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.14ms, accelerator: 84231707.87sec, total: 84231707.87sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.91ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.34ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.58ms, accelerator: 1.34ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.57ms, total: 5.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_54750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 83848836.46sec, total: 83848836.46sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 405us, accelerator: 83848836.46sec, total: 83848836.46sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.33ms, accelerator: 0us, total: 139.33ms
train.py:442:<module>, cpu: 5.25ms, accelerator: 83848836.47sec, total: 83848836.48sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 83848836.47sec, total: 83848836.47sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 83848836.47sec, total: 83848836.47sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 83848836.47sec, total: 83848836.47sec
  train.py:359:image_losses, cpu: 1.98ms, accelerator: 1.28ms, total: 3.26ms
    train.py:322:loss_fn, cpu: 1.96ms, accelerator: 1.28ms, total: 3.25ms
      train.py:342:hfe, cpu: 1.12ms, accelerator: 259us, total: 1.38ms
      train.py:343:hfe, cpu: 461us, accelerator: 602us, total: 1.07ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 83848836.47sec, total: 83848836.47sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.95ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.34ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.62ms, accelerator: 1.34ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.61ms, total: 5.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_55000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 83469429.96sec, total: 83469429.97sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 406us, accelerator: 83469429.96sec, total: 83469429.96sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.11ms, accelerator: 0us, total: 139.11ms
train.py:442:<module>, cpu: 5.31ms, accelerator: 83469429.97sec, total: 83469429.98sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 83469429.97sec, total: 83469429.97sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 83469429.97sec, total: 83469429.97sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 83469429.97sec, total: 83469429.97sec
  train.py:359:image_losses, cpu: 2.03ms, accelerator: 1.28ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.01ms, accelerator: 1.28ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 257us, total: 1.44ms
      train.py:343:hfe, cpu: 460us, accelerator: 609us, total: 1.07ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 83469429.97sec, total: 83469429.97sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.96ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.33ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.63ms, accelerator: 1.33ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.63ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_55250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 83093441.54sec, total: 83093441.54sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 405us, accelerator: 83093441.54sec, total: 83093441.54sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.95ms, accelerator: 0us, total: 138.95ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 83093441.55sec, total: 83093441.55sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 83093441.55sec, total: 83093441.55sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 83093441.55sec, total: 83093441.55sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 83093441.55sec, total: 83093441.55sec
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.28ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.28ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 256us, total: 1.45ms
      train.py:343:hfe, cpu: 460us, accelerator: 606us, total: 1.07ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 83093441.54sec, total: 83093441.55sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.94ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.33ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.33ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.62ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_55500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 82720825.21sec, total: 82720825.21sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 405us, accelerator: 82720825.21sec, total: 82720825.21sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.03ms, accelerator: 0us, total: 139.03ms
train.py:442:<module>, cpu: 5.33ms, accelerator: 82720825.22sec, total: 82720825.22sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 82720825.22sec, total: 82720825.22sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 82720825.22sec, total: 82720825.22sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 82720825.22sec, total: 82720825.22sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.28ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.28ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 256us, total: 1.44ms
      train.py:343:hfe, cpu: 479us, accelerator: 605us, total: 1.09ms
train.py:441:<module> (gradient), cpu: 4.14ms, accelerator: 82720825.21sec, total: 82720825.22sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.93ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.32ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 1.32ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.61ms, total: 5.52ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_55750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 82351535.81sec, total: 82351535.81sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 405us, accelerator: 82351535.81sec, total: 82351535.81sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.19ms, accelerator: 0us, total: 139.19ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 82351535.82sec, total: 82351535.82sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 82351535.82sec, total: 82351535.82sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 82351535.82sec, total: 82351535.82sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 82351535.82sec, total: 82351535.82sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.29ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.29ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 259us, total: 1.44ms
      train.py:343:hfe, cpu: 476us, accelerator: 607us, total: 1.09ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 82351535.82sec, total: 82351535.82sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.94ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.32ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.32ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.62ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_56000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 81985528.99sec, total: 81985528.99sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 405us, accelerator: 81985528.99sec, total: 81985528.99sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.15ms, accelerator: 0us, total: 139.15ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 81985528.99sec, total: 81985529.00sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 81985528.99sec, total: 81985528.99sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 81985528.99sec, total: 81985528.99sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 81985528.99sec, total: 81985528.99sec
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.28ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.28ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 258us, total: 1.44ms
      train.py:343:hfe, cpu: 476us, accelerator: 604us, total: 1.08ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 81985528.99sec, total: 81985528.99sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.93ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.32ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 1.32ms, total: 6.93ms
  __init__.py:185:compute_gradients, cpu: 2.87ms, accelerator: 2.61ms, total: 5.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_56250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 81622761.16sec, total: 81622761.16sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 405us, accelerator: 81622761.16sec, total: 81622761.16sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.24ms, accelerator: 0us, total: 139.24ms
train.py:442:<module>, cpu: 5.31ms, accelerator: 81622761.17sec, total: 81622761.17sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 81622761.16sec, total: 81622761.17sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 81622761.16sec, total: 81622761.17sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 81622761.16sec, total: 81622761.17sec
  train.py:359:image_losses, cpu: 2.05ms, accelerator: 1.28ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.03ms, accelerator: 1.28ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.18ms, accelerator: 256us, total: 1.44ms
      train.py:343:hfe, cpu: 475us, accelerator: 601us, total: 1.08ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 81622761.16sec, total: 81622761.17sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.92ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.31ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.57ms, accelerator: 1.31ms, total: 6.91ms
  __init__.py:185:compute_gradients, cpu: 2.86ms, accelerator: 2.60ms, total: 5.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_56500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 81263189.52sec, total: 81263189.53sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 403us, accelerator: 81263189.52sec, total: 81263189.53sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.30ms, accelerator: 0us, total: 139.30ms
train.py:442:<module>, cpu: 5.35ms, accelerator: 81263189.53sec, total: 81263189.54sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 81263189.53sec, total: 81263189.53sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 81263189.53sec, total: 81263189.53sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 81263189.53sec, total: 81263189.53sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.30ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.30ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 272us, total: 1.50ms
      train.py:343:hfe, cpu: 473us, accelerator: 604us, total: 1.08ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 81263189.53sec, total: 81263189.53sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.92ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.31ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.56ms, accelerator: 1.31ms, total: 6.89ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.61ms, total: 5.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_56750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 80906772.03sec, total: 80906772.03sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 404us, accelerator: 80906772.03sec, total: 80906772.03sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.23ms, accelerator: 0us, total: 139.23ms
train.py:442:<module>, cpu: 5.36ms, accelerator: 80906772.03sec, total: 80906772.04sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 80906772.03sec, total: 80906772.03sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 80906772.03sec, total: 80906772.03sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 80906772.03sec, total: 80906772.03sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.30ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.30ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 272us, total: 1.49ms
      train.py:343:hfe, cpu: 472us, accelerator: 602us, total: 1.08ms
train.py:441:<module> (gradient), cpu: 4.13ms, accelerator: 80906772.03sec, total: 80906772.03sec
train.py:511:<module>, cpu: 8.02sec, accelerator: 3.91ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.02sec, accelerator: 1.31ms, total: 8.02sec
    __init__.py:83:allreduce, cpu: 8.01sec, accelerator: 0us, total: 8.01sec
    __init__.py:86:allreduce, cpu: 5.55ms, accelerator: 1.31ms, total: 6.88ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.60ms, total: 5.50ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2123.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_57000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 80553467.35sec, total: 80553467.35sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 403us, accelerator: 80553467.35sec, total: 80553467.35sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.15ms, accelerator: 0us, total: 139.15ms
train.py:442:<module>, cpu: 5.35ms, accelerator: 80553467.35sec, total: 80553467.36sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 80553467.35sec, total: 80553467.35sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 80553467.35sec, total: 80553467.35sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 80553467.35sec, total: 80553467.35sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.29ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.29ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 271us, total: 1.49ms
      train.py:343:hfe, cpu: 470us, accelerator: 600us, total: 1.07ms
train.py:441:<module> (gradient), cpu: 4.12ms, accelerator: 80553467.35sec, total: 80553467.35sec
train.py:511:<module>, cpu: 8.01sec, accelerator: 3.89ms, total: 8.02sec
  __init__.py:194:compute_gradients, cpu: 8.01sec, accelerator: 1.30ms, total: 8.01sec
    __init__.py:83:allreduce, cpu: 8.00sec, accelerator: 0us, total: 8.00sec
    __init__.py:86:allreduce, cpu: 5.53ms, accelerator: 1.30ms, total: 6.86ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.59ms, total: 5.49ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_57250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 80203234.88sec, total: 80203234.88sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 402us, accelerator: 80203234.88sec, total: 80203234.88sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.16ms, accelerator: 0us, total: 139.16ms
train.py:442:<module>, cpu: 5.34ms, accelerator: 80203234.89sec, total: 80203234.89sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 80203234.88sec, total: 80203234.89sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 80203234.88sec, total: 80203234.89sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 80203234.88sec, total: 80203234.89sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.29ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.29ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 271us, total: 1.48ms
      train.py:343:hfe, cpu: 469us, accelerator: 597us, total: 1.07ms
train.py:441:<module> (gradient), cpu: 4.12ms, accelerator: 80203234.88sec, total: 80203234.89sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.93ms, total: 8.03sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.29ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.55ms, accelerator: 1.29ms, total: 6.87ms
  __init__.py:185:compute_gradients, cpu: 2.85ms, accelerator: 2.64ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_57500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 79856034.73sec, total: 79856034.73sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 402us, accelerator: 79856034.73sec, total: 79856034.73sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.04ms, accelerator: 0us, total: 139.04ms
train.py:442:<module>, cpu: 5.33ms, accelerator: 79856034.73sec, total: 79856034.74sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 79856034.73sec, total: 79856034.73sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 79856034.73sec, total: 79856034.73sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 79856034.73sec, total: 79856034.73sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.29ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.29ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 270us, total: 1.48ms
      train.py:343:hfe, cpu: 468us, accelerator: 597us, total: 1.07ms
train.py:441:<module> (gradient), cpu: 4.12ms, accelerator: 79856034.73sec, total: 79856034.73sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.92ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.29ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.62ms, accelerator: 1.29ms, total: 6.93ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.63ms, total: 5.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_57750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 79511827.68sec, total: 79511827.68sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 402us, accelerator: 79511827.68sec, total: 79511827.68sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.04ms, accelerator: 0us, total: 139.04ms
train.py:442:<module>, cpu: 5.32ms, accelerator: 79511827.69sec, total: 79511827.69sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 79511827.69sec, total: 79511827.69sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 79511827.69sec, total: 79511827.69sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 79511827.69sec, total: 79511827.69sec
  train.py:359:image_losses, cpu: 2.06ms, accelerator: 1.28ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.04ms, accelerator: 1.28ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 268us, total: 1.48ms
      train.py:343:hfe, cpu: 466us, accelerator: 593us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 79511827.68sec, total: 79511827.69sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.91ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.29ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 1.29ms, total: 6.90ms
  __init__.py:185:compute_gradients, cpu: 2.84ms, accelerator: 2.62ms, total: 5.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_58000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 79170575.20sec, total: 79170575.20sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 401us, accelerator: 79170575.20sec, total: 79170575.20sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.21ms, accelerator: 0us, total: 139.21ms
train.py:442:<module>, cpu: 5.36ms, accelerator: 79170575.21sec, total: 79170575.21sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 79170575.21sec, total: 79170575.21sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 79170575.21sec, total: 79170575.21sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 79170575.21sec, total: 79170575.21sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.27ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.27ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 267us, total: 1.52ms
      train.py:343:hfe, cpu: 465us, accelerator: 592us, total: 1.06ms
train.py:441:<module> (gradient), cpu: 4.14ms, accelerator: 79170575.20sec, total: 79170575.21sec
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.90ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.28ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.28ms, total: 6.91ms
  __init__.py:185:compute_gradients, cpu: 2.90ms, accelerator: 2.61ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_58250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 78832239.41sec, total: 78832239.41sec (50.00%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 78832239.41sec, total: 78832239.41sec (50.00%)
top 3 operation type: HorovodAllreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec (0.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.31ms, accelerator: 0us, total: 139.31ms
train.py:442:<module>, cpu: 5.35ms, accelerator: 78832239.42sec, total: 78832239.42sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 78832239.41sec, total: 78832239.42sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 78832239.41sec, total: 78832239.42sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 78832239.41sec, total: 78832239.42sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.27ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.27ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 266us, total: 1.51ms
      train.py:343:hfe, cpu: 465us, accelerator: 587us, total: 1.05ms
train.py:441:<module> (gradient), cpu: 4.14ms, accelerator: 78832239.41sec, total: 78832239.42sec
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.88ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.28ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.60ms, accelerator: 1.28ms, total: 6.90ms
  __init__.py:185:compute_gradients, cpu: 2.89ms, accelerator: 2.60ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_58500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 78496783.07sec, total: 78496783.07sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 78496783.07sec, total: 78496783.07sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.93ms, accelerator: 78496783.07sec, total: 78496783.07sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.38ms, accelerator: 0us, total: 139.38ms
train.py:441:<module> (gradient), cpu: 4.14ms, accelerator: 156993566.14sec, total: 156993566.15sec
train.py:442:<module>, cpu: 5.35ms, accelerator: 78496783.08sec, total: 78496783.08sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 78496783.08sec, total: 78496783.08sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 78496783.08sec, total: 78496783.08sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 78496783.08sec, total: 78496783.08sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.26ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.26ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 266us, total: 1.52ms
      train.py:343:hfe, cpu: 465us, accelerator: 586us, total: 1.05ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.93ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.27ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.27ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.65ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_58750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 78164169.59sec, total: 78164169.59sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 78164169.59sec, total: 78164169.59sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.92ms, accelerator: 78164169.58sec, total: 78164169.58sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.42ms, accelerator: 0us, total: 139.42ms
train.py:441:<module> (gradient), cpu: 4.14ms, accelerator: 156328339.17sec, total: 156328339.17sec
train.py:442:<module>, cpu: 5.36ms, accelerator: 78164169.59sec, total: 78164169.60sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 78164169.59sec, total: 78164169.59sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 78164169.59sec, total: 78164169.59sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 78164169.59sec, total: 78164169.59sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.26ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.26ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 264us, total: 1.52ms
      train.py:343:hfe, cpu: 467us, accelerator: 585us, total: 1.06ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.91ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.27ms, total: 8.04sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.62ms, accelerator: 1.27ms, total: 6.92ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.64ms, total: 5.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_59000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 77834362.96sec, total: 77834362.96sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 77834362.96sec, total: 77834362.96sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 77834362.96sec, total: 77834362.96sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.51ms, accelerator: 0us, total: 139.51ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 155668725.92sec, total: 155668725.93sec
train.py:442:<module>, cpu: 5.39ms, accelerator: 77834362.97sec, total: 77834362.97sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 77834362.97sec, total: 77834362.97sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 77834362.97sec, total: 77834362.97sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 77834362.97sec, total: 77834362.97sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.25ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.25ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 264us, total: 1.52ms
      train.py:343:hfe, cpu: 505us, accelerator: 581us, total: 1.09ms
train.py:511:<module>, cpu: 8.04sec, accelerator: 3.90ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.27ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.03sec, accelerator: 0us, total: 8.03sec
    __init__.py:86:allreduce, cpu: 5.60ms, accelerator: 1.27ms, total: 6.89ms
  __init__.py:185:compute_gradients, cpu: 2.89ms, accelerator: 2.63ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_59250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 77507327.82sec, total: 77507327.83sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 77507327.82sec, total: 77507327.82sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 77507327.82sec, total: 77507327.82sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.39ms, accelerator: 0us, total: 139.39ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 155014655.65sec, total: 155014655.65sec
train.py:442:<module>, cpu: 5.43ms, accelerator: 77507327.83sec, total: 77507327.84sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 77507327.83sec, total: 77507327.83sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 77507327.83sec, total: 77507327.83sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 77507327.83sec, total: 77507327.83sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.27ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.27ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 263us, total: 1.57ms
      train.py:343:hfe, cpu: 505us, accelerator: 601us, total: 1.11ms
train.py:511:<module>, cpu: 8.03sec, accelerator: 3.90ms, total: 8.04sec
  __init__.py:194:compute_gradients, cpu: 8.03sec, accelerator: 1.27ms, total: 8.03sec
    __init__.py:83:allreduce, cpu: 8.02sec, accelerator: 0us, total: 8.02sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 1.27ms, total: 6.89ms
  __init__.py:185:compute_gradients, cpu: 2.88ms, accelerator: 2.63ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_59500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 77183029.38sec, total: 77183029.38sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 77183029.38sec, total: 77183029.38sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 77183029.38sec, total: 77183029.38sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.45ms, accelerator: 0us, total: 139.45ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 154366058.76sec, total: 154366058.76sec
train.py:442:<module>, cpu: 5.43ms, accelerator: 77183029.39sec, total: 77183029.39sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 77183029.39sec, total: 77183029.39sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 77183029.39sec, total: 77183029.39sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 77183029.39sec, total: 77183029.39sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.27ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.27ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 263us, total: 1.56ms
      train.py:343:hfe, cpu: 505us, accelerator: 601us, total: 1.11ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.89ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.27ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.57ms, accelerator: 1.27ms, total: 6.87ms
  __init__.py:185:compute_gradients, cpu: 2.92ms, accelerator: 2.62ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_59750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 76861433.43sec, total: 76861433.43sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 76861433.43sec, total: 76861433.43sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 76861433.42sec, total: 76861433.42sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.43ms, accelerator: 0us, total: 139.43ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 153722866.85sec, total: 153722866.85sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 76861433.43sec, total: 76861433.44sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 76861433.43sec, total: 76861433.43sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 76861433.43sec, total: 76861433.43sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 76861433.43sec, total: 76861433.43sec
  train.py:359:image_losses, cpu: 2.25ms, accelerator: 1.27ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.23ms, accelerator: 1.27ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 262us, total: 1.58ms
      train.py:343:hfe, cpu: 548us, accelerator: 599us, total: 1.15ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.88ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.26ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.62ms, accelerator: 1.26ms, total: 6.90ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.62ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_60000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 76542506.32sec, total: 76542506.32sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 76542506.32sec, total: 76542506.32sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 76542506.31sec, total: 76542506.31sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.50ms, accelerator: 0us, total: 139.50ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 153085012.63sec, total: 153085012.63sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 76542506.32sec, total: 76542506.33sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 76542506.32sec, total: 76542506.32sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 76542506.32sec, total: 76542506.32sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 76542506.32sec, total: 76542506.32sec
  train.py:359:image_losses, cpu: 2.24ms, accelerator: 1.26ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.23ms, accelerator: 1.26ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 262us, total: 1.58ms
      train.py:343:hfe, cpu: 547us, accelerator: 596us, total: 1.15ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 3.92ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.30ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.73ms, accelerator: 1.30ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.62ms, total: 5.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_60250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 76226214.97sec, total: 76226214.97sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 76226214.97sec, total: 76226214.97sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 76226214.96sec, total: 76226214.97sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.46ms, accelerator: 0us, total: 139.46ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 152452429.93sec, total: 152452429.94sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 76226214.97sec, total: 76226214.98sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 76226214.97sec, total: 76226214.97sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 76226214.97sec, total: 76226214.97sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 76226214.97sec, total: 76226214.97sec
  train.py:359:image_losses, cpu: 2.24ms, accelerator: 1.26ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.22ms, accelerator: 1.26ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 261us, total: 1.57ms
      train.py:343:hfe, cpu: 546us, accelerator: 593us, total: 1.14ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 3.91ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.30ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.71ms, accelerator: 1.30ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.61ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_60500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 75912526.84sec, total: 75912526.84sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 75912526.84sec, total: 75912526.84sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 75912526.84sec, total: 75912526.84sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.44ms, accelerator: 0us, total: 139.44ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 151825053.68sec, total: 151825053.68sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 75912526.85sec, total: 75912526.85sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 75912526.84sec, total: 75912526.85sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 75912526.84sec, total: 75912526.85sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 75912526.84sec, total: 75912526.85sec
  train.py:359:image_losses, cpu: 2.23ms, accelerator: 1.25ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.21ms, accelerator: 1.25ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 260us, total: 1.56ms
      train.py:343:hfe, cpu: 544us, accelerator: 590us, total: 1.14ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.06ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.29ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.69ms, accelerator: 1.29ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.76ms, total: 5.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_60750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 75601409.93sec, total: 75601409.93sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 75601409.93sec, total: 75601409.93sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 75601409.92sec, total: 75601409.93sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.44ms, accelerator: 0us, total: 139.44ms
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 151202819.85sec, total: 151202819.86sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 75601409.93sec, total: 75601409.94sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 75601409.93sec, total: 75601409.93sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 75601409.93sec, total: 75601409.93sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 75601409.93sec, total: 75601409.93sec
  train.py:359:image_losses, cpu: 2.22ms, accelerator: 1.25ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.21ms, accelerator: 1.25ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 260us, total: 1.56ms
      train.py:343:hfe, cpu: 542us, accelerator: 590us, total: 1.14ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.05ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.04sec, accelerator: 1.29ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.68ms, accelerator: 1.29ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.75ms, total: 5.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_61000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 75292832.74sec, total: 75292832.74sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 75292832.74sec, total: 75292832.74sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 75292832.74sec, total: 75292832.74sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.57ms, accelerator: 0us, total: 139.57ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 150585665.48sec, total: 150585665.49sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 75292832.75sec, total: 75292832.75sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 75292832.75sec, total: 75292832.75sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 75292832.75sec, total: 75292832.75sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 75292832.75sec, total: 75292832.75sec
  train.py:359:image_losses, cpu: 2.22ms, accelerator: 1.25ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.20ms, accelerator: 1.25ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 259us, total: 1.56ms
      train.py:343:hfe, cpu: 540us, accelerator: 587us, total: 1.13ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.03ms, total: 8.05sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.29ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.71ms, accelerator: 1.29ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.75ms, total: 5.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_61250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 74986764.32sec, total: 74986764.32sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 74986764.32sec, total: 74986764.32sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 74986764.31sec, total: 74986764.32sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.64ms, accelerator: 0us, total: 139.64ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 149973528.63sec, total: 149973528.64sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 74986764.32sec, total: 74986764.33sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 74986764.32sec, total: 74986764.32sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 74986764.32sec, total: 74986764.32sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 74986764.32sec, total: 74986764.32sec
  train.py:359:image_losses, cpu: 2.22ms, accelerator: 1.24ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.20ms, accelerator: 1.24ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 258us, total: 1.55ms
      train.py:343:hfe, cpu: 539us, accelerator: 585us, total: 1.13ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.02ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.28ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.70ms, accelerator: 1.28ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.92ms, accelerator: 2.74ms, total: 5.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_61500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 74683174.18sec, total: 74683174.18sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 74683174.18sec, total: 74683174.18sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 74683174.18sec, total: 74683174.18sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.71ms, accelerator: 0us, total: 139.71ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 149366348.36sec, total: 149366348.36sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 74683174.18sec, total: 74683174.19sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 74683174.18sec, total: 74683174.19sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 74683174.18sec, total: 74683174.19sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 74683174.18sec, total: 74683174.19sec
  train.py:359:image_losses, cpu: 2.21ms, accelerator: 1.25ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.25ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 257us, total: 1.55ms
      train.py:343:hfe, cpu: 537us, accelerator: 585us, total: 1.13ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.08ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.29ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.73ms, accelerator: 1.29ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.92ms, accelerator: 2.79ms, total: 5.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_61750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 74382032.35sec, total: 74382032.35sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 74382032.35sec, total: 74382032.35sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 74382032.34sec, total: 74382032.35sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.54ms, accelerator: 0us, total: 139.54ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 148764064.69sec, total: 148764064.70sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 74382032.35sec, total: 74382032.36sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 74382032.35sec, total: 74382032.35sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 74382032.35sec, total: 74382032.35sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 74382032.35sec, total: 74382032.35sec
  train.py:359:image_losses, cpu: 2.23ms, accelerator: 1.25ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.21ms, accelerator: 1.25ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 257us, total: 1.57ms
      train.py:343:hfe, cpu: 536us, accelerator: 584us, total: 1.12ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.07ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.29ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.72ms, accelerator: 1.29ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.91ms, accelerator: 2.79ms, total: 5.75ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_62000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 74083309.33sec, total: 74083309.33sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 74083309.33sec, total: 74083309.33sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 74083309.32sec, total: 74083309.33sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.47ms, accelerator: 0us, total: 139.47ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 148166618.65sec, total: 148166618.65sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 74083309.33sec, total: 74083309.34sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 74083309.33sec, total: 74083309.33sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 74083309.33sec, total: 74083309.33sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 74083309.33sec, total: 74083309.33sec
  train.py:359:image_losses, cpu: 2.24ms, accelerator: 1.24ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.22ms, accelerator: 1.24ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.31ms, accelerator: 256us, total: 1.56ms
      train.py:343:hfe, cpu: 556us, accelerator: 582us, total: 1.14ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.06ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.28ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.70ms, accelerator: 1.28ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.77ms, total: 5.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_62250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 73786976.09sec, total: 73786976.09sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 73786976.09sec, total: 73786976.09sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 73786976.09sec, total: 73786976.09sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.45ms, accelerator: 0us, total: 139.45ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 147573952.17sec, total: 147573952.18sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 73786976.09sec, total: 73786976.10sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 73786976.09sec, total: 73786976.10sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 73786976.09sec, total: 73786976.10sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 73786976.09sec, total: 73786976.10sec
  train.py:359:image_losses, cpu: 2.23ms, accelerator: 1.24ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.22ms, accelerator: 1.24ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 253us, total: 1.56ms
      train.py:343:hfe, cpu: 554us, accelerator: 581us, total: 1.14ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.04ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.28ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.69ms, accelerator: 1.28ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.76ms, total: 5.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_62500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 73493004.07sec, total: 73493004.07sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 73493004.07sec, total: 73493004.07sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 73493004.07sec, total: 73493004.07sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.27ms, accelerator: 0us, total: 139.27ms
train.py:441:<module> (gradient), cpu: 4.15ms, accelerator: 146986008.14sec, total: 146986008.15sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 73493004.08sec, total: 73493004.08sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 73493004.08sec, total: 73493004.08sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 73493004.08sec, total: 73493004.08sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 73493004.08sec, total: 73493004.08sec
  train.py:359:image_losses, cpu: 2.23ms, accelerator: 1.27ms, total: 3.51ms
    train.py:322:loss_fn, cpu: 2.21ms, accelerator: 1.27ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 253us, total: 1.56ms
      train.py:343:hfe, cpu: 553us, accelerator: 602us, total: 1.16ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.08ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.31ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.68ms, accelerator: 1.31ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.77ms, total: 5.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_62750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 73201365.17sec, total: 73201365.17sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 401us, accelerator: 73201365.17sec, total: 73201365.17sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 73201365.16sec, total: 73201365.17sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.09ms, accelerator: 0us, total: 139.09ms
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 146402730.33sec, total: 146402730.34sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 73201365.17sec, total: 73201365.18sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 73201365.17sec, total: 73201365.17sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 73201365.17sec, total: 73201365.17sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 73201365.17sec, total: 73201365.17sec
  train.py:359:image_losses, cpu: 2.23ms, accelerator: 1.26ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.21ms, accelerator: 1.26ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.30ms, accelerator: 253us, total: 1.55ms
      train.py:343:hfe, cpu: 553us, accelerator: 599us, total: 1.16ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.07ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.31ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.67ms, accelerator: 1.31ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.76ms, total: 5.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_63000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 72912031.71sec, total: 72912031.71sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 401us, accelerator: 72912031.71sec, total: 72912031.71sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 72912031.71sec, total: 72912031.71sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.01ms, accelerator: 0us, total: 139.01ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 145824063.41sec, total: 145824063.42sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 72912031.71sec, total: 72912031.72sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 72912031.71sec, total: 72912031.71sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 72912031.71sec, total: 72912031.71sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 72912031.71sec, total: 72912031.71sec
  train.py:359:image_losses, cpu: 2.22ms, accelerator: 1.26ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.20ms, accelerator: 1.26ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 251us, total: 1.55ms
      train.py:343:hfe, cpu: 551us, accelerator: 598us, total: 1.15ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.06ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.31ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.69ms, accelerator: 1.31ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.75ms, total: 5.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_63250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 72624976.46sec, total: 72624976.47sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 72624976.47sec, total: 72624976.47sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 72624976.46sec, total: 72624976.46sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.87ms, accelerator: 0us, total: 138.87ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 145249952.93sec, total: 145249952.93sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 72624976.47sec, total: 72624976.48sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 72624976.47sec, total: 72624976.47sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 72624976.47sec, total: 72624976.47sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 72624976.47sec, total: 72624976.47sec
  train.py:359:image_losses, cpu: 2.21ms, accelerator: 1.27ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.27ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 251us, total: 1.54ms
      train.py:343:hfe, cpu: 549us, accelerator: 608us, total: 1.16ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.07ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.30ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.68ms, accelerator: 1.30ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.77ms, total: 5.74ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_63500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 72340172.64sec, total: 72340172.64sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 72340172.64sec, total: 72340172.64sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 72340172.63sec, total: 72340172.64sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.76ms, accelerator: 0us, total: 138.76ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 144680345.27sec, total: 144680345.27sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 72340172.64sec, total: 72340172.65sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 72340172.64sec, total: 72340172.64sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 72340172.64sec, total: 72340172.64sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 72340172.64sec, total: 72340172.64sec
  train.py:359:image_losses, cpu: 2.21ms, accelerator: 1.29ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.29ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 254us, total: 1.54ms
      train.py:343:hfe, cpu: 549us, accelerator: 622us, total: 1.18ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.10ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.34ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.67ms, accelerator: 1.34ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.76ms, total: 5.74ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_63750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 72057593.84sec, total: 72057593.84sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 396us, accelerator: 72057593.84sec, total: 72057593.84sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 72057593.83sec, total: 72057593.84sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.60ms, accelerator: 0us, total: 138.60ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 144115187.67sec, total: 144115187.68sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 72057593.84sec, total: 72057593.85sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 72057593.84sec, total: 72057593.84sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 72057593.84sec, total: 72057593.84sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 72057593.84sec, total: 72057593.84sec
  train.py:359:image_losses, cpu: 2.21ms, accelerator: 1.28ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.28ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 254us, total: 1.54ms
      train.py:343:hfe, cpu: 549us, accelerator: 619us, total: 1.17ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.09ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.34ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.65ms, accelerator: 1.34ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.75ms, total: 5.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_64000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 71777214.09sec, total: 71777214.10sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 71777214.09sec, total: 71777214.09sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 71777214.09sec, total: 71777214.09sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.63ms, accelerator: 0us, total: 138.63ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 143554428.19sec, total: 143554428.19sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 71777214.10sec, total: 71777214.11sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 71777214.10sec, total: 71777214.10sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 71777214.10sec, total: 71777214.10sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 71777214.10sec, total: 71777214.10sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.28ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.18ms, accelerator: 1.28ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 253us, total: 1.53ms
      train.py:343:hfe, cpu: 547us, accelerator: 619us, total: 1.17ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.08ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.34ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.34ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.74ms, total: 5.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_64250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 71499007.84sec, total: 71499007.84sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 71499007.84sec, total: 71499007.84sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 71499007.84sec, total: 71499007.84sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.63ms, accelerator: 0us, total: 138.63ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 142998015.67sec, total: 142998015.68sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 71499007.84sec, total: 71499007.85sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 71499007.84sec, total: 71499007.84sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 71499007.84sec, total: 71499007.84sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 71499007.84sec, total: 71499007.84sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.27ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.18ms, accelerator: 1.27ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 253us, total: 1.53ms
      train.py:343:hfe, cpu: 550us, accelerator: 616us, total: 1.17ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.07ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.33ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.62ms, accelerator: 1.33ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.74ms, total: 5.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_64500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 71222949.89sec, total: 71222949.89sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 71222949.89sec, total: 71222949.89sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 71222949.89sec, total: 71222949.89sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.57ms, accelerator: 0us, total: 138.57ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 142445899.78sec, total: 142445899.79sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 71222949.90sec, total: 71222949.90sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 71222949.90sec, total: 71222949.90sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 71222949.90sec, total: 71222949.90sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 71222949.90sec, total: 71222949.90sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.27ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.27ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 252us, total: 1.52ms
      train.py:343:hfe, cpu: 550us, accelerator: 614us, total: 1.17ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.05ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.32ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.63ms, accelerator: 1.32ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.73ms, total: 5.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_64750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 70949015.47sec, total: 70949015.47sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 70949015.47sec, total: 70949015.47sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 70949015.47sec, total: 70949015.47sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.44ms, accelerator: 0us, total: 138.44ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 141898030.94sec, total: 141898030.94sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 70949015.48sec, total: 70949015.48sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 70949015.47sec, total: 70949015.48sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 70949015.47sec, total: 70949015.48sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 70949015.47sec, total: 70949015.48sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.27ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.27ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 252us, total: 1.52ms
      train.py:343:hfe, cpu: 549us, accelerator: 614us, total: 1.17ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.04ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.32ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.04sec, accelerator: 0us, total: 8.04sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.32ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.72ms, total: 5.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_65000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 70677180.16sec, total: 70677180.16sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 70677180.16sec, total: 70677180.16sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 70677180.16sec, total: 70677180.16sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.45ms, accelerator: 0us, total: 138.45ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 141354360.32sec, total: 141354360.33sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 70677180.17sec, total: 70677180.17sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 70677180.17sec, total: 70677180.17sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 70677180.17sec, total: 70677180.17sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 70677180.17sec, total: 70677180.17sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.27ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.27ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 251us, total: 1.52ms
      train.py:343:hfe, cpu: 547us, accelerator: 618us, total: 1.17ms
train.py:511:<module>, cpu: 8.05sec, accelerator: 4.07ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.32ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.65ms, accelerator: 1.32ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.75ms, total: 5.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_65250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 70407419.93sec, total: 70407419.93sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 70407419.93sec, total: 70407419.93sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 70407419.93sec, total: 70407419.93sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.64ms, accelerator: 0us, total: 138.64ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 140814839.86sec, total: 140814839.87sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 70407419.94sec, total: 70407419.94sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 70407419.94sec, total: 70407419.94sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 70407419.94sec, total: 70407419.94sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 70407419.94sec, total: 70407419.94sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.27ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.27ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 250us, total: 1.51ms
      train.py:343:hfe, cpu: 546us, accelerator: 616us, total: 1.17ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.06ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.31ms, total: 8.05sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.66ms, accelerator: 1.31ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.75ms, total: 5.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_65500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 70139711.11sec, total: 70139711.11sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 396us, accelerator: 70139711.11sec, total: 70139711.11sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 70139711.11sec, total: 70139711.11sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.62ms, accelerator: 0us, total: 138.62ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 140279422.22sec, total: 140279422.22sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 70139711.12sec, total: 70139711.12sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 70139711.11sec, total: 70139711.12sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 70139711.11sec, total: 70139711.12sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 70139711.11sec, total: 70139711.12sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.26ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.26ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 249us, total: 1.51ms
      train.py:343:hfe, cpu: 546us, accelerator: 614us, total: 1.16ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.04ms, total: 8.06sec
  __init__.py:194:compute_gradients, cpu: 8.05sec, accelerator: 1.31ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.05sec, accelerator: 0us, total: 8.05sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.31ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.73ms, total: 5.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_65750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 69874030.39sec, total: 69874030.39sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 396us, accelerator: 69874030.39sec, total: 69874030.39sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 69874030.38sec, total: 69874030.39sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.69ms, accelerator: 0us, total: 138.69ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 139748060.77sec, total: 139748060.78sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 69874030.39sec, total: 69874030.40sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 69874030.39sec, total: 69874030.39sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 69874030.39sec, total: 69874030.39sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 69874030.39sec, total: 69874030.39sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.26ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.26ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 249us, total: 1.51ms
      train.py:343:hfe, cpu: 546us, accelerator: 611us, total: 1.16ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.03ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.30ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.63ms, accelerator: 1.30ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.73ms, total: 5.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_66000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 69610354.80sec, total: 69610354.80sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 69610354.80sec, total: 69610354.80sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 69610354.80sec, total: 69610354.80sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.70ms, accelerator: 0us, total: 138.70ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 139220709.60sec, total: 139220709.60sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 69610354.81sec, total: 69610354.81sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 69610354.80sec, total: 69610354.81sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 69610354.80sec, total: 69610354.81sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 69610354.80sec, total: 69610354.81sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.26ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.26ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 249us, total: 1.50ms
      train.py:343:hfe, cpu: 545us, accelerator: 609us, total: 1.16ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.02ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.30ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.65ms, accelerator: 1.30ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.71ms, total: 5.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_66250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 69348661.74sec, total: 69348661.74sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 69348661.74sec, total: 69348661.74sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 69348661.73sec, total: 69348661.74sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.76ms, accelerator: 0us, total: 138.76ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 138697323.47sec, total: 138697323.48sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 69348661.74sec, total: 69348661.75sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 69348661.74sec, total: 69348661.74sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 69348661.74sec, total: 69348661.74sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 69348661.74sec, total: 69348661.74sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.25ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.25ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 248us, total: 1.50ms
      train.py:343:hfe, cpu: 544us, accelerator: 609us, total: 1.16ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.01ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.30ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.63ms, accelerator: 1.30ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.71ms, total: 5.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_66500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 69088928.92sec, total: 69088928.92sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 69088928.92sec, total: 69088928.92sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 69088928.92sec, total: 69088928.92sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.78ms, accelerator: 0us, total: 138.78ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 138177857.84sec, total: 138177857.85sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 69088928.93sec, total: 69088928.93sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 69088928.93sec, total: 69088928.93sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 69088928.93sec, total: 69088928.93sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 69088928.93sec, total: 69088928.93sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.25ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.25ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 247us, total: 1.49ms
      train.py:343:hfe, cpu: 542us, accelerator: 604us, total: 1.15ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.08ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.37ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.37ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.71ms, total: 5.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_66750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 68831134.41sec, total: 68831134.41sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 401us, accelerator: 68831134.41sec, total: 68831134.41sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 68831134.41sec, total: 68831134.41sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.80ms, accelerator: 0us, total: 138.80ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 137662268.82sec, total: 137662268.82sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 68831134.42sec, total: 68831134.42sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 68831134.41sec, total: 68831134.42sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 68831134.41sec, total: 68831134.42sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 68831134.41sec, total: 68831134.42sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.26ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.26ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 246us, total: 1.49ms
      train.py:343:hfe, cpu: 540us, accelerator: 614us, total: 1.16ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.14ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.43ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.62ms, accelerator: 1.43ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.71ms, total: 5.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_67000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 68575256.59sec, total: 68575256.59sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 68575256.59sec, total: 68575256.59sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 68575256.59sec, total: 68575256.59sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.75ms, accelerator: 0us, total: 138.75ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 137150513.17sec, total: 137150513.18sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 68575256.59sec, total: 68575256.60sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 68575256.59sec, total: 68575256.59sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 68575256.59sec, total: 68575256.59sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 68575256.59sec, total: 68575256.59sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.26ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.26ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 246us, total: 1.49ms
      train.py:343:hfe, cpu: 539us, accelerator: 613us, total: 1.16ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.13ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.43ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.43ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.71ms, total: 5.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_67250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 68321274.16sec, total: 68321274.16sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 68321274.16sec, total: 68321274.16sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 68321274.15sec, total: 68321274.16sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.93ms, accelerator: 0us, total: 138.93ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 136642548.31sec, total: 136642548.31sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 68321274.16sec, total: 68321274.17sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 68321274.16sec, total: 68321274.16sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 68321274.16sec, total: 68321274.16sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 68321274.16sec, total: 68321274.16sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.25ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.25ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 245us, total: 1.48ms
      train.py:343:hfe, cpu: 539us, accelerator: 609us, total: 1.15ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.12ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.42ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.60ms, accelerator: 1.42ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.69ms, total: 5.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_67500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 68069166.13sec, total: 68069166.13sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 68069166.13sec, total: 68069166.13sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 68069166.13sec, total: 68069166.13sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.92ms, accelerator: 0us, total: 138.92ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 136138332.26sec, total: 136138332.27sec
train.py:442:<module>, cpu: 5.44ms, accelerator: 68069166.14sec, total: 68069166.14sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 68069166.14sec, total: 68069166.14sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 68069166.14sec, total: 68069166.14sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 68069166.14sec, total: 68069166.14sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.27ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.27ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 245us, total: 1.48ms
      train.py:343:hfe, cpu: 537us, accelerator: 621us, total: 1.16ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.12ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.42ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 1.42ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.70ms, total: 5.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_67750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 67818911.85sec, total: 67818911.85sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 67818911.85sec, total: 67818911.85sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 67818911.84sec, total: 67818911.85sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.89ms, accelerator: 0us, total: 138.89ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 135637823.69sec, total: 135637823.69sec
train.py:442:<module>, cpu: 5.43ms, accelerator: 67818911.85sec, total: 67818911.86sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 67818911.85sec, total: 67818911.85sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 67818911.85sec, total: 67818911.85sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 67818911.85sec, total: 67818911.85sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.27ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.27ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 244us, total: 1.47ms
      train.py:343:hfe, cpu: 537us, accelerator: 618us, total: 1.16ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.11ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.42ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.58ms, accelerator: 1.42ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.69ms, total: 5.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_68000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 67570490.92sec, total: 67570490.92sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 67570490.92sec, total: 67570490.92sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 67570490.92sec, total: 67570490.92sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.88ms, accelerator: 0us, total: 138.88ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 135140981.85sec, total: 135140981.85sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 67570490.93sec, total: 67570490.94sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 67570490.93sec, total: 67570490.93sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 67570490.93sec, total: 67570490.93sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 67570490.93sec, total: 67570490.93sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.26ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.26ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 243us, total: 1.49ms
      train.py:343:hfe, cpu: 533us, accelerator: 616us, total: 1.16ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.10ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.42ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.57ms, accelerator: 1.42ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.68ms, total: 5.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_68250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 67323883.29sec, total: 67323883.29sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 67323883.29sec, total: 67323883.29sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 67323883.29sec, total: 67323883.29sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.91ms, accelerator: 0us, total: 138.91ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 134647766.58sec, total: 134647766.59sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 67323883.30sec, total: 67323883.30sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 67323883.30sec, total: 67323883.30sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 67323883.30sec, total: 67323883.30sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 67323883.30sec, total: 67323883.30sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.26ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.26ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 243us, total: 1.49ms
      train.py:343:hfe, cpu: 533us, accelerator: 615us, total: 1.15ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.09ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.41ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.56ms, accelerator: 1.41ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.67ms, total: 5.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_68500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 67079069.17sec, total: 67079069.17sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 67079069.17sec, total: 67079069.17sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 67079069.17sec, total: 67079069.17sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.92ms, accelerator: 0us, total: 138.92ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 134158138.34sec, total: 134158138.35sec
train.py:442:<module>, cpu: 5.44ms, accelerator: 67079069.18sec, total: 67079069.18sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 67079069.18sec, total: 67079069.18sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 67079069.18sec, total: 67079069.18sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 67079069.18sec, total: 67079069.18sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.25ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.25ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 242us, total: 1.48ms
      train.py:343:hfe, cpu: 532us, accelerator: 612us, total: 1.15ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.08ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.41ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.55ms, accelerator: 1.41ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.67ms, total: 5.71ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_68750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 66836029.07sec, total: 66836029.07sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 66836029.07sec, total: 66836029.07sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 66836029.06sec, total: 66836029.07sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.83ms, accelerator: 0us, total: 138.83ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 133672058.13sec, total: 133672058.13sec
train.py:442:<module>, cpu: 5.44ms, accelerator: 66836029.07sec, total: 66836029.08sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 66836029.07sec, total: 66836029.07sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 66836029.07sec, total: 66836029.07sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 66836029.07sec, total: 66836029.07sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.25ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.25ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 242us, total: 1.48ms
      train.py:343:hfe, cpu: 531us, accelerator: 610us, total: 1.15ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.06ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.40ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.54ms, accelerator: 1.40ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.65ms, total: 5.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_69000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 66594743.76sec, total: 66594743.76sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 66594743.76sec, total: 66594743.76sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 66594743.76sec, total: 66594743.76sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.74ms, accelerator: 0us, total: 138.74ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 133189487.52sec, total: 133189487.53sec
train.py:442:<module>, cpu: 5.43ms, accelerator: 66594743.77sec, total: 66594743.77sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 66594743.77sec, total: 66594743.77sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 66594743.77sec, total: 66594743.77sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 66594743.77sec, total: 66594743.77sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.25ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.25ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 241us, total: 1.48ms
      train.py:343:hfe, cpu: 531us, accelerator: 609us, total: 1.14ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.05ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.40ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.53ms, accelerator: 1.40ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.65ms, total: 5.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_69250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 66355194.32sec, total: 66355194.33sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 66355194.32sec, total: 66355194.32sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 66355194.32sec, total: 66355194.32sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.82ms, accelerator: 0us, total: 138.82ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 132710388.65sec, total: 132710388.65sec
train.py:442:<module>, cpu: 5.42ms, accelerator: 66355194.33sec, total: 66355194.34sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 66355194.33sec, total: 66355194.33sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 66355194.33sec, total: 66355194.33sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 66355194.33sec, total: 66355194.33sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.24ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.24ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 239us, total: 1.47ms
      train.py:343:hfe, cpu: 530us, accelerator: 606us, total: 1.14ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.06ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.40ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.52ms, accelerator: 1.40ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.67ms, total: 5.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_69500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 66117362.09sec, total: 66117362.09sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 66117362.09sec, total: 66117362.09sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 66117362.08sec, total: 66117362.09sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.69ms, accelerator: 0us, total: 138.69ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 132234724.17sec, total: 132234724.18sec
train.py:442:<module>, cpu: 5.42ms, accelerator: 66117362.09sec, total: 66117362.10sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 66117362.09sec, total: 66117362.09sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 66117362.09sec, total: 66117362.09sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 66117362.09sec, total: 66117362.09sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.24ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.24ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 239us, total: 1.47ms
      train.py:343:hfe, cpu: 530us, accelerator: 605us, total: 1.14ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.09ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.44ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.50ms, accelerator: 1.44ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.66ms, total: 5.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2122.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_69750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 65881228.65sec, total: 65881228.65sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 65881228.65sec, total: 65881228.65sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 65881228.65sec, total: 65881228.65sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.77ms, accelerator: 0us, total: 138.77ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 131762457.30sec, total: 131762457.30sec
train.py:442:<module>, cpu: 5.42ms, accelerator: 65881228.66sec, total: 65881228.66sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 65881228.65sec, total: 65881228.66sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 65881228.65sec, total: 65881228.66sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 65881228.65sec, total: 65881228.66sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.24ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.24ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 239us, total: 1.47ms
      train.py:343:hfe, cpu: 528us, accelerator: 603us, total: 1.13ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.08ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.43ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.43ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.65ms, total: 5.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_70000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 65646775.88sec, total: 65646775.88sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 65646775.88sec, total: 65646775.88sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 65646775.88sec, total: 65646775.88sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.94ms, accelerator: 0us, total: 138.94ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 131293551.76sec, total: 131293551.76sec
train.py:442:<module>, cpu: 5.42ms, accelerator: 65646775.89sec, total: 65646775.89sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 65646775.88sec, total: 65646775.89sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 65646775.88sec, total: 65646775.89sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 65646775.88sec, total: 65646775.89sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.23ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.23ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 237us, total: 1.47ms
      train.py:343:hfe, cpu: 527us, accelerator: 603us, total: 1.13ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.07ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.43ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.43ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.64ms, total: 5.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2123.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_70250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 65413985.89sec, total: 65413985.90sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 65413985.89sec, total: 65413985.89sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 65413985.89sec, total: 65413985.89sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.85ms, accelerator: 0us, total: 138.85ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 130827971.79sec, total: 130827971.79sec
train.py:442:<module>, cpu: 5.41ms, accelerator: 65413985.90sec, total: 65413985.91sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 65413985.90sec, total: 65413985.90sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 65413985.90sec, total: 65413985.90sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 65413985.90sec, total: 65413985.90sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.23ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.23ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 236us, total: 1.47ms
      train.py:343:hfe, cpu: 527us, accelerator: 600us, total: 1.13ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.22ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.54ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 1.54ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.68ms, total: 5.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_70500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 65182841.07sec, total: 65182841.07sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 65182841.07sec, total: 65182841.07sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 65182841.07sec, total: 65182841.07sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.73ms, accelerator: 0us, total: 138.73ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 130365682.13sec, total: 130365682.14sec
train.py:442:<module>, cpu: 5.41ms, accelerator: 65182841.07sec, total: 65182841.08sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 65182841.07sec, total: 65182841.07sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 65182841.07sec, total: 65182841.07sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 65182841.07sec, total: 65182841.07sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.23ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.23ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 235us, total: 1.46ms
      train.py:343:hfe, cpu: 526us, accelerator: 600us, total: 1.13ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.21ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.53ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.58ms, accelerator: 1.53ms, total: 7.14ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.67ms, total: 5.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_70750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 64953324.02sec, total: 64953324.02sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 64953324.02sec, total: 64953324.02sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 64953324.02sec, total: 64953324.02sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.79ms, accelerator: 0us, total: 138.79ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 129906648.04sec, total: 129906648.05sec
train.py:442:<module>, cpu: 5.41ms, accelerator: 64953324.03sec, total: 64953324.03sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 64953324.03sec, total: 64953324.03sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 64953324.03sec, total: 64953324.03sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 64953324.03sec, total: 64953324.03sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.22ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.22ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 234us, total: 1.47ms
      train.py:343:hfe, cpu: 524us, accelerator: 599us, total: 1.13ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.20ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.53ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.57ms, accelerator: 1.53ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.67ms, total: 5.69ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_71000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 64725417.62sec, total: 64725417.62sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 64725417.62sec, total: 64725417.62sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 64725417.62sec, total: 64725417.62sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.77ms, accelerator: 0us, total: 138.77ms
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 129450835.24sec, total: 129450835.25sec
train.py:442:<module>, cpu: 5.43ms, accelerator: 64725417.63sec, total: 64725417.63sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 64725417.63sec, total: 64725417.63sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 64725417.63sec, total: 64725417.63sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 64725417.63sec, total: 64725417.63sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.22ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.22ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 234us, total: 1.47ms
      train.py:343:hfe, cpu: 525us, accelerator: 594us, total: 1.12ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.18ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.53ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.56ms, accelerator: 1.53ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.66ms, total: 5.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_71250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 64499104.97sec, total: 64499104.97sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 64499104.97sec, total: 64499104.97sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 64499104.97sec, total: 64499104.97sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.89ms, accelerator: 0us, total: 138.89ms
train.py:441:<module> (gradient), cpu: 4.26ms, accelerator: 128998209.94sec, total: 128998209.95sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 64499104.98sec, total: 64499104.98sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 64499104.98sec, total: 64499104.98sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 64499104.98sec, total: 64499104.98sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 64499104.98sec, total: 64499104.98sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.21ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.21ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 234us, total: 1.47ms
      train.py:343:hfe, cpu: 525us, accelerator: 594us, total: 1.12ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.17ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.51ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.66ms, accelerator: 1.51ms, total: 7.20ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.65ms, total: 5.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_71500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 64274369.42sec, total: 64274369.42sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 64274369.42sec, total: 64274369.42sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 64274369.41sec, total: 64274369.41sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.98ms, accelerator: 0us, total: 138.98ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 128548738.83sec, total: 128548738.83sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 64274369.42sec, total: 64274369.43sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 64274369.42sec, total: 64274369.42sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 64274369.42sec, total: 64274369.42sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 64274369.42sec, total: 64274369.42sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.21ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.21ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 523us, accelerator: 591us, total: 1.12ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.16ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.51ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.51ms, total: 7.19ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.65ms, total: 5.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_71750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 64051194.52sec, total: 64051194.52sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 64051194.52sec, total: 64051194.52sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 64051194.52sec, total: 64051194.52sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.92ms, accelerator: 0us, total: 138.92ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 128102389.04sec, total: 128102389.05sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 64051194.53sec, total: 64051194.53sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 64051194.53sec, total: 64051194.53sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 64051194.53sec, total: 64051194.53sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 64051194.53sec, total: 64051194.53sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.21ms, total: 3.32ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.21ms, total: 3.30ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 521us, accelerator: 589us, total: 1.11ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.15ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.51ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.51ms, total: 7.17ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.64ms, total: 5.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_72000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 63829564.09sec, total: 63829564.09sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 63829564.09sec, total: 63829564.09sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 63829564.09sec, total: 63829564.09sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.97ms, accelerator: 0us, total: 138.97ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 127659128.18sec, total: 127659128.18sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 63829564.10sec, total: 63829564.10sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 63829564.09sec, total: 63829564.10sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 63829564.09sec, total: 63829564.10sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 63829564.09sec, total: 63829564.10sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.20ms, total: 3.31ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.20ms, total: 3.30ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 519us, accelerator: 589us, total: 1.11ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.13ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.50ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.63ms, accelerator: 1.50ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.63ms, total: 5.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2121.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_72250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 63609462.15sec, total: 63609462.15sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 63609462.15sec, total: 63609462.15sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 63609462.14sec, total: 63609462.15sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.94ms, accelerator: 0us, total: 138.94ms
train.py:441:<module> (gradient), cpu: 4.26ms, accelerator: 127218924.29sec, total: 127218924.29sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 63609462.15sec, total: 63609462.16sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 63609462.15sec, total: 63609462.15sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 63609462.15sec, total: 63609462.15sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 63609462.15sec, total: 63609462.15sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.20ms, total: 3.30ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.20ms, total: 3.29ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 518us, accelerator: 586us, total: 1.11ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.13ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.50ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.50ms, total: 7.14ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.62ms, total: 5.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_72500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 63390872.93sec, total: 63390872.93sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 63390872.93sec, total: 63390872.93sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 63390872.93sec, total: 63390872.93sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.13ms, accelerator: 0us, total: 139.13ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 126781745.86sec, total: 126781745.86sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 63390872.93sec, total: 63390872.94sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 63390872.93sec, total: 63390872.94sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 63390872.93sec, total: 63390872.94sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 63390872.93sec, total: 63390872.93sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.20ms, total: 3.30ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.20ms, total: 3.28ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 232us, total: 1.45ms
      train.py:343:hfe, cpu: 518us, accelerator: 584us, total: 1.11ms
train.py:511:<module>, cpu: 8.06sec, accelerator: 4.12ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.50ms, total: 8.06sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.50ms, total: 7.13ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.62ms, total: 5.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_72750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 63173780.90sec, total: 63173780.90sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 63173780.90sec, total: 63173780.90sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 63173780.90sec, total: 63173780.90sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.02ms, accelerator: 0us, total: 139.02ms
train.py:441:<module> (gradient), cpu: 4.26ms, accelerator: 126347561.79sec, total: 126347561.80sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 63173780.90sec, total: 63173780.91sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 63173780.90sec, total: 63173780.90sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 63173780.90sec, total: 63173780.90sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 63173780.90sec, total: 63173780.90sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.19ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.19ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 545us, accelerator: 582us, total: 1.13ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.11ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.49ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 1.49ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.61ms, total: 5.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_73000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 62958170.72sec, total: 62958170.73sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 62958170.72sec, total: 62958170.72sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 62958170.72sec, total: 62958170.72sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.00ms, accelerator: 0us, total: 139.00ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 125916341.45sec, total: 125916341.45sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 62958170.73sec, total: 62958170.74sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 62958170.73sec, total: 62958170.73sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 62958170.73sec, total: 62958170.73sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 62958170.73sec, total: 62958170.73sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.19ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.19ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 543us, accelerator: 581us, total: 1.13ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.09ms, total: 8.07sec
  __init__.py:194:compute_gradients, cpu: 8.06sec, accelerator: 1.49ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.58ms, accelerator: 1.49ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.60ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_73250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 62744027.29sec, total: 62744027.29sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 62744027.29sec, total: 62744027.29sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 62744027.28sec, total: 62744027.29sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.97ms, accelerator: 0us, total: 138.97ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 125488054.57sec, total: 125488054.58sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 62744027.29sec, total: 62744027.30sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 62744027.29sec, total: 62744027.29sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 62744027.29sec, total: 62744027.29sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 62744027.29sec, total: 62744027.29sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.19ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.19ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 229us, total: 1.46ms
      train.py:343:hfe, cpu: 543us, accelerator: 579us, total: 1.13ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.08ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.49ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.56ms, accelerator: 1.49ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.59ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2132.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_73500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 62531335.67sec, total: 62531335.67sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 401us, accelerator: 62531335.67sec, total: 62531335.67sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 62531335.67sec, total: 62531335.67sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 139.08ms, accelerator: 0us, total: 139.08ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 125062671.34sec, total: 125062671.34sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 62531335.67sec, total: 62531335.68sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 62531335.67sec, total: 62531335.67sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 62531335.67sec, total: 62531335.67sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 62531335.67sec, total: 62531335.67sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.18ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.18ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 228us, total: 1.46ms
      train.py:343:hfe, cpu: 543us, accelerator: 578us, total: 1.12ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.07ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.48ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.56ms, accelerator: 1.48ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.59ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_73750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 62320081.16sec, total: 62320081.16sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 401us, accelerator: 62320081.16sec, total: 62320081.16sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 62320081.15sec, total: 62320081.16sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.97ms, accelerator: 0us, total: 138.97ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 124640162.31sec, total: 124640162.31sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 62320081.16sec, total: 62320081.17sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 62320081.16sec, total: 62320081.16sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 62320081.16sec, total: 62320081.16sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 62320081.16sec, total: 62320081.16sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.24ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.24ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 228us, total: 1.45ms
      train.py:343:hfe, cpu: 540us, accelerator: 576us, total: 1.12ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.06ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.48ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.48ms, total: 7.14ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.58ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_74000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 62110249.23sec, total: 62110249.23sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 401us, accelerator: 62110249.23sec, total: 62110249.23sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 62110249.23sec, total: 62110249.23sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.92ms, accelerator: 0us, total: 138.92ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 124220498.46sec, total: 124220498.47sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 62110249.24sec, total: 62110249.24sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 62110249.24sec, total: 62110249.24sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 62110249.24sec, total: 62110249.24sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 62110249.24sec, total: 62110249.24sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.24ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.24ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 539us, accelerator: 574us, total: 1.12ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.04ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.48ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.65ms, accelerator: 1.48ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.57ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_74250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 61901825.58sec, total: 61901825.58sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 401us, accelerator: 61901825.58sec, total: 61901825.58sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 61901825.58sec, total: 61901825.58sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.89ms, accelerator: 0us, total: 138.89ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 123803651.15sec, total: 123803651.16sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 61901825.58sec, total: 61901825.59sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 61901825.58sec, total: 61901825.58sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 61901825.58sec, total: 61901825.58sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 61901825.58sec, total: 61901825.58sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.23ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.23ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 538us, accelerator: 572us, total: 1.11ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.03ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.47ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.67ms, accelerator: 1.47ms, total: 7.16ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.56ms, total: 5.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_74500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 61694796.06sec, total: 61694796.06sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 61694796.06sec, total: 61694796.06sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 61694796.06sec, total: 61694796.06sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.78ms, accelerator: 0us, total: 138.78ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 123389592.12sec, total: 123389592.12sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 61694796.07sec, total: 61694796.07sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 61694796.06sec, total: 61694796.07sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 61694796.06sec, total: 61694796.07sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 61694796.06sec, total: 61694796.07sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.23ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.23ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 227us, total: 1.44ms
      train.py:343:hfe, cpu: 537us, accelerator: 572us, total: 1.11ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.02ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.47ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.66ms, accelerator: 1.47ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 3.00ms, accelerator: 2.56ms, total: 5.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_74750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.21ms, accelerator: 61489146.74sec, total: 61489146.74sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 61489146.74sec, total: 61489146.74sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 61489146.74sec, total: 61489146.74sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.81ms, accelerator: 0us, total: 138.81ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 122978293.48sec, total: 122978293.48sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 61489146.75sec, total: 61489146.75sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 61489146.74sec, total: 61489146.75sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 61489146.74sec, total: 61489146.75sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 61489146.74sec, total: 61489146.75sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.22ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.22ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 224us, total: 1.44ms
      train.py:343:hfe, cpu: 537us, accelerator: 569us, total: 1.11ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.03ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.46ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.64ms, accelerator: 1.46ms, total: 7.13ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.57ms, total: 5.62ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_75000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 61284863.86sec, total: 61284863.86sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 61284863.86sec, total: 61284863.86sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 61284863.86sec, total: 61284863.86sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.79ms, accelerator: 0us, total: 138.79ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 122569727.72sec, total: 122569727.72sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 61284863.87sec, total: 61284863.87sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 61284863.86sec, total: 61284863.87sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 61284863.86sec, total: 61284863.87sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 61284863.86sec, total: 61284863.87sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.22ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.22ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 224us, total: 1.43ms
      train.py:343:hfe, cpu: 536us, accelerator: 567us, total: 1.10ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.06ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.50ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.63ms, accelerator: 1.50ms, total: 7.15ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.56ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_75250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 61081933.85sec, total: 61081933.85sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 61081933.85sec, total: 61081933.85sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 61081933.85sec, total: 61081933.85sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.88ms, accelerator: 0us, total: 138.88ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 122163867.69sec, total: 122163867.70sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 61081933.85sec, total: 61081933.86sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 61081933.85sec, total: 61081933.85sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 61081933.85sec, total: 61081933.85sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 61081933.85sec, total: 61081933.85sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.22ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.22ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 224us, total: 1.43ms
      train.py:343:hfe, cpu: 534us, accelerator: 567us, total: 1.10ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.05ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.50ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.62ms, accelerator: 1.50ms, total: 7.13ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.56ms, total: 5.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_75500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 60880343.31sec, total: 60880343.31sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 60880343.31sec, total: 60880343.31sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 60880343.31sec, total: 60880343.31sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.95ms, accelerator: 0us, total: 138.95ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 121760686.61sec, total: 121760686.62sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 60880343.31sec, total: 60880343.32sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 60880343.31sec, total: 60880343.31sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 60880343.31sec, total: 60880343.31sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 60880343.31sec, total: 60880343.31sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.22ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.22ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 224us, total: 1.43ms
      train.py:343:hfe, cpu: 535us, accelerator: 564us, total: 1.10ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.04ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.49ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.60ms, accelerator: 1.49ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.01ms, accelerator: 2.55ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_75750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 60680079.02sec, total: 60680079.02sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 60680079.02sec, total: 60680079.02sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 60680079.02sec, total: 60680079.02sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.86ms, accelerator: 0us, total: 138.86ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 121360158.04sec, total: 121360158.04sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 60680079.03sec, total: 60680079.03sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 60680079.02sec, total: 60680079.03sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 60680079.02sec, total: 60680079.03sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 60680079.02sec, total: 60680079.03sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.21ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.21ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 224us, total: 1.43ms
      train.py:343:hfe, cpu: 534us, accelerator: 562us, total: 1.10ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.03ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.49ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.61ms, accelerator: 1.49ms, total: 7.12ms
  __init__.py:185:compute_gradients, cpu: 3.00ms, accelerator: 2.54ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_76000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 60481127.94sec, total: 60481127.94sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 60481127.94sec, total: 60481127.94sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 60481127.94sec, total: 60481127.94sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.89ms, accelerator: 0us, total: 138.89ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 120962255.88sec, total: 120962255.89sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 60481127.95sec, total: 60481127.95sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 60481127.95sec, total: 60481127.95sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 60481127.95sec, total: 60481127.95sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 60481127.95sec, total: 60481127.95sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.21ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.21ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 224us, total: 1.42ms
      train.py:343:hfe, cpu: 533us, accelerator: 562us, total: 1.10ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.03ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.48ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.60ms, accelerator: 1.48ms, total: 7.11ms
  __init__.py:185:compute_gradients, cpu: 3.00ms, accelerator: 2.55ms, total: 5.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_76250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 60283477.20sec, total: 60283477.20sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 60283477.20sec, total: 60283477.20sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 60283477.19sec, total: 60283477.20sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.72ms, accelerator: 0us, total: 138.72ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 120566954.39sec, total: 120566954.40sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 60283477.20sec, total: 60283477.21sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 60283477.20sec, total: 60283477.20sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 60283477.20sec, total: 60283477.20sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 60283477.20sec, total: 60283477.20sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.21ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.21ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 230us, total: 1.43ms
      train.py:343:hfe, cpu: 532us, accelerator: 560us, total: 1.10ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.04ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.48ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 5.59ms, accelerator: 1.48ms, total: 7.10ms
  __init__.py:185:compute_gradients, cpu: 3.00ms, accelerator: 2.56ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_76500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 60087114.08sec, total: 60087114.08sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 400us, accelerator: 60087114.08sec, total: 60087114.08sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 60087114.08sec, total: 60087114.08sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.77ms, accelerator: 0us, total: 138.77ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 120174228.16sec, total: 120174228.16sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 60087114.08sec, total: 60087114.09sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 60087114.08sec, total: 60087114.09sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 60087114.08sec, total: 60087114.09sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 60087114.08sec, total: 60087114.09sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.21ms, total: 3.31ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.21ms, total: 3.30ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 230us, total: 1.43ms
      train.py:343:hfe, cpu: 531us, accelerator: 556us, total: 1.09ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.07ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.48ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.58ms, accelerator: 1.48ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 3.00ms, accelerator: 2.59ms, total: 5.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_76750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 59892026.05sec, total: 59892026.05sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 59892026.05sec, total: 59892026.05sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.95ms, accelerator: 59892026.04sec, total: 59892026.05sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.90ms, accelerator: 0us, total: 138.90ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 119784052.09sec, total: 119784052.09sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 59892026.05sec, total: 59892026.06sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 59892026.05sec, total: 59892026.05sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 59892026.05sec, total: 59892026.05sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 59892026.05sec, total: 59892026.05sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.21ms, total: 3.31ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.21ms, total: 3.29ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 230us, total: 1.42ms
      train.py:343:hfe, cpu: 530us, accelerator: 556us, total: 1.09ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.06ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.47ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.56ms, accelerator: 1.47ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.59ms, total: 5.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_77000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 59698200.72sec, total: 59698200.72sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 59698200.72sec, total: 59698200.72sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 59698200.72sec, total: 59698200.72sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.93ms, accelerator: 0us, total: 138.93ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 119396401.44sec, total: 119396401.44sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 59698200.72sec, total: 59698200.73sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 59698200.72sec, total: 59698200.73sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 59698200.72sec, total: 59698200.73sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 59698200.72sec, total: 59698200.73sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.21ms, total: 3.30ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.21ms, total: 3.29ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 230us, total: 1.42ms
      train.py:343:hfe, cpu: 531us, accelerator: 555us, total: 1.09ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.04ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.47ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.55ms, accelerator: 1.47ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.58ms, total: 5.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_77250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 59505625.88sec, total: 59505625.88sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 59505625.88sec, total: 59505625.88sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 59505625.88sec, total: 59505625.88sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.93ms, accelerator: 0us, total: 138.93ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 119011251.75sec, total: 119011251.76sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 59505625.88sec, total: 59505625.89sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 59505625.88sec, total: 59505625.88sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 59505625.88sec, total: 59505625.88sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 59505625.88sec, total: 59505625.88sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.20ms, total: 3.31ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.20ms, total: 3.29ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 229us, total: 1.43ms
      train.py:343:hfe, cpu: 529us, accelerator: 553us, total: 1.09ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.04ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.46ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.56ms, accelerator: 1.46ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.57ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_77500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 59314289.46sec, total: 59314289.46sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 59314289.46sec, total: 59314289.46sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 59314289.46sec, total: 59314289.46sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.81ms, accelerator: 0us, total: 138.81ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 118628578.92sec, total: 118628578.92sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 59314289.47sec, total: 59314289.47sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 59314289.46sec, total: 59314289.47sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 59314289.46sec, total: 59314289.47sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 59314289.46sec, total: 59314289.47sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.20ms, total: 3.32ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.20ms, total: 3.30ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 229us, total: 1.44ms
      train.py:343:hfe, cpu: 529us, accelerator: 551us, total: 1.08ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.03ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.46ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.11sec, accelerator: 0us, total: 8.11sec
    __init__.py:86:allreduce, cpu: 5.55ms, accelerator: 1.46ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 3.00ms, accelerator: 2.57ms, total: 5.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2117.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_77750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 59124179.56sec, total: 59124179.56sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 59124179.56sec, total: 59124179.56sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 59124179.56sec, total: 59124179.56sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.74ms, accelerator: 0us, total: 138.74ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 118248359.12sec, total: 118248359.12sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 59124179.56sec, total: 59124179.57sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 59124179.56sec, total: 59124179.56sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 59124179.56sec, total: 59124179.56sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 59124179.56sec, total: 59124179.56sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.20ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.20ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 229us, total: 1.48ms
      train.py:343:hfe, cpu: 528us, accelerator: 551us, total: 1.08ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.03ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.47ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.54ms, accelerator: 1.47ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 3.00ms, accelerator: 2.56ms, total: 5.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_78000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 58935284.42sec, total: 58935284.42sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 399us, accelerator: 58935284.42sec, total: 58935284.42sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 58935284.41sec, total: 58935284.42sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.80ms, accelerator: 0us, total: 138.80ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 117870568.83sec, total: 117870568.83sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 58935284.42sec, total: 58935284.43sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 58935284.42sec, total: 58935284.42sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 58935284.42sec, total: 58935284.42sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 58935284.42sec, total: 58935284.42sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.21ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.21ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 246us, total: 1.51ms
      train.py:343:hfe, cpu: 526us, accelerator: 549us, total: 1.08ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.02ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.46ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.53ms, accelerator: 1.46ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 3.00ms, accelerator: 2.56ms, total: 5.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_78250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 58747592.43sec, total: 58747592.43sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 58747592.43sec, total: 58747592.43sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 58747592.43sec, total: 58747592.43sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.72ms, accelerator: 0us, total: 138.72ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 117495184.85sec, total: 117495184.86sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 58747592.43sec, total: 58747592.44sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 58747592.43sec, total: 58747592.43sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 58747592.43sec, total: 58747592.43sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 58747592.43sec, total: 58747592.43sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.21ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.21ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 246us, total: 1.51ms
      train.py:343:hfe, cpu: 526us, accelerator: 547us, total: 1.08ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.01ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.46ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.52ms, accelerator: 1.46ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.55ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_78500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 58561092.13sec, total: 58561092.14sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 58561092.13sec, total: 58561092.13sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 58561092.13sec, total: 58561092.13sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.59ms, accelerator: 0us, total: 138.59ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 117122184.27sec, total: 117122184.27sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 58561092.14sec, total: 58561092.15sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 58561092.14sec, total: 58561092.14sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 58561092.14sec, total: 58561092.14sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 58561092.14sec, total: 58561092.14sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.20ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.20ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 246us, total: 1.50ms
      train.py:343:hfe, cpu: 524us, accelerator: 545us, total: 1.07ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.01ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.47ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.51ms, accelerator: 1.47ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.55ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_78750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 58375772.22sec, total: 58375772.22sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 58375772.22sec, total: 58375772.22sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 58375772.22sec, total: 58375772.22sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.63ms, accelerator: 0us, total: 138.63ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 116751544.44sec, total: 116751544.45sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 58375772.23sec, total: 58375772.23sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 58375772.23sec, total: 58375772.23sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 58375772.23sec, total: 58375772.23sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 58375772.23sec, total: 58375772.23sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.20ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.20ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 246us, total: 1.50ms
      train.py:343:hfe, cpu: 523us, accelerator: 543us, total: 1.07ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.00ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.46ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.50ms, accelerator: 1.46ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.54ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_79000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 58191621.52sec, total: 58191621.52sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 58191621.52sec, total: 58191621.52sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 58191621.52sec, total: 58191621.52sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.68ms, accelerator: 0us, total: 138.68ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 116383243.04sec, total: 116383243.05sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 58191621.53sec, total: 58191621.53sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 58191621.52sec, total: 58191621.53sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 58191621.52sec, total: 58191621.53sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 58191621.52sec, total: 58191621.53sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.20ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.20ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 246us, total: 1.50ms
      train.py:343:hfe, cpu: 522us, accelerator: 541us, total: 1.07ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.99ms, total: 8.12sec
  __init__.py:194:compute_gradients, cpu: 8.11sec, accelerator: 1.46ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 1.46ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.53ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_79250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 58008629.00sec, total: 58008629.00sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 58008629.00sec, total: 58008629.00sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 58008629.00sec, total: 58008629.00sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.61ms, accelerator: 0us, total: 138.61ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 116017258.00sec, total: 116017258.00sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 58008629.01sec, total: 58008629.01sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 58008629.00sec, total: 58008629.01sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 58008629.00sec, total: 58008629.01sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 58008629.00sec, total: 58008629.01sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.20ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.20ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 246us, total: 1.49ms
      train.py:343:hfe, cpu: 521us, accelerator: 541us, total: 1.07ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.98ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.46ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.48ms, accelerator: 1.46ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.53ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_79500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 57826783.77sec, total: 57826783.77sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 57826783.77sec, total: 57826783.77sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 57826783.77sec, total: 57826783.77sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.63ms, accelerator: 0us, total: 138.63ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 115653567.54sec, total: 115653567.54sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 57826783.77sec, total: 57826783.78sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 57826783.77sec, total: 57826783.78sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 57826783.77sec, total: 57826783.78sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 57826783.77sec, total: 57826783.77sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.21ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.21ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 244us, total: 1.50ms
      train.py:343:hfe, cpu: 519us, accelerator: 549us, total: 1.07ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.98ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.46ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 1.46ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.52ms, total: 5.56ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_79750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 57646075.07sec, total: 57646075.07sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 57646075.07sec, total: 57646075.07sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 57646075.07sec, total: 57646075.07sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.58ms, accelerator: 0us, total: 138.58ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 115292150.14sec, total: 115292150.14sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 57646075.07sec, total: 57646075.08sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 57646075.07sec, total: 57646075.08sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 57646075.07sec, total: 57646075.08sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 57646075.07sec, total: 57646075.08sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.21ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.21ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 243us, total: 1.49ms
      train.py:343:hfe, cpu: 518us, accelerator: 548us, total: 1.07ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 3.97ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.45ms, total: 8.11sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 1.45ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.52ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_80000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 57466492.28sec, total: 57466492.28sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 57466492.28sec, total: 57466492.28sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 57466492.28sec, total: 57466492.28sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.64ms, accelerator: 0us, total: 138.64ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 114932984.56sec, total: 114932984.56sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 57466492.29sec, total: 57466492.29sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 57466492.28sec, total: 57466492.29sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 57466492.28sec, total: 57466492.29sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 57466492.28sec, total: 57466492.29sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.21ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.21ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 243us, total: 1.49ms
      train.py:343:hfe, cpu: 520us, accelerator: 547us, total: 1.07ms
train.py:511:<module>, cpu: 8.11sec, accelerator: 4.02ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.51ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.10sec, accelerator: 0us, total: 8.10sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 1.51ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.51ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_80250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.22ms, accelerator: 57288024.91sec, total: 57288024.92sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 57288024.91sec, total: 57288024.91sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 57288024.91sec, total: 57288024.91sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.56ms, accelerator: 0us, total: 138.56ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 114576049.83sec, total: 114576049.83sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 57288024.92sec, total: 57288024.92sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 57288024.92sec, total: 57288024.92sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 57288024.92sec, total: 57288024.92sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 57288024.92sec, total: 57288024.92sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.20ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.20ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 243us, total: 1.48ms
      train.py:343:hfe, cpu: 523us, accelerator: 545us, total: 1.07ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.01ms, total: 8.11sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.51ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 1.51ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.50ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2119.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_80500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 57110662.61sec, total: 57110662.61sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 57110662.61sec, total: 57110662.61sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 57110662.61sec, total: 57110662.61sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.60ms, accelerator: 0us, total: 138.60ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 114221325.21sec, total: 114221325.22sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 57110662.61sec, total: 57110662.62sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 57110662.61sec, total: 57110662.61sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 57110662.61sec, total: 57110662.61sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 57110662.61sec, total: 57110662.61sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.20ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.20ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 243us, total: 1.48ms
      train.py:343:hfe, cpu: 521us, accelerator: 542us, total: 1.07ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.00ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.50ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.50ms, accelerator: 1.50ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.99ms, accelerator: 2.50ms, total: 5.53ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_80750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 56934395.13sec, total: 56934395.13sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 56934395.13sec, total: 56934395.13sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 56934395.13sec, total: 56934395.13sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.59ms, accelerator: 0us, total: 138.59ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 113868790.26sec, total: 113868790.26sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 56934395.14sec, total: 56934395.14sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 56934395.13sec, total: 56934395.14sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 56934395.13sec, total: 56934395.14sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 56934395.13sec, total: 56934395.14sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.20ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.20ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 243us, total: 1.48ms
      train.py:343:hfe, cpu: 521us, accelerator: 541us, total: 1.07ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.02ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.50ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 1.50ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.52ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_81000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 56759212.38sec, total: 56759212.38sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 398us, accelerator: 56759212.38sec, total: 56759212.38sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 56759212.37sec, total: 56759212.38sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.46ms, accelerator: 0us, total: 138.46ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 113518424.75sec, total: 113518424.75sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 56759212.38sec, total: 56759212.39sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 56759212.38sec, total: 56759212.38sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 56759212.38sec, total: 56759212.38sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 56759212.38sec, total: 56759212.38sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.22ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.22ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 252us, total: 1.49ms
      train.py:343:hfe, cpu: 520us, accelerator: 547us, total: 1.07ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.01ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.50ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.48ms, accelerator: 1.50ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.98ms, accelerator: 2.52ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2131.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_81250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 56585104.36sec, total: 56585104.36sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 56585104.36sec, total: 56585104.36sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 56585104.36sec, total: 56585104.36sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.46ms, accelerator: 0us, total: 138.46ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 113170208.72sec, total: 113170208.73sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 56585104.37sec, total: 56585104.37sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 56585104.37sec, total: 56585104.37sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 56585104.37sec, total: 56585104.37sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 56585104.37sec, total: 56585104.37sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.22ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.22ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 250us, total: 1.48ms
      train.py:343:hfe, cpu: 517us, accelerator: 546us, total: 1.07ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.01ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.50ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 1.50ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.51ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_81500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 56412061.23sec, total: 56412061.23sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 56412061.23sec, total: 56412061.23sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.96ms, accelerator: 56412061.23sec, total: 56412061.23sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.36ms, accelerator: 0us, total: 138.36ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 112824122.46sec, total: 112824122.46sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 56412061.24sec, total: 56412061.24sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 56412061.23sec, total: 56412061.24sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 56412061.23sec, total: 56412061.24sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 56412061.23sec, total: 56412061.24sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.21ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.21ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 249us, total: 1.48ms
      train.py:343:hfe, cpu: 519us, accelerator: 544us, total: 1.07ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.00ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.49ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 1.49ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.51ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_81750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 56240073.24sec, total: 56240073.24sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 56240073.24sec, total: 56240073.24sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 56240073.24sec, total: 56240073.24sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.27ms, accelerator: 0us, total: 138.27ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 112480146.48sec, total: 112480146.48sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 56240073.24sec, total: 56240073.25sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 56240073.24sec, total: 56240073.24sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 56240073.24sec, total: 56240073.24sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 56240073.24sec, total: 56240073.24sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.21ms, total: 3.32ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.21ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 248us, total: 1.48ms
      train.py:343:hfe, cpu: 517us, accelerator: 544us, total: 1.06ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.06ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.54ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 1.54ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.52ms, total: 5.53ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_82000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 56069130.77sec, total: 56069130.77sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 56069130.77sec, total: 56069130.77sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 56069130.76sec, total: 56069130.77sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.17ms, accelerator: 0us, total: 138.17ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 112138261.53sec, total: 112138261.54sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 56069130.77sec, total: 56069130.78sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 56069130.77sec, total: 56069130.77sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 56069130.77sec, total: 56069130.77sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 56069130.77sec, total: 56069130.77sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.21ms, total: 3.32ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.21ms, total: 3.30ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 248us, total: 1.47ms
      train.py:343:hfe, cpu: 516us, accelerator: 542us, total: 1.06ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.10ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.55ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 1.55ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.55ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_82250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 55899224.31sec, total: 55899224.31sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 55899224.31sec, total: 55899224.31sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 55899224.31sec, total: 55899224.31sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.16ms, accelerator: 0us, total: 138.16ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 111798448.62sec, total: 111798448.62sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 55899224.32sec, total: 55899224.32sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 55899224.31sec, total: 55899224.32sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 55899224.31sec, total: 55899224.32sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 55899224.31sec, total: 55899224.32sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.20ms, total: 3.31ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.20ms, total: 3.29ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 248us, total: 1.47ms
      train.py:343:hfe, cpu: 516us, accelerator: 539us, total: 1.06ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.09ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.54ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 1.54ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.97ms, accelerator: 2.55ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_82500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 55730344.48sec, total: 55730344.48sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 397us, accelerator: 55730344.48sec, total: 55730344.48sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 55730344.48sec, total: 55730344.48sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.15ms, accelerator: 0us, total: 138.15ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 111460688.95sec, total: 111460688.96sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 55730344.48sec, total: 55730344.49sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 55730344.48sec, total: 55730344.48sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 55730344.48sec, total: 55730344.48sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 55730344.48sec, total: 55730344.48sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.20ms, total: 3.30ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.20ms, total: 3.28ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 248us, total: 1.47ms
      train.py:343:hfe, cpu: 514us, accelerator: 538us, total: 1.06ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.08ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.54ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 1.54ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.54ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_82750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 55562481.99sec, total: 55562482.00sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 396us, accelerator: 55562481.99sec, total: 55562482.00sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 55562481.99sec, total: 55562481.99sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.07ms, accelerator: 0us, total: 138.07ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 111124963.99sec, total: 111124963.99sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 55562482.00sec, total: 55562482.01sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 55562482.00sec, total: 55562482.00sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 55562482.00sec, total: 55562482.00sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 55562482.00sec, total: 55562482.00sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.20ms, total: 3.29ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.20ms, total: 3.28ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 248us, total: 1.46ms
      train.py:343:hfe, cpu: 513us, accelerator: 537us, total: 1.06ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.07ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.53ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 1.53ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.54ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_83000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 55395627.69sec, total: 55395627.70sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 55395627.69sec, total: 55395627.69sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 55395627.69sec, total: 55395627.69sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.99ms, accelerator: 0us, total: 137.99ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 110791255.39sec, total: 110791255.39sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 55395627.70sec, total: 55395627.71sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 55395627.70sec, total: 55395627.70sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 55395627.70sec, total: 55395627.70sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 55395627.70sec, total: 55395627.70sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.21ms, total: 3.30ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.21ms, total: 3.28ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 246us, total: 1.46ms
      train.py:343:hfe, cpu: 512us, accelerator: 545us, total: 1.06ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.06ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.53ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 1.53ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.53ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_83250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 55229772.52sec, total: 55229772.52sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 55229772.52sec, total: 55229772.52sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 55229772.52sec, total: 55229772.52sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.88ms, accelerator: 0us, total: 137.88ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 110459545.04sec, total: 110459545.05sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 55229772.53sec, total: 55229772.53sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 55229772.53sec, total: 55229772.53sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 55229772.53sec, total: 55229772.53sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 55229772.53sec, total: 55229772.53sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.20ms, total: 3.32ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.20ms, total: 3.30ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 246us, total: 1.48ms
      train.py:343:hfe, cpu: 512us, accelerator: 544us, total: 1.06ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.05ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.53ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.52ms, accelerator: 1.53ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.52ms, total: 5.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_83500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 55064907.53sec, total: 55064907.53sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 55064907.53sec, total: 55064907.53sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 55064907.53sec, total: 55064907.53sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.97ms, accelerator: 0us, total: 137.97ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 110129815.06sec, total: 110129815.06sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 55064907.53sec, total: 55064907.54sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 55064907.53sec, total: 55064907.54sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 55064907.53sec, total: 55064907.54sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 55064907.53sec, total: 55064907.54sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.22ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.22ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 511us, accelerator: 547us, total: 1.06ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.12ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.52ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.52ms, accelerator: 1.52ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.60ms, total: 5.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_83750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 54901023.88sec, total: 54901023.88sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 54901023.88sec, total: 54901023.88sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 54901023.87sec, total: 54901023.88sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.89ms, accelerator: 0us, total: 137.89ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 109802047.75sec, total: 109802047.75sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 54901023.88sec, total: 54901023.89sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 54901023.88sec, total: 54901023.88sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 54901023.88sec, total: 54901023.88sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 54901023.88sec, total: 54901023.88sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.22ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.22ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 253us, total: 1.49ms
      train.py:343:hfe, cpu: 510us, accelerator: 544us, total: 1.06ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.12ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.10sec, accelerator: 1.52ms, total: 8.10sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.50ms, accelerator: 1.52ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.60ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_84000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 54738112.83sec, total: 54738112.83sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 54738112.83sec, total: 54738112.83sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 54738112.82sec, total: 54738112.83sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.02ms, accelerator: 0us, total: 138.02ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 109476225.65sec, total: 109476225.65sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 54738112.83sec, total: 54738112.84sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 54738112.83sec, total: 54738112.83sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 54738112.83sec, total: 54738112.83sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 54738112.83sec, total: 54738112.83sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.22ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.22ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 252us, total: 1.52ms
      train.py:343:hfe, cpu: 510us, accelerator: 544us, total: 1.06ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.11ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.52ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.51ms, accelerator: 1.52ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.59ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2074.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_84250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 54576165.75sec, total: 54576165.75sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 54576165.75sec, total: 54576165.75sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 54576165.74sec, total: 54576165.75sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.07ms, accelerator: 0us, total: 138.07ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 109152331.49sec, total: 109152331.50sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 54576165.75sec, total: 54576165.76sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 54576165.75sec, total: 54576165.75sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 54576165.75sec, total: 54576165.75sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 54576165.75sec, total: 54576165.75sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.21ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.21ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 252us, total: 1.51ms
      train.py:343:hfe, cpu: 507us, accelerator: 543us, total: 1.05ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.14ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.55ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.50ms, accelerator: 1.55ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.59ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_84500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 54415174.11sec, total: 54415174.11sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 54415174.11sec, total: 54415174.11sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 54415174.10sec, total: 54415174.11sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 108830348.21sec, total: 108830348.22sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 54415174.11sec, total: 54415174.12sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 54415174.11sec, total: 54415174.11sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 54415174.11sec, total: 54415174.11sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 54415174.11sec, total: 54415174.11sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.23ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.23ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 252us, total: 1.51ms
      train.py:343:hfe, cpu: 507us, accelerator: 549us, total: 1.06ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.12ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.54ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 1.54ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.58ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_84750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 54255129.48sec, total: 54255129.48sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 54255129.48sec, total: 54255129.48sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.97ms, accelerator: 54255129.48sec, total: 54255129.48sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.10ms, accelerator: 0us, total: 138.10ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 108510258.95sec, total: 108510258.96sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 54255129.48sec, total: 54255129.49sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 54255129.48sec, total: 54255129.48sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 54255129.48sec, total: 54255129.48sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 54255129.48sec, total: 54255129.48sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.22ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.22ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 251us, total: 1.51ms
      train.py:343:hfe, cpu: 507us, accelerator: 548us, total: 1.06ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.12ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.54ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 1.54ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.58ms, total: 5.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_85000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 54096023.53sec, total: 54096023.53sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 395us, accelerator: 54096023.53sec, total: 54096023.53sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 54096023.52sec, total: 54096023.53sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.04ms, accelerator: 0us, total: 138.04ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 108192047.05sec, total: 108192047.05sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 54096023.53sec, total: 54096023.54sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 54096023.53sec, total: 54096023.53sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 54096023.53sec, total: 54096023.53sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 54096023.53sec, total: 54096023.53sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.22ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.22ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 251us, total: 1.51ms
      train.py:343:hfe, cpu: 505us, accelerator: 546us, total: 1.06ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.11ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.54ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.50ms, accelerator: 1.54ms, total: 7.06ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.57ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_85250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 53937848.02sec, total: 53937848.02sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 53937848.02sec, total: 53937848.02sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 53937848.02sec, total: 53937848.02sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.07ms, accelerator: 0us, total: 138.07ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 107875696.04sec, total: 107875696.04sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 53937848.02sec, total: 53937848.03sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 53937848.02sec, total: 53937848.02sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 53937848.02sec, total: 53937848.02sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 53937848.02sec, total: 53937848.02sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.22ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.22ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 250us, total: 1.50ms
      train.py:343:hfe, cpu: 505us, accelerator: 546us, total: 1.05ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.10ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.53ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 1.53ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.56ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_85500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 53780594.82sec, total: 53780594.82sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 53780594.82sec, total: 53780594.82sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 53780594.82sec, total: 53780594.82sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.01ms, accelerator: 0us, total: 138.01ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 107561189.63sec, total: 107561189.64sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 53780594.82sec, total: 53780594.83sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 53780594.82sec, total: 53780594.82sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 53780594.82sec, total: 53780594.82sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 53780594.82sec, total: 53780594.82sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.23ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.23ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 249us, total: 1.50ms
      train.py:343:hfe, cpu: 504us, accelerator: 560us, total: 1.07ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.09ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.53ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.48ms, accelerator: 1.53ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.56ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2121.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_85750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 53624255.88sec, total: 53624255.88sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 53624255.88sec, total: 53624255.88sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 53624255.88sec, total: 53624255.88sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.95ms, accelerator: 0us, total: 137.95ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 107248511.76sec, total: 107248511.76sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 53624255.88sec, total: 53624255.89sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 53624255.88sec, total: 53624255.89sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 53624255.88sec, total: 53624255.89sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 53624255.88sec, total: 53624255.88sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.23ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.23ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 247us, total: 1.50ms
      train.py:343:hfe, cpu: 503us, accelerator: 559us, total: 1.06ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.09ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.53ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 1.53ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.56ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_86000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 53468823.25sec, total: 53468823.25sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 53468823.25sec, total: 53468823.25sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 53468823.25sec, total: 53468823.25sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.91ms, accelerator: 0us, total: 137.91ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 106937646.50sec, total: 106937646.51sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 53468823.26sec, total: 53468823.26sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 53468823.26sec, total: 53468823.26sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 53468823.26sec, total: 53468823.26sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 53468823.26sec, total: 53468823.26sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.24ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.24ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 247us, total: 1.49ms
      train.py:343:hfe, cpu: 502us, accelerator: 570us, total: 1.08ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.10ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.53ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.49ms, accelerator: 1.53ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.57ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_86250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 53314289.08sec, total: 53314289.08sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 53314289.08sec, total: 53314289.08sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 53314289.08sec, total: 53314289.08sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.79ms, accelerator: 0us, total: 137.79ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 106628578.16sec, total: 106628578.17sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 53314289.09sec, total: 53314289.09sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 53314289.09sec, total: 53314289.09sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 53314289.09sec, total: 53314289.09sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 53314289.09sec, total: 53314289.09sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.26ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.26ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 256us, total: 1.50ms
      train.py:343:hfe, cpu: 501us, accelerator: 576us, total: 1.08ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.09ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.53ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 1.53ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.56ms, total: 5.54ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_86500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 53160645.60sec, total: 53160645.60sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 53160645.60sec, total: 53160645.60sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 53160645.60sec, total: 53160645.60sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.77ms, accelerator: 0us, total: 137.77ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 106321291.19sec, total: 106321291.20sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 53160645.60sec, total: 53160645.61sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 53160645.60sec, total: 53160645.60sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 53160645.60sec, total: 53160645.60sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 53160645.60sec, total: 53160645.60sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.27ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.27ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 256us, total: 1.49ms
      train.py:343:hfe, cpu: 500us, accelerator: 583us, total: 1.09ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.09ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.53ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.47ms, accelerator: 1.53ms, total: 7.02ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.56ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2127.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_86750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 53007885.12sec, total: 53007885.12sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 53007885.12sec, total: 53007885.12sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 53007885.12sec, total: 53007885.12sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.80ms, accelerator: 0us, total: 137.80ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 106015770.24sec, total: 106015770.25sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 53007885.13sec, total: 53007885.13sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 53007885.13sec, total: 53007885.13sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 53007885.13sec, total: 53007885.13sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 53007885.12sec, total: 53007885.13sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.26ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.26ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 255us, total: 1.50ms
      train.py:343:hfe, cpu: 500us, accelerator: 581us, total: 1.08ms
train.py:511:<module>, cpu: 8.10sec, accelerator: 4.11ms, total: 8.10sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.53ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.09sec, accelerator: 0us, total: 8.09sec
    __init__.py:86:allreduce, cpu: 5.46ms, accelerator: 1.53ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.59ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_87000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 52856000.06sec, total: 52856000.07sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 52856000.06sec, total: 52856000.06sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 52856000.06sec, total: 52856000.06sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.76ms, accelerator: 0us, total: 137.76ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 105712000.13sec, total: 105712000.13sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 52856000.07sec, total: 52856000.07sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 52856000.07sec, total: 52856000.07sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 52856000.07sec, total: 52856000.07sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 52856000.07sec, total: 52856000.07sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.26ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.26ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 255us, total: 1.52ms
      train.py:343:hfe, cpu: 519us, accelerator: 580us, total: 1.10ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.11ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.52ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.45ms, accelerator: 1.52ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.92ms, accelerator: 2.58ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_87250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 52704982.92sec, total: 52704982.92sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 52704982.92sec, total: 52704982.92sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 52704982.92sec, total: 52704982.92sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.75ms, accelerator: 0us, total: 137.75ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 105409965.84sec, total: 105409965.84sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 52704982.93sec, total: 52704982.93sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 52704982.92sec, total: 52704982.93sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 52704982.92sec, total: 52704982.93sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 52704982.92sec, total: 52704982.93sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.27ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.27ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 254us, total: 1.51ms
      train.py:343:hfe, cpu: 519us, accelerator: 584us, total: 1.11ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.15ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.57ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 1.57ms, total: 7.04ms
  __init__.py:185:compute_gradients, cpu: 2.92ms, accelerator: 2.57ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_87500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 52554826.27sec, total: 52554826.28sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 52554826.27sec, total: 52554826.27sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 52554826.27sec, total: 52554826.27sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.78ms, accelerator: 0us, total: 137.78ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 105109652.55sec, total: 105109652.55sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 52554826.28sec, total: 52554826.29sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 52554826.28sec, total: 52554826.28sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 52554826.28sec, total: 52554826.28sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 52554826.28sec, total: 52554826.28sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.27ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.27ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 253us, total: 1.52ms
      train.py:343:hfe, cpu: 518us, accelerator: 582us, total: 1.10ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.14ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.57ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.44ms, accelerator: 1.57ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.91ms, accelerator: 2.57ms, total: 5.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_87750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 52405522.79sec, total: 52405522.79sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 52405522.79sec, total: 52405522.79sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 52405522.79sec, total: 52405522.79sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.77ms, accelerator: 0us, total: 137.77ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 104811045.58sec, total: 104811045.58sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 52405522.80sec, total: 52405522.80sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 52405522.79sec, total: 52405522.80sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 52405522.79sec, total: 52405522.80sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 52405522.79sec, total: 52405522.80sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.26ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.26ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 252us, total: 1.52ms
      train.py:343:hfe, cpu: 516us, accelerator: 581us, total: 1.10ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.20ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.09sec, accelerator: 1.63ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.43ms, accelerator: 1.63ms, total: 7.08ms
  __init__.py:185:compute_gradients, cpu: 2.91ms, accelerator: 2.57ms, total: 5.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_88000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 52257065.22sec, total: 52257065.22sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 52257065.22sec, total: 52257065.22sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 52257065.22sec, total: 52257065.22sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.74ms, accelerator: 0us, total: 137.74ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 104514130.44sec, total: 104514130.44sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 52257065.22sec, total: 52257065.23sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 52257065.22sec, total: 52257065.23sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 52257065.22sec, total: 52257065.23sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 52257065.22sec, total: 52257065.23sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.27ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.27ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 252us, total: 1.52ms
      train.py:343:hfe, cpu: 516us, accelerator: 581us, total: 1.10ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.19ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.62ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 1.62ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 2.91ms, accelerator: 2.56ms, total: 5.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_88250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 52109446.39sec, total: 52109446.39sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 52109446.39sec, total: 52109446.39sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 52109446.39sec, total: 52109446.39sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.73ms, accelerator: 0us, total: 137.73ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 104218892.78sec, total: 104218892.78sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 52109446.40sec, total: 52109446.40sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 52109446.39sec, total: 52109446.40sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 52109446.39sec, total: 52109446.40sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 52109446.39sec, total: 52109446.40sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.27ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.27ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 252us, total: 1.52ms
      train.py:343:hfe, cpu: 514us, accelerator: 580us, total: 1.10ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.17ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.62ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.42ms, accelerator: 1.62ms, total: 7.07ms
  __init__.py:185:compute_gradients, cpu: 2.91ms, accelerator: 2.55ms, total: 5.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_88500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 51962659.22sec, total: 51962659.22sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 394us, accelerator: 51962659.22sec, total: 51962659.22sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 51962659.22sec, total: 51962659.22sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.78ms, accelerator: 0us, total: 137.78ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 103925318.43sec, total: 103925318.44sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 51962659.22sec, total: 51962659.23sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 51962659.22sec, total: 51962659.22sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 51962659.22sec, total: 51962659.22sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 51962659.22sec, total: 51962659.22sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 252us, total: 1.51ms
      train.py:343:hfe, cpu: 514us, accelerator: 587us, total: 1.11ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.61ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.41ms, accelerator: 1.61ms, total: 7.05ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.55ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_88750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 51816696.69sec, total: 51816696.69sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 51816696.69sec, total: 51816696.69sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 51816696.69sec, total: 51816696.69sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.85ms, accelerator: 0us, total: 137.85ms
train.py:441:<module> (gradient), cpu: 4.25ms, accelerator: 103633393.38sec, total: 103633393.39sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 51816696.70sec, total: 51816696.70sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 51816696.70sec, total: 51816696.70sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 51816696.70sec, total: 51816696.70sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 51816696.70sec, total: 51816696.70sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 251us, total: 1.51ms
      train.py:343:hfe, cpu: 514us, accelerator: 585us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.61ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 1.61ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.55ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_89000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 51671551.88sec, total: 51671551.88sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 51671551.88sec, total: 51671551.88sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 51671551.88sec, total: 51671551.88sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.91ms, accelerator: 0us, total: 137.91ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 103343103.76sec, total: 103343103.77sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 51671551.89sec, total: 51671551.89sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 51671551.89sec, total: 51671551.89sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 51671551.89sec, total: 51671551.89sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 51671551.89sec, total: 51671551.89sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.29ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 251us, total: 1.51ms
      train.py:343:hfe, cpu: 513us, accelerator: 590us, total: 1.11ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.61ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 1.61ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.54ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_89250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 51527217.94sec, total: 51527217.94sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 51527217.94sec, total: 51527217.94sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 51527217.94sec, total: 51527217.94sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.87ms, accelerator: 0us, total: 137.87ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 103054435.88sec, total: 103054435.88sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 51527217.95sec, total: 51527217.95sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 51527217.94sec, total: 51527217.95sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 51527217.94sec, total: 51527217.95sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 51527217.94sec, total: 51527217.95sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.29ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 250us, total: 1.50ms
      train.py:343:hfe, cpu: 512us, accelerator: 589us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.14ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.61ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 1.61ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.54ms, total: 5.52ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_89500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 51383688.08sec, total: 51383688.09sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 51383688.08sec, total: 51383688.08sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 51383688.08sec, total: 51383688.08sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.00ms, accelerator: 0us, total: 138.00ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 102767376.17sec, total: 102767376.17sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 51383688.09sec, total: 51383688.10sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 51383688.09sec, total: 51383688.09sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 51383688.09sec, total: 51383688.09sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 51383688.09sec, total: 51383688.09sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.28ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.28ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 248us, total: 1.50ms
      train.py:343:hfe, cpu: 512us, accelerator: 588us, total: 1.10ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.17ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.60ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.60ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.56ms, total: 5.54ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_89750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 51240955.62sec, total: 51240955.62sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 51240955.62sec, total: 51240955.62sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 51240955.62sec, total: 51240955.62sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.07ms, accelerator: 0us, total: 138.07ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 102481911.23sec, total: 102481911.24sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 51240955.62sec, total: 51240955.63sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 51240955.62sec, total: 51240955.62sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 51240955.62sec, total: 51240955.62sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 51240955.62sec, total: 51240955.62sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.28ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.28ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 248us, total: 1.50ms
      train.py:343:hfe, cpu: 510us, accelerator: 585us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.60ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 1.60ms, total: 7.03ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.56ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2059.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_90000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 51099013.91sec, total: 51099013.91sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 51099013.91sec, total: 51099013.91sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 51099013.91sec, total: 51099013.91sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.01ms, accelerator: 0us, total: 138.01ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 102198027.82sec, total: 102198027.83sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 51099013.92sec, total: 51099013.92sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 51099013.92sec, total: 51099013.92sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 51099013.92sec, total: 51099013.92sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 51099013.92sec, total: 51099013.92sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.28ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 247us, total: 1.50ms
      train.py:343:hfe, cpu: 508us, accelerator: 584us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.15ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.60ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 1.60ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.96ms, accelerator: 2.56ms, total: 5.55ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2116.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_90250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 50957856.42sec, total: 50957856.42sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 50957856.42sec, total: 50957856.42sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 50957856.41sec, total: 50957856.42sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.02ms, accelerator: 0us, total: 138.02ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 101915712.83sec, total: 101915712.83sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 50957856.42sec, total: 50957856.43sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 50957856.42sec, total: 50957856.42sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 50957856.42sec, total: 50957856.42sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 50957856.42sec, total: 50957856.42sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.28ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.28ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 249us, total: 1.50ms
      train.py:343:hfe, cpu: 508us, accelerator: 586us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.19ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.59ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 1.59ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.59ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2121.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_90500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 50817476.65sec, total: 50817476.65sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 50817476.65sec, total: 50817476.65sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 50817476.64sec, total: 50817476.65sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.05ms, accelerator: 0us, total: 138.05ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 101634953.29sec, total: 101634953.29sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 50817476.65sec, total: 50817476.66sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 50817476.65sec, total: 50817476.65sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 50817476.65sec, total: 50817476.65sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 50817476.65sec, total: 50817476.65sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.28ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 249us, total: 1.49ms
      train.py:343:hfe, cpu: 508us, accelerator: 585us, total: 1.09ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.18ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.59ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.59ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.59ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_90750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 50677868.19sec, total: 50677868.19sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 50677868.19sec, total: 50677868.19sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 50677868.19sec, total: 50677868.19sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.07ms, accelerator: 0us, total: 138.07ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 101355736.38sec, total: 101355736.39sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 50677868.20sec, total: 50677868.20sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 50677868.20sec, total: 50677868.20sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 50677868.20sec, total: 50677868.20sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 50677868.20sec, total: 50677868.20sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.29ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 253us, total: 1.50ms
      train.py:343:hfe, cpu: 507us, accelerator: 589us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.18ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.58ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 1.58ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.60ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2133.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_91000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 50539024.72sec, total: 50539024.72sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 50539024.72sec, total: 50539024.72sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 50539024.72sec, total: 50539024.72sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.14ms, accelerator: 0us, total: 138.14ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 101078049.44sec, total: 101078049.44sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 50539024.72sec, total: 50539024.73sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 50539024.72sec, total: 50539024.73sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 50539024.72sec, total: 50539024.73sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 50539024.72sec, total: 50539024.72sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.29ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 251us, total: 1.50ms
      train.py:343:hfe, cpu: 504us, accelerator: 588us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.17ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.58ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.40ms, accelerator: 1.58ms, total: 7.01ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.59ms, total: 5.58ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_91250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 50400939.95sec, total: 50400939.95sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 50400939.95sec, total: 50400939.95sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 50400939.95sec, total: 50400939.95sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.23ms, accelerator: 0us, total: 138.23ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 100801879.90sec, total: 100801879.91sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 50400939.96sec, total: 50400939.96sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 50400939.96sec, total: 50400939.96sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 50400939.96sec, total: 50400939.96sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 50400939.96sec, total: 50400939.96sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.30ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.30ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 267us, total: 1.51ms
      train.py:343:hfe, cpu: 506us, accelerator: 587us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.58ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 1.58ms, total: 7.00ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.58ms, total: 5.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_91500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 50263607.69sec, total: 50263607.69sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 50263607.69sec, total: 50263607.69sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 50263607.69sec, total: 50263607.69sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.15ms, accelerator: 0us, total: 138.15ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 100527215.38sec, total: 100527215.38sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 50263607.70sec, total: 50263607.70sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 50263607.69sec, total: 50263607.70sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 50263607.69sec, total: 50263607.70sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 50263607.69sec, total: 50263607.70sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.30ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.30ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 266us, total: 1.51ms
      train.py:343:hfe, cpu: 505us, accelerator: 586us, total: 1.10ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.58ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.39ms, accelerator: 1.58ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.58ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_91750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 50127021.80sec, total: 50127021.80sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 393us, accelerator: 50127021.80sec, total: 50127021.80sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 50127021.80sec, total: 50127021.80sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.08ms, accelerator: 0us, total: 138.08ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 100254043.60sec, total: 100254043.60sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 50127021.81sec, total: 50127021.81sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 50127021.80sec, total: 50127021.81sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 50127021.80sec, total: 50127021.81sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 50127021.80sec, total: 50127021.81sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.30ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.30ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 266us, total: 1.51ms
      train.py:343:hfe, cpu: 503us, accelerator: 585us, total: 1.09ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.14ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.57ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 1.57ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.57ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_92000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 49991176.21sec, total: 49991176.21sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 392us, accelerator: 49991176.21sec, total: 49991176.21sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 49991176.21sec, total: 49991176.21sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.12ms, accelerator: 0us, total: 138.12ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 99982352.42sec, total: 99982352.43sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 49991176.22sec, total: 49991176.22sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 49991176.22sec, total: 49991176.22sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 49991176.22sec, total: 49991176.22sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 49991176.22sec, total: 49991176.22sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.29ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 266us, total: 1.51ms
      train.py:343:hfe, cpu: 502us, accelerator: 584us, total: 1.09ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.13ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.57ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.57ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.57ms, total: 5.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_92250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 49856064.93sec, total: 49856064.93sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 392us, accelerator: 49856064.93sec, total: 49856064.93sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 49856064.92sec, total: 49856064.93sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 138.00ms, accelerator: 0us, total: 138.00ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 99712129.85sec, total: 99712129.85sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 49856064.93sec, total: 49856064.94sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 49856064.93sec, total: 49856064.93sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 49856064.93sec, total: 49856064.93sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 49856064.93sec, total: 49856064.93sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.29ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 266us, total: 1.51ms
      train.py:343:hfe, cpu: 502us, accelerator: 580us, total: 1.09ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.12ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.56ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 1.56ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.56ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_92500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 49721682.00sec, total: 49721682.00sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 391us, accelerator: 49721682.00sec, total: 49721682.00sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 49721682.00sec, total: 49721682.00sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.92ms, accelerator: 0us, total: 137.92ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 99443364.00sec, total: 99443364.00sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 49721682.01sec, total: 49721682.01sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 49721682.00sec, total: 49721682.01sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 49721682.00sec, total: 49721682.01sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 49721682.00sec, total: 49721682.01sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.28ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 265us, total: 1.51ms
      train.py:343:hfe, cpu: 502us, accelerator: 578us, total: 1.09ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.56ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.56ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.60ms, total: 5.59ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_92750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 49588021.57sec, total: 49588021.57sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 49588021.57sec, total: 49588021.57sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 49588021.56sec, total: 49588021.57sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.96ms, accelerator: 0us, total: 137.96ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 99176043.13sec, total: 99176043.13sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 49588021.57sec, total: 49588021.58sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 49588021.57sec, total: 49588021.57sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 49588021.57sec, total: 49588021.57sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 49588021.57sec, total: 49588021.57sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.28ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 265us, total: 1.51ms
      train.py:343:hfe, cpu: 502us, accelerator: 578us, total: 1.09ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.56ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.56ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.60ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_93000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 49455077.81sec, total: 49455077.81sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 391us, accelerator: 49455077.81sec, total: 49455077.81sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 49455077.81sec, total: 49455077.81sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.87ms, accelerator: 0us, total: 137.87ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 98910155.61sec, total: 98910155.62sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 49455077.81sec, total: 49455077.82sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 49455077.81sec, total: 49455077.81sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 49455077.81sec, total: 49455077.81sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 49455077.81sec, total: 49455077.81sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 263us, total: 1.50ms
      train.py:343:hfe, cpu: 502us, accelerator: 578us, total: 1.08ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.15ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.55ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 1.55ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.60ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_93250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 49322844.98sec, total: 49322844.98sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 391us, accelerator: 49322844.98sec, total: 49322844.98sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 49322844.98sec, total: 49322844.98sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.97ms, accelerator: 0us, total: 137.97ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 98645689.96sec, total: 98645689.96sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 49322844.98sec, total: 49322844.99sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 49322844.98sec, total: 49322844.99sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 49322844.98sec, total: 49322844.99sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 49322844.98sec, total: 49322844.99sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.27ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.27ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 262us, total: 1.51ms
      train.py:343:hfe, cpu: 541us, accelerator: 576us, total: 1.12ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.20ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.61ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.61ms, total: 6.99ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.59ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_93500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 49191317.39sec, total: 49191317.39sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 49191317.39sec, total: 49191317.39sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 49191317.39sec, total: 49191317.39sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.93ms, accelerator: 0us, total: 137.93ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 98382634.78sec, total: 98382634.79sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 49191317.40sec, total: 49191317.40sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 49191317.40sec, total: 49191317.40sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 49191317.40sec, total: 49191317.40sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 49191317.40sec, total: 49191317.40sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.27ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.27ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 262us, total: 1.51ms
      train.py:343:hfe, cpu: 541us, accelerator: 575us, total: 1.12ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.19ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.61ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 1.61ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.58ms, total: 5.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_93750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 49060489.42sec, total: 49060489.42sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 49060489.42sec, total: 49060489.42sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 49060489.42sec, total: 49060489.42sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.95ms, accelerator: 0us, total: 137.95ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 98120978.84sec, total: 98120978.85sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 49060489.43sec, total: 49060489.43sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 49060489.42sec, total: 49060489.43sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 49060489.42sec, total: 49060489.43sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 49060489.42sec, total: 49060489.43sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.27ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.27ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 262us, total: 1.50ms
      train.py:343:hfe, cpu: 541us, accelerator: 574us, total: 1.12ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.18ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.61ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.61ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.58ms, total: 5.57ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_94000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 48930355.50sec, total: 48930355.50sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 48930355.50sec, total: 48930355.50sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 48930355.49sec, total: 48930355.50sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.84ms, accelerator: 0us, total: 137.84ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 97860710.99sec, total: 97860711.00sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 48930355.50sec, total: 48930355.51sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 48930355.50sec, total: 48930355.50sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 48930355.50sec, total: 48930355.50sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 48930355.50sec, total: 48930355.50sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.27ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.27ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 260us, total: 1.50ms
      train.py:343:hfe, cpu: 539us, accelerator: 574us, total: 1.12ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.17ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.60ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 1.60ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.57ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_94250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 48800910.11sec, total: 48800910.11sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 391us, accelerator: 48800910.11sec, total: 48800910.11sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 48800910.11sec, total: 48800910.11sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.85ms, accelerator: 0us, total: 137.85ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 97601820.22sec, total: 97601820.23sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 48800910.12sec, total: 48800910.12sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 48800910.12sec, total: 48800910.12sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 48800910.12sec, total: 48800910.12sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 48800910.12sec, total: 48800910.12sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.26ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.26ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 260us, total: 1.51ms
      train.py:343:hfe, cpu: 538us, accelerator: 568us, total: 1.11ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.60ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 1.60ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.56ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_94500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 48672147.82sec, total: 48672147.82sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 48672147.82sec, total: 48672147.82sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 48672147.81sec, total: 48672147.82sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.90ms, accelerator: 0us, total: 137.90ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 97344295.63sec, total: 97344295.64sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 48672147.82sec, total: 48672147.83sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 48672147.82sec, total: 48672147.82sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 48672147.82sec, total: 48672147.82sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 48672147.82sec, total: 48672147.82sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.26ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.26ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 260us, total: 1.51ms
      train.py:343:hfe, cpu: 537us, accelerator: 568us, total: 1.11ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.60ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 1.60ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.56ms, total: 5.54ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_94750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 48544063.22sec, total: 48544063.22sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 48544063.22sec, total: 48544063.22sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 48544063.21sec, total: 48544063.22sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.81ms, accelerator: 0us, total: 137.81ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 97088126.43sec, total: 97088126.44sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 48544063.22sec, total: 48544063.23sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 48544063.22sec, total: 48544063.22sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 48544063.22sec, total: 48544063.22sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 48544063.22sec, total: 48544063.22sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.26ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.26ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 260us, total: 1.50ms
      train.py:343:hfe, cpu: 538us, accelerator: 568us, total: 1.11ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.60ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 1.60ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.56ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_95000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 48416650.98sec, total: 48416650.98sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 48416650.98sec, total: 48416650.98sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 48416650.98sec, total: 48416650.98sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.78ms, accelerator: 0us, total: 137.78ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 96833301.95sec, total: 96833301.96sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 48416650.98sec, total: 48416650.99sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 48416650.98sec, total: 48416650.98sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 48416650.98sec, total: 48416650.98sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 48416650.98sec, total: 48416650.98sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.25ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.25ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 259us, total: 1.50ms
      train.py:343:hfe, cpu: 536us, accelerator: 565us, total: 1.11ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.15ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.59ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 1.59ms, total: 6.93ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.56ms, total: 5.54ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_95250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 48289905.82sec, total: 48289905.82sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 48289905.82sec, total: 48289905.82sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 48289905.82sec, total: 48289905.82sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.69ms, accelerator: 0us, total: 137.69ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 96579811.63sec, total: 96579811.64sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 48289905.82sec, total: 48289905.83sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 48289905.82sec, total: 48289905.82sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 48289905.82sec, total: 48289905.82sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 48289905.82sec, total: 48289905.82sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.25ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.25ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 259us, total: 1.50ms
      train.py:343:hfe, cpu: 536us, accelerator: 565us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.14ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.59ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.59ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.55ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_95500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 48163822.51sec, total: 48163822.51sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 48163822.51sec, total: 48163822.51sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 48163822.51sec, total: 48163822.51sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.60ms, accelerator: 0us, total: 137.60ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 96327645.02sec, total: 96327645.03sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 48163822.52sec, total: 48163822.52sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 48163822.52sec, total: 48163822.52sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 48163822.52sec, total: 48163822.52sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 48163822.52sec, total: 48163822.52sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.25ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.25ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 259us, total: 1.50ms
      train.py:343:hfe, cpu: 535us, accelerator: 564us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.13ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.59ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 1.59ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.55ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_95750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 48038395.89sec, total: 48038395.89sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 48038395.89sec, total: 48038395.89sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 48038395.89sec, total: 48038395.89sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.59ms, accelerator: 0us, total: 137.59ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 96076791.78sec, total: 96076791.79sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 48038395.90sec, total: 48038395.90sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 48038395.89sec, total: 48038395.90sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 48038395.89sec, total: 48038395.90sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 48038395.89sec, total: 48038395.90sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.25ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.25ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 258us, total: 1.49ms
      train.py:343:hfe, cpu: 535us, accelerator: 564us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.13ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.58ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 1.58ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.54ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_96000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 47913620.84sec, total: 47913620.84sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 390us, accelerator: 47913620.84sec, total: 47913620.84sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 47913620.84sec, total: 47913620.84sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.53ms, accelerator: 0us, total: 137.53ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 95827241.67sec, total: 95827241.68sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 47913620.84sec, total: 47913620.85sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 47913620.84sec, total: 47913620.84sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 47913620.84sec, total: 47913620.84sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 47913620.84sec, total: 47913620.84sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.25ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.25ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 258us, total: 1.50ms
      train.py:343:hfe, cpu: 535us, accelerator: 563us, total: 1.10ms
train.py:511:<module>, cpu: 8.07sec, accelerator: 4.12ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.58ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.06sec, accelerator: 0us, total: 8.06sec
    __init__.py:86:allreduce, cpu: 5.38ms, accelerator: 1.58ms, total: 6.98ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.54ms, total: 5.52ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2132.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_96250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 47789492.29sec, total: 47789492.29sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 47789492.29sec, total: 47789492.29sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 47789492.28sec, total: 47789492.29sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.55ms, accelerator: 0us, total: 137.55ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 95578984.57sec, total: 95578984.57sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 47789492.29sec, total: 47789492.30sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 47789492.29sec, total: 47789492.29sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 47789492.29sec, total: 47789492.29sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 47789492.29sec, total: 47789492.29sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.25ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.25ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 257us, total: 1.49ms
      train.py:343:hfe, cpu: 534us, accelerator: 562us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.14ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.57ms, total: 8.07sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.37ms, accelerator: 1.57ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.56ms, total: 5.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_96500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 47666005.23sec, total: 47666005.23sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 47666005.23sec, total: 47666005.23sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 47666005.22sec, total: 47666005.23sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.53ms, accelerator: 0us, total: 137.53ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 95332010.45sec, total: 95332010.45sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 47666005.23sec, total: 47666005.24sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 47666005.23sec, total: 47666005.23sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 47666005.23sec, total: 47666005.23sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 47666005.23sec, total: 47666005.23sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.24ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.24ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 257us, total: 1.49ms
      train.py:343:hfe, cpu: 532us, accelerator: 561us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.13ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.07sec, accelerator: 1.57ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 1.57ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.56ms, total: 5.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_96750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 47543154.70sec, total: 47543154.70sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 47543154.70sec, total: 47543154.70sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 47543154.69sec, total: 47543154.70sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.61ms, accelerator: 0us, total: 137.61ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 95086309.39sec, total: 95086309.40sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 47543154.70sec, total: 47543154.71sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 47543154.70sec, total: 47543154.70sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 47543154.70sec, total: 47543154.70sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 47543154.70sec, total: 47543154.70sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.24ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.24ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 257us, total: 1.49ms
      train.py:343:hfe, cpu: 530us, accelerator: 559us, total: 1.09ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.12ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.57ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 1.57ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.55ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_97000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 47420935.79sec, total: 47420935.79sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 47420935.79sec, total: 47420935.79sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 47420935.79sec, total: 47420935.79sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.58ms, accelerator: 0us, total: 137.58ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 94841871.58sec, total: 94841871.58sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 47420935.80sec, total: 47420935.80sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 47420935.79sec, total: 47420935.80sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 47420935.79sec, total: 47420935.80sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 47420935.79sec, total: 47420935.80sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.26ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.26ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 267us, total: 1.50ms
      train.py:343:hfe, cpu: 530us, accelerator: 561us, total: 1.10ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.12ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.57ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 1.57ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.55ms, total: 5.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_97250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 47299343.65sec, total: 47299343.65sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 47299343.65sec, total: 47299343.65sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 47299343.65sec, total: 47299343.65sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.50ms, accelerator: 0us, total: 137.50ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 94598687.29sec, total: 94598687.30sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 47299343.65sec, total: 47299343.66sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 47299343.65sec, total: 47299343.65sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 47299343.65sec, total: 47299343.65sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 47299343.65sec, total: 47299343.65sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.26ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.26ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 267us, total: 1.49ms
      train.py:343:hfe, cpu: 529us, accelerator: 561us, total: 1.09ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.12ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.57ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.57ms, total: 6.93ms
  __init__.py:185:compute_gradients, cpu: 2.93ms, accelerator: 2.55ms, total: 5.52ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_97500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 47178373.46sec, total: 47178373.46sec (33.33%)
top 2 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 47178373.46sec, total: 47178373.46sec (33.33%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 47178373.46sec, total: 47178373.46sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.47ms, accelerator: 0us, total: 137.47ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 94356746.92sec, total: 94356746.92sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 47178373.46sec, total: 47178373.47sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 47178373.46sec, total: 47178373.46sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 47178373.46sec, total: 47178373.46sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 47178373.46sec, total: 47178373.46sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.28ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 266us, total: 1.49ms
      train.py:343:hfe, cpu: 529us, accelerator: 586us, total: 1.12ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.19ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.60ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.33ms, accelerator: 1.60ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.60ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_97750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 47058020.47sec, total: 47058020.47sec (33.33%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 47058020.46sec, total: 47058020.47sec (33.33%)
top 3 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 47058020.47sec, total: 47058020.47sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.48ms, accelerator: 0us, total: 137.48ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 94116040.93sec, total: 94116040.93sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 47058020.47sec, total: 47058020.48sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 47058020.47sec, total: 47058020.47sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 47058020.47sec, total: 47058020.47sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 47058020.47sec, total: 47058020.47sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.28ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 264us, total: 1.49ms
      train.py:343:hfe, cpu: 529us, accelerator: 586us, total: 1.12ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.20ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.59ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 1.59ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.61ms, total: 5.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_98000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 46938279.96sec, total: 46938279.96sec (33.33%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 46938279.95sec, total: 46938279.96sec (33.33%)
top 3 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 46938279.95sec, total: 46938279.96sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.47ms, accelerator: 0us, total: 137.47ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 93876559.91sec, total: 93876559.91sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 46938279.96sec, total: 46938279.97sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 46938279.96sec, total: 46938279.96sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 46938279.96sec, total: 46938279.96sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 46938279.96sec, total: 46938279.96sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.27ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.27ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 264us, total: 1.49ms
      train.py:343:hfe, cpu: 528us, accelerator: 583us, total: 1.11ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.20ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.59ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.36ms, accelerator: 1.59ms, total: 6.97ms
  __init__.py:185:compute_gradients, cpu: 2.95ms, accelerator: 2.61ms, total: 5.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_98250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 46819147.26sec, total: 46819147.27sec (33.33%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 46819147.26sec, total: 46819147.27sec (33.33%)
top 3 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 46819147.26sec, total: 46819147.27sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.54ms, accelerator: 0us, total: 137.54ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 93638294.53sec, total: 93638294.53sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 46819147.27sec, total: 46819147.28sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 46819147.27sec, total: 46819147.27sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 46819147.27sec, total: 46819147.27sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 46819147.27sec, total: 46819147.27sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.27ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.27ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 264us, total: 1.48ms
      train.py:343:hfe, cpu: 528us, accelerator: 581us, total: 1.11ms
train.py:511:<module>, cpu: 8.09sec, accelerator: 4.19ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.59ms, total: 8.09sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.35ms, accelerator: 1.59ms, total: 6.96ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.60ms, total: 5.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_98500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 46700617.78sec, total: 46700617.78sec (33.33%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 46700617.78sec, total: 46700617.78sec (33.33%)
top 3 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 46700617.78sec, total: 46700617.78sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.50ms, accelerator: 0us, total: 137.50ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 93401235.55sec, total: 93401235.56sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 46700617.78sec, total: 46700617.79sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 46700617.78sec, total: 46700617.78sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 46700617.78sec, total: 46700617.78sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 46700617.78sec, total: 46700617.78sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.27ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.27ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 263us, total: 1.48ms
      train.py:343:hfe, cpu: 527us, accelerator: 580us, total: 1.11ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.18ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.58ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.08sec, accelerator: 0us, total: 8.08sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.58ms, total: 6.95ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.60ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2117.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_98750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 46582686.93sec, total: 46582686.93sec (33.33%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 46582686.92sec, total: 46582686.93sec (33.33%)
top 3 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 46582686.92sec, total: 46582686.93sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.66ms, accelerator: 0us, total: 137.66ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 93165373.85sec, total: 93165373.85sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 46582686.93sec, total: 46582686.94sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 46582686.93sec, total: 46582686.93sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 46582686.93sec, total: 46582686.93sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 46582686.93sec, total: 46582686.93sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.27ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.27ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 263us, total: 1.48ms
      train.py:343:hfe, cpu: 526us, accelerator: 580us, total: 1.11ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.17ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.58ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.34ms, accelerator: 1.58ms, total: 6.94ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.59ms, total: 5.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_99000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 46465350.18sec, total: 46465350.18sec (33.33%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 46465350.18sec, total: 46465350.18sec (33.33%)
top 3 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 46465350.18sec, total: 46465350.18sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.57ms, accelerator: 0us, total: 137.57ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 92930700.36sec, total: 92930700.37sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 46465350.19sec, total: 46465350.19sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 46465350.19sec, total: 46465350.19sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 46465350.19sec, total: 46465350.19sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 46465350.19sec, total: 46465350.19sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.27ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.27ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 263us, total: 1.48ms
      train.py:343:hfe, cpu: 525us, accelerator: 579us, total: 1.11ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.09sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.57ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.32ms, accelerator: 1.57ms, total: 6.92ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.59ms, total: 5.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_99250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 46348603.07sec, total: 46348603.07sec (33.33%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 46348603.07sec, total: 46348603.07sec (33.33%)
top 3 operation type: DepthwiseConv2dNative, cpu: 389us, accelerator: 46348603.07sec, total: 46348603.07sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.48ms, accelerator: 0us, total: 137.48ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 92697206.14sec, total: 92697206.15sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 46348603.08sec, total: 46348603.08sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 46348603.07sec, total: 46348603.08sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 46348603.07sec, total: 46348603.08sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 46348603.07sec, total: 46348603.08sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.29ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 276us, total: 1.49ms
      train.py:343:hfe, cpu: 524us, accelerator: 588us, total: 1.12ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.16ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.57ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 1.57ms, total: 6.92ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.58ms, total: 5.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_99500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 46232441.16sec, total: 46232441.16sec (33.33%)
top 2 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 46232441.16sec, total: 46232441.16sec (33.33%)
top 3 operation type: DepthwiseConv2dNative, cpu: 388us, accelerator: 46232441.16sec, total: 46232441.16sec (33.33%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.38ms, accelerator: 0us, total: 137.38ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 92464882.32sec, total: 92464882.32sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 46232441.16sec, total: 46232441.17sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 46232441.16sec, total: 46232441.16sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 46232441.16sec, total: 46232441.16sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 46232441.16sec, total: 46232441.16sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.29ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 276us, total: 1.49ms
      train.py:343:hfe, cpu: 522us, accelerator: 585us, total: 1.11ms
train.py:511:<module>, cpu: 8.08sec, accelerator: 4.15ms, total: 8.08sec
  __init__.py:194:compute_gradients, cpu: 8.08sec, accelerator: 1.57ms, total: 8.08sec
    __init__.py:83:allreduce, cpu: 8.07sec, accelerator: 0us, total: 8.07sec
    __init__.py:86:allreduce, cpu: 5.31ms, accelerator: 1.57ms, total: 6.92ms
  __init__.py:185:compute_gradients, cpu: 2.94ms, accelerator: 2.58ms, total: 5.56ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_99750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 46116860.06sec, total: 46116860.06sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.60ms, accelerator: 46116860.05sec, total: 46116860.06sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 46116860.05sec, total: 46116860.06sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.35ms, accelerator: 0us, total: 137.35ms
train.py:441:<module> (gradient), cpu: 4.24ms, accelerator: 92233720.11sec, total: 92233720.11sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 46116860.06sec, total: 46116860.07sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 46116860.06sec, total: 46116860.06sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 46116860.06sec, total: 46116860.06sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 46116860.06sec, total: 46116860.06sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.29ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 275us, total: 1.48ms
      train.py:343:hfe, cpu: 522us, accelerator: 585us, total: 1.11ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 46116860.06sec, total: 46116860.06sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 1.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_100000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 46001855.42sec, total: 46001855.42sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.60ms, accelerator: 46001855.42sec, total: 46001855.42sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 46001855.42sec, total: 46001855.42sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.37ms, accelerator: 0us, total: 137.37ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 92003710.83sec, total: 92003710.84sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 46001855.42sec, total: 46001855.43sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 46001855.42sec, total: 46001855.42sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 46001855.42sec, total: 46001855.42sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 46001855.42sec, total: 46001855.42sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.28ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 273us, total: 1.48ms
      train.py:343:hfe, cpu: 521us, accelerator: 585us, total: 1.11ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 46001855.42sec, total: 46001855.42sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_100250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 45887422.94sec, total: 45887422.94sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.60ms, accelerator: 45887422.94sec, total: 45887422.94sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 45887422.94sec, total: 45887422.94sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.41ms, accelerator: 0us, total: 137.41ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 91774845.88sec, total: 91774845.89sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 45887422.95sec, total: 45887422.95sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 45887422.94sec, total: 45887422.95sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 45887422.94sec, total: 45887422.95sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 45887422.94sec, total: 45887422.95sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 272us, total: 1.48ms
      train.py:343:hfe, cpu: 521us, accelerator: 585us, total: 1.11ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 45887422.94sec, total: 45887422.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_100500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 45773558.37sec, total: 45773558.37sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 45773558.37sec, total: 45773558.37sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 45773558.37sec, total: 45773558.37sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.49ms, accelerator: 0us, total: 137.49ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 91547116.74sec, total: 91547116.74sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 45773558.37sec, total: 45773558.38sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 45773558.37sec, total: 45773558.37sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 45773558.37sec, total: 45773558.37sec
      train.py:349:msssim, cpu: 2.76ms, accelerator: 45773558.37sec, total: 45773558.37sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 272us, total: 1.48ms
      train.py:343:hfe, cpu: 520us, accelerator: 582us, total: 1.10ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 45773558.37sec, total: 45773558.37sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_100750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 45660257.48sec, total: 45660257.48sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 45660257.48sec, total: 45660257.48sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 45660257.48sec, total: 45660257.48sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.64ms, accelerator: 0us, total: 137.64ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 91320514.96sec, total: 91320514.97sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 45660257.49sec, total: 45660257.49sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 45660257.48sec, total: 45660257.49sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 45660257.48sec, total: 45660257.49sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 45660257.48sec, total: 45660257.49sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 271us, total: 1.48ms
      train.py:343:hfe, cpu: 519us, accelerator: 582us, total: 1.10ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 45660257.48sec, total: 45660257.49sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_101000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 45547516.10sec, total: 45547516.11sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 45547516.10sec, total: 45547516.11sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 45547516.10sec, total: 45547516.10sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.72ms, accelerator: 0us, total: 137.72ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 91095032.21sec, total: 91095032.21sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 45547516.11sec, total: 45547516.12sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 45547516.11sec, total: 45547516.11sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 45547516.11sec, total: 45547516.11sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 45547516.11sec, total: 45547516.11sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.27ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.27ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 271us, total: 1.48ms
      train.py:343:hfe, cpu: 518us, accelerator: 579us, total: 1.10ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 45547516.11sec, total: 45547516.11sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_101250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 45435330.10sec, total: 45435330.11sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 45435330.10sec, total: 45435330.11sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 45435330.10sec, total: 45435330.10sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.74ms, accelerator: 0us, total: 137.74ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 90870660.21sec, total: 90870660.21sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 45435330.11sec, total: 45435330.12sec
  train.py:360:image_losses, cpu: 2.82ms, accelerator: 45435330.11sec, total: 45435330.11sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 45435330.11sec, total: 45435330.11sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 45435330.11sec, total: 45435330.11sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.27ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.27ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 270us, total: 1.47ms
      train.py:343:hfe, cpu: 524us, accelerator: 576us, total: 1.10ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 45435330.11sec, total: 45435330.11sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_101500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 45323695.39sec, total: 45323695.39sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 45323695.38sec, total: 45323695.39sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 45323695.39sec, total: 45323695.39sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.69ms, accelerator: 0us, total: 137.69ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 90647390.77sec, total: 90647390.78sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 45323695.39sec, total: 45323695.40sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 45323695.39sec, total: 45323695.39sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 45323695.39sec, total: 45323695.39sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 45323695.39sec, total: 45323695.39sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.26ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.26ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 270us, total: 1.47ms
      train.py:343:hfe, cpu: 524us, accelerator: 575us, total: 1.10ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 45323695.39sec, total: 45323695.39sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_101750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 45212607.90sec, total: 45212607.90sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 45212607.90sec, total: 45212607.90sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 45212607.90sec, total: 45212607.90sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.64ms, accelerator: 0us, total: 137.64ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 90425215.79sec, total: 90425215.80sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 45212607.90sec, total: 45212607.91sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 45212607.90sec, total: 45212607.90sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 45212607.90sec, total: 45212607.90sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 45212607.90sec, total: 45212607.90sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.26ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.26ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 270us, total: 1.47ms
      train.py:343:hfe, cpu: 523us, accelerator: 574us, total: 1.10ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 45212607.90sec, total: 45212607.90sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_102000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 45102063.62sec, total: 45102063.63sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 45102063.62sec, total: 45102063.63sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 45102063.62sec, total: 45102063.62sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.55ms, accelerator: 0us, total: 137.55ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 90204127.25sec, total: 90204127.25sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 45102063.63sec, total: 45102063.64sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 45102063.63sec, total: 45102063.63sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 45102063.63sec, total: 45102063.63sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 45102063.63sec, total: 45102063.63sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.26ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.26ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 270us, total: 1.47ms
      train.py:343:hfe, cpu: 523us, accelerator: 574us, total: 1.10ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 45102063.63sec, total: 45102063.63sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_102250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 44992058.59sec, total: 44992058.59sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 44992058.59sec, total: 44992058.59sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 44992058.59sec, total: 44992058.59sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.49ms, accelerator: 0us, total: 137.49ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 89984117.18sec, total: 89984117.19sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 44992058.60sec, total: 44992058.60sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 44992058.59sec, total: 44992058.60sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 44992058.59sec, total: 44992058.60sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 44992058.59sec, total: 44992058.60sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.26ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.26ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 269us, total: 1.47ms
      train.py:343:hfe, cpu: 523us, accelerator: 573us, total: 1.10ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 44992058.59sec, total: 44992058.60sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_102500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 44882588.86sec, total: 44882588.86sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 44882588.86sec, total: 44882588.86sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 44882588.86sec, total: 44882588.86sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.49ms, accelerator: 0us, total: 137.49ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 89765177.72sec, total: 89765177.73sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 44882588.87sec, total: 44882588.87sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 44882588.87sec, total: 44882588.87sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 44882588.87sec, total: 44882588.87sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 44882588.87sec, total: 44882588.87sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.26ms, total: 3.35ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.26ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 268us, total: 1.47ms
      train.py:343:hfe, cpu: 522us, accelerator: 572us, total: 1.10ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 44882588.86sec, total: 44882588.87sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_102750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 44773650.54sec, total: 44773650.54sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 44773650.54sec, total: 44773650.54sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 44773650.54sec, total: 44773650.54sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.51ms, accelerator: 0us, total: 137.51ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 89547301.08sec, total: 89547301.08sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 44773650.54sec, total: 44773650.55sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 44773650.54sec, total: 44773650.55sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 44773650.54sec, total: 44773650.55sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 44773650.54sec, total: 44773650.55sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.25ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.25ms, total: 3.33ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 268us, total: 1.47ms
      train.py:343:hfe, cpu: 521us, accelerator: 570us, total: 1.09ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 44773650.54sec, total: 44773650.55sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2065.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_103000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 44665239.76sec, total: 44665239.77sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 44665239.76sec, total: 44665239.76sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 44665239.76sec, total: 44665239.76sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.50ms, accelerator: 0us, total: 137.50ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 89330479.53sec, total: 89330479.53sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 44665239.77sec, total: 44665239.77sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 44665239.77sec, total: 44665239.77sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 44665239.77sec, total: 44665239.77sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 44665239.77sec, total: 44665239.77sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.25ms, total: 3.34ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.25ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 268us, total: 1.47ms
      train.py:343:hfe, cpu: 520us, accelerator: 569us, total: 1.09ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 44665239.77sec, total: 44665239.77sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_103250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 44557352.71sec, total: 44557352.71sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 44557352.71sec, total: 44557352.71sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 44557352.71sec, total: 44557352.71sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.49ms, accelerator: 0us, total: 137.49ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 89114705.42sec, total: 89114705.43sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 44557352.72sec, total: 44557352.72sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 44557352.71sec, total: 44557352.72sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 44557352.71sec, total: 44557352.72sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 44557352.71sec, total: 44557352.72sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.25ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.25ms, total: 3.32ms
      train.py:342:hfe, cpu: 1.20ms, accelerator: 267us, total: 1.47ms
      train.py:343:hfe, cpu: 521us, accelerator: 568us, total: 1.09ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 44557352.71sec, total: 44557352.72sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_103500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 44449985.60sec, total: 44449985.60sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 44449985.59sec, total: 44449985.60sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 44449985.59sec, total: 44449985.60sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.43ms, accelerator: 0us, total: 137.43ms
train.py:441:<module> (gradient), cpu: 4.23ms, accelerator: 88899971.19sec, total: 88899971.20sec
train.py:442:<module>, cpu: 5.44ms, accelerator: 44449985.60sec, total: 44449985.61sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 44449985.60sec, total: 44449985.60sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 44449985.60sec, total: 44449985.60sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 44449985.60sec, total: 44449985.60sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.25ms, total: 3.33ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.25ms, total: 3.31ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 266us, total: 1.46ms
      train.py:343:hfe, cpu: 521us, accelerator: 567us, total: 1.09ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 44449985.60sec, total: 44449985.60sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_103750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 44343134.67sec, total: 44343134.67sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 44343134.67sec, total: 44343134.67sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 44343134.67sec, total: 44343134.67sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.41ms, accelerator: 0us, total: 137.41ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 88686269.34sec, total: 88686269.34sec
train.py:442:<module>, cpu: 5.44ms, accelerator: 44343134.67sec, total: 44343134.68sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 44343134.67sec, total: 44343134.68sec
    train.py:322:loss_fn, cpu: 2.80ms, accelerator: 44343134.67sec, total: 44343134.68sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 44343134.67sec, total: 44343134.68sec
  train.py:359:image_losses, cpu: 2.07ms, accelerator: 1.29ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.05ms, accelerator: 1.29ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.19ms, accelerator: 265us, total: 1.46ms
      train.py:343:hfe, cpu: 521us, accelerator: 614us, total: 1.14ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 44343134.67sec, total: 44343134.67sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_104000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 44236796.22sec, total: 44236796.22sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 44236796.21sec, total: 44236796.22sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 44236796.22sec, total: 44236796.22sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.45ms, accelerator: 0us, total: 137.45ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 88473592.43sec, total: 88473592.44sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 44236796.22sec, total: 44236796.23sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 44236796.22sec, total: 44236796.22sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 44236796.22sec, total: 44236796.22sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 44236796.22sec, total: 44236796.22sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 265us, total: 1.50ms
      train.py:343:hfe, cpu: 521us, accelerator: 614us, total: 1.14ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 44236796.22sec, total: 44236796.22sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_104250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 44130966.56sec, total: 44130966.56sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 44130966.56sec, total: 44130966.56sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 44130966.56sec, total: 44130966.56sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.41ms, accelerator: 0us, total: 137.41ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 88261933.12sec, total: 88261933.12sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 44130966.57sec, total: 44130966.57sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 44130966.56sec, total: 44130966.57sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 44130966.56sec, total: 44130966.57sec
      train.py:349:msssim, cpu: 2.75ms, accelerator: 44130966.56sec, total: 44130966.57sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.28ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.28ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 265us, total: 1.49ms
      train.py:343:hfe, cpu: 519us, accelerator: 610us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 44130966.56sec, total: 44130966.57sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_104500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 44025642.06sec, total: 44025642.06sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 44025642.06sec, total: 44025642.06sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 44025642.06sec, total: 44025642.06sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.44ms, accelerator: 0us, total: 137.44ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 88051284.12sec, total: 88051284.12sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 44025642.06sec, total: 44025642.07sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 44025642.06sec, total: 44025642.06sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 44025642.06sec, total: 44025642.06sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 44025642.06sec, total: 44025642.06sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.28ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 265us, total: 1.49ms
      train.py:343:hfe, cpu: 517us, accelerator: 607us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 44025642.06sec, total: 44025642.06sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_104750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 43920819.10sec, total: 43920819.10sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 43920819.10sec, total: 43920819.10sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 43920819.10sec, total: 43920819.10sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.37ms, accelerator: 0us, total: 137.37ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 87841638.20sec, total: 87841638.21sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 43920819.11sec, total: 43920819.11sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 43920819.10sec, total: 43920819.11sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 43920819.10sec, total: 43920819.11sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 43920819.10sec, total: 43920819.11sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.28ms, total: 3.39ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 264us, total: 1.49ms
      train.py:343:hfe, cpu: 520us, accelerator: 607us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 43920819.10sec, total: 43920819.11sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_105000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 43816494.12sec, total: 43816494.12sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 43816494.11sec, total: 43816494.12sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 43816494.11sec, total: 43816494.12sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.40ms, accelerator: 0us, total: 137.40ms
train.py:441:<module> (gradient), cpu: 4.22ms, accelerator: 87632988.23sec, total: 87632988.23sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 43816494.12sec, total: 43816494.13sec
  train.py:360:image_losses, cpu: 2.81ms, accelerator: 43816494.12sec, total: 43816494.12sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 43816494.12sec, total: 43816494.12sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 43816494.12sec, total: 43816494.12sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.28ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 264us, total: 1.49ms
      train.py:343:hfe, cpu: 517us, accelerator: 607us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 43816494.12sec, total: 43816494.12sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2130.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_105250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 43712663.56sec, total: 43712663.56sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 43712663.56sec, total: 43712663.56sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 43712663.56sec, total: 43712663.56sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.34ms, accelerator: 0us, total: 137.34ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 87425327.12sec, total: 87425327.12sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 43712663.57sec, total: 43712663.57sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 43712663.56sec, total: 43712663.57sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 43712663.56sec, total: 43712663.57sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 43712663.56sec, total: 43712663.57sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.28ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 263us, total: 1.48ms
      train.py:343:hfe, cpu: 517us, accelerator: 607us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 43712663.56sec, total: 43712663.57sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_105500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 43609323.93sec, total: 43609323.93sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 43609323.93sec, total: 43609323.93sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 43609323.93sec, total: 43609323.93sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.37ms, accelerator: 0us, total: 137.37ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 87218647.86sec, total: 87218647.86sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 43609323.94sec, total: 43609323.94sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 43609323.93sec, total: 43609323.94sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 43609323.93sec, total: 43609323.94sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 43609323.93sec, total: 43609323.94sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.27ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.27ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 262us, total: 1.48ms
      train.py:343:hfe, cpu: 515us, accelerator: 607us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 43609323.93sec, total: 43609323.94sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_105750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 43506471.75sec, total: 43506471.75sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 43506471.75sec, total: 43506471.75sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 43506471.75sec, total: 43506471.75sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.41ms, accelerator: 0us, total: 137.41ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 87012943.50sec, total: 87012943.51sec
train.py:442:<module>, cpu: 5.44ms, accelerator: 43506471.76sec, total: 43506471.76sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 43506471.75sec, total: 43506471.76sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 43506471.75sec, total: 43506471.76sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 43506471.75sec, total: 43506471.76sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.27ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.27ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 262us, total: 1.48ms
      train.py:343:hfe, cpu: 515us, accelerator: 606us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 43506471.75sec, total: 43506471.76sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2122.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_106000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 43404103.58sec, total: 43404103.58sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 43404103.58sec, total: 43404103.58sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 43404103.58sec, total: 43404103.58sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.31ms, accelerator: 0us, total: 137.31ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 86808207.16sec, total: 86808207.17sec
train.py:442:<module>, cpu: 5.44ms, accelerator: 43404103.59sec, total: 43404103.59sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 43404103.59sec, total: 43404103.59sec
    train.py:322:loss_fn, cpu: 2.79ms, accelerator: 43404103.59sec, total: 43404103.59sec
      train.py:349:msssim, cpu: 2.74ms, accelerator: 43404103.59sec, total: 43404103.59sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.27ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.27ms, total: 3.35ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 262us, total: 1.48ms
      train.py:343:hfe, cpu: 515us, accelerator: 604us, total: 1.12ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 43404103.58sec, total: 43404103.59sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.25 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_106250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 43302216.02sec, total: 43302216.02sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 43302216.01sec, total: 43302216.02sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 43302216.01sec, total: 43302216.02sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.44ms, accelerator: 0us, total: 137.44ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 86604432.03sec, total: 86604432.03sec
train.py:442:<module>, cpu: 5.43ms, accelerator: 43302216.02sec, total: 43302216.03sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 43302216.02sec, total: 43302216.02sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 43302216.02sec, total: 43302216.02sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 43302216.02sec, total: 43302216.02sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.27ms, total: 3.36ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.27ms, total: 3.34ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 262us, total: 1.47ms
      train.py:343:hfe, cpu: 515us, accelerator: 602us, total: 1.12ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 43302216.02sec, total: 43302216.02sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2134.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_106500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 43200805.67sec, total: 43200805.67sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 43200805.67sec, total: 43200805.67sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 43200805.67sec, total: 43200805.67sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.36ms, accelerator: 0us, total: 137.36ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 86401611.35sec, total: 86401611.35sec
train.py:442:<module>, cpu: 5.43ms, accelerator: 43200805.68sec, total: 43200805.68sec
  train.py:360:image_losses, cpu: 2.80ms, accelerator: 43200805.68sec, total: 43200805.68sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 43200805.68sec, total: 43200805.68sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 43200805.68sec, total: 43200805.68sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.28ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 261us, total: 1.47ms
      train.py:343:hfe, cpu: 515us, accelerator: 613us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 43200805.67sec, total: 43200805.68sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_106750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 43099869.21sec, total: 43099869.21sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 43099869.21sec, total: 43099869.21sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 43099869.21sec, total: 43099869.21sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.42ms, accelerator: 0us, total: 137.42ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 86199738.42sec, total: 86199738.43sec
train.py:442:<module>, cpu: 5.42ms, accelerator: 43099869.22sec, total: 43099869.22sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 43099869.21sec, total: 43099869.22sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 43099869.21sec, total: 43099869.22sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 43099869.21sec, total: 43099869.22sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.28ms, total: 3.37ms
    train.py:322:loss_fn, cpu: 2.06ms, accelerator: 1.28ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 260us, total: 1.47ms
      train.py:343:hfe, cpu: 514us, accelerator: 613us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 43099869.21sec, total: 43099869.22sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_107000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 42999403.32sec, total: 42999403.32sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 42999403.31sec, total: 42999403.32sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 42999403.31sec, total: 42999403.32sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.37ms, accelerator: 0us, total: 137.37ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 85998806.63sec, total: 85998806.63sec
train.py:442:<module>, cpu: 5.43ms, accelerator: 42999403.32sec, total: 42999403.33sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 42999403.32sec, total: 42999403.32sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 42999403.32sec, total: 42999403.32sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 42999403.32sec, total: 42999403.32sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.28ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 260us, total: 1.48ms
      train.py:343:hfe, cpu: 514us, accelerator: 612us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 42999403.32sec, total: 42999403.32sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_107250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 42899404.70sec, total: 42899404.70sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 42899404.70sec, total: 42899404.70sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 42899404.70sec, total: 42899404.70sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.44ms, accelerator: 0us, total: 137.44ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 85798809.41sec, total: 85798809.41sec
train.py:442:<module>, cpu: 5.43ms, accelerator: 42899404.71sec, total: 42899404.71sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 42899404.71sec, total: 42899404.71sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 42899404.71sec, total: 42899404.71sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 42899404.71sec, total: 42899404.71sec
  train.py:359:image_losses, cpu: 2.08ms, accelerator: 1.28ms, total: 3.38ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.28ms, total: 3.36ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 259us, total: 1.48ms
      train.py:343:hfe, cpu: 512us, accelerator: 612us, total: 1.13ms
train.py:436:<module> (gradient), cpu: 4.17ms, accelerator: 42899404.70sec, total: 42899404.71sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_107500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 42799870.12sec, total: 42799870.12sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 42799870.12sec, total: 42799870.12sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 42799870.12sec, total: 42799870.12sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.47ms, accelerator: 0us, total: 137.47ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 85599740.24sec, total: 85599740.25sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 42799870.13sec, total: 42799870.13sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 42799870.12sec, total: 42799870.13sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 42799870.12sec, total: 42799870.13sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 42799870.12sec, total: 42799870.13sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.30ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.30ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 261us, total: 1.52ms
      train.py:343:hfe, cpu: 510us, accelerator: 630us, total: 1.15ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 42799870.12sec, total: 42799870.13sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_107750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 42700796.35sec, total: 42700796.35sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 42700796.35sec, total: 42700796.35sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 42700796.35sec, total: 42700796.35sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.50ms, accelerator: 0us, total: 137.50ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 85401592.70sec, total: 85401592.70sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 42700796.35sec, total: 42700796.36sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 42700796.35sec, total: 42700796.35sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 42700796.35sec, total: 42700796.35sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 42700796.35sec, total: 42700796.35sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.30ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.30ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 260us, total: 1.52ms
      train.py:343:hfe, cpu: 510us, accelerator: 629us, total: 1.14ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 42700796.35sec, total: 42700796.35sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_108000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 42602180.19sec, total: 42602180.19sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 42602180.19sec, total: 42602180.19sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 42602180.19sec, total: 42602180.19sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.53ms, accelerator: 0us, total: 137.53ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 85204360.38sec, total: 85204360.38sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 42602180.20sec, total: 42602180.20sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 42602180.19sec, total: 42602180.20sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 42602180.19sec, total: 42602180.20sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 42602180.19sec, total: 42602180.20sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.29ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.29ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 259us, total: 1.51ms
      train.py:343:hfe, cpu: 509us, accelerator: 628us, total: 1.14ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 42602180.19sec, total: 42602180.20sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_108250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 42504018.49sec, total: 42504018.49sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 42504018.48sec, total: 42504018.49sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 42504018.48sec, total: 42504018.49sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.46ms, accelerator: 0us, total: 137.46ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 85008036.97sec, total: 85008036.97sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 42504018.49sec, total: 42504018.50sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 42504018.49sec, total: 42504018.49sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 42504018.49sec, total: 42504018.49sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 42504018.49sec, total: 42504018.49sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.29ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.29ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 259us, total: 1.51ms
      train.py:343:hfe, cpu: 509us, accelerator: 627us, total: 1.14ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 42504018.49sec, total: 42504018.49sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_108500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 42406308.10sec, total: 42406308.10sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 42406308.10sec, total: 42406308.10sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 42406308.10sec, total: 42406308.10sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.39ms, accelerator: 0us, total: 137.39ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 84812616.19sec, total: 84812616.20sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 42406308.10sec, total: 42406308.11sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 42406308.10sec, total: 42406308.10sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 42406308.10sec, total: 42406308.10sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 42406308.10sec, total: 42406308.10sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.29ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 259us, total: 1.51ms
      train.py:343:hfe, cpu: 509us, accelerator: 626us, total: 1.14ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 42406308.10sec, total: 42406308.10sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_108750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 42309045.92sec, total: 42309045.92sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 42309045.92sec, total: 42309045.92sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 42309045.92sec, total: 42309045.92sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.45ms, accelerator: 0us, total: 137.45ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 84618091.84sec, total: 84618091.85sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 42309045.93sec, total: 42309045.93sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 42309045.93sec, total: 42309045.93sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 42309045.93sec, total: 42309045.93sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 42309045.93sec, total: 42309045.93sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.30ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.30ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 259us, total: 1.51ms
      train.py:343:hfe, cpu: 513us, accelerator: 636us, total: 1.15ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 42309045.92sec, total: 42309045.93sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_109000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 42212228.88sec, total: 42212228.89sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 42212228.88sec, total: 42212228.89sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 42212228.88sec, total: 42212228.88sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.36ms, accelerator: 0us, total: 137.36ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 84424457.77sec, total: 84424457.77sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 42212228.89sec, total: 42212228.89sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 42212228.89sec, total: 42212228.89sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 42212228.89sec, total: 42212228.89sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 42212228.89sec, total: 42212228.89sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.30ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.30ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 259us, total: 1.50ms
      train.py:343:hfe, cpu: 512us, accelerator: 634us, total: 1.15ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 42212228.89sec, total: 42212228.89sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_109250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 42115853.93sec, total: 42115853.93sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 42115853.93sec, total: 42115853.93sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 42115853.93sec, total: 42115853.93sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.37ms, accelerator: 0us, total: 137.37ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 84231707.86sec, total: 84231707.87sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 42115853.94sec, total: 42115853.94sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 42115853.94sec, total: 42115853.94sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 42115853.94sec, total: 42115853.94sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 42115853.94sec, total: 42115853.94sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.31ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.31ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 264us, total: 1.51ms
      train.py:343:hfe, cpu: 515us, accelerator: 643us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 42115853.93sec, total: 42115853.94sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_109500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 42019918.05sec, total: 42019918.05sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 42019918.04sec, total: 42019918.05sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 42019918.04sec, total: 42019918.05sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.35ms, accelerator: 0us, total: 137.35ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 84039836.09sec, total: 84039836.10sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 42019918.05sec, total: 42019918.06sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 42019918.05sec, total: 42019918.05sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 42019918.05sec, total: 42019918.05sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 42019918.05sec, total: 42019918.05sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.31ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.31ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 263us, total: 1.53ms
      train.py:343:hfe, cpu: 514us, accelerator: 641us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 42019918.05sec, total: 42019918.05sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_109750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 41924418.23sec, total: 41924418.23sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 41924418.23sec, total: 41924418.23sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 41924418.23sec, total: 41924418.23sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.29ms, accelerator: 0us, total: 137.29ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 83848836.46sec, total: 83848836.47sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 41924418.24sec, total: 41924418.24sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 41924418.24sec, total: 41924418.24sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 41924418.24sec, total: 41924418.24sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 41924418.24sec, total: 41924418.24sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 262us, total: 1.53ms
      train.py:343:hfe, cpu: 514us, accelerator: 646us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 41924418.23sec, total: 41924418.24sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_110000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 41829351.52sec, total: 41829351.53sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 41829351.52sec, total: 41829351.53sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 41829351.52sec, total: 41829351.53sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.21ms, accelerator: 0us, total: 137.21ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 83658703.05sec, total: 83658703.05sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 41829351.53sec, total: 41829351.54sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 41829351.53sec, total: 41829351.53sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 41829351.53sec, total: 41829351.53sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 41829351.53sec, total: 41829351.53sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 261us, total: 1.52ms
      train.py:343:hfe, cpu: 514us, accelerator: 658us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 41829351.53sec, total: 41829351.53sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.89 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_110250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 41734714.98sec, total: 41734714.98sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 41734714.98sec, total: 41734714.98sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 41734714.98sec, total: 41734714.98sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.25ms, accelerator: 0us, total: 137.25ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 83469429.96sec, total: 83469429.97sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 41734714.99sec, total: 41734714.99sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 41734714.99sec, total: 41734714.99sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 41734714.99sec, total: 41734714.99sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 41734714.99sec, total: 41734714.99sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.33ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.33ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 261us, total: 1.52ms
      train.py:343:hfe, cpu: 511us, accelerator: 656us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 41734714.98sec, total: 41734714.99sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_110500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 41640505.69sec, total: 41640505.70sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 41640505.69sec, total: 41640505.69sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 41640505.69sec, total: 41640505.69sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.30ms, accelerator: 0us, total: 137.30ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 83281011.39sec, total: 83281011.39sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 41640505.70sec, total: 41640505.70sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 41640505.70sec, total: 41640505.70sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 41640505.70sec, total: 41640505.70sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 41640505.70sec, total: 41640505.70sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.34ms, total: 3.51ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.34ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 276us, total: 1.53ms
      train.py:343:hfe, cpu: 511us, accelerator: 655us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 41640505.70sec, total: 41640505.70sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_110750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 41546720.77sec, total: 41546720.77sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 41546720.77sec, total: 41546720.77sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 41546720.77sec, total: 41546720.77sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.43ms, accelerator: 0us, total: 137.43ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 83093441.54sec, total: 83093441.55sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 41546720.78sec, total: 41546720.78sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 41546720.77sec, total: 41546720.78sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 41546720.77sec, total: 41546720.78sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 41546720.77sec, total: 41546720.78sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.34ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.34ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 276us, total: 1.54ms
      train.py:343:hfe, cpu: 510us, accelerator: 653us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 41546720.77sec, total: 41546720.78sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_111000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 41453357.35sec, total: 41453357.36sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 41453357.35sec, total: 41453357.35sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 41453357.35sec, total: 41453357.35sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.36ms, accelerator: 0us, total: 137.36ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 82906714.71sec, total: 82906714.71sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 41453357.36sec, total: 41453357.36sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 41453357.36sec, total: 41453357.36sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 41453357.36sec, total: 41453357.36sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 41453357.36sec, total: 41453357.36sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.34ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.34ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 276us, total: 1.54ms
      train.py:343:hfe, cpu: 510us, accelerator: 653us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 41453357.36sec, total: 41453357.36sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_111250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 41360412.61sec, total: 41360412.61sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.60ms, accelerator: 41360412.60sec, total: 41360412.61sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 41360412.60sec, total: 41360412.61sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.29ms, accelerator: 0us, total: 137.29ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 82720825.21sec, total: 82720825.22sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 41360412.61sec, total: 41360412.62sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 41360412.61sec, total: 41360412.61sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 41360412.61sec, total: 41360412.61sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 41360412.61sec, total: 41360412.61sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.33ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.33ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.29ms, accelerator: 275us, total: 1.56ms
      train.py:343:hfe, cpu: 509us, accelerator: 651us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 41360412.61sec, total: 41360412.61sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_111500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 41267883.72sec, total: 41267883.72sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 41267883.72sec, total: 41267883.72sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 41267883.72sec, total: 41267883.72sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.21ms, accelerator: 0us, total: 137.21ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 82535767.44sec, total: 82535767.44sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 41267883.72sec, total: 41267883.73sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 41267883.72sec, total: 41267883.73sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 41267883.72sec, total: 41267883.73sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 41267883.72sec, total: 41267883.72sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.33ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.33ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 275us, total: 1.56ms
      train.py:343:hfe, cpu: 509us, accelerator: 651us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 41267883.72sec, total: 41267883.73sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_111750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 41175767.91sec, total: 41175767.91sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 41175767.91sec, total: 41175767.91sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 41175767.91sec, total: 41175767.91sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.11ms, accelerator: 0us, total: 137.11ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 82351535.81sec, total: 82351535.82sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 41175767.91sec, total: 41175767.92sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 41175767.91sec, total: 41175767.91sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 41175767.91sec, total: 41175767.91sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 41175767.91sec, total: 41175767.91sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.33ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.33ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 275us, total: 1.56ms
      train.py:343:hfe, cpu: 508us, accelerator: 649us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 41175767.91sec, total: 41175767.91sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2117.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_112000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 41084062.41sec, total: 41084062.41sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 41084062.41sec, total: 41084062.41sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 41084062.41sec, total: 41084062.41sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.02ms, accelerator: 0us, total: 137.02ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 82168124.82sec, total: 82168124.82sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 41084062.42sec, total: 41084062.42sec
  train.py:360:image_losses, cpu: 2.77ms, accelerator: 41084062.41sec, total: 41084062.42sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 41084062.41sec, total: 41084062.42sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 41084062.41sec, total: 41084062.42sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.34ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.34ms, total: 3.53ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 276us, total: 1.56ms
      train.py:343:hfe, cpu: 524us, accelerator: 657us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 41084062.41sec, total: 41084062.42sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_112250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40992764.49sec, total: 40992764.50sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 40992764.49sec, total: 40992764.50sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40992764.49sec, total: 40992764.49sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.06ms, accelerator: 0us, total: 137.06ms
train.py:441:<module> (gradient), cpu: 4.21ms, accelerator: 81985528.99sec, total: 81985528.99sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 40992764.50sec, total: 40992764.50sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 40992764.50sec, total: 40992764.50sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 40992764.50sec, total: 40992764.50sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 40992764.50sec, total: 40992764.50sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.34ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.34ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 275us, total: 1.55ms
      train.py:343:hfe, cpu: 524us, accelerator: 657us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 40992764.50sec, total: 40992764.50sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_112500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40901871.45sec, total: 40901871.45sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.59ms, accelerator: 40901871.44sec, total: 40901871.45sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40901871.45sec, total: 40901871.45sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 137.00ms, accelerator: 0us, total: 137.00ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 81803742.89sec, total: 81803742.90sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 40901871.45sec, total: 40901871.46sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 40901871.45sec, total: 40901871.45sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 40901871.45sec, total: 40901871.45sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 40901871.45sec, total: 40901871.45sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.35ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.35ms, total: 3.53ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 274us, total: 1.55ms
      train.py:343:hfe, cpu: 524us, accelerator: 664us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.16ms, accelerator: 40901871.45sec, total: 40901871.45sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_112750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40811380.58sec, total: 40811380.58sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 40811380.58sec, total: 40811380.58sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40811380.58sec, total: 40811380.58sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.90ms, accelerator: 0us, total: 136.90ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 81622761.16sec, total: 81622761.16sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 40811380.59sec, total: 40811380.59sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 40811380.58sec, total: 40811380.59sec
    train.py:322:loss_fn, cpu: 2.76ms, accelerator: 40811380.58sec, total: 40811380.59sec
      train.py:349:msssim, cpu: 2.71ms, accelerator: 40811380.58sec, total: 40811380.59sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.34ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.34ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 272us, total: 1.56ms
      train.py:343:hfe, cpu: 523us, accelerator: 661us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 40811380.58sec, total: 40811380.59sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_113000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40721289.23sec, total: 40721289.23sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 40721289.23sec, total: 40721289.23sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40721289.23sec, total: 40721289.23sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.81ms, accelerator: 0us, total: 136.81ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 81442578.46sec, total: 81442578.47sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 40721289.24sec, total: 40721289.24sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 40721289.24sec, total: 40721289.24sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 40721289.24sec, total: 40721289.24sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 40721289.24sec, total: 40721289.24sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.34ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.34ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 271us, total: 1.55ms
      train.py:343:hfe, cpu: 520us, accelerator: 660us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 40721289.23sec, total: 40721289.24sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_113250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40631594.76sec, total: 40631594.76sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 40631594.76sec, total: 40631594.76sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40631594.76sec, total: 40631594.76sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.74ms, accelerator: 0us, total: 136.74ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 81263189.53sec, total: 81263189.53sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 40631594.77sec, total: 40631594.77sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 40631594.77sec, total: 40631594.77sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 40631594.77sec, total: 40631594.77sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 40631594.77sec, total: 40631594.77sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.34ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.34ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 271us, total: 1.55ms
      train.py:343:hfe, cpu: 520us, accelerator: 662us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 40631594.77sec, total: 40631594.77sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_113500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40542294.56sec, total: 40542294.56sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.58ms, accelerator: 40542294.55sec, total: 40542294.56sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40542294.55sec, total: 40542294.56sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.75ms, accelerator: 0us, total: 136.75ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 81084589.11sec, total: 81084589.11sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 40542294.56sec, total: 40542294.57sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 40542294.56sec, total: 40542294.56sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 40542294.56sec, total: 40542294.56sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 40542294.56sec, total: 40542294.56sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.34ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.34ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 271us, total: 1.55ms
      train.py:343:hfe, cpu: 520us, accelerator: 661us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 40542294.56sec, total: 40542294.56sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_113750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40453386.01sec, total: 40453386.02sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 40453386.01sec, total: 40453386.02sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40453386.01sec, total: 40453386.01sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.72ms, accelerator: 0us, total: 136.72ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 80906772.03sec, total: 80906772.03sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 40453386.02sec, total: 40453386.02sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 40453386.02sec, total: 40453386.02sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 40453386.02sec, total: 40453386.02sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 40453386.02sec, total: 40453386.02sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.34ms, total: 3.56ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.34ms, total: 3.54ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 271us, total: 1.54ms
      train.py:343:hfe, cpu: 548us, accelerator: 661us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 40453386.02sec, total: 40453386.02sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_114000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40364866.57sec, total: 40364866.57sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 40364866.57sec, total: 40364866.57sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40364866.57sec, total: 40364866.57sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.66ms, accelerator: 0us, total: 136.66ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 80729733.14sec, total: 80729733.14sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 40364866.58sec, total: 40364866.58sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 40364866.57sec, total: 40364866.58sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 40364866.57sec, total: 40364866.58sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 40364866.57sec, total: 40364866.58sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.34ms, total: 3.56ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.34ms, total: 3.54ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 271us, total: 1.54ms
      train.py:343:hfe, cpu: 548us, accelerator: 664us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 40364866.57sec, total: 40364866.58sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_114250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40276733.67sec, total: 40276733.67sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 40276733.67sec, total: 40276733.67sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40276733.67sec, total: 40276733.67sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.59ms, accelerator: 0us, total: 136.59ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 80553467.35sec, total: 80553467.35sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 40276733.68sec, total: 40276733.68sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 40276733.68sec, total: 40276733.68sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 40276733.68sec, total: 40276733.68sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 40276733.68sec, total: 40276733.68sec
  train.py:359:image_losses, cpu: 2.21ms, accelerator: 1.34ms, total: 3.56ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.34ms, total: 3.54ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 271us, total: 1.55ms
      train.py:343:hfe, cpu: 547us, accelerator: 663us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 40276733.68sec, total: 40276733.68sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_114500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40188984.80sec, total: 40188984.80sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 40188984.80sec, total: 40188984.80sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40188984.80sec, total: 40188984.80sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.62ms, accelerator: 0us, total: 136.62ms
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 80377969.60sec, total: 80377969.60sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 40188984.80sec, total: 40188984.81sec
  train.py:360:image_losses, cpu: 2.78ms, accelerator: 40188984.80sec, total: 40188984.80sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 40188984.80sec, total: 40188984.80sec
      train.py:349:msssim, cpu: 2.72ms, accelerator: 40188984.80sec, total: 40188984.80sec
  train.py:359:image_losses, cpu: 2.21ms, accelerator: 1.36ms, total: 3.58ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.36ms, total: 3.56ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 273us, total: 1.55ms
      train.py:343:hfe, cpu: 545us, accelerator: 674us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 40188984.80sec, total: 40188984.80sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_114750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40101617.44sec, total: 40101617.44sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.57ms, accelerator: 40101617.44sec, total: 40101617.44sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40101617.44sec, total: 40101617.44sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.66ms, accelerator: 0us, total: 136.66ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 80203234.88sec, total: 80203234.88sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 40101617.45sec, total: 40101617.45sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 40101617.44sec, total: 40101617.45sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 40101617.44sec, total: 40101617.45sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 40101617.44sec, total: 40101617.45sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.36ms, total: 3.57ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.36ms, total: 3.55ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 273us, total: 1.55ms
      train.py:343:hfe, cpu: 545us, accelerator: 674us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 40101617.44sec, total: 40101617.45sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_115000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 40014629.12sec, total: 40014629.12sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 40014629.11sec, total: 40014629.12sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 40014629.11sec, total: 40014629.12sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.63ms, accelerator: 0us, total: 136.63ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 80029258.23sec, total: 80029258.24sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 40014629.12sec, total: 40014629.13sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 40014629.12sec, total: 40014629.12sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 40014629.12sec, total: 40014629.12sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 40014629.12sec, total: 40014629.12sec
  train.py:359:image_losses, cpu: 2.21ms, accelerator: 1.36ms, total: 3.58ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.36ms, total: 3.56ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 271us, total: 1.55ms
      train.py:343:hfe, cpu: 545us, accelerator: 676us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 40014629.12sec, total: 40014629.12sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_115250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39928017.36sec, total: 39928017.37sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 39928017.36sec, total: 39928017.37sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 39928017.36sec, total: 39928017.37sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.67ms, accelerator: 0us, total: 136.67ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 79856034.73sec, total: 79856034.73sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 39928017.37sec, total: 39928017.38sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 39928017.37sec, total: 39928017.37sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 39928017.37sec, total: 39928017.37sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 39928017.37sec, total: 39928017.37sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.36ms, total: 3.57ms
    train.py:322:loss_fn, cpu: 2.18ms, accelerator: 1.36ms, total: 3.55ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 271us, total: 1.55ms
      train.py:343:hfe, cpu: 545us, accelerator: 674us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 39928017.37sec, total: 39928017.37sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_115500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39841779.75sec, total: 39841779.75sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 39841779.74sec, total: 39841779.75sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 39841779.74sec, total: 39841779.75sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.61ms, accelerator: 0us, total: 136.61ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 79683559.49sec, total: 79683559.50sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 39841779.75sec, total: 39841779.76sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 39841779.75sec, total: 39841779.75sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 39841779.75sec, total: 39841779.75sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 39841779.75sec, total: 39841779.75sec
  train.py:359:image_losses, cpu: 2.21ms, accelerator: 1.38ms, total: 3.60ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.38ms, total: 3.58ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 269us, total: 1.55ms
      train.py:343:hfe, cpu: 544us, accelerator: 694us, total: 1.24ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 39841779.75sec, total: 39841779.75sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_115750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39755913.84sec, total: 39755913.84sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 39755913.84sec, total: 39755913.84sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 39755913.84sec, total: 39755913.84sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.64ms, accelerator: 0us, total: 136.64ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 79511827.68sec, total: 79511827.69sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 39755913.85sec, total: 39755913.85sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 39755913.84sec, total: 39755913.85sec
    train.py:322:loss_fn, cpu: 2.78ms, accelerator: 39755913.84sec, total: 39755913.85sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 39755913.84sec, total: 39755913.85sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.37ms, total: 3.59ms
    train.py:322:loss_fn, cpu: 2.19ms, accelerator: 1.37ms, total: 3.57ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 268us, total: 1.55ms
      train.py:343:hfe, cpu: 542us, accelerator: 692us, total: 1.24ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 39755913.84sec, total: 39755913.85sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.93 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_116000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39670417.25sec, total: 39670417.25sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 39670417.25sec, total: 39670417.25sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 39670417.25sec, total: 39670417.25sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.57ms, accelerator: 0us, total: 136.57ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 79340834.50sec, total: 79340834.51sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 39670417.26sec, total: 39670417.26sec
  train.py:360:image_losses, cpu: 2.79ms, accelerator: 39670417.26sec, total: 39670417.26sec
    train.py:322:loss_fn, cpu: 2.77ms, accelerator: 39670417.26sec, total: 39670417.26sec
      train.py:349:msssim, cpu: 2.73ms, accelerator: 39670417.26sec, total: 39670417.26sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.37ms, total: 3.58ms
    train.py:322:loss_fn, cpu: 2.18ms, accelerator: 1.37ms, total: 3.57ms
      train.py:342:hfe, cpu: 1.28ms, accelerator: 268us, total: 1.55ms
      train.py:343:hfe, cpu: 542us, accelerator: 691us, total: 1.24ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 39670417.25sec, total: 39670417.26sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_116250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39585287.60sec, total: 39585287.60sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 39585287.60sec, total: 39585287.60sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 39585287.60sec, total: 39585287.60sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.79ms, accelerator: 0us, total: 136.79ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 79170575.20sec, total: 79170575.21sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 39585287.61sec, total: 39585287.61sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 39585287.60sec, total: 39585287.61sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 39585287.60sec, total: 39585287.61sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 39585287.60sec, total: 39585287.61sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.37ms, total: 3.58ms
    train.py:322:loss_fn, cpu: 2.18ms, accelerator: 1.37ms, total: 3.56ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 267us, total: 1.55ms
      train.py:343:hfe, cpu: 541us, accelerator: 691us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 39585287.60sec, total: 39585287.61sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_116500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39500522.53sec, total: 39500522.53sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.56ms, accelerator: 39500522.53sec, total: 39500522.53sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 39500522.53sec, total: 39500522.53sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.78ms, accelerator: 0us, total: 136.78ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 79001045.06sec, total: 79001045.07sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 39500522.54sec, total: 39500522.54sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 39500522.54sec, total: 39500522.54sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 39500522.54sec, total: 39500522.54sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 39500522.54sec, total: 39500522.54sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.37ms, total: 3.57ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.37ms, total: 3.56ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 267us, total: 1.54ms
      train.py:343:hfe, cpu: 539us, accelerator: 690us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 39500522.53sec, total: 39500522.54sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_116750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39416119.71sec, total: 39416119.71sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.55ms, accelerator: 39416119.70sec, total: 39416119.71sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 39416119.70sec, total: 39416119.71sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.81ms, accelerator: 0us, total: 136.81ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 78832239.41sec, total: 78832239.42sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 39416119.71sec, total: 39416119.72sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 39416119.71sec, total: 39416119.71sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 39416119.71sec, total: 39416119.71sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 39416119.71sec, total: 39416119.71sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.36ms, total: 3.57ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.36ms, total: 3.55ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 267us, total: 1.54ms
      train.py:343:hfe, cpu: 538us, accelerator: 687us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 39416119.71sec, total: 39416119.71sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_117000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39332076.81sec, total: 39332076.81sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.55ms, accelerator: 39332076.81sec, total: 39332076.81sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 39332076.81sec, total: 39332076.81sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.79ms, accelerator: 0us, total: 136.79ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 78664153.61sec, total: 78664153.62sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 39332076.81sec, total: 39332076.82sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 39332076.81sec, total: 39332076.81sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 39332076.81sec, total: 39332076.81sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 39332076.81sec, total: 39332076.81sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.36ms, total: 3.56ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.36ms, total: 3.54ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 267us, total: 1.54ms
      train.py:343:hfe, cpu: 538us, accelerator: 686us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 39332076.81sec, total: 39332076.81sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_117250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39248391.54sec, total: 39248391.54sec (25.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.55ms, accelerator: 39248391.54sec, total: 39248391.54sec (25.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 39248391.54sec, total: 39248391.54sec (25.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: autoencoded, cpu: 136.69ms, accelerator: 0us, total: 136.69ms
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 78496783.07sec, total: 78496783.08sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 39248391.54sec, total: 39248391.55sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 39248391.54sec, total: 39248391.54sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 39248391.54sec, total: 39248391.54sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 39248391.54sec, total: 39248391.54sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.36ms, total: 3.56ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.36ms, total: 3.54ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 266us, total: 1.53ms
      train.py:343:hfe, cpu: 537us, accelerator: 685us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 39248391.54sec, total: 39248391.54sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2117.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_117500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39165061.62sec, total: 39165061.62sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.55ms, accelerator: 39165061.62sec, total: 39165061.62sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 39165061.62sec, total: 39165061.62sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 78330123.24sec, total: 78330123.24sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 39165061.62sec, total: 39165061.63sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 39165061.62sec, total: 39165061.62sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 39165061.62sec, total: 39165061.62sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 39165061.62sec, total: 39165061.62sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.36ms, total: 3.55ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.36ms, total: 3.53ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 268us, total: 1.54ms
      train.py:343:hfe, cpu: 536us, accelerator: 683us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 39165061.62sec, total: 39165061.63sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.50
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_117750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 39082084.79sec, total: 39082084.79sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.54ms, accelerator: 39082084.79sec, total: 39082084.79sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 39082084.79sec, total: 39082084.79sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 78164169.59sec, total: 78164169.59sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 39082084.80sec, total: 39082084.80sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 39082084.80sec, total: 39082084.80sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 39082084.80sec, total: 39082084.80sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 39082084.80sec, total: 39082084.80sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.36ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.36ms, total: 3.53ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 268us, total: 1.53ms
      train.py:343:hfe, cpu: 534us, accelerator: 681us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 39082084.80sec, total: 39082084.80sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.43 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_118000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38999458.82sec, total: 38999458.82sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.54ms, accelerator: 38999458.82sec, total: 38999458.82sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38999458.82sec, total: 38999458.82sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 77998917.64sec, total: 77998917.65sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 38999458.83sec, total: 38999458.83sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38999458.82sec, total: 38999458.83sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38999458.82sec, total: 38999458.83sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38999458.82sec, total: 38999458.83sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.35ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.35ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 268us, total: 1.53ms
      train.py:343:hfe, cpu: 534us, accelerator: 681us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 38999458.82sec, total: 38999458.83sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_118250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38917181.48sec, total: 38917181.48sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.54ms, accelerator: 38917181.48sec, total: 38917181.48sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38917181.48sec, total: 38917181.48sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 77834362.96sec, total: 77834362.97sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 38917181.49sec, total: 38917181.49sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38917181.49sec, total: 38917181.49sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38917181.49sec, total: 38917181.49sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38917181.49sec, total: 38917181.49sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.36ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.36ms, total: 3.53ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 268us, total: 1.53ms
      train.py:343:hfe, cpu: 535us, accelerator: 682us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 38917181.48sec, total: 38917181.49sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_118500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38835250.57sec, total: 38835250.58sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.54ms, accelerator: 38835250.57sec, total: 38835250.57sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38835250.57sec, total: 38835250.57sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 77670501.15sec, total: 77670501.15sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 38835250.58sec, total: 38835250.58sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38835250.58sec, total: 38835250.58sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38835250.58sec, total: 38835250.58sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38835250.58sec, total: 38835250.58sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.36ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.36ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 268us, total: 1.53ms
      train.py:343:hfe, cpu: 534us, accelerator: 682us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 38835250.58sec, total: 38835250.58sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.73 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_118750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38753663.91sec, total: 38753663.91sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.54ms, accelerator: 38753663.91sec, total: 38753663.91sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38753663.91sec, total: 38753663.91sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 77507327.82sec, total: 77507327.83sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 38753663.92sec, total: 38753663.92sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38753663.92sec, total: 38753663.92sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38753663.92sec, total: 38753663.92sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38753663.92sec, total: 38753663.92sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.36ms, total: 3.55ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.36ms, total: 3.53ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 268us, total: 1.54ms
      train.py:343:hfe, cpu: 534us, accelerator: 680us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 38753663.91sec, total: 38753663.92sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_119000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38672419.33sec, total: 38672419.34sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.54ms, accelerator: 38672419.33sec, total: 38672419.34sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38672419.33sec, total: 38672419.33sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 77344838.67sec, total: 77344838.67sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 38672419.34sec, total: 38672419.35sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38672419.34sec, total: 38672419.34sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38672419.34sec, total: 38672419.34sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38672419.34sec, total: 38672419.34sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.35ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.35ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 268us, total: 1.54ms
      train.py:343:hfe, cpu: 532us, accelerator: 679us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 38672419.34sec, total: 38672419.34sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_119250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38591514.69sec, total: 38591514.69sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.54ms, accelerator: 38591514.69sec, total: 38591514.69sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38591514.69sec, total: 38591514.69sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 77183029.38sec, total: 77183029.39sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 38591514.70sec, total: 38591514.70sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38591514.69sec, total: 38591514.70sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38591514.69sec, total: 38591514.70sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38591514.69sec, total: 38591514.70sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.35ms, total: 3.56ms
    train.py:322:loss_fn, cpu: 2.18ms, accelerator: 1.35ms, total: 3.54ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 268us, total: 1.55ms
      train.py:343:hfe, cpu: 547us, accelerator: 678us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 38591514.69sec, total: 38591514.70sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_119500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38510947.86sec, total: 38510947.86sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.54ms, accelerator: 38510947.85sec, total: 38510947.86sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38510947.85sec, total: 38510947.86sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 77021895.71sec, total: 77021895.71sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 38510947.86sec, total: 38510947.87sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38510947.86sec, total: 38510947.86sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38510947.86sec, total: 38510947.86sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38510947.86sec, total: 38510947.86sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.35ms, total: 3.56ms
    train.py:322:loss_fn, cpu: 2.18ms, accelerator: 1.35ms, total: 3.54ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 265us, total: 1.54ms
      train.py:343:hfe, cpu: 549us, accelerator: 677us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 38510947.86sec, total: 38510947.86sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_119750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38430716.71sec, total: 38430716.72sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 38430716.71sec, total: 38430716.71sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38430716.71sec, total: 38430716.71sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 76861433.43sec, total: 76861433.43sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 38430716.72sec, total: 38430716.72sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38430716.72sec, total: 38430716.72sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38430716.72sec, total: 38430716.72sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38430716.72sec, total: 38430716.72sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.34ms, total: 3.56ms
    train.py:322:loss_fn, cpu: 2.18ms, accelerator: 1.34ms, total: 3.54ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 265us, total: 1.54ms
      train.py:343:hfe, cpu: 548us, accelerator: 672us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 38430716.72sec, total: 38430716.72sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_120000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38350819.17sec, total: 38350819.18sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 38350819.17sec, total: 38350819.17sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38350819.17sec, total: 38350819.17sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 76701638.35sec, total: 76701638.35sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 38350819.18sec, total: 38350819.18sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38350819.18sec, total: 38350819.18sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38350819.18sec, total: 38350819.18sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38350819.18sec, total: 38350819.18sec
  train.py:359:image_losses, cpu: 2.20ms, accelerator: 1.34ms, total: 3.55ms
    train.py:322:loss_fn, cpu: 2.18ms, accelerator: 1.34ms, total: 3.53ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 265us, total: 1.54ms
      train.py:343:hfe, cpu: 546us, accelerator: 672us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 38350819.18sec, total: 38350819.18sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_120250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38271253.16sec, total: 38271253.16sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 38271253.16sec, total: 38271253.16sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 38271253.16sec, total: 38271253.16sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 76542506.32sec, total: 76542506.32sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 38271253.16sec, total: 38271253.17sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38271253.16sec, total: 38271253.16sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38271253.16sec, total: 38271253.16sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38271253.16sec, total: 38271253.16sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.34ms, total: 3.55ms
    train.py:322:loss_fn, cpu: 2.18ms, accelerator: 1.34ms, total: 3.53ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 265us, total: 1.54ms
      train.py:343:hfe, cpu: 546us, accelerator: 671us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 38271253.16sec, total: 38271253.16sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_120500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38192016.61sec, total: 38192016.61sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 38192016.61sec, total: 38192016.61sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 38192016.61sec, total: 38192016.61sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 76384033.22sec, total: 76384033.22sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 38192016.61sec, total: 38192016.62sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 38192016.61sec, total: 38192016.62sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 38192016.61sec, total: 38192016.62sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 38192016.61sec, total: 38192016.62sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.34ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.34ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 264us, total: 1.54ms
      train.py:343:hfe, cpu: 547us, accelerator: 671us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 38192016.61sec, total: 38192016.62sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_120750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38113107.48sec, total: 38113107.49sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 38113107.48sec, total: 38113107.49sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38113107.48sec, total: 38113107.49sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 76226214.97sec, total: 76226214.97sec
train.py:442:<module>, cpu: 5.60ms, accelerator: 38113107.49sec, total: 38113107.50sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 38113107.49sec, total: 38113107.49sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 38113107.49sec, total: 38113107.49sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 38113107.49sec, total: 38113107.49sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.34ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.34ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 264us, total: 1.53ms
      train.py:343:hfe, cpu: 546us, accelerator: 669us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 38113107.49sec, total: 38113107.49sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_121000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 38034523.76sec, total: 38034523.76sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 38034523.76sec, total: 38034523.76sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 38034523.76sec, total: 38034523.76sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 76069047.51sec, total: 76069047.52sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 38034523.76sec, total: 38034523.77sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 38034523.76sec, total: 38034523.76sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 38034523.76sec, total: 38034523.76sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 38034523.76sec, total: 38034523.76sec
  train.py:359:image_losses, cpu: 2.19ms, accelerator: 1.34ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.34ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 264us, total: 1.53ms
      train.py:343:hfe, cpu: 545us, accelerator: 669us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 38034523.76sec, total: 38034523.76sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_121250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 37956263.42sec, total: 37956263.42sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 37956263.42sec, total: 37956263.42sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37956263.42sec, total: 37956263.42sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 75912526.84sec, total: 75912526.85sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 37956263.43sec, total: 37956263.43sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 37956263.42sec, total: 37956263.43sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 37956263.42sec, total: 37956263.43sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 37956263.42sec, total: 37956263.43sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.33ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.17ms, accelerator: 1.33ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 264us, total: 1.53ms
      train.py:343:hfe, cpu: 543us, accelerator: 669us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 37956263.42sec, total: 37956263.43sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_121500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 37878324.48sec, total: 37878324.48sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 37878324.48sec, total: 37878324.48sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37878324.48sec, total: 37878324.48sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 75756648.96sec, total: 75756648.97sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 37878324.49sec, total: 37878324.49sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 37878324.48sec, total: 37878324.49sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 37878324.48sec, total: 37878324.49sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 37878324.48sec, total: 37878324.49sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.34ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.34ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 264us, total: 1.53ms
      train.py:343:hfe, cpu: 543us, accelerator: 671us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 37878324.48sec, total: 37878324.49sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_121750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 37800704.96sec, total: 37800704.97sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 37800704.96sec, total: 37800704.97sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 37800704.96sec, total: 37800704.96sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 75601409.93sec, total: 75601409.93sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 37800704.97sec, total: 37800704.97sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 37800704.97sec, total: 37800704.97sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 37800704.97sec, total: 37800704.97sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 37800704.97sec, total: 37800704.97sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.34ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.34ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 264us, total: 1.53ms
      train.py:343:hfe, cpu: 543us, accelerator: 671us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 37800704.97sec, total: 37800704.97sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_122000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 37723402.91sec, total: 37723402.91sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 37723402.91sec, total: 37723402.91sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37723402.91sec, total: 37723402.91sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 75446805.82sec, total: 75446805.82sec
train.py:442:<module>, cpu: 5.59ms, accelerator: 37723402.91sec, total: 37723402.92sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 37723402.91sec, total: 37723402.92sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 37723402.91sec, total: 37723402.92sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 37723402.91sec, total: 37723402.91sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.33ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.33ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 263us, total: 1.53ms
      train.py:343:hfe, cpu: 543us, accelerator: 667us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 37723402.91sec, total: 37723402.92sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_122250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 37646416.37sec, total: 37646416.37sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 37646416.37sec, total: 37646416.37sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37646416.37sec, total: 37646416.37sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 75292832.74sec, total: 75292832.75sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 37646416.38sec, total: 37646416.38sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 37646416.38sec, total: 37646416.38sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 37646416.38sec, total: 37646416.38sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 37646416.38sec, total: 37646416.38sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.33ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.33ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 263us, total: 1.53ms
      train.py:343:hfe, cpu: 541us, accelerator: 667us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 37646416.37sec, total: 37646416.38sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_122500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 37569743.43sec, total: 37569743.43sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 37569743.43sec, total: 37569743.43sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37569743.43sec, total: 37569743.43sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 75139486.85sec, total: 75139486.86sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 37569743.43sec, total: 37569743.44sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 37569743.43sec, total: 37569743.43sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 37569743.43sec, total: 37569743.43sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 37569743.43sec, total: 37569743.43sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.34ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.34ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 263us, total: 1.53ms
      train.py:343:hfe, cpu: 540us, accelerator: 670us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 37569743.43sec, total: 37569743.43sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_122750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 37493382.16sec, total: 37493382.16sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 37493382.16sec, total: 37493382.16sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37493382.16sec, total: 37493382.16sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 74986764.32sec, total: 74986764.32sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 37493382.16sec, total: 37493382.17sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 37493382.16sec, total: 37493382.17sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 37493382.16sec, total: 37493382.17sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 37493382.16sec, total: 37493382.17sec
  train.py:359:image_losses, cpu: 2.18ms, accelerator: 1.35ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.35ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 262us, total: 1.53ms
      train.py:343:hfe, cpu: 540us, accelerator: 679us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 37493382.16sec, total: 37493382.17sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_123000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 37417330.67sec, total: 37417330.68sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 37417330.67sec, total: 37417330.68sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37417330.67sec, total: 37417330.68sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 74834661.35sec, total: 74834661.35sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 37417330.68sec, total: 37417330.69sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 37417330.68sec, total: 37417330.68sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 37417330.68sec, total: 37417330.68sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 37417330.68sec, total: 37417330.68sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.35ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.16ms, accelerator: 1.35ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 262us, total: 1.53ms
      train.py:343:hfe, cpu: 540us, accelerator: 675us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 37417330.68sec, total: 37417330.68sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_123250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 37341587.09sec, total: 37341587.09sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 37341587.09sec, total: 37341587.09sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37341587.09sec, total: 37341587.09sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 74683174.18sec, total: 74683174.18sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 37341587.10sec, total: 37341587.10sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 37341587.09sec, total: 37341587.10sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 37341587.09sec, total: 37341587.10sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 37341587.09sec, total: 37341587.10sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.35ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.35ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 262us, total: 1.52ms
      train.py:343:hfe, cpu: 539us, accelerator: 674us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 37341587.09sec, total: 37341587.10sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_123500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 37266149.54sec, total: 37266149.54sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.51ms, accelerator: 37266149.54sec, total: 37266149.54sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37266149.54sec, total: 37266149.54sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 74532299.08sec, total: 74532299.08sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 37266149.55sec, total: 37266149.55sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 37266149.54sec, total: 37266149.55sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 37266149.54sec, total: 37266149.55sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 37266149.54sec, total: 37266149.55sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.35ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.35ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 262us, total: 1.52ms
      train.py:343:hfe, cpu: 539us, accelerator: 676us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 37266149.54sec, total: 37266149.55sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_123750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 37191016.17sec, total: 37191016.18sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 37191016.17sec, total: 37191016.18sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37191016.17sec, total: 37191016.18sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 74382032.35sec, total: 74382032.35sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 37191016.18sec, total: 37191016.19sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 37191016.18sec, total: 37191016.18sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 37191016.18sec, total: 37191016.18sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 37191016.18sec, total: 37191016.18sec
  train.py:359:image_losses, cpu: 2.17ms, accelerator: 1.35ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.15ms, accelerator: 1.35ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 262us, total: 1.52ms
      train.py:343:hfe, cpu: 539us, accelerator: 676us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 37191016.18sec, total: 37191016.18sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_124000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 37116185.16sec, total: 37116185.16sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 37116185.15sec, total: 37116185.16sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37116185.15sec, total: 37116185.16sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 74232370.31sec, total: 74232370.32sec
train.py:442:<module>, cpu: 5.58ms, accelerator: 37116185.16sec, total: 37116185.17sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 37116185.16sec, total: 37116185.16sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 37116185.16sec, total: 37116185.16sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 37116185.16sec, total: 37116185.16sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.35ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.35ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 261us, total: 1.52ms
      train.py:343:hfe, cpu: 537us, accelerator: 675us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 37116185.16sec, total: 37116185.16sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_124250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 37041654.66sec, total: 37041654.67sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 37041654.66sec, total: 37041654.66sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 37041654.66sec, total: 37041654.66sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 74083309.33sec, total: 74083309.33sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 37041654.67sec, total: 37041654.67sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 37041654.67sec, total: 37041654.67sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 37041654.67sec, total: 37041654.67sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 37041654.67sec, total: 37041654.67sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.34ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.34ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 260us, total: 1.52ms
      train.py:343:hfe, cpu: 536us, accelerator: 673us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 37041654.67sec, total: 37041654.67sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_124500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36967422.89sec, total: 36967422.89sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 36967422.89sec, total: 36967422.89sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 36967422.89sec, total: 36967422.89sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 73934845.78sec, total: 73934845.79sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 36967422.90sec, total: 36967422.90sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 36967422.89sec, total: 36967422.90sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36967422.89sec, total: 36967422.90sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36967422.89sec, total: 36967422.90sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.34ms, total: 3.51ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.34ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 260us, total: 1.51ms
      train.py:343:hfe, cpu: 536us, accelerator: 673us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 36967422.89sec, total: 36967422.90sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_124750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36893488.05sec, total: 36893488.05sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 36893488.04sec, total: 36893488.05sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 36893488.04sec, total: 36893488.05sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 73786976.09sec, total: 73786976.09sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 36893488.05sec, total: 36893488.06sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36893488.05sec, total: 36893488.05sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36893488.05sec, total: 36893488.05sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36893488.05sec, total: 36893488.05sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.34ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.34ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 260us, total: 1.51ms
      train.py:343:hfe, cpu: 536us, accelerator: 671us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 36893488.05sec, total: 36893488.05sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_125000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36819848.35sec, total: 36819848.35sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.51ms, accelerator: 36819848.35sec, total: 36819848.35sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36819848.35sec, total: 36819848.35sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 73639696.70sec, total: 73639696.70sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 36819848.35sec, total: 36819848.36sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36819848.35sec, total: 36819848.35sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36819848.35sec, total: 36819848.35sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36819848.35sec, total: 36819848.35sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.35ms, total: 3.51ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.35ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 259us, total: 1.51ms
      train.py:343:hfe, cpu: 536us, accelerator: 672us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 36819848.35sec, total: 36819848.35sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_125250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36746502.04sec, total: 36746502.04sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 36746502.04sec, total: 36746502.04sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36746502.04sec, total: 36746502.04sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 73493004.07sec, total: 73493004.08sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 36746502.04sec, total: 36746502.05sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36746502.04sec, total: 36746502.04sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36746502.04sec, total: 36746502.04sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36746502.04sec, total: 36746502.04sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.34ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.34ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 258us, total: 1.50ms
      train.py:343:hfe, cpu: 536us, accelerator: 670us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 36746502.04sec, total: 36746502.04sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_125500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36673447.36sec, total: 36673447.36sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 36673447.36sec, total: 36673447.36sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36673447.36sec, total: 36673447.36sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 73346894.72sec, total: 73346894.73sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 36673447.37sec, total: 36673447.37sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36673447.36sec, total: 36673447.37sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36673447.36sec, total: 36673447.37sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36673447.36sec, total: 36673447.37sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.34ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 257us, total: 1.50ms
      train.py:343:hfe, cpu: 535us, accelerator: 669us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 36673447.36sec, total: 36673447.37sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_125750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36600682.58sec, total: 36600682.59sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.53ms, accelerator: 36600682.58sec, total: 36600682.59sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36600682.58sec, total: 36600682.59sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 73201365.17sec, total: 73201365.17sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 36600682.59sec, total: 36600682.60sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36600682.59sec, total: 36600682.59sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36600682.59sec, total: 36600682.59sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36600682.59sec, total: 36600682.59sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.34ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.34ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 257us, total: 1.50ms
      train.py:343:hfe, cpu: 535us, accelerator: 667us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 36600682.59sec, total: 36600682.59sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_126000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36528205.99sec, total: 36528205.99sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 36528205.98sec, total: 36528205.99sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36528205.98sec, total: 36528205.99sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 73056411.97sec, total: 73056411.97sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 36528205.99sec, total: 36528206.00sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36528205.99sec, total: 36528205.99sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36528205.99sec, total: 36528205.99sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36528205.99sec, total: 36528205.99sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.34ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 257us, total: 1.50ms
      train.py:343:hfe, cpu: 532us, accelerator: 666us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 36528205.99sec, total: 36528205.99sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_126250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36456015.86sec, total: 36456015.86sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 36456015.85sec, total: 36456015.86sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36456015.85sec, total: 36456015.86sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 72912031.71sec, total: 72912031.71sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 36456015.86sec, total: 36456015.87sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36456015.86sec, total: 36456015.86sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36456015.86sec, total: 36456015.86sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36456015.86sec, total: 36456015.86sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 256us, total: 1.50ms
      train.py:343:hfe, cpu: 531us, accelerator: 665us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 36456015.86sec, total: 36456015.86sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_126500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36384110.50sec, total: 36384110.50sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 36384110.50sec, total: 36384110.50sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36384110.50sec, total: 36384110.50sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 72768221.00sec, total: 72768221.00sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 36384110.50sec, total: 36384110.51sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36384110.50sec, total: 36384110.50sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36384110.50sec, total: 36384110.50sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36384110.50sec, total: 36384110.50sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 255us, total: 1.50ms
      train.py:343:hfe, cpu: 530us, accelerator: 663us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 36384110.50sec, total: 36384110.50sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_126750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36312488.23sec, total: 36312488.23sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 36312488.23sec, total: 36312488.23sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36312488.23sec, total: 36312488.23sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 72624976.47sec, total: 72624976.47sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 36312488.24sec, total: 36312488.24sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36312488.24sec, total: 36312488.24sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36312488.24sec, total: 36312488.24sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36312488.24sec, total: 36312488.24sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.34ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.50ms
      train.py:343:hfe, cpu: 530us, accelerator: 673us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 36312488.24sec, total: 36312488.24sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_127000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36241147.39sec, total: 36241147.39sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 36241147.39sec, total: 36241147.39sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36241147.39sec, total: 36241147.39sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 72482294.78sec, total: 72482294.79sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 36241147.40sec, total: 36241147.40sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36241147.40sec, total: 36241147.40sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36241147.40sec, total: 36241147.40sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36241147.40sec, total: 36241147.40sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.34ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.50ms
      train.py:343:hfe, cpu: 530us, accelerator: 670us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 36241147.39sec, total: 36241147.40sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_127250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36170086.32sec, total: 36170086.32sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 36170086.32sec, total: 36170086.32sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36170086.32sec, total: 36170086.32sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 72340172.64sec, total: 72340172.64sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 36170086.32sec, total: 36170086.33sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36170086.32sec, total: 36170086.32sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36170086.32sec, total: 36170086.32sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36170086.32sec, total: 36170086.32sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 531us, accelerator: 669us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 36170086.32sec, total: 36170086.32sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_127500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36099303.37sec, total: 36099303.37sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 36099303.37sec, total: 36099303.37sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36099303.37sec, total: 36099303.37sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 72198606.74sec, total: 72198606.75sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 36099303.38sec, total: 36099303.38sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 36099303.37sec, total: 36099303.38sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 36099303.37sec, total: 36099303.38sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 36099303.37sec, total: 36099303.38sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 530us, accelerator: 667us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 36099303.37sec, total: 36099303.38sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_127750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 36028796.92sec, total: 36028796.92sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 36028796.92sec, total: 36028796.92sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 36028796.92sec, total: 36028796.92sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 72057593.84sec, total: 72057593.84sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 36028796.92sec, total: 36028796.93sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 36028796.92sec, total: 36028796.93sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 36028796.92sec, total: 36028796.93sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 36028796.92sec, total: 36028796.93sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 253us, total: 1.49ms
      train.py:343:hfe, cpu: 530us, accelerator: 669us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 36028796.92sec, total: 36028796.93sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_128000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35958565.35sec, total: 35958565.35sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.51ms, accelerator: 35958565.34sec, total: 35958565.35sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35958565.34sec, total: 35958565.35sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 71917130.69sec, total: 71917130.70sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 35958565.35sec, total: 35958565.36sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 35958565.35sec, total: 35958565.35sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 35958565.35sec, total: 35958565.35sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 35958565.35sec, total: 35958565.35sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 252us, total: 1.49ms
      train.py:343:hfe, cpu: 528us, accelerator: 667us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 35958565.35sec, total: 35958565.35sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_128250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35888607.05sec, total: 35888607.05sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.51ms, accelerator: 35888607.05sec, total: 35888607.05sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35888607.05sec, total: 35888607.05sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 71777214.09sec, total: 71777214.10sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 35888607.05sec, total: 35888607.06sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 35888607.05sec, total: 35888607.05sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 35888607.05sec, total: 35888607.05sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 35888607.05sec, total: 35888607.05sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.35ms, total: 3.51ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.35ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 259us, total: 1.52ms
      train.py:343:hfe, cpu: 528us, accelerator: 669us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 35888607.05sec, total: 35888607.05sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_128500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35818920.43sec, total: 35818920.43sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.51ms, accelerator: 35818920.43sec, total: 35818920.43sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35818920.43sec, total: 35818920.43sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 71637840.86sec, total: 71637840.87sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 35818920.44sec, total: 35818920.44sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 35818920.44sec, total: 35818920.44sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35818920.44sec, total: 35818920.44sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 35818920.44sec, total: 35818920.44sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.34ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.34ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 259us, total: 1.52ms
      train.py:343:hfe, cpu: 539us, accelerator: 666us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 35818920.43sec, total: 35818920.44sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2123.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_128750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35749503.92sec, total: 35749503.92sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.51ms, accelerator: 35749503.92sec, total: 35749503.92sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35749503.92sec, total: 35749503.92sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 71499007.84sec, total: 71499007.84sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 35749503.92sec, total: 35749503.93sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 35749503.92sec, total: 35749503.93sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35749503.92sec, total: 35749503.93sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 35749503.92sec, total: 35749503.93sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.34ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.34ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 259us, total: 1.52ms
      train.py:343:hfe, cpu: 539us, accelerator: 665us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 35749503.92sec, total: 35749503.93sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_129000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35680355.94sec, total: 35680355.94sec (20.00%)
top 2 operation type: Conv2DBackpropInput, cpu: 2.51ms, accelerator: 35680355.94sec, total: 35680355.94sec (20.00%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35680355.94sec, total: 35680355.94sec (20.00%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: cmap, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 71360711.89sec, total: 71360711.89sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 35680355.95sec, total: 35680355.95sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 35680355.95sec, total: 35680355.95sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35680355.95sec, total: 35680355.95sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 35680355.95sec, total: 35680355.95sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.34ms, total: 3.51ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.34ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 259us, total: 1.51ms
      train.py:343:hfe, cpu: 539us, accelerator: 665us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 35680355.95sec, total: 35680355.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_129250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 71222949.89sec, total: 71222949.89sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35611474.95sec, total: 35611474.95sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35611474.95sec, total: 35611474.95sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 71222949.89sec, total: 71222949.90sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 35611474.95sec, total: 35611474.96sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 35611474.95sec, total: 35611474.95sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35611474.95sec, total: 35611474.95sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 35611474.95sec, total: 35611474.95sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.36ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.36ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 262us, total: 1.51ms
      train.py:343:hfe, cpu: 538us, accelerator: 672us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 35611474.95sec, total: 35611474.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.50
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_129500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 71085718.77sec, total: 71085718.77sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35542859.39sec, total: 35542859.39sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35542859.39sec, total: 35542859.39sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 71085718.78sec, total: 71085718.78sec
train.py:442:<module>, cpu: 5.57ms, accelerator: 35542859.39sec, total: 35542859.40sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 35542859.39sec, total: 35542859.39sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35542859.39sec, total: 35542859.39sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 35542859.39sec, total: 35542859.39sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.37ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.37ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 262us, total: 1.53ms
      train.py:343:hfe, cpu: 537us, accelerator: 682us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 35542859.39sec, total: 35542859.39sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.11 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_129750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 70949015.46sec, total: 70949015.47sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35474507.74sec, total: 35474507.74sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35474507.73sec, total: 35474507.74sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 70949015.47sec, total: 70949015.47sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 35474507.74sec, total: 35474507.75sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 35474507.74sec, total: 35474507.74sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35474507.74sec, total: 35474507.74sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 35474507.74sec, total: 35474507.74sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.37ms, total: 3.54ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.37ms, total: 3.52ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 261us, total: 1.53ms
      train.py:343:hfe, cpu: 536us, accelerator: 682us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 35474507.74sec, total: 35474507.74sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_130000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.51ms, accelerator: 70812836.93sec, total: 70812836.93sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35406418.47sec, total: 35406418.47sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35406418.47sec, total: 35406418.47sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 70812836.94sec, total: 70812836.94sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 35406418.47sec, total: 35406418.48sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 35406418.47sec, total: 35406418.48sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35406418.47sec, total: 35406418.48sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 35406418.47sec, total: 35406418.48sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.36ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.36ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 260us, total: 1.52ms
      train.py:343:hfe, cpu: 535us, accelerator: 681us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 35406418.47sec, total: 35406418.48sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_130250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 70677180.16sec, total: 70677180.16sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35338590.08sec, total: 35338590.08sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35338590.08sec, total: 35338590.08sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 70677180.16sec, total: 70677180.17sec
train.py:442:<module>, cpu: 5.56ms, accelerator: 35338590.09sec, total: 35338590.09sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 35338590.08sec, total: 35338590.09sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35338590.08sec, total: 35338590.09sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 35338590.08sec, total: 35338590.09sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.36ms, total: 3.53ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.36ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 260us, total: 1.52ms
      train.py:343:hfe, cpu: 535us, accelerator: 679us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 35338590.08sec, total: 35338590.09sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_130500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.51ms, accelerator: 70542042.14sec, total: 70542042.15sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.23ms, accelerator: 35271021.08sec, total: 35271021.08sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35271021.07sec, total: 35271021.08sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 70542042.15sec, total: 70542042.15sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 35271021.08sec, total: 35271021.09sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 35271021.08sec, total: 35271021.08sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35271021.08sec, total: 35271021.08sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 35271021.08sec, total: 35271021.08sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.36ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.36ms, total: 3.51ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 260us, total: 1.52ms
      train.py:343:hfe, cpu: 534us, accelerator: 677us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 35271021.08sec, total: 35271021.08sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_130750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 70407419.93sec, total: 70407419.93sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 35203709.97sec, total: 35203709.97sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35203709.97sec, total: 35203709.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 70407419.93sec, total: 70407419.94sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 35203709.97sec, total: 35203709.98sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 35203709.97sec, total: 35203709.97sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35203709.97sec, total: 35203709.97sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 35203709.97sec, total: 35203709.97sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.35ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.35ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 259us, total: 1.52ms
      train.py:343:hfe, cpu: 534us, accelerator: 676us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 35203709.97sec, total: 35203709.97sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2128.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_131000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 70273310.56sec, total: 70273310.56sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 35136655.28sec, total: 35136655.28sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35136655.28sec, total: 35136655.28sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 70273310.56sec, total: 70273310.57sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 35136655.29sec, total: 35136655.29sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 35136655.28sec, total: 35136655.29sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35136655.28sec, total: 35136655.29sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 35136655.28sec, total: 35136655.29sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.35ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.35ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 258us, total: 1.52ms
      train.py:343:hfe, cpu: 534us, accelerator: 675us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 35136655.28sec, total: 35136655.29sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_131250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 70139711.11sec, total: 70139711.11sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 35069855.56sec, total: 35069855.56sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35069855.55sec, total: 35069855.56sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 70139711.11sec, total: 70139711.12sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 35069855.56sec, total: 35069855.57sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 35069855.56sec, total: 35069855.56sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 35069855.56sec, total: 35069855.56sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 35069855.56sec, total: 35069855.56sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.35ms, total: 3.51ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.35ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 258us, total: 1.52ms
      train.py:343:hfe, cpu: 534us, accelerator: 673us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 35069855.56sec, total: 35069855.56sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_131500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 70006618.68sec, total: 70006618.68sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 35003309.34sec, total: 35003309.34sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.00ms, accelerator: 35003309.34sec, total: 35003309.34sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 70006618.68sec, total: 70006618.69sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 35003309.35sec, total: 35003309.35sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 35003309.34sec, total: 35003309.35sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 35003309.34sec, total: 35003309.35sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 35003309.34sec, total: 35003309.35sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.35ms, total: 3.52ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.35ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 257us, total: 1.52ms
      train.py:343:hfe, cpu: 535us, accelerator: 672us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 35003309.34sec, total: 35003309.35sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_131750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 69874030.38sec, total: 69874030.38sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34937015.19sec, total: 34937015.20sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34937015.19sec, total: 34937015.19sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 69874030.39sec, total: 69874030.39sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 34937015.20sec, total: 34937015.20sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 34937015.20sec, total: 34937015.20sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34937015.20sec, total: 34937015.20sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34937015.20sec, total: 34937015.20sec
  train.py:359:image_losses, cpu: 2.16ms, accelerator: 1.35ms, total: 3.51ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.35ms, total: 3.50ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 257us, total: 1.52ms
      train.py:343:hfe, cpu: 535us, accelerator: 672us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 34937015.20sec, total: 34937015.20sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_132000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 69741943.37sec, total: 69741943.37sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34870971.69sec, total: 34870971.69sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34870971.69sec, total: 34870971.69sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 69741943.37sec, total: 69741943.38sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 34870971.69sec, total: 34870971.70sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 34870971.69sec, total: 34870971.69sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34870971.69sec, total: 34870971.69sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34870971.69sec, total: 34870971.69sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.34ms, total: 3.51ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.34ms, total: 3.49ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 257us, total: 1.52ms
      train.py:343:hfe, cpu: 534us, accelerator: 670us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 34870971.69sec, total: 34870971.69sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.61 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_132250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 69610354.80sec, total: 69610354.80sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34805177.40sec, total: 34805177.40sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34805177.40sec, total: 34805177.40sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 69610354.80sec, total: 69610354.81sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 34805177.41sec, total: 34805177.41sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 34805177.40sec, total: 34805177.41sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34805177.40sec, total: 34805177.41sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34805177.40sec, total: 34805177.41sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.34ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 257us, total: 1.51ms
      train.py:343:hfe, cpu: 534us, accelerator: 668us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 34805177.40sec, total: 34805177.41sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.26 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_132500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 69479261.85sec, total: 69479261.85sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34739630.93sec, total: 34739630.93sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34739630.93sec, total: 34739630.93sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 69479261.85sec, total: 69479261.86sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 34739630.93sec, total: 34739630.94sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 34739630.93sec, total: 34739630.93sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34739630.93sec, total: 34739630.93sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34739630.93sec, total: 34739630.93sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.34ms, total: 3.50ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 257us, total: 1.52ms
      train.py:343:hfe, cpu: 533us, accelerator: 668us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 34739630.93sec, total: 34739630.93sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_132750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 69348661.73sec, total: 69348661.74sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34674330.87sec, total: 34674330.87sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34674330.87sec, total: 34674330.87sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 69348661.74sec, total: 69348661.74sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 34674330.87sec, total: 34674330.88sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 34674330.87sec, total: 34674330.88sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34674330.87sec, total: 34674330.88sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34674330.87sec, total: 34674330.88sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.34ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 257us, total: 1.51ms
      train.py:343:hfe, cpu: 531us, accelerator: 668us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 34674330.87sec, total: 34674330.88sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_133000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 69218551.67sec, total: 69218551.68sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34609275.84sec, total: 34609275.84sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34609275.84sec, total: 34609275.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 69218551.68sec, total: 69218551.68sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 34609275.84sec, total: 34609275.85sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 34609275.84sec, total: 34609275.85sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34609275.84sec, total: 34609275.85sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34609275.84sec, total: 34609275.85sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.34ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 257us, total: 1.51ms
      train.py:343:hfe, cpu: 530us, accelerator: 667us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 34609275.84sec, total: 34609275.85sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_133250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 69088928.92sec, total: 69088928.92sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34544464.46sec, total: 34544464.46sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34544464.46sec, total: 34544464.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 69088928.92sec, total: 69088928.93sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 34544464.47sec, total: 34544464.47sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 34544464.46sec, total: 34544464.47sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34544464.46sec, total: 34544464.47sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34544464.46sec, total: 34544464.47sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 257us, total: 1.51ms
      train.py:343:hfe, cpu: 530us, accelerator: 665us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 34544464.46sec, total: 34544464.47sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2128.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_133500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 68959790.73sec, total: 68959790.73sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34479895.37sec, total: 34479895.37sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34479895.37sec, total: 34479895.37sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 68959790.74sec, total: 68959790.74sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 34479895.37sec, total: 34479895.38sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 34479895.37sec, total: 34479895.38sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34479895.37sec, total: 34479895.38sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34479895.37sec, total: 34479895.38sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 257us, total: 1.51ms
      train.py:343:hfe, cpu: 530us, accelerator: 666us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 34479895.37sec, total: 34479895.38sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_133750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 68831134.41sec, total: 68831134.41sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34415567.21sec, total: 34415567.21sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34415567.20sec, total: 34415567.21sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 68831134.41sec, total: 68831134.42sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 34415567.21sec, total: 34415567.22sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 34415567.21sec, total: 34415567.21sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34415567.21sec, total: 34415567.21sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34415567.21sec, total: 34415567.21sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 256us, total: 1.51ms
      train.py:343:hfe, cpu: 529us, accelerator: 663us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 34415567.21sec, total: 34415567.21sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_134000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 68702957.25sec, total: 68702957.25sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34351478.63sec, total: 34351478.63sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34351478.63sec, total: 34351478.63sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 68702957.25sec, total: 68702957.26sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 34351478.63sec, total: 34351478.64sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 34351478.63sec, total: 34351478.63sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34351478.63sec, total: 34351478.63sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34351478.63sec, total: 34351478.63sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 256us, total: 1.51ms
      train.py:343:hfe, cpu: 528us, accelerator: 662us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 34351478.63sec, total: 34351478.63sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_134250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 68575256.58sec, total: 68575256.59sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34287628.30sec, total: 34287628.30sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34287628.29sec, total: 34287628.30sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 68575256.59sec, total: 68575256.59sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 34287628.30sec, total: 34287628.31sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 34287628.30sec, total: 34287628.30sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34287628.30sec, total: 34287628.30sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34287628.30sec, total: 34287628.30sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.33ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 255us, total: 1.51ms
      train.py:343:hfe, cpu: 528us, accelerator: 662us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 34287628.30sec, total: 34287628.30sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.46 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_134500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 68448029.76sec, total: 68448029.76sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34224014.88sec, total: 34224014.89sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34224014.88sec, total: 34224014.88sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 68448029.77sec, total: 68448029.77sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 34224014.89sec, total: 34224014.89sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 34224014.89sec, total: 34224014.89sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34224014.89sec, total: 34224014.89sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34224014.89sec, total: 34224014.89sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 255us, total: 1.51ms
      train.py:343:hfe, cpu: 527us, accelerator: 660us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 34224014.89sec, total: 34224014.89sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_134750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 68321274.15sec, total: 68321274.15sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34160637.08sec, total: 34160637.08sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34160637.08sec, total: 34160637.08sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 68321274.16sec, total: 68321274.16sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 34160637.08sec, total: 34160637.09sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 34160637.08sec, total: 34160637.08sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34160637.08sec, total: 34160637.08sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34160637.08sec, total: 34160637.08sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.50ms
      train.py:343:hfe, cpu: 525us, accelerator: 660us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 34160637.08sec, total: 34160637.09sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_135000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 68194987.14sec, total: 68194987.14sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34097493.57sec, total: 34097493.57sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34097493.57sec, total: 34097493.57sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 68194987.14sec, total: 68194987.15sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 34097493.58sec, total: 34097493.58sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 34097493.58sec, total: 34097493.58sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 34097493.58sec, total: 34097493.58sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34097493.58sec, total: 34097493.58sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.50ms
      train.py:343:hfe, cpu: 525us, accelerator: 658us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 34097493.57sec, total: 34097493.58sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_135250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 68069166.13sec, total: 68069166.13sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 34034583.07sec, total: 34034583.07sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 34034583.07sec, total: 34034583.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 68069166.13sec, total: 68069166.14sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 34034583.07sec, total: 34034583.08sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 34034583.07sec, total: 34034583.07sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 34034583.07sec, total: 34034583.07sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 34034583.07sec, total: 34034583.07sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.50ms
      train.py:343:hfe, cpu: 525us, accelerator: 658us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 34034583.07sec, total: 34034583.07sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_135500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 67943808.55sec, total: 67943808.55sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33971904.28sec, total: 33971904.28sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33971904.28sec, total: 33971904.28sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 67943808.55sec, total: 67943808.56sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 33971904.28sec, total: 33971904.29sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33971904.28sec, total: 33971904.28sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33971904.28sec, total: 33971904.28sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 33971904.28sec, total: 33971904.28sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 253us, total: 1.50ms
      train.py:343:hfe, cpu: 524us, accelerator: 657us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 33971904.28sec, total: 33971904.28sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.77 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_135750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 67818911.84sec, total: 67818911.84sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33909455.92sec, total: 33909455.93sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 33909455.92sec, total: 33909455.92sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 67818911.85sec, total: 67818911.85sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 33909455.93sec, total: 33909455.93sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33909455.93sec, total: 33909455.93sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33909455.93sec, total: 33909455.93sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 33909455.93sec, total: 33909455.93sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.35ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 253us, total: 1.50ms
      train.py:343:hfe, cpu: 524us, accelerator: 694us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 33909455.93sec, total: 33909455.93sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_136000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 67694473.47sec, total: 67694473.47sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33847236.74sec, total: 33847236.74sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 33847236.74sec, total: 33847236.74sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 67694473.48sec, total: 67694473.48sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 33847236.74sec, total: 33847236.75sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33847236.74sec, total: 33847236.74sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33847236.74sec, total: 33847236.74sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 33847236.74sec, total: 33847236.74sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.35ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 252us, total: 1.49ms
      train.py:343:hfe, cpu: 524us, accelerator: 693us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 33847236.74sec, total: 33847236.75sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_136250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 67570490.92sec, total: 67570490.92sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33785245.46sec, total: 33785245.46sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 33785245.46sec, total: 33785245.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 67570490.92sec, total: 67570490.93sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 33785245.47sec, total: 33785245.47sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33785245.47sec, total: 33785245.47sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 33785245.47sec, total: 33785245.47sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 33785245.47sec, total: 33785245.47sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 252us, total: 1.49ms
      train.py:343:hfe, cpu: 524us, accelerator: 693us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 33785245.46sec, total: 33785245.47sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2071.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_136500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 67446961.69sec, total: 67446961.69sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33723480.85sec, total: 33723480.85sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 33723480.84sec, total: 33723480.85sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 67446961.69sec, total: 67446961.70sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 33723480.85sec, total: 33723480.86sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33723480.85sec, total: 33723480.85sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 33723480.85sec, total: 33723480.85sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 33723480.85sec, total: 33723480.85sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.35ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 252us, total: 1.49ms
      train.py:343:hfe, cpu: 523us, accelerator: 693us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33723480.85sec, total: 33723480.85sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_136750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 67323883.29sec, total: 67323883.29sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33661941.65sec, total: 33661941.65sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 33661941.65sec, total: 33661941.65sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 67323883.29sec, total: 67323883.30sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 33661941.65sec, total: 33661941.66sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33661941.65sec, total: 33661941.65sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33661941.65sec, total: 33661941.65sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 33661941.65sec, total: 33661941.65sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.35ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 252us, total: 1.50ms
      train.py:343:hfe, cpu: 522us, accelerator: 692us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33661941.65sec, total: 33661941.65sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2127.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_137000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 67201253.26sec, total: 67201253.27sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33600626.64sec, total: 33600626.64sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 33600626.63sec, total: 33600626.64sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 67201253.27sec, total: 67201253.27sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 33600626.64sec, total: 33600626.65sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33600626.64sec, total: 33600626.64sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 33600626.64sec, total: 33600626.64sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 33600626.64sec, total: 33600626.64sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 252us, total: 1.50ms
      train.py:343:hfe, cpu: 522us, accelerator: 688us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33600626.64sec, total: 33600626.64sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_137250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 67079069.17sec, total: 67079069.17sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33539534.59sec, total: 33539534.59sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 33539534.59sec, total: 33539534.59sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 67079069.17sec, total: 67079069.18sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 33539534.59sec, total: 33539534.60sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33539534.59sec, total: 33539534.59sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 33539534.59sec, total: 33539534.59sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 33539534.59sec, total: 33539534.59sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 252us, total: 1.50ms
      train.py:343:hfe, cpu: 522us, accelerator: 687us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33539534.59sec, total: 33539534.59sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_137500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 66957328.57sec, total: 66957328.57sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33478664.29sec, total: 33478664.29sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.98ms, accelerator: 33478664.29sec, total: 33478664.29sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 66957328.58sec, total: 66957328.58sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 33478664.29sec, total: 33478664.30sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33478664.29sec, total: 33478664.29sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33478664.29sec, total: 33478664.29sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 33478664.29sec, total: 33478664.29sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 251us, total: 1.51ms
      train.py:343:hfe, cpu: 521us, accelerator: 687us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33478664.29sec, total: 33478664.29sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_137750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 66836029.06sec, total: 66836029.06sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33418014.53sec, total: 33418014.54sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33418014.53sec, total: 33418014.53sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 66836029.07sec, total: 66836029.07sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 33418014.54sec, total: 33418014.54sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33418014.54sec, total: 33418014.54sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33418014.54sec, total: 33418014.54sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 33418014.54sec, total: 33418014.54sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 251us, total: 1.51ms
      train.py:343:hfe, cpu: 520us, accelerator: 686us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33418014.54sec, total: 33418014.54sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_138000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 66715168.25sec, total: 66715168.25sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33357584.13sec, total: 33357584.13sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33357584.13sec, total: 33357584.13sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 66715168.25sec, total: 66715168.26sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 33357584.13sec, total: 33357584.14sec
  train.py:360:image_losses, cpu: 2.87ms, accelerator: 33357584.13sec, total: 33357584.13sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33357584.13sec, total: 33357584.13sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 33357584.13sec, total: 33357584.13sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.33ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.33ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 251us, total: 1.52ms
      train.py:343:hfe, cpu: 521us, accelerator: 685us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33357584.13sec, total: 33357584.13sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_138250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 66594743.76sec, total: 66594743.76sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33297371.88sec, total: 33297371.88sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33297371.88sec, total: 33297371.88sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 66594743.76sec, total: 66594743.77sec
train.py:442:<module>, cpu: 5.55ms, accelerator: 33297371.89sec, total: 33297371.89sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 33297371.88sec, total: 33297371.89sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33297371.88sec, total: 33297371.89sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 33297371.88sec, total: 33297371.89sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 250us, total: 1.52ms
      train.py:343:hfe, cpu: 520us, accelerator: 684us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33297371.88sec, total: 33297371.89sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_138500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 66474753.23sec, total: 66474753.23sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33237376.62sec, total: 33237376.62sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33237376.62sec, total: 33237376.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 66474753.23sec, total: 66474753.24sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 33237376.62sec, total: 33237376.63sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 33237376.62sec, total: 33237376.62sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33237376.62sec, total: 33237376.62sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 33237376.62sec, total: 33237376.62sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.34ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.48ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 250us, total: 1.52ms
      train.py:343:hfe, cpu: 518us, accelerator: 690us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33237376.62sec, total: 33237376.62sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.10 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_138750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 66355194.32sec, total: 66355194.32sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33177597.16sec, total: 33177597.16sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33177597.16sec, total: 33177597.16sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 66355194.33sec, total: 66355194.33sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 33177597.17sec, total: 33177597.17sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 33177597.17sec, total: 33177597.17sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33177597.17sec, total: 33177597.17sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 33177597.17sec, total: 33177597.17sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.34ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 250us, total: 1.52ms
      train.py:343:hfe, cpu: 518us, accelerator: 688us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 33177597.17sec, total: 33177597.17sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_139000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 66236064.71sec, total: 66236064.71sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33118032.36sec, total: 33118032.36sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 1.99ms, accelerator: 33118032.36sec, total: 33118032.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 66236064.71sec, total: 66236064.72sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 33118032.36sec, total: 33118032.37sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 33118032.36sec, total: 33118032.36sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33118032.36sec, total: 33118032.36sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 33118032.36sec, total: 33118032.36sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.34ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 250us, total: 1.52ms
      train.py:343:hfe, cpu: 516us, accelerator: 689us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33118032.36sec, total: 33118032.36sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_139250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 66117362.08sec, total: 66117362.08sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 33058681.04sec, total: 33058681.05sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 33058681.04sec, total: 33058681.04sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 66117362.09sec, total: 66117362.09sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 33058681.05sec, total: 33058681.05sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 33058681.05sec, total: 33058681.05sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 33058681.05sec, total: 33058681.05sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 33058681.05sec, total: 33058681.05sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 250us, total: 1.51ms
      train.py:343:hfe, cpu: 516us, accelerator: 690us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 33058681.05sec, total: 33058681.05sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_139500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 65999084.15sec, total: 65999084.16sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32999542.08sec, total: 32999542.08sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32999542.08sec, total: 32999542.08sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 65999084.16sec, total: 65999084.16sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 32999542.08sec, total: 32999542.09sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 32999542.08sec, total: 32999542.09sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 32999542.08sec, total: 32999542.09sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 32999542.08sec, total: 32999542.09sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 248us, total: 1.51ms
      train.py:343:hfe, cpu: 517us, accelerator: 689us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 32999542.08sec, total: 32999542.09sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_139750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.50ms, accelerator: 65881228.65sec, total: 65881228.65sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32940614.33sec, total: 32940614.33sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32940614.32sec, total: 32940614.33sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 65881228.65sec, total: 65881228.66sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 32940614.33sec, total: 32940614.34sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 32940614.33sec, total: 32940614.33sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 32940614.33sec, total: 32940614.33sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 32940614.33sec, total: 32940614.33sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.34ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 247us, total: 1.52ms
      train.py:343:hfe, cpu: 515us, accelerator: 689us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 32940614.33sec, total: 32940614.33sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_140000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 65763793.30sec, total: 65763793.30sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32881896.65sec, total: 32881896.66sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32881896.65sec, total: 32881896.65sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 65763793.31sec, total: 65763793.31sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 32881896.66sec, total: 32881896.66sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 32881896.66sec, total: 32881896.66sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 32881896.66sec, total: 32881896.66sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 32881896.66sec, total: 32881896.66sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 246us, total: 1.52ms
      train.py:343:hfe, cpu: 515us, accelerator: 688us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 32881896.66sec, total: 32881896.66sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_140250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 65646775.88sec, total: 65646775.88sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32823387.94sec, total: 32823387.94sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32823387.94sec, total: 32823387.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 65646775.88sec, total: 65646775.88sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 32823387.95sec, total: 32823387.95sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 32823387.94sec, total: 32823387.95sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 32823387.94sec, total: 32823387.95sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 32823387.94sec, total: 32823387.95sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 246us, total: 1.52ms
      train.py:343:hfe, cpu: 518us, accelerator: 686us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 32823387.94sec, total: 32823387.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_140500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 65530174.14sec, total: 65530174.14sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32765087.07sec, total: 32765087.08sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32765087.07sec, total: 32765087.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 65530174.15sec, total: 65530174.15sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 32765087.08sec, total: 32765087.08sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 32765087.08sec, total: 32765087.08sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 32765087.08sec, total: 32765087.08sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 32765087.08sec, total: 32765087.08sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.27ms, accelerator: 246us, total: 1.52ms
      train.py:343:hfe, cpu: 517us, accelerator: 685us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 32765087.08sec, total: 32765087.08sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_140750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 65413985.89sec, total: 65413985.89sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32706992.95sec, total: 32706992.95sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32706992.95sec, total: 32706992.95sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 65413985.90sec, total: 65413985.90sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 32706992.95sec, total: 32706992.96sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 32706992.95sec, total: 32706992.95sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32706992.95sec, total: 32706992.95sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32706992.95sec, total: 32706992.95sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 245us, total: 1.51ms
      train.py:343:hfe, cpu: 517us, accelerator: 683us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.04ms, accelerator: 32706992.95sec, total: 32706992.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.58 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_141000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 65298208.92sec, total: 65298208.93sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32649104.47sec, total: 32649104.47sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32649104.46sec, total: 32649104.47sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 65298208.93sec, total: 65298208.93sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 32649104.47sec, total: 32649104.48sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 32649104.47sec, total: 32649104.47sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32649104.47sec, total: 32649104.47sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32649104.47sec, total: 32649104.47sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 245us, total: 1.51ms
      train.py:343:hfe, cpu: 517us, accelerator: 683us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.04ms, accelerator: 32649104.47sec, total: 32649104.47sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2116.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_141250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 65182841.06sec, total: 65182841.07sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32591420.53sec, total: 32591420.54sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32591420.53sec, total: 32591420.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.20ms, accelerator: 65182841.07sec, total: 65182841.07sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 32591420.54sec, total: 32591420.55sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32591420.54sec, total: 32591420.54sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32591420.54sec, total: 32591420.54sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32591420.54sec, total: 32591420.54sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 245us, total: 1.51ms
      train.py:343:hfe, cpu: 517us, accelerator: 682us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.04ms, accelerator: 32591420.54sec, total: 32591420.54sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_141500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 65067880.14sec, total: 65067880.15sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32533940.08sec, total: 32533940.08sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32533940.07sec, total: 32533940.08sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 65067880.15sec, total: 65067880.15sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 32533940.08sec, total: 32533940.09sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32533940.08sec, total: 32533940.08sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32533940.08sec, total: 32533940.08sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32533940.08sec, total: 32533940.08sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 245us, total: 1.51ms
      train.py:343:hfe, cpu: 517us, accelerator: 682us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.04ms, accelerator: 32533940.08sec, total: 32533940.08sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_141750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 64953324.02sec, total: 64953324.02sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32476662.01sec, total: 32476662.01sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32476662.01sec, total: 32476662.01sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 64953324.02sec, total: 64953324.03sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 32476662.02sec, total: 32476662.02sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32476662.01sec, total: 32476662.02sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32476662.01sec, total: 32476662.02sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32476662.01sec, total: 32476662.02sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.33ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 245us, total: 1.51ms
      train.py:343:hfe, cpu: 516us, accelerator: 687us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.04ms, accelerator: 32476662.01sec, total: 32476662.02sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_142000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 64839170.55sec, total: 64839170.55sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32419585.28sec, total: 32419585.28sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 32419585.28sec, total: 32419585.28sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 64839170.55sec, total: 64839170.56sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 32419585.28sec, total: 32419585.29sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32419585.28sec, total: 32419585.28sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32419585.28sec, total: 32419585.28sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32419585.28sec, total: 32419585.28sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.33ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 245us, total: 1.51ms
      train.py:343:hfe, cpu: 516us, accelerator: 685us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.04ms, accelerator: 32419585.28sec, total: 32419585.28sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_142250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 64725417.62sec, total: 64725417.62sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32362708.81sec, total: 32362708.81sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 32362708.81sec, total: 32362708.81sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 64725417.62sec, total: 64725417.63sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 32362708.82sec, total: 32362708.82sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32362708.81sec, total: 32362708.82sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32362708.81sec, total: 32362708.82sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32362708.81sec, total: 32362708.82sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.26ms, accelerator: 245us, total: 1.50ms
      train.py:343:hfe, cpu: 515us, accelerator: 682us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 32362708.81sec, total: 32362708.82sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_142500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 64612063.12sec, total: 64612063.12sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32306031.56sec, total: 32306031.56sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 32306031.56sec, total: 32306031.56sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 64612063.13sec, total: 64612063.13sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 32306031.57sec, total: 32306031.57sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32306031.57sec, total: 32306031.57sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32306031.57sec, total: 32306031.57sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32306031.57sec, total: 32306031.57sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.33ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 245us, total: 1.50ms
      train.py:343:hfe, cpu: 515us, accelerator: 686us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 32306031.57sec, total: 32306031.57sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_142750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 64499104.97sec, total: 64499104.97sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32249552.49sec, total: 32249552.49sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 32249552.49sec, total: 32249552.49sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 64499104.97sec, total: 64499104.98sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 32249552.49sec, total: 32249552.50sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32249552.49sec, total: 32249552.49sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32249552.49sec, total: 32249552.49sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32249552.49sec, total: 32249552.49sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 243us, total: 1.50ms
      train.py:343:hfe, cpu: 514us, accelerator: 687us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.06ms, accelerator: 32249552.49sec, total: 32249552.49sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_143000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 64386541.09sec, total: 64386541.09sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32193270.55sec, total: 32193270.55sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 32193270.54sec, total: 32193270.55sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 64386541.09sec, total: 64386541.09sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 32193270.55sec, total: 32193270.56sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32193270.55sec, total: 32193270.55sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32193270.55sec, total: 32193270.55sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32193270.55sec, total: 32193270.55sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 243us, total: 1.50ms
      train.py:343:hfe, cpu: 513us, accelerator: 689us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.05ms, accelerator: 32193270.55sec, total: 32193270.55sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_143250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.49ms, accelerator: 64274369.41sec, total: 64274369.41sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32137184.71sec, total: 32137184.71sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 32137184.71sec, total: 32137184.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 64274369.42sec, total: 64274369.42sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 32137184.71sec, total: 32137184.72sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32137184.71sec, total: 32137184.71sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32137184.71sec, total: 32137184.71sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32137184.71sec, total: 32137184.71sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.33ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 243us, total: 1.50ms
      train.py:343:hfe, cpu: 512us, accelerator: 688us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.07ms, accelerator: 32137184.71sec, total: 32137184.71sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.14 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_143500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 64162587.90sec, total: 64162587.90sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32081293.95sec, total: 32081293.95sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 32081293.95sec, total: 32081293.95sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 64162587.90sec, total: 64162587.91sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 32081293.96sec, total: 32081293.96sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32081293.96sec, total: 32081293.96sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 32081293.96sec, total: 32081293.96sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32081293.96sec, total: 32081293.96sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 243us, total: 1.50ms
      train.py:343:hfe, cpu: 512us, accelerator: 691us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 32081293.95sec, total: 32081293.96sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_143750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 64051194.52sec, total: 64051194.52sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 32025597.26sec, total: 32025597.26sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 32025597.26sec, total: 32025597.26sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 64051194.52sec, total: 64051194.53sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 32025597.27sec, total: 32025597.27sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 32025597.26sec, total: 32025597.27sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 32025597.26sec, total: 32025597.27sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 32025597.26sec, total: 32025597.27sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 242us, total: 1.49ms
      train.py:343:hfe, cpu: 512us, accelerator: 691us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 32025597.26sec, total: 32025597.27sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_144000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 63940187.25sec, total: 63940187.25sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 31970093.63sec, total: 31970093.63sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31970093.63sec, total: 31970093.63sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 63940187.25sec, total: 63940187.26sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 31970093.63sec, total: 31970093.64sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 31970093.63sec, total: 31970093.63sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31970093.63sec, total: 31970093.63sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31970093.63sec, total: 31970093.63sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 242us, total: 1.49ms
      train.py:343:hfe, cpu: 512us, accelerator: 688us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 31970093.63sec, total: 31970093.63sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_144250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 63829564.09sec, total: 63829564.09sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 31914782.05sec, total: 31914782.05sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31914782.04sec, total: 31914782.05sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 63829564.09sec, total: 63829564.10sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 31914782.05sec, total: 31914782.06sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 31914782.05sec, total: 31914782.05sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31914782.05sec, total: 31914782.05sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31914782.05sec, total: 31914782.05sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 241us, total: 1.49ms
      train.py:343:hfe, cpu: 512us, accelerator: 687us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 31914782.05sec, total: 31914782.05sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_144500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 63719323.04sec, total: 63719323.05sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 31859661.52sec, total: 31859661.53sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31859661.52sec, total: 31859661.53sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 63719323.05sec, total: 63719323.05sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 31859661.53sec, total: 31859661.54sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 31859661.53sec, total: 31859661.53sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31859661.53sec, total: 31859661.53sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31859661.53sec, total: 31859661.53sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.49ms
      train.py:343:hfe, cpu: 511us, accelerator: 687us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 31859661.53sec, total: 31859661.53sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.48 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_144750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.48ms, accelerator: 63609462.14sec, total: 63609462.14sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 31804731.07sec, total: 31804731.08sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31804731.07sec, total: 31804731.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 63609462.15sec, total: 63609462.15sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 31804731.08sec, total: 31804731.08sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 31804731.08sec, total: 31804731.08sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31804731.08sec, total: 31804731.08sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31804731.08sec, total: 31804731.08sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.33ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.49ms
      train.py:343:hfe, cpu: 512us, accelerator: 685us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 31804731.08sec, total: 31804731.08sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_145000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 63499979.42sec, total: 63499979.42sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 31749989.71sec, total: 31749989.71sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31749989.71sec, total: 31749989.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 63499979.42sec, total: 63499979.43sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 31749989.72sec, total: 31749989.72sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 31749989.71sec, total: 31749989.72sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31749989.71sec, total: 31749989.72sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31749989.71sec, total: 31749989.72sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.33ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.48ms
      train.py:343:hfe, cpu: 512us, accelerator: 684us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 31749989.71sec, total: 31749989.72sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_145250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 63390872.92sec, total: 63390872.93sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.24ms, accelerator: 31695436.47sec, total: 31695436.47sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31695436.46sec, total: 31695436.47sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 63390872.93sec, total: 63390872.93sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 31695436.47sec, total: 31695436.48sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 31695436.47sec, total: 31695436.47sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31695436.47sec, total: 31695436.47sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31695436.47sec, total: 31695436.47sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.48ms
      train.py:343:hfe, cpu: 511us, accelerator: 684us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 31695436.47sec, total: 31695436.47sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_145500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 63282140.72sec, total: 63282140.73sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31641070.37sec, total: 31641070.37sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31641070.36sec, total: 31641070.37sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 63282140.73sec, total: 63282140.73sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 31641070.37sec, total: 31641070.38sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 31641070.37sec, total: 31641070.37sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31641070.37sec, total: 31641070.37sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 31641070.37sec, total: 31641070.37sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.48ms
      train.py:343:hfe, cpu: 510us, accelerator: 683us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31641070.37sec, total: 31641070.37sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.04 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_145750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 63173780.89sec, total: 63173780.90sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31586890.45sec, total: 31586890.45sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31586890.45sec, total: 31586890.45sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 63173780.90sec, total: 63173780.90sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 31586890.45sec, total: 31586890.46sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 31586890.45sec, total: 31586890.46sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31586890.45sec, total: 31586890.46sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31586890.45sec, total: 31586890.46sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.48ms
      train.py:343:hfe, cpu: 510us, accelerator: 682us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31586890.45sec, total: 31586890.46sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_146000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 63065791.52sec, total: 63065791.53sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31532895.77sec, total: 31532895.77sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31532895.76sec, total: 31532895.77sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 63065791.53sec, total: 63065791.53sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 31532895.77sec, total: 31532895.78sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 31532895.77sec, total: 31532895.77sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31532895.77sec, total: 31532895.77sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31532895.77sec, total: 31532895.77sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.48ms
      train.py:343:hfe, cpu: 510us, accelerator: 680us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 31532895.77sec, total: 31532895.77sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_146250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 62958170.72sec, total: 62958170.72sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31479085.36sec, total: 31479085.36sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31479085.36sec, total: 31479085.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 62958170.73sec, total: 62958170.73sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 31479085.37sec, total: 31479085.37sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 31479085.37sec, total: 31479085.37sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31479085.37sec, total: 31479085.37sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31479085.37sec, total: 31479085.37sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.48ms
      train.py:343:hfe, cpu: 509us, accelerator: 679us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31479085.37sec, total: 31479085.37sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.35 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_146500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 62850916.60sec, total: 62850916.60sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31425458.30sec, total: 31425458.30sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 31425458.30sec, total: 31425458.30sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 62850916.60sec, total: 62850916.61sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 31425458.31sec, total: 31425458.31sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 31425458.30sec, total: 31425458.31sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31425458.30sec, total: 31425458.31sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31425458.30sec, total: 31425458.31sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.48ms
      train.py:343:hfe, cpu: 508us, accelerator: 679us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31425458.30sec, total: 31425458.31sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_146750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 62744027.28sec, total: 62744027.28sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31372013.64sec, total: 31372013.65sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 31372013.64sec, total: 31372013.64sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 62744027.29sec, total: 62744027.29sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 31372013.65sec, total: 31372013.65sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 31372013.65sec, total: 31372013.65sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31372013.65sec, total: 31372013.65sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31372013.65sec, total: 31372013.65sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.49ms
      train.py:343:hfe, cpu: 507us, accelerator: 678us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31372013.65sec, total: 31372013.65sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_147000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 62637500.92sec, total: 62637500.92sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31318750.46sec, total: 31318750.46sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 31318750.46sec, total: 31318750.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 62637500.93sec, total: 62637500.93sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 31318750.47sec, total: 31318750.47sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 31318750.47sec, total: 31318750.47sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 31318750.47sec, total: 31318750.47sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 31318750.47sec, total: 31318750.47sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.48ms
      train.py:343:hfe, cpu: 507us, accelerator: 677us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31318750.47sec, total: 31318750.47sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_147250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 62531335.66sec, total: 62531335.67sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31265667.84sec, total: 31265667.84sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 31265667.83sec, total: 31265667.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 62531335.67sec, total: 62531335.67sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 31265667.84sec, total: 31265667.85sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 31265667.84sec, total: 31265667.84sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 31265667.84sec, total: 31265667.84sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 31265667.84sec, total: 31265667.84sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.31ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.31ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.48ms
      train.py:343:hfe, cpu: 506us, accelerator: 676us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31265667.84sec, total: 31265667.84sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_147500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 62425529.68sec, total: 62425529.68sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31212764.84sec, total: 31212764.85sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 31212764.84sec, total: 31212764.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 62425529.69sec, total: 62425529.69sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 31212764.85sec, total: 31212764.85sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 31212764.85sec, total: 31212764.85sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 31212764.85sec, total: 31212764.85sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 31212764.85sec, total: 31212764.85sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.31ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.31ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 240us, total: 1.48ms
      train.py:343:hfe, cpu: 506us, accelerator: 675us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31212764.85sec, total: 31212764.85sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_147750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 62320081.15sec, total: 62320081.15sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31160040.58sec, total: 31160040.58sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 31160040.58sec, total: 31160040.58sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 62320081.16sec, total: 62320081.16sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 31160040.58sec, total: 31160040.59sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 31160040.58sec, total: 31160040.58sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 31160040.58sec, total: 31160040.58sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 31160040.58sec, total: 31160040.58sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.31ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.31ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 239us, total: 1.48ms
      train.py:343:hfe, cpu: 506us, accelerator: 672us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31160040.58sec, total: 31160040.59sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_148000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 62214988.27sec, total: 62214988.27sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31107494.14sec, total: 31107494.14sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 31107494.13sec, total: 31107494.14sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 62214988.27sec, total: 62214988.28sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 31107494.14sec, total: 31107494.15sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 31107494.14sec, total: 31107494.14sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 31107494.14sec, total: 31107494.14sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 31107494.14sec, total: 31107494.14sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.31ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.31ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 239us, total: 1.48ms
      train.py:343:hfe, cpu: 505us, accelerator: 672us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31107494.14sec, total: 31107494.14sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_148250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 62110249.23sec, total: 62110249.23sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31055124.62sec, total: 31055124.62sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 31055124.62sec, total: 31055124.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 62110249.23sec, total: 62110249.24sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 31055124.62sec, total: 31055124.63sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 31055124.62sec, total: 31055124.62sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 31055124.62sec, total: 31055124.62sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 31055124.62sec, total: 31055124.62sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.30ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.30ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 237us, total: 1.47ms
      train.py:343:hfe, cpu: 505us, accelerator: 670us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31055124.62sec, total: 31055124.62sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2117.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_148500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 62005862.26sec, total: 62005862.26sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 31002931.13sec, total: 31002931.13sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 31002931.13sec, total: 31002931.13sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 62005862.26sec, total: 62005862.26sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 31002931.14sec, total: 31002931.14sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 31002931.13sec, total: 31002931.14sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 31002931.13sec, total: 31002931.14sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 31002931.13sec, total: 31002931.14sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 237us, total: 1.47ms
      train.py:343:hfe, cpu: 505us, accelerator: 690us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 31002931.13sec, total: 31002931.14sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_148750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 61901825.57sec, total: 61901825.58sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30950912.79sec, total: 30950912.79sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30950912.79sec, total: 30950912.79sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 61901825.58sec, total: 61901825.58sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 30950912.79sec, total: 30950912.80sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 30950912.79sec, total: 30950912.80sec
    train.py:322:loss_fn, cpu: 2.85ms, accelerator: 30950912.79sec, total: 30950912.80sec
      train.py:349:msssim, cpu: 2.80ms, accelerator: 30950912.79sec, total: 30950912.80sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 236us, total: 1.48ms
      train.py:343:hfe, cpu: 504us, accelerator: 689us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 30950912.79sec, total: 30950912.80sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_149000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 61798137.42sec, total: 61798137.43sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30899068.71sec, total: 30899068.72sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30899068.71sec, total: 30899068.72sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 61798137.43sec, total: 61798137.43sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 30899068.72sec, total: 30899068.73sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 30899068.72sec, total: 30899068.72sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 30899068.72sec, total: 30899068.72sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 30899068.72sec, total: 30899068.72sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 236us, total: 1.48ms
      train.py:343:hfe, cpu: 504us, accelerator: 688us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 30899068.72sec, total: 30899068.72sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2072.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_149250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 61694796.06sec, total: 61694796.06sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30847398.03sec, total: 30847398.03sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30847398.03sec, total: 30847398.03sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 61694796.06sec, total: 61694796.07sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 30847398.04sec, total: 30847398.04sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 30847398.03sec, total: 30847398.04sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 30847398.03sec, total: 30847398.04sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 30847398.03sec, total: 30847398.04sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 236us, total: 1.48ms
      train.py:343:hfe, cpu: 503us, accelerator: 689us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 30847398.03sec, total: 30847398.04sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_149500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 61591799.74sec, total: 61591799.74sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30795899.87sec, total: 30795899.87sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30795899.87sec, total: 30795899.87sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 61591799.74sec, total: 61591799.75sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 30795899.88sec, total: 30795899.88sec
  train.py:360:image_losses, cpu: 2.86ms, accelerator: 30795899.87sec, total: 30795899.88sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 30795899.87sec, total: 30795899.88sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 30795899.87sec, total: 30795899.88sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 235us, total: 1.47ms
      train.py:343:hfe, cpu: 502us, accelerator: 688us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 30795899.87sec, total: 30795899.88sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.70 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_149750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 61489146.74sec, total: 61489146.74sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30744573.37sec, total: 30744573.37sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30744573.37sec, total: 30744573.37sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 61489146.74sec, total: 61489146.75sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 30744573.38sec, total: 30744573.38sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 30744573.37sec, total: 30744573.38sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 30744573.37sec, total: 30744573.38sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 30744573.37sec, total: 30744573.38sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 235us, total: 1.47ms
      train.py:343:hfe, cpu: 502us, accelerator: 688us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 30744573.37sec, total: 30744573.38sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_150000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.47ms, accelerator: 61386835.34sec, total: 61386835.35sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30693417.68sec, total: 30693417.68sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30693417.67sec, total: 30693417.68sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 61386835.35sec, total: 61386835.35sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 30693417.68sec, total: 30693417.69sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 30693417.68sec, total: 30693417.68sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 30693417.68sec, total: 30693417.68sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 30693417.68sec, total: 30693417.68sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.31ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 235us, total: 1.47ms
      train.py:343:hfe, cpu: 502us, accelerator: 686us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 30693417.68sec, total: 30693417.68sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_150250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 61284863.86sec, total: 61284863.86sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30642431.93sec, total: 30642431.93sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30642431.93sec, total: 30642431.93sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 61284863.86sec, total: 61284863.87sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 30642431.94sec, total: 30642431.94sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 30642431.93sec, total: 30642431.94sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 30642431.93sec, total: 30642431.94sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 30642431.93sec, total: 30642431.94sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.31ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 235us, total: 1.47ms
      train.py:343:hfe, cpu: 501us, accelerator: 684us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 30642431.93sec, total: 30642431.94sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_150500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 61183230.58sec, total: 61183230.59sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30591615.29sec, total: 30591615.30sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30591615.29sec, total: 30591615.30sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 61183230.59sec, total: 61183230.59sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 30591615.30sec, total: 30591615.31sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 30591615.30sec, total: 30591615.30sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 30591615.30sec, total: 30591615.30sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 30591615.30sec, total: 30591615.30sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.31ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.31ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 235us, total: 1.47ms
      train.py:343:hfe, cpu: 501us, accelerator: 685us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 30591615.30sec, total: 30591615.30sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_150750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 61081933.84sec, total: 61081933.85sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30540966.93sec, total: 30540966.93sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30540966.92sec, total: 30540966.93sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 61081933.85sec, total: 61081933.85sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 30540966.93sec, total: 30540966.94sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 30540966.93sec, total: 30540966.93sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 30540966.93sec, total: 30540966.93sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 30540966.93sec, total: 30540966.93sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.31ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.31ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 684us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 30540966.93sec, total: 30540966.93sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2078.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_151000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 60980971.97sec, total: 60980971.97sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30490485.99sec, total: 30490485.99sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30490485.99sec, total: 30490485.99sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 60980971.98sec, total: 60980971.98sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 30490485.99sec, total: 30490486.00sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 30490485.99sec, total: 30490485.99sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 30490485.99sec, total: 30490485.99sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 30490485.99sec, total: 30490485.99sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.31ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.31ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 684us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 30490485.99sec, total: 30490485.99sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.82 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_151250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 60880343.30sec, total: 60880343.31sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30440171.65sec, total: 30440171.66sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30440171.65sec, total: 30440171.66sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 60880343.31sec, total: 60880343.31sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 30440171.66sec, total: 30440171.67sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 30440171.66sec, total: 30440171.66sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 30440171.66sec, total: 30440171.66sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 30440171.66sec, total: 30440171.66sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.31ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 500us, accelerator: 683us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 30440171.66sec, total: 30440171.66sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_151500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 60780046.20sec, total: 60780046.20sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30390023.10sec, total: 30390023.10sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30390023.10sec, total: 30390023.10sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 60780046.20sec, total: 60780046.21sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 30390023.11sec, total: 30390023.11sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 30390023.10sec, total: 30390023.11sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 30390023.10sec, total: 30390023.11sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 30390023.10sec, total: 30390023.11sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.31ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 500us, accelerator: 683us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 30390023.10sec, total: 30390023.11sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_151750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 60680079.02sec, total: 60680079.02sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30340039.51sec, total: 30340039.51sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30340039.51sec, total: 30340039.51sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 60680079.02sec, total: 60680079.03sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 30340039.52sec, total: 30340039.52sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 30340039.51sec, total: 30340039.52sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 30340039.51sec, total: 30340039.52sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 30340039.51sec, total: 30340039.52sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.31ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 499us, accelerator: 684us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 30340039.51sec, total: 30340039.52sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_152000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 60580440.13sec, total: 60580440.14sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30290220.07sec, total: 30290220.07sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30290220.07sec, total: 30290220.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 60580440.14sec, total: 60580440.14sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 30290220.08sec, total: 30290220.08sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 30290220.07sec, total: 30290220.08sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 30290220.07sec, total: 30290220.08sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 30290220.07sec, total: 30290220.08sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.31ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 499us, accelerator: 684us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 30290220.07sec, total: 30290220.08sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_152250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 60481127.94sec, total: 60481127.94sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30240563.97sec, total: 30240563.97sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30240563.97sec, total: 30240563.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 60481127.94sec, total: 60481127.95sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 30240563.98sec, total: 30240563.98sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 30240563.97sec, total: 30240563.98sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 30240563.97sec, total: 30240563.98sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 30240563.97sec, total: 30240563.98sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.31ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 233us, total: 1.45ms
      train.py:343:hfe, cpu: 498us, accelerator: 683us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 30240563.97sec, total: 30240563.98sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_152500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.46ms, accelerator: 60382140.82sec, total: 60382140.82sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30191070.41sec, total: 30191070.42sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30191070.41sec, total: 30191070.41sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 60382140.83sec, total: 60382140.83sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 30191070.42sec, total: 30191070.42sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 30191070.42sec, total: 30191070.42sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 30191070.42sec, total: 30191070.42sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 30191070.42sec, total: 30191070.42sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.31ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 233us, total: 1.45ms
      train.py:343:hfe, cpu: 497us, accelerator: 683us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 30191070.42sec, total: 30191070.42sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_152750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 60283477.19sec, total: 60283477.20sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30141738.60sec, total: 30141738.60sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30141738.60sec, total: 30141738.60sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 60283477.20sec, total: 60283477.20sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 30141738.60sec, total: 30141738.61sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 30141738.60sec, total: 30141738.60sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 30141738.60sec, total: 30141738.60sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 30141738.60sec, total: 30141738.60sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.30ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.30ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 232us, total: 1.45ms
      train.py:343:hfe, cpu: 496us, accelerator: 681us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 30141738.60sec, total: 30141738.61sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_153000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 60185135.47sec, total: 60185135.47sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30092567.74sec, total: 30092567.74sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30092567.74sec, total: 30092567.74sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 60185135.47sec, total: 60185135.48sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 30092567.74sec, total: 30092567.75sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 30092567.74sec, total: 30092567.74sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 30092567.74sec, total: 30092567.74sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 30092567.74sec, total: 30092567.74sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.30ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.30ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 231us, total: 1.45ms
      train.py:343:hfe, cpu: 496us, accelerator: 679us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 30092567.74sec, total: 30092567.74sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.60 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_153250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 60087114.07sec, total: 60087114.08sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 30043557.04sec, total: 30043557.04sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 30043557.04sec, total: 30043557.04sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 60087114.08sec, total: 60087114.08sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 30043557.05sec, total: 30043557.05sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 30043557.04sec, total: 30043557.05sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 30043557.04sec, total: 30043557.05sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 30043557.04sec, total: 30043557.05sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.30ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.30ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 231us, total: 1.45ms
      train.py:343:hfe, cpu: 496us, accelerator: 679us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 30043557.04sec, total: 30043557.05sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_153500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59989411.45sec, total: 59989411.45sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29994705.73sec, total: 29994705.73sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29994705.73sec, total: 29994705.73sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 59989411.46sec, total: 59989411.46sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 29994705.73sec, total: 29994705.74sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29994705.73sec, total: 29994705.73sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29994705.73sec, total: 29994705.73sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29994705.73sec, total: 29994705.73sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.30ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.30ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 231us, total: 1.45ms
      train.py:343:hfe, cpu: 496us, accelerator: 678us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 29994705.73sec, total: 29994705.73sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_153750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59892026.04sec, total: 59892026.04sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29946013.02sec, total: 29946013.03sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29946013.02sec, total: 29946013.02sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 59892026.05sec, total: 59892026.05sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 29946013.03sec, total: 29946013.03sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29946013.03sec, total: 29946013.03sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29946013.03sec, total: 29946013.03sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29946013.03sec, total: 29946013.03sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.30ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.30ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 231us, total: 1.44ms
      train.py:343:hfe, cpu: 496us, accelerator: 678us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 29946013.03sec, total: 29946013.03sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_154000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59794956.31sec, total: 59794956.31sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29897478.16sec, total: 29897478.16sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29897478.16sec, total: 29897478.16sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 59794956.31sec, total: 59794956.32sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 29897478.16sec, total: 29897478.17sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29897478.16sec, total: 29897478.16sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29897478.16sec, total: 29897478.16sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29897478.16sec, total: 29897478.16sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.30ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.30ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 231us, total: 1.44ms
      train.py:343:hfe, cpu: 497us, accelerator: 677us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 29897478.16sec, total: 29897478.16sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2070.88 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_154250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59698200.72sec, total: 59698200.72sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29849100.36sec, total: 29849100.36sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29849100.36sec, total: 29849100.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 59698200.72sec, total: 59698200.72sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 29849100.37sec, total: 29849100.37sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29849100.36sec, total: 29849100.37sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29849100.36sec, total: 29849100.37sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29849100.36sec, total: 29849100.37sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.30ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.30ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 231us, total: 1.45ms
      train.py:343:hfe, cpu: 497us, accelerator: 676us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 29849100.36sec, total: 29849100.37sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_154500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59601757.74sec, total: 59601757.74sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29800878.87sec, total: 29800878.88sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29800878.87sec, total: 29800878.87sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 59601757.75sec, total: 59601757.75sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 29800878.88sec, total: 29800878.88sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29800878.88sec, total: 29800878.88sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29800878.88sec, total: 29800878.88sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29800878.88sec, total: 29800878.88sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.29ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 231us, total: 1.44ms
      train.py:343:hfe, cpu: 498us, accelerator: 673us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 29800878.88sec, total: 29800878.88sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.19 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_154750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59505625.87sec, total: 59505625.88sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29752812.94sec, total: 29752812.94sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29752812.94sec, total: 29752812.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 59505625.88sec, total: 59505625.88sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 29752812.94sec, total: 29752812.95sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29752812.94sec, total: 29752812.95sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29752812.94sec, total: 29752812.95sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29752812.94sec, total: 29752812.95sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.29ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 231us, total: 1.45ms
      train.py:343:hfe, cpu: 497us, accelerator: 672us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 29752812.94sec, total: 29752812.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_155000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59409803.61sec, total: 59409803.61sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29704901.81sec, total: 29704901.81sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29704901.81sec, total: 29704901.81sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 59409803.62sec, total: 59409803.62sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 29704901.81sec, total: 29704901.82sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29704901.81sec, total: 29704901.81sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29704901.81sec, total: 29704901.81sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29704901.81sec, total: 29704901.81sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.29ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 231us, total: 1.45ms
      train.py:343:hfe, cpu: 495us, accelerator: 670us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 29704901.81sec, total: 29704901.81sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_155250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59314289.46sec, total: 59314289.46sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29657144.73sec, total: 29657144.73sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 29657144.73sec, total: 29657144.73sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 59314289.46sec, total: 59314289.47sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 29657144.74sec, total: 29657144.74sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29657144.73sec, total: 29657144.74sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29657144.73sec, total: 29657144.74sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29657144.73sec, total: 29657144.74sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 229us, total: 1.46ms
      train.py:343:hfe, cpu: 494us, accelerator: 670us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29657144.73sec, total: 29657144.74sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_155500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59219081.93sec, total: 59219081.93sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29609540.97sec, total: 29609540.97sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 29609540.97sec, total: 29609540.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 59219081.93sec, total: 59219081.94sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 29609540.97sec, total: 29609540.98sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29609540.97sec, total: 29609540.97sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29609540.97sec, total: 29609540.97sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29609540.97sec, total: 29609540.97sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.28ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 229us, total: 1.47ms
      train.py:343:hfe, cpu: 493us, accelerator: 670us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29609540.97sec, total: 29609540.97sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_155750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59124179.55sec, total: 59124179.56sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29562089.78sec, total: 29562089.78sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 29562089.78sec, total: 29562089.78sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 59124179.56sec, total: 59124179.56sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 29562089.78sec, total: 29562089.79sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29562089.78sec, total: 29562089.79sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29562089.78sec, total: 29562089.79sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29562089.78sec, total: 29562089.79sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 229us, total: 1.46ms
      train.py:343:hfe, cpu: 493us, accelerator: 670us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29562089.78sec, total: 29562089.79sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_156000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 59029580.87sec, total: 59029580.87sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29514790.44sec, total: 29514790.44sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29514790.44sec, total: 29514790.44sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 59029580.87sec, total: 59029580.88sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 29514790.44sec, total: 29514790.45sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29514790.44sec, total: 29514790.44sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 29514790.44sec, total: 29514790.44sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 29514790.44sec, total: 29514790.44sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 229us, total: 1.46ms
      train.py:343:hfe, cpu: 493us, accelerator: 669us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29514790.44sec, total: 29514790.44sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.79 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_156250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 58935284.41sec, total: 58935284.41sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29467642.21sec, total: 29467642.21sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29467642.21sec, total: 29467642.21sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58935284.42sec, total: 58935284.42sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 29467642.21sec, total: 29467642.22sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29467642.21sec, total: 29467642.21sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29467642.21sec, total: 29467642.21sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29467642.21sec, total: 29467642.21sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 229us, total: 1.46ms
      train.py:343:hfe, cpu: 493us, accelerator: 666us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29467642.21sec, total: 29467642.22sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2124.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_156500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 58841288.74sec, total: 58841288.75sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29420644.37sec, total: 29420644.38sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29420644.37sec, total: 29420644.38sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58841288.75sec, total: 58841288.75sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 29420644.38sec, total: 29420644.38sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29420644.38sec, total: 29420644.38sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29420644.38sec, total: 29420644.38sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29420644.38sec, total: 29420644.38sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 228us, total: 1.46ms
      train.py:343:hfe, cpu: 493us, accelerator: 668us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29420644.38sec, total: 29420644.38sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_156750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 58747592.42sec, total: 58747592.43sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29373796.21sec, total: 29373796.22sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29373796.21sec, total: 29373796.22sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58747592.43sec, total: 58747592.43sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 29373796.22sec, total: 29373796.22sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29373796.22sec, total: 29373796.22sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29373796.22sec, total: 29373796.22sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29373796.22sec, total: 29373796.22sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 229us, total: 1.46ms
      train.py:343:hfe, cpu: 493us, accelerator: 668us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29373796.22sec, total: 29373796.22sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_157000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 58654194.03sec, total: 58654194.03sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29327097.02sec, total: 29327097.02sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29327097.01sec, total: 29327097.02sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58654194.03sec, total: 58654194.03sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 29327097.02sec, total: 29327097.03sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29327097.02sec, total: 29327097.02sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29327097.02sec, total: 29327097.02sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29327097.02sec, total: 29327097.02sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.28ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 229us, total: 1.46ms
      train.py:343:hfe, cpu: 492us, accelerator: 666us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 29327097.02sec, total: 29327097.02sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.97 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_157250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 58561092.13sec, total: 58561092.13sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29280546.07sec, total: 29280546.07sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29280546.07sec, total: 29280546.07sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58561092.14sec, total: 58561092.14sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 29280546.07sec, total: 29280546.08sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29280546.07sec, total: 29280546.07sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29280546.07sec, total: 29280546.07sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29280546.07sec, total: 29280546.07sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.28ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.28ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 229us, total: 1.46ms
      train.py:343:hfe, cpu: 491us, accelerator: 669us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 29280546.07sec, total: 29280546.07sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_157500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 58468285.33sec, total: 58468285.33sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29234142.67sec, total: 29234142.67sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29234142.67sec, total: 29234142.67sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58468285.33sec, total: 58468285.34sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 29234142.67sec, total: 29234142.68sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29234142.67sec, total: 29234142.67sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29234142.67sec, total: 29234142.67sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29234142.67sec, total: 29234142.67sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.29ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 229us, total: 1.45ms
      train.py:343:hfe, cpu: 490us, accelerator: 671us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29234142.67sec, total: 29234142.67sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_157750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 58375772.22sec, total: 58375772.22sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29187886.11sec, total: 29187886.11sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29187886.11sec, total: 29187886.11sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58375772.22sec, total: 58375772.23sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 29187886.12sec, total: 29187886.12sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29187886.11sec, total: 29187886.12sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29187886.11sec, total: 29187886.12sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29187886.11sec, total: 29187886.12sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.29ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.29ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 229us, total: 1.45ms
      train.py:343:hfe, cpu: 490us, accelerator: 671us, total: 1.16ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29187886.11sec, total: 29187886.12sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2116.85 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_158000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 58283551.41sec, total: 58283551.41sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29141775.71sec, total: 29141775.71sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29141775.71sec, total: 29141775.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58283551.41sec, total: 58283551.42sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 29141775.71sec, total: 29141775.72sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 29141775.71sec, total: 29141775.71sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29141775.71sec, total: 29141775.71sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29141775.71sec, total: 29141775.71sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.30ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.30ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 228us, total: 1.45ms
      train.py:343:hfe, cpu: 489us, accelerator: 685us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29141775.71sec, total: 29141775.71sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_158250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 58191621.52sec, total: 58191621.52sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29095810.76sec, total: 29095810.76sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29095810.76sec, total: 29095810.76sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58191621.52sec, total: 58191621.53sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 29095810.77sec, total: 29095810.77sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 29095810.76sec, total: 29095810.77sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29095810.76sec, total: 29095810.77sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29095810.76sec, total: 29095810.77sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.29ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 489us, accelerator: 684us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29095810.76sec, total: 29095810.77sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_158500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 58099981.17sec, total: 58099981.17sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29049990.59sec, total: 29049990.59sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 29049990.59sec, total: 29049990.59sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58099981.17sec, total: 58099981.18sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 29049990.59sec, total: 29049990.60sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 29049990.59sec, total: 29049990.59sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29049990.59sec, total: 29049990.59sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29049990.59sec, total: 29049990.59sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 489us, accelerator: 684us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 29049990.59sec, total: 29049990.59sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_158750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 58008629.00sec, total: 58008629.00sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 29004314.50sec, total: 29004314.50sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 29004314.50sec, total: 29004314.50sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 58008629.00sec, total: 58008629.01sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 29004314.51sec, total: 29004314.51sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 29004314.50sec, total: 29004314.51sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 29004314.50sec, total: 29004314.51sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 29004314.50sec, total: 29004314.51sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.29ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 226us, total: 1.45ms
      train.py:343:hfe, cpu: 489us, accelerator: 684us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 29004314.50sec, total: 29004314.51sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_159000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 57917563.65sec, total: 57917563.65sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 28958781.83sec, total: 28958781.83sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 28958781.82sec, total: 28958781.83sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57917563.65sec, total: 57917563.65sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 28958781.83sec, total: 28958781.84sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 28958781.83sec, total: 28958781.83sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 28958781.83sec, total: 28958781.83sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 28958781.83sec, total: 28958781.83sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.29ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 226us, total: 1.45ms
      train.py:343:hfe, cpu: 488us, accelerator: 683us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28958781.83sec, total: 28958781.83sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_159250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 57826783.76sec, total: 57826783.77sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 28913391.89sec, total: 28913391.89sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 28913391.88sec, total: 28913391.89sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57826783.77sec, total: 57826783.77sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 28913391.89sec, total: 28913391.90sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 28913391.89sec, total: 28913391.89sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 28913391.89sec, total: 28913391.89sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 28913391.89sec, total: 28913391.89sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.29ms, total: 3.38ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 226us, total: 1.44ms
      train.py:343:hfe, cpu: 487us, accelerator: 682us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28913391.89sec, total: 28913391.89sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_159500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 57736288.02sec, total: 57736288.02sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 28868144.01sec, total: 28868144.01sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 28868144.01sec, total: 28868144.01sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57736288.02sec, total: 57736288.02sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 28868144.02sec, total: 28868144.02sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 28868144.01sec, total: 28868144.02sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 28868144.01sec, total: 28868144.02sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 28868144.01sec, total: 28868144.02sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.30ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.30ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.46ms
      train.py:343:hfe, cpu: 486us, accelerator: 686us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28868144.01sec, total: 28868144.02sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_159750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 57646075.07sec, total: 57646075.07sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 28823037.54sec, total: 28823037.54sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28823037.53sec, total: 28823037.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57646075.07sec, total: 57646075.07sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 28823037.54sec, total: 28823037.55sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 28823037.54sec, total: 28823037.54sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 28823037.54sec, total: 28823037.54sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 28823037.54sec, total: 28823037.54sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.41ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.29ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 486us, accelerator: 685us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28823037.54sec, total: 28823037.54sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_160000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 57556143.59sec, total: 57556143.59sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28778071.80sec, total: 28778071.80sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28778071.80sec, total: 28778071.80sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57556143.60sec, total: 57556143.60sec
train.py:442:<module>, cpu: 5.46ms, accelerator: 28778071.80sec, total: 28778071.81sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 28778071.80sec, total: 28778071.80sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 28778071.80sec, total: 28778071.80sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 28778071.80sec, total: 28778071.80sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.29ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 486us, accelerator: 684us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28778071.80sec, total: 28778071.80sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_160250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 57466492.28sec, total: 57466492.28sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28733246.14sec, total: 28733246.14sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28733246.14sec, total: 28733246.14sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57466492.28sec, total: 57466492.29sec
train.py:442:<module>, cpu: 5.45ms, accelerator: 28733246.15sec, total: 28733246.15sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 28733246.14sec, total: 28733246.15sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 28733246.14sec, total: 28733246.15sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 28733246.14sec, total: 28733246.15sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.29ms, total: 3.40ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.29ms, total: 3.39ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 486us, accelerator: 682us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28733246.14sec, total: 28733246.15sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_160500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 57377119.82sec, total: 57377119.82sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28688559.91sec, total: 28688559.91sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28688559.91sec, total: 28688559.91sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57377119.82sec, total: 57377119.83sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 28688559.92sec, total: 28688559.92sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28688559.91sec, total: 28688559.92sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28688559.91sec, total: 28688559.92sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28688559.91sec, total: 28688559.92sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.31ms, total: 3.40ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 487us, accelerator: 682us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28688559.91sec, total: 28688559.92sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_160750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 57288024.91sec, total: 57288024.91sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28644012.46sec, total: 28644012.46sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28644012.46sec, total: 28644012.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57288024.92sec, total: 57288024.92sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28644012.46sec, total: 28644012.47sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28644012.46sec, total: 28644012.46sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28644012.46sec, total: 28644012.46sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28644012.46sec, total: 28644012.46sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.31ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 227us, total: 1.46ms
      train.py:343:hfe, cpu: 488us, accelerator: 681us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28644012.46sec, total: 28644012.46sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_161000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 57199206.27sec, total: 57199206.27sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28599603.14sec, total: 28599603.14sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28599603.13sec, total: 28599603.14sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57199206.27sec, total: 57199206.28sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28599603.14sec, total: 28599603.15sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28599603.14sec, total: 28599603.14sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28599603.14sec, total: 28599603.14sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28599603.14sec, total: 28599603.14sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 226us, total: 1.46ms
      train.py:343:hfe, cpu: 487us, accelerator: 682us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28599603.14sec, total: 28599603.14sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2084.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_161250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 57110662.60sec, total: 57110662.61sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28555331.30sec, total: 28555331.31sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28555331.30sec, total: 28555331.31sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57110662.61sec, total: 57110662.61sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28555331.31sec, total: 28555331.32sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28555331.31sec, total: 28555331.31sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28555331.31sec, total: 28555331.31sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28555331.31sec, total: 28555331.31sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 226us, total: 1.46ms
      train.py:343:hfe, cpu: 486us, accelerator: 682us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28555331.31sec, total: 28555331.31sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_161500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 57022392.65sec, total: 57022392.65sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28511196.33sec, total: 28511196.33sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28511196.32sec, total: 28511196.33sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 57022392.65sec, total: 57022392.66sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28511196.33sec, total: 28511196.34sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28511196.33sec, total: 28511196.33sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28511196.33sec, total: 28511196.33sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28511196.33sec, total: 28511196.33sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 226us, total: 1.45ms
      train.py:343:hfe, cpu: 486us, accelerator: 687us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 28511196.33sec, total: 28511196.33sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_161750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 56934395.13sec, total: 56934395.13sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28467197.57sec, total: 28467197.57sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28467197.56sec, total: 28467197.57sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 56934395.13sec, total: 56934395.14sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 28467197.57sec, total: 28467197.58sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28467197.57sec, total: 28467197.57sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28467197.57sec, total: 28467197.57sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28467197.57sec, total: 28467197.57sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 226us, total: 1.45ms
      train.py:343:hfe, cpu: 488us, accelerator: 684us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 28467197.57sec, total: 28467197.57sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_162000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 56846668.79sec, total: 56846668.79sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28423334.40sec, total: 28423334.40sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28423334.39sec, total: 28423334.40sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 56846668.79sec, total: 56846668.80sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28423334.40sec, total: 28423334.41sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28423334.40sec, total: 28423334.40sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28423334.40sec, total: 28423334.40sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28423334.40sec, total: 28423334.40sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 226us, total: 1.45ms
      train.py:343:hfe, cpu: 488us, accelerator: 684us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 28423334.40sec, total: 28423334.40sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_162250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 56759212.37sec, total: 56759212.37sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28379606.19sec, total: 28379606.19sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28379606.19sec, total: 28379606.19sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 56759212.38sec, total: 56759212.38sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 28379606.19sec, total: 28379606.20sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28379606.19sec, total: 28379606.19sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28379606.19sec, total: 28379606.19sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28379606.19sec, total: 28379606.19sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 225us, total: 1.45ms
      train.py:343:hfe, cpu: 488us, accelerator: 683us, total: 1.17ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 28379606.19sec, total: 28379606.20sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.29 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_162500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 56672024.64sec, total: 56672024.64sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28336012.32sec, total: 28336012.33sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28336012.32sec, total: 28336012.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 56672024.65sec, total: 56672024.65sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 28336012.33sec, total: 28336012.33sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28336012.33sec, total: 28336012.33sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28336012.33sec, total: 28336012.33sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28336012.33sec, total: 28336012.33sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 225us, total: 1.45ms
      train.py:343:hfe, cpu: 508us, accelerator: 682us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 28336012.33sec, total: 28336012.33sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.41 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_162750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 56585104.36sec, total: 56585104.36sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28292552.18sec, total: 28292552.18sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28292552.18sec, total: 28292552.18sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 56585104.36sec, total: 56585104.37sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 28292552.19sec, total: 28292552.19sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28292552.19sec, total: 28292552.19sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28292552.19sec, total: 28292552.19sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28292552.18sec, total: 28292552.19sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 225us, total: 1.45ms
      train.py:343:hfe, cpu: 507us, accelerator: 679us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 28292552.18sec, total: 28292552.19sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_163000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 56498450.29sec, total: 56498450.30sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28249225.15sec, total: 28249225.15sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28249225.15sec, total: 28249225.15sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 56498450.30sec, total: 56498450.30sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28249225.15sec, total: 28249225.16sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28249225.15sec, total: 28249225.16sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28249225.15sec, total: 28249225.16sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28249225.15sec, total: 28249225.16sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 225us, total: 1.45ms
      train.py:343:hfe, cpu: 507us, accelerator: 678us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 28249225.15sec, total: 28249225.16sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_163250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 56412061.23sec, total: 56412061.23sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28206030.62sec, total: 28206030.62sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28206030.61sec, total: 28206030.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 56412061.23sec, total: 56412061.24sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28206030.62sec, total: 28206030.63sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28206030.62sec, total: 28206030.62sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28206030.62sec, total: 28206030.62sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28206030.62sec, total: 28206030.62sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 225us, total: 1.44ms
      train.py:343:hfe, cpu: 506us, accelerator: 678us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 28206030.62sec, total: 28206030.62sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_163500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 56325935.94sec, total: 56325935.94sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28162967.97sec, total: 28162967.98sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28162967.97sec, total: 28162967.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 56325935.95sec, total: 56325935.95sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28162967.98sec, total: 28162967.98sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28162967.98sec, total: 28162967.98sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28162967.98sec, total: 28162967.98sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28162967.98sec, total: 28162967.98sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 224us, total: 1.44ms
      train.py:343:hfe, cpu: 505us, accelerator: 678us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 28162967.98sec, total: 28162967.98sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.78 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_163750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 56240073.23sec, total: 56240073.24sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28120036.62sec, total: 28120036.62sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28120036.62sec, total: 28120036.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 56240073.24sec, total: 56240073.24sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28120036.62sec, total: 28120036.63sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28120036.62sec, total: 28120036.63sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28120036.62sec, total: 28120036.63sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28120036.62sec, total: 28120036.63sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.31ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.31ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 223us, total: 1.44ms
      train.py:343:hfe, cpu: 503us, accelerator: 678us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 28120036.62sec, total: 28120036.63sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_164000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 56154471.91sec, total: 56154471.91sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28077235.96sec, total: 28077235.96sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28077235.95sec, total: 28077235.96sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 56154471.91sec, total: 56154471.91sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28077235.96sec, total: 28077235.97sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28077235.96sec, total: 28077235.96sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28077235.96sec, total: 28077235.96sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28077235.96sec, total: 28077235.96sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.31ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.31ms, total: 3.41ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 222us, total: 1.44ms
      train.py:343:hfe, cpu: 503us, accelerator: 677us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 28077235.96sec, total: 28077235.96sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.31 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_164250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 56069130.76sec, total: 56069130.77sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 28034565.38sec, total: 28034565.39sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 28034565.38sec, total: 28034565.39sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 56069130.77sec, total: 56069130.77sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 28034565.39sec, total: 28034565.39sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 28034565.39sec, total: 28034565.39sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 28034565.39sec, total: 28034565.39sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 28034565.39sec, total: 28034565.39sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 222us, total: 1.44ms
      train.py:343:hfe, cpu: 505us, accelerator: 681us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 28034565.39sec, total: 28034565.39sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2068.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_164500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 55984048.62sec, total: 55984048.62sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 27992024.31sec, total: 27992024.32sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27992024.31sec, total: 27992024.31sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55984048.63sec, total: 55984048.63sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 27992024.32sec, total: 27992024.32sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27992024.32sec, total: 27992024.32sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27992024.32sec, total: 27992024.32sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27992024.32sec, total: 27992024.32sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.32ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.32ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 220us, total: 1.47ms
      train.py:343:hfe, cpu: 510us, accelerator: 680us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27992024.32sec, total: 27992024.32sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_164750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 55899224.31sec, total: 55899224.31sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27949612.16sec, total: 27949612.16sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27949612.15sec, total: 27949612.16sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55899224.31sec, total: 55899224.32sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 27949612.16sec, total: 27949612.17sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27949612.16sec, total: 27949612.16sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 27949612.16sec, total: 27949612.16sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27949612.16sec, total: 27949612.16sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.31ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.31ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 220us, total: 1.47ms
      train.py:343:hfe, cpu: 510us, accelerator: 679us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 27949612.16sec, total: 27949612.16sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_165000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 55814656.64sec, total: 55814656.65sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27907328.33sec, total: 27907328.33sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27907328.32sec, total: 27907328.33sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55814656.65sec, total: 55814656.65sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 27907328.33sec, total: 27907328.34sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27907328.33sec, total: 27907328.33sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 27907328.33sec, total: 27907328.33sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27907328.33sec, total: 27907328.33sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.31ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.14ms, accelerator: 1.31ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.25ms, accelerator: 220us, total: 1.47ms
      train.py:343:hfe, cpu: 510us, accelerator: 678us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 27907328.33sec, total: 27907328.33sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2073.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_165250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 55730344.47sec, total: 55730344.48sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27865172.24sec, total: 27865172.24sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27865172.24sec, total: 27865172.24sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55730344.48sec, total: 55730344.48sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 27865172.24sec, total: 27865172.25sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27865172.24sec, total: 27865172.25sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27865172.24sec, total: 27865172.25sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27865172.24sec, total: 27865172.25sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.31ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.31ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 220us, total: 1.47ms
      train.py:343:hfe, cpu: 510us, accelerator: 678us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27865172.24sec, total: 27865172.25sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_165500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 55646286.64sec, total: 55646286.64sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27823143.32sec, total: 27823143.32sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27823143.32sec, total: 27823143.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55646286.64sec, total: 55646286.65sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 27823143.33sec, total: 27823143.33sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27823143.33sec, total: 27823143.33sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27823143.33sec, total: 27823143.33sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27823143.33sec, total: 27823143.33sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.32ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 223us, total: 1.47ms
      train.py:343:hfe, cpu: 510us, accelerator: 685us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27823143.32sec, total: 27823143.33sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2079.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_165750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 55562481.99sec, total: 55562481.99sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27781241.00sec, total: 27781241.00sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27781241.00sec, total: 27781241.00sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55562482.00sec, total: 55562482.00sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 27781241.00sec, total: 27781241.01sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27781241.00sec, total: 27781241.00sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27781241.00sec, total: 27781241.00sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27781241.00sec, total: 27781241.00sec
  train.py:359:image_losses, cpu: 2.15ms, accelerator: 1.32ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 222us, total: 1.47ms
      train.py:343:hfe, cpu: 509us, accelerator: 683us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27781241.00sec, total: 27781241.00sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_166000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 55478929.39sec, total: 55478929.39sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27739464.70sec, total: 27739464.70sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27739464.69sec, total: 27739464.70sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55478929.39sec, total: 55478929.40sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 27739464.70sec, total: 27739464.71sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27739464.70sec, total: 27739464.70sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27739464.70sec, total: 27739464.70sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27739464.70sec, total: 27739464.70sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 223us, total: 1.47ms
      train.py:343:hfe, cpu: 508us, accelerator: 686us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27739464.70sec, total: 27739464.70sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_166250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 55395627.69sec, total: 55395627.69sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27697813.85sec, total: 27697813.85sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27697813.85sec, total: 27697813.85sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55395627.70sec, total: 55395627.70sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 27697813.85sec, total: 27697813.86sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27697813.85sec, total: 27697813.85sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27697813.85sec, total: 27697813.85sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27697813.85sec, total: 27697813.85sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 223us, total: 1.47ms
      train.py:343:hfe, cpu: 508us, accelerator: 685us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 27697813.85sec, total: 27697813.85sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.27 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_166500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 55312575.78sec, total: 55312575.78sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27656287.89sec, total: 27656287.89sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27656287.89sec, total: 27656287.89sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55312575.78sec, total: 55312575.78sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 27656287.90sec, total: 27656287.90sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27656287.89sec, total: 27656287.90sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27656287.89sec, total: 27656287.90sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27656287.89sec, total: 27656287.90sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 222us, total: 1.47ms
      train.py:343:hfe, cpu: 508us, accelerator: 686us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 27656287.89sec, total: 27656287.90sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.34 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_166750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 55229772.52sec, total: 55229772.52sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27614886.26sec, total: 27614886.26sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27614886.26sec, total: 27614886.26sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55229772.52sec, total: 55229772.53sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 27614886.27sec, total: 27614886.27sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27614886.26sec, total: 27614886.27sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27614886.26sec, total: 27614886.27sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27614886.26sec, total: 27614886.27sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 222us, total: 1.46ms
      train.py:343:hfe, cpu: 507us, accelerator: 686us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 27614886.26sec, total: 27614886.27sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.57 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_167000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 55147216.80sec, total: 55147216.81sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27573608.41sec, total: 27573608.41sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27573608.40sec, total: 27573608.41sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55147216.81sec, total: 55147216.81sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27573608.41sec, total: 27573608.42sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27573608.41sec, total: 27573608.41sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 27573608.41sec, total: 27573608.41sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 27573608.41sec, total: 27573608.41sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.33ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 222us, total: 1.46ms
      train.py:343:hfe, cpu: 507us, accelerator: 686us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 27573608.41sec, total: 27573608.41sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2120.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_167250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 55064907.53sec, total: 55064907.53sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 27532453.77sec, total: 27532453.77sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27532453.76sec, total: 27532453.77sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 55064907.53sec, total: 55064907.53sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 27532453.77sec, total: 27532453.78sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27532453.77sec, total: 27532453.77sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27532453.77sec, total: 27532453.77sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27532453.77sec, total: 27532453.77sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.32ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 221us, total: 1.46ms
      train.py:343:hfe, cpu: 507us, accelerator: 685us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27532453.77sec, total: 27532453.77sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_167500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 54982843.58sec, total: 54982843.58sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27491421.79sec, total: 27491421.79sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27491421.79sec, total: 27491421.79sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54982843.58sec, total: 54982843.59sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27491421.80sec, total: 27491421.80sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27491421.80sec, total: 27491421.80sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27491421.80sec, total: 27491421.80sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27491421.80sec, total: 27491421.80sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 221us, total: 1.46ms
      train.py:343:hfe, cpu: 506us, accelerator: 682us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 27491421.80sec, total: 27491421.80sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_167750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 54901023.87sec, total: 54901023.87sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27450511.94sec, total: 27450511.94sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27450511.94sec, total: 27450511.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54901023.88sec, total: 54901023.88sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27450511.94sec, total: 27450511.95sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27450511.94sec, total: 27450511.94sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27450511.94sec, total: 27450511.94sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27450511.94sec, total: 27450511.94sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 221us, total: 1.46ms
      train.py:343:hfe, cpu: 506us, accelerator: 682us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27450511.94sec, total: 27450511.95sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_168000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 54819447.31sec, total: 54819447.32sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27409723.66sec, total: 27409723.66sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27409723.66sec, total: 27409723.66sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54819447.32sec, total: 54819447.32sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 27409723.66sec, total: 27409723.67sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27409723.66sec, total: 27409723.67sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27409723.66sec, total: 27409723.67sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27409723.66sec, total: 27409723.67sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 221us, total: 1.46ms
      train.py:343:hfe, cpu: 506us, accelerator: 680us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27409723.66sec, total: 27409723.67sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_168250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 54738112.82sec, total: 54738112.82sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27369056.41sec, total: 27369056.42sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27369056.41sec, total: 27369056.41sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54738112.83sec, total: 54738112.83sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27369056.42sec, total: 27369056.42sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27369056.42sec, total: 27369056.42sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27369056.42sec, total: 27369056.42sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27369056.42sec, total: 27369056.42sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 221us, total: 1.46ms
      train.py:343:hfe, cpu: 506us, accelerator: 680us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27369056.42sec, total: 27369056.42sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.75 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_168500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 54657019.32sec, total: 54657019.32sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27328509.66sec, total: 27328509.67sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27328509.66sec, total: 27328509.66sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54657019.33sec, total: 54657019.33sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27328509.67sec, total: 27328509.67sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27328509.67sec, total: 27328509.67sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27328509.67sec, total: 27328509.67sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27328509.67sec, total: 27328509.67sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 221us, total: 1.47ms
      train.py:343:hfe, cpu: 506us, accelerator: 680us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27328509.67sec, total: 27328509.67sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.90 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_168750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 54576165.74sec, total: 54576165.75sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27288082.87sec, total: 27288082.88sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27288082.87sec, total: 27288082.87sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54576165.75sec, total: 54576165.75sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27288082.88sec, total: 27288082.88sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27288082.88sec, total: 27288082.88sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27288082.88sec, total: 27288082.88sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27288082.88sec, total: 27288082.88sec
  train.py:359:image_losses, cpu: 2.14ms, accelerator: 1.31ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.31ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 221us, total: 1.46ms
      train.py:343:hfe, cpu: 506us, accelerator: 679us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27288082.88sec, total: 27288082.88sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.50 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_169000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 54495551.02sec, total: 54495551.02sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 27247775.51sec, total: 27247775.52sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27247775.51sec, total: 27247775.51sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54495551.03sec, total: 54495551.03sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27247775.52sec, total: 27247775.52sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27247775.52sec, total: 27247775.52sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27247775.52sec, total: 27247775.52sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27247775.52sec, total: 27247775.52sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.31ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.31ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 221us, total: 1.46ms
      train.py:343:hfe, cpu: 507us, accelerator: 677us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27247775.52sec, total: 27247775.52sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_169250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 54415174.10sec, total: 54415174.11sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 27207587.05sec, total: 27207587.06sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27207587.05sec, total: 27207587.06sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54415174.11sec, total: 54415174.11sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27207587.06sec, total: 27207587.06sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27207587.06sec, total: 27207587.06sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27207587.06sec, total: 27207587.06sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27207587.06sec, total: 27207587.06sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 221us, total: 1.46ms
      train.py:343:hfe, cpu: 506us, accelerator: 677us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27207587.06sec, total: 27207587.06sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_169500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 54335033.94sec, total: 54335033.94sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 27167516.97sec, total: 27167516.97sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27167516.97sec, total: 27167516.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54335033.94sec, total: 54335033.94sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27167516.98sec, total: 27167516.98sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27167516.97sec, total: 27167516.98sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27167516.97sec, total: 27167516.98sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27167516.97sec, total: 27167516.98sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.31ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.31ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 221us, total: 1.46ms
      train.py:343:hfe, cpu: 505us, accelerator: 676us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27167516.97sec, total: 27167516.98sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_169750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 54255129.47sec, total: 54255129.48sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.26ms, accelerator: 27127564.74sec, total: 27127564.74sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27127564.74sec, total: 27127564.74sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54255129.48sec, total: 54255129.48sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27127564.74sec, total: 27127564.75sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27127564.74sec, total: 27127564.75sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27127564.74sec, total: 27127564.75sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27127564.74sec, total: 27127564.75sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.31ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.12ms, accelerator: 1.31ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 221us, total: 1.46ms
      train.py:343:hfe, cpu: 505us, accelerator: 676us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27127564.74sec, total: 27127564.75sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.42 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_170000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 54175459.68sec, total: 54175459.68sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 27087729.84sec, total: 27087729.84sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27087729.84sec, total: 27087729.84sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54175459.68sec, total: 54175459.69sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 27087729.85sec, total: 27087729.85sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27087729.85sec, total: 27087729.85sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27087729.85sec, total: 27087729.85sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27087729.85sec, total: 27087729.85sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 230us, total: 1.47ms
      train.py:343:hfe, cpu: 505us, accelerator: 676us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27087729.85sec, total: 27087729.85sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_170250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 54096023.52sec, total: 54096023.52sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 27048011.76sec, total: 27048011.77sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27048011.76sec, total: 27048011.76sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54096023.53sec, total: 54096023.53sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 27048011.77sec, total: 27048011.77sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27048011.77sec, total: 27048011.77sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 27048011.77sec, total: 27048011.77sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27048011.77sec, total: 27048011.77sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.32ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.32ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 230us, total: 1.47ms
      train.py:343:hfe, cpu: 504us, accelerator: 673us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 27048011.77sec, total: 27048011.77sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_170500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 54016819.97sec, total: 54016819.98sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 27008409.99sec, total: 27008409.99sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 27008409.99sec, total: 27008409.99sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 54016819.98sec, total: 54016819.98sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 27008409.99sec, total: 27008410.00sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 27008409.99sec, total: 27008410.00sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 27008409.99sec, total: 27008410.00sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 27008409.99sec, total: 27008410.00sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 230us, total: 1.47ms
      train.py:343:hfe, cpu: 504us, accelerator: 690us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 27008409.99sec, total: 27008410.00sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2122.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_170750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 53937848.01sec, total: 53937848.02sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26968924.01sec, total: 26968924.01sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26968924.01sec, total: 26968924.01sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 53937848.02sec, total: 53937848.02sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 26968924.01sec, total: 26968924.02sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26968924.01sec, total: 26968924.02sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 26968924.01sec, total: 26968924.02sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26968924.01sec, total: 26968924.02sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 230us, total: 1.46ms
      train.py:343:hfe, cpu: 504us, accelerator: 694us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26968924.01sec, total: 26968924.02sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_171000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 53859106.63sec, total: 53859106.63sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26929553.32sec, total: 26929553.32sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26929553.32sec, total: 26929553.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 53859106.64sec, total: 53859106.64sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26929553.32sec, total: 26929553.33sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26929553.32sec, total: 26929553.32sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26929553.32sec, total: 26929553.32sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26929553.32sec, total: 26929553.32sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 228us, total: 1.46ms
      train.py:343:hfe, cpu: 504us, accelerator: 694us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 26929553.32sec, total: 26929553.32sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.96 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_171250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 53780594.81sec, total: 53780594.82sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26890297.41sec, total: 26890297.41sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26890297.41sec, total: 26890297.41sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 53780594.82sec, total: 53780594.82sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26890297.41sec, total: 26890297.42sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26890297.41sec, total: 26890297.42sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 26890297.41sec, total: 26890297.42sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26890297.41sec, total: 26890297.42sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 228us, total: 1.46ms
      train.py:343:hfe, cpu: 503us, accelerator: 692us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 26890297.41sec, total: 26890297.42sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.15 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_171500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 53702311.56sec, total: 53702311.56sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26851155.78sec, total: 26851155.78sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26851155.78sec, total: 26851155.78sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 53702311.57sec, total: 53702311.57sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26851155.79sec, total: 26851155.79sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26851155.79sec, total: 26851155.79sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 26851155.79sec, total: 26851155.79sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26851155.79sec, total: 26851155.79sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 228us, total: 1.46ms
      train.py:343:hfe, cpu: 503us, accelerator: 691us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.08ms, accelerator: 26851155.79sec, total: 26851155.79sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_171750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 53624255.88sec, total: 53624255.88sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26812127.94sec, total: 26812127.94sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26812127.94sec, total: 26812127.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 53624255.88sec, total: 53624255.88sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26812127.95sec, total: 26812127.95sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26812127.94sec, total: 26812127.95sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 26812127.94sec, total: 26812127.95sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26812127.94sec, total: 26812127.95sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 228us, total: 1.46ms
      train.py:343:hfe, cpu: 502us, accelerator: 691us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26812127.94sec, total: 26812127.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_172000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 53546426.77sec, total: 53546426.77sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26773213.39sec, total: 26773213.39sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26773213.38sec, total: 26773213.39sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 53546426.77sec, total: 53546426.78sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26773213.39sec, total: 26773213.40sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26773213.39sec, total: 26773213.39sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 26773213.39sec, total: 26773213.39sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26773213.39sec, total: 26773213.39sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.36ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.36ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 227us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 712us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26773213.39sec, total: 26773213.39sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_172250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 53468823.25sec, total: 53468823.25sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26734411.63sec, total: 26734411.63sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26734411.63sec, total: 26734411.63sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 53468823.25sec, total: 53468823.26sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 26734411.63sec, total: 26734411.64sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26734411.63sec, total: 26734411.63sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 26734411.63sec, total: 26734411.63sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26734411.63sec, total: 26734411.63sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.35ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 227us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 711us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26734411.63sec, total: 26734411.63sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_172500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 53391444.34sec, total: 53391444.35sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26695722.18sec, total: 26695722.18sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.01ms, accelerator: 26695722.17sec, total: 26695722.18sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 53391444.35sec, total: 53391444.35sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26695722.18sec, total: 26695722.19sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26695722.18sec, total: 26695722.18sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 26695722.18sec, total: 26695722.18sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26695722.18sec, total: 26695722.18sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.35ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 225us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 710us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26695722.18sec, total: 26695722.18sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_172750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 53314289.08sec, total: 53314289.08sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26657144.54sec, total: 26657144.54sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26657144.54sec, total: 26657144.54sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 53314289.08sec, total: 53314289.09sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26657144.55sec, total: 26657144.55sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26657144.54sec, total: 26657144.55sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 26657144.54sec, total: 26657144.55sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26657144.54sec, total: 26657144.55sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 225us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 708us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26657144.54sec, total: 26657144.55sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_173000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 53237356.48sec, total: 53237356.48sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26618678.24sec, total: 26618678.25sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26618678.24sec, total: 26618678.24sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 53237356.49sec, total: 53237356.49sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26618678.25sec, total: 26618678.25sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26618678.25sec, total: 26618678.25sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 26618678.25sec, total: 26618678.25sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26618678.25sec, total: 26618678.25sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 225us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 706us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26618678.25sec, total: 26618678.25sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.40 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_173250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 53160645.59sec, total: 53160645.60sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26580322.80sec, total: 26580322.80sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26580322.80sec, total: 26580322.80sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 53160645.60sec, total: 53160645.60sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26580322.80sec, total: 26580322.81sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26580322.80sec, total: 26580322.81sec
    train.py:322:loss_fn, cpu: 2.84ms, accelerator: 26580322.80sec, total: 26580322.81sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26580322.80sec, total: 26580322.81sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 706us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26580322.80sec, total: 26580322.81sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.02 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_173500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 53084155.46sec, total: 53084155.46sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26542077.73sec, total: 26542077.73sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26542077.73sec, total: 26542077.73sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 53084155.46sec, total: 53084155.47sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26542077.74sec, total: 26542077.74sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26542077.73sec, total: 26542077.74sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26542077.73sec, total: 26542077.74sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26542077.73sec, total: 26542077.74sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 501us, accelerator: 713us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26542077.73sec, total: 26542077.74sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_173750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 53007885.12sec, total: 53007885.12sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26503942.56sec, total: 26503942.56sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26503942.56sec, total: 26503942.56sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 53007885.12sec, total: 53007885.13sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26503942.57sec, total: 26503942.57sec
  train.py:360:image_losses, cpu: 2.85ms, accelerator: 26503942.56sec, total: 26503942.57sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26503942.56sec, total: 26503942.57sec
      train.py:349:msssim, cpu: 2.79ms, accelerator: 26503942.56sec, total: 26503942.57sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 501us, accelerator: 713us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26503942.56sec, total: 26503942.57sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_174000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 52931833.63sec, total: 52931833.64sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26465916.82sec, total: 26465916.82sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26465916.82sec, total: 26465916.82sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 52931833.64sec, total: 52931833.64sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 26465916.82sec, total: 26465916.83sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26465916.82sec, total: 26465916.82sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26465916.82sec, total: 26465916.82sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26465916.82sec, total: 26465916.82sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.35ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 500us, accelerator: 713us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26465916.82sec, total: 26465916.83sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_174250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 52856000.06sec, total: 52856000.06sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26428000.03sec, total: 26428000.03sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26428000.03sec, total: 26428000.03sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 52856000.07sec, total: 52856000.07sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 26428000.04sec, total: 26428000.04sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26428000.04sec, total: 26428000.04sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26428000.04sec, total: 26428000.04sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26428000.04sec, total: 26428000.04sec
  train.py:359:image_losses, cpu: 2.13ms, accelerator: 1.35ms, total: 3.49ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.35ms, total: 3.47ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 521us, accelerator: 713us, total: 1.24ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26428000.04sec, total: 26428000.04sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_174500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 52780383.47sec, total: 52780383.47sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26390191.74sec, total: 26390191.74sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26390191.73sec, total: 26390191.74sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 52780383.47sec, total: 52780383.47sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26390191.74sec, total: 26390191.75sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26390191.74sec, total: 26390191.74sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26390191.74sec, total: 26390191.74sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26390191.74sec, total: 26390191.74sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.35ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 518us, accelerator: 709us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26390191.74sec, total: 26390191.74sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_174750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 52704982.92sec, total: 52704982.92sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26352491.46sec, total: 26352491.46sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26352491.46sec, total: 26352491.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 52704982.92sec, total: 52704982.93sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26352491.47sec, total: 26352491.47sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26352491.46sec, total: 26352491.47sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26352491.46sec, total: 26352491.47sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26352491.46sec, total: 26352491.47sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.35ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 518us, accelerator: 709us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26352491.46sec, total: 26352491.47sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_175000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 52629797.49sec, total: 52629797.49sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26314898.75sec, total: 26314898.75sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26314898.75sec, total: 26314898.75sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 52629797.50sec, total: 52629797.50sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26314898.75sec, total: 26314898.76sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26314898.75sec, total: 26314898.75sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26314898.75sec, total: 26314898.75sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26314898.75sec, total: 26314898.75sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.44ms
      train.py:343:hfe, cpu: 516us, accelerator: 707us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26314898.75sec, total: 26314898.76sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2113.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_175250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 52554826.27sec, total: 52554826.27sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.25ms, accelerator: 26277413.14sec, total: 26277413.14sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26277413.14sec, total: 26277413.14sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 52554826.28sec, total: 52554826.28sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 26277413.14sec, total: 26277413.15sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26277413.14sec, total: 26277413.14sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26277413.14sec, total: 26277413.14sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26277413.14sec, total: 26277413.14sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 227us, total: 1.44ms
      train.py:343:hfe, cpu: 516us, accelerator: 707us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.09ms, accelerator: 26277413.14sec, total: 26277413.14sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_175500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 52480068.34sec, total: 52480068.34sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 26240034.17sec, total: 26240034.17sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26240034.17sec, total: 26240034.17sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 52480068.34sec, total: 52480068.35sec
train.py:442:<module>, cpu: 5.50ms, accelerator: 26240034.18sec, total: 26240034.18sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26240034.17sec, total: 26240034.18sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26240034.17sec, total: 26240034.18sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26240034.17sec, total: 26240034.18sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.45ms
      train.py:343:hfe, cpu: 516us, accelerator: 706us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 26240034.17sec, total: 26240034.18sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_175750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 52405522.79sec, total: 52405522.79sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 26202761.40sec, total: 26202761.40sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26202761.40sec, total: 26202761.40sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 52405522.79sec, total: 52405522.80sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 26202761.40sec, total: 26202761.41sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26202761.40sec, total: 26202761.40sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26202761.40sec, total: 26202761.40sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26202761.40sec, total: 26202761.40sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 227us, total: 1.44ms
      train.py:343:hfe, cpu: 516us, accelerator: 705us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 26202761.40sec, total: 26202761.40sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.22 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_176000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 52331188.71sec, total: 52331188.71sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 26165594.36sec, total: 26165594.36sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26165594.36sec, total: 26165594.36sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 52331188.72sec, total: 52331188.72sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 26165594.36sec, total: 26165594.37sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26165594.36sec, total: 26165594.36sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26165594.36sec, total: 26165594.36sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26165594.36sec, total: 26165594.36sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.35ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 238us, total: 1.46ms
      train.py:343:hfe, cpu: 516us, accelerator: 709us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 26165594.36sec, total: 26165594.37sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2111.92 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_176250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 52257065.22sec, total: 52257065.22sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 26128532.61sec, total: 26128532.61sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26128532.61sec, total: 26128532.61sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 52257065.22sec, total: 52257065.22sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 26128532.62sec, total: 26128532.62sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26128532.61sec, total: 26128532.62sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26128532.61sec, total: 26128532.62sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26128532.61sec, total: 26128532.62sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.48ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 238us, total: 1.46ms
      train.py:343:hfe, cpu: 516us, accelerator: 707us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 26128532.61sec, total: 26128532.62sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2094.44 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_176500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 52183151.40sec, total: 52183151.41sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 26091575.70sec, total: 26091575.71sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26091575.70sec, total: 26091575.71sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 52183151.41sec, total: 52183151.41sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 26091575.71sec, total: 26091575.71sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26091575.71sec, total: 26091575.71sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26091575.71sec, total: 26091575.71sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26091575.71sec, total: 26091575.71sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.35ms, total: 3.46ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 238us, total: 1.45ms
      train.py:343:hfe, cpu: 516us, accelerator: 706us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 26091575.71sec, total: 26091575.71sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2076.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_176750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 52109446.39sec, total: 52109446.39sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 26054723.20sec, total: 26054723.20sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26054723.20sec, total: 26054723.20sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 52109446.39sec, total: 52109446.40sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 26054723.20sec, total: 26054723.21sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26054723.20sec, total: 26054723.20sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26054723.20sec, total: 26054723.20sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26054723.20sec, total: 26054723.20sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.35ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 238us, total: 1.45ms
      train.py:343:hfe, cpu: 516us, accelerator: 705us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 26054723.20sec, total: 26054723.20sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_177000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 52035949.28sec, total: 52035949.29sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 26017974.64sec, total: 26017974.65sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 26017974.64sec, total: 26017974.65sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 52035949.29sec, total: 52035949.29sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 26017974.65sec, total: 26017974.65sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 26017974.65sec, total: 26017974.65sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 26017974.65sec, total: 26017974.65sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 26017974.65sec, total: 26017974.65sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.35ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 238us, total: 1.45ms
      train.py:343:hfe, cpu: 516us, accelerator: 704us, total: 1.23ms
train.py:436:<module> (gradient), cpu: 4.10ms, accelerator: 26017974.65sec, total: 26017974.65sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.20 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_177250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51962659.21sec, total: 51962659.22sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25981329.61sec, total: 25981329.61sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25981329.61sec, total: 25981329.61sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 51962659.22sec, total: 51962659.22sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25981329.61sec, total: 25981329.62sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 25981329.61sec, total: 25981329.62sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 25981329.61sec, total: 25981329.62sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 25981329.61sec, total: 25981329.62sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.35ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 238us, total: 1.45ms
      train.py:343:hfe, cpu: 516us, accelerator: 703us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 25981329.61sec, total: 25981329.62sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_177500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51889575.31sec, total: 51889575.31sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25944787.66sec, total: 25944787.66sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25944787.65sec, total: 25944787.66sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 51889575.31sec, total: 51889575.31sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25944787.66sec, total: 25944787.67sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 25944787.66sec, total: 25944787.66sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25944787.66sec, total: 25944787.66sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25944787.66sec, total: 25944787.66sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 236us, total: 1.45ms
      train.py:343:hfe, cpu: 515us, accelerator: 702us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 25944787.66sec, total: 25944787.66sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_177750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51816696.69sec, total: 51816696.69sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25908348.35sec, total: 25908348.35sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25908348.35sec, total: 25908348.35sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 51816696.69sec, total: 51816696.70sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25908348.35sec, total: 25908348.36sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 25908348.35sec, total: 25908348.35sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 25908348.35sec, total: 25908348.35sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 25908348.35sec, total: 25908348.35sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 235us, total: 1.45ms
      train.py:343:hfe, cpu: 515us, accelerator: 701us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 25908348.35sec, total: 25908348.35sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.53 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_178000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51744022.50sec, total: 51744022.50sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25872011.25sec, total: 25872011.25sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25872011.25sec, total: 25872011.25sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 51744022.50sec, total: 51744022.51sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25872011.26sec, total: 25872011.26sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 25872011.26sec, total: 25872011.26sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25872011.26sec, total: 25872011.26sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25872011.26sec, total: 25872011.26sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 234us, total: 1.45ms
      train.py:343:hfe, cpu: 515us, accelerator: 700us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 25872011.25sec, total: 25872011.26sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.06 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_178250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51671551.88sec, total: 51671551.88sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25835775.94sec, total: 25835775.94sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25835775.94sec, total: 25835775.94sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 51671551.88sec, total: 51671551.89sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25835775.95sec, total: 25835775.95sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 25835775.95sec, total: 25835775.95sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25835775.95sec, total: 25835775.95sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25835775.95sec, total: 25835775.95sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 234us, total: 1.45ms
      train.py:343:hfe, cpu: 515us, accelerator: 699us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 25835775.94sec, total: 25835775.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_178500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51599283.97sec, total: 51599283.98sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25799641.99sec, total: 25799641.99sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25799641.99sec, total: 25799641.99sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 51599283.98sec, total: 51599283.98sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25799641.99sec, total: 25799642.00sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 25799641.99sec, total: 25799642.00sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25799641.99sec, total: 25799642.00sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25799641.99sec, total: 25799642.00sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 233us, total: 1.45ms
      train.py:343:hfe, cpu: 515us, accelerator: 697us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 25799641.99sec, total: 25799642.00sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.47 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_178750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51527217.94sec, total: 51527217.94sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25763608.97sec, total: 25763608.97sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25763608.97sec, total: 25763608.97sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 51527217.94sec, total: 51527217.94sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 25763608.98sec, total: 25763608.98sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25763608.97sec, total: 25763608.98sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25763608.97sec, total: 25763608.98sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25763608.97sec, total: 25763608.98sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 232us, total: 1.45ms
      train.py:343:hfe, cpu: 515us, accelerator: 697us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 25763608.97sec, total: 25763608.98sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.63 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_179000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51455352.92sec, total: 51455352.92sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25727676.46sec, total: 25727676.46sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25727676.46sec, total: 25727676.46sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 51455352.92sec, total: 51455352.93sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25727676.47sec, total: 25727676.47sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25727676.46sec, total: 25727676.47sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25727676.46sec, total: 25727676.47sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25727676.46sec, total: 25727676.47sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 232us, total: 1.45ms
      train.py:343:hfe, cpu: 514us, accelerator: 700us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 25727676.46sec, total: 25727676.47sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_179250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51383688.08sec, total: 51383688.08sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25691844.04sec, total: 25691844.04sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25691844.04sec, total: 25691844.04sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 51383688.09sec, total: 51383688.09sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25691844.05sec, total: 25691844.05sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25691844.05sec, total: 25691844.05sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25691844.05sec, total: 25691844.05sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25691844.05sec, total: 25691844.05sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 232us, total: 1.45ms
      train.py:343:hfe, cpu: 514us, accelerator: 699us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 25691844.05sec, total: 25691844.05sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2122.00 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_179500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 51312222.59sec, total: 51312222.59sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25656111.30sec, total: 25656111.30sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.02ms, accelerator: 25656111.30sec, total: 25656111.30sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 51312222.59sec, total: 51312222.60sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 25656111.30sec, total: 25656111.31sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25656111.30sec, total: 25656111.30sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25656111.30sec, total: 25656111.30sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25656111.30sec, total: 25656111.30sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 232us, total: 1.45ms
      train.py:343:hfe, cpu: 513us, accelerator: 699us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.11ms, accelerator: 25656111.30sec, total: 25656111.30sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.56 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_179750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51240955.61sec, total: 51240955.62sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25620477.81sec, total: 25620477.81sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 25620477.81sec, total: 25620477.81sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 51240955.62sec, total: 51240955.62sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 25620477.81sec, total: 25620477.82sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 25620477.81sec, total: 25620477.82sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25620477.81sec, total: 25620477.82sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25620477.81sec, total: 25620477.82sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 232us, total: 1.45ms
      train.py:343:hfe, cpu: 513us, accelerator: 699us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 25620477.81sec, total: 25620477.82sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_180000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51169886.33sec, total: 51169886.33sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25584943.17sec, total: 25584943.17sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 25584943.17sec, total: 25584943.17sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 51169886.33sec, total: 51169886.34sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 25584943.17sec, total: 25584943.18sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25584943.17sec, total: 25584943.17sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25584943.17sec, total: 25584943.17sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25584943.17sec, total: 25584943.17sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 232us, total: 1.44ms
      train.py:343:hfe, cpu: 513us, accelerator: 698us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 25584943.17sec, total: 25584943.17sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_180250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 51099013.91sec, total: 51099013.91sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25549506.96sec, total: 25549506.96sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 25549506.96sec, total: 25549506.96sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 51099013.91sec, total: 51099013.92sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 25549506.96sec, total: 25549506.97sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25549506.96sec, total: 25549506.96sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25549506.96sec, total: 25549506.96sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25549506.96sec, total: 25549506.96sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 232us, total: 1.44ms
      train.py:343:hfe, cpu: 513us, accelerator: 697us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 25549506.96sec, total: 25549506.96sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_180500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 51028337.54sec, total: 51028337.54sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25514168.77sec, total: 25514168.77sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 25514168.77sec, total: 25514168.77sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 51028337.55sec, total: 51028337.55sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 25514168.78sec, total: 25514168.78sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25514168.78sec, total: 25514168.78sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25514168.78sec, total: 25514168.78sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25514168.78sec, total: 25514168.78sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 513us, accelerator: 696us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 25514168.78sec, total: 25514168.78sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.38 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_180750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 50957856.41sec, total: 50957856.41sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25478928.21sec, total: 25478928.21sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.03ms, accelerator: 25478928.21sec, total: 25478928.21sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 50957856.42sec, total: 50957856.42sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 25478928.21sec, total: 25478928.22sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25478928.21sec, total: 25478928.21sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25478928.21sec, total: 25478928.21sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25478928.21sec, total: 25478928.21sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 512us, accelerator: 694us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 25478928.21sec, total: 25478928.22sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.18 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_181000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 50887569.71sec, total: 50887569.72sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25443784.86sec, total: 25443784.86sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 25443784.86sec, total: 25443784.86sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 50887569.72sec, total: 50887569.72sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25443784.86sec, total: 25443784.87sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25443784.86sec, total: 25443784.86sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25443784.86sec, total: 25443784.86sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25443784.86sec, total: 25443784.86sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 232us, total: 1.45ms
      train.py:343:hfe, cpu: 510us, accelerator: 694us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25443784.86sec, total: 25443784.87sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.30 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_181250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 50817476.64sec, total: 50817476.64sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25408738.32sec, total: 25408738.33sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 25408738.32sec, total: 25408738.32sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 50817476.65sec, total: 50817476.65sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 25408738.33sec, total: 25408738.33sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25408738.33sec, total: 25408738.33sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25408738.33sec, total: 25408738.33sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25408738.33sec, total: 25408738.33sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 233us, total: 1.46ms
      train.py:343:hfe, cpu: 510us, accelerator: 699us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25408738.33sec, total: 25408738.33sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.49 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_181500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 50747576.40sec, total: 50747576.40sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25373788.20sec, total: 25373788.20sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 25373788.20sec, total: 25373788.20sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 50747576.40sec, total: 50747576.41sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 25373788.21sec, total: 25373788.21sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25373788.20sec, total: 25373788.21sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25373788.20sec, total: 25373788.21sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25373788.20sec, total: 25373788.21sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 233us, total: 1.46ms
      train.py:343:hfe, cpu: 510us, accelerator: 699us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25373788.20sec, total: 25373788.21sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.65 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_181750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 50677868.19sec, total: 50677868.19sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25338934.10sec, total: 25338934.10sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 25338934.10sec, total: 25338934.10sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 50677868.19sec, total: 50677868.20sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 25338934.10sec, total: 25338934.11sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25338934.10sec, total: 25338934.10sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25338934.10sec, total: 25338934.10sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25338934.10sec, total: 25338934.10sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 510us, accelerator: 699us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25338934.10sec, total: 25338934.10sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.07 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_182000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 50608351.22sec, total: 50608351.23sec (33.33%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25304175.61sec, total: 25304175.62sec (16.67%)
top 3 operation type: Conv2DBackpropFilter, cpu: 2.04ms, accelerator: 25304175.61sec, total: 25304175.62sec (16.67%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: decoder, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 50608351.23sec, total: 50608351.23sec
train.py:442:<module>, cpu: 5.49ms, accelerator: 25304175.62sec, total: 25304175.62sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25304175.62sec, total: 25304175.62sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25304175.62sec, total: 25304175.62sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25304175.62sec, total: 25304175.62sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 509us, accelerator: 698us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25304175.62sec, total: 25304175.62sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.94 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_182250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 50539024.72sec, total: 50539024.72sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25269512.36sec, total: 25269512.36sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.41ms, accelerator: 25269512.36sec, total: 25269512.36sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 50539024.72sec, total: 50539024.72sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25269512.37sec, total: 25269512.37sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25269512.36sec, total: 25269512.37sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 25269512.36sec, total: 25269512.37sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25269512.36sec, total: 25269512.37sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 235us, total: 1.46ms
      train.py:343:hfe, cpu: 508us, accelerator: 701us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25269512.36sec, total: 25269512.37sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.50
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_182500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 50469887.88sec, total: 50469887.88sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25234943.94sec, total: 25234943.95sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.41ms, accelerator: 25234943.94sec, total: 25234943.94sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 50469887.89sec, total: 50469887.89sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25234943.95sec, total: 25234943.95sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25234943.95sec, total: 25234943.95sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 25234943.95sec, total: 25234943.95sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25234943.95sec, total: 25234943.95sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 509us, accelerator: 700us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 25234943.95sec, total: 25234943.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2107.37 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_182750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 50400939.95sec, total: 50400939.95sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25200469.98sec, total: 25200469.98sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.41ms, accelerator: 25200469.97sec, total: 25200469.98sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 50400939.95sec, total: 50400939.96sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25200469.98sec, total: 25200469.99sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25200469.98sec, total: 25200469.98sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 25200469.98sec, total: 25200469.98sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25200469.98sec, total: 25200469.98sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 509us, accelerator: 698us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25200469.98sec, total: 25200469.98sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2085.23 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_183000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 50332180.14sec, total: 50332180.14sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.27ms, accelerator: 25166090.07sec, total: 25166090.07sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.41ms, accelerator: 25166090.07sec, total: 25166090.07sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.16ms, accelerator: 50332180.14sec, total: 50332180.15sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25166090.08sec, total: 25166090.08sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25166090.08sec, total: 25166090.08sec
    train.py:322:loss_fn, cpu: 2.81ms, accelerator: 25166090.08sec, total: 25166090.08sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25166090.08sec, total: 25166090.08sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 237us, total: 1.46ms
      train.py:343:hfe, cpu: 508us, accelerator: 706us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 25166090.07sec, total: 25166090.08sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_183250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 50263607.69sec, total: 50263607.69sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 25131803.85sec, total: 25131803.85sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.41ms, accelerator: 25131803.84sec, total: 25131803.85sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 50263607.69sec, total: 50263607.70sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25131803.85sec, total: 25131803.86sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25131803.85sec, total: 25131803.85sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25131803.85sec, total: 25131803.85sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25131803.85sec, total: 25131803.85sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 237us, total: 1.46ms
      train.py:343:hfe, cpu: 509us, accelerator: 706us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25131803.85sec, total: 25131803.85sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.05 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_183500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.45ms, accelerator: 50195221.83sec, total: 50195221.83sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 25097610.92sec, total: 25097610.92sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.41ms, accelerator: 25097610.91sec, total: 25097610.92sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 50195221.83sec, total: 50195221.83sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25097610.92sec, total: 25097610.93sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25097610.92sec, total: 25097610.92sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25097610.92sec, total: 25097610.92sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25097610.92sec, total: 25097610.92sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 235us, total: 1.46ms
      train.py:343:hfe, cpu: 508us, accelerator: 703us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25097610.92sec, total: 25097610.92sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2112.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_183750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 50127021.80sec, total: 50127021.80sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 25063510.90sec, total: 25063510.90sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.41ms, accelerator: 25063510.90sec, total: 25063510.90sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 50127021.80sec, total: 50127021.81sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25063510.91sec, total: 25063510.91sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25063510.90sec, total: 25063510.91sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25063510.90sec, total: 25063510.91sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25063510.90sec, total: 25063510.91sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 235us, total: 1.46ms
      train.py:343:hfe, cpu: 508us, accelerator: 702us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25063510.90sec, total: 25063510.91sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_184000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 50059006.84sec, total: 50059006.84sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 25029503.42sec, total: 25029503.42sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.41ms, accelerator: 25029503.42sec, total: 25029503.42sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 50059006.85sec, total: 50059006.85sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 25029503.43sec, total: 25029503.43sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 25029503.43sec, total: 25029503.43sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 25029503.43sec, total: 25029503.43sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 25029503.43sec, total: 25029503.43sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 235us, total: 1.45ms
      train.py:343:hfe, cpu: 508us, accelerator: 701us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 25029503.43sec, total: 25029503.43sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.28 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_184250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 49991176.21sec, total: 49991176.21sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24995588.11sec, total: 24995588.11sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.41ms, accelerator: 24995588.10sec, total: 24995588.11sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 49991176.21sec, total: 49991176.22sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 24995588.11sec, total: 24995588.12sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 24995588.11sec, total: 24995588.11sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 24995588.11sec, total: 24995588.11sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 24995588.11sec, total: 24995588.11sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 235us, total: 1.45ms
      train.py:343:hfe, cpu: 508us, accelerator: 707us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24995588.11sec, total: 24995588.11sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.62 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_184500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 49923529.15sec, total: 49923529.15sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24961764.58sec, total: 24961764.58sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.41ms, accelerator: 24961764.58sec, total: 24961764.58sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 49923529.16sec, total: 49923529.16sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 24961764.58sec, total: 24961764.59sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 24961764.58sec, total: 24961764.58sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 24961764.58sec, total: 24961764.58sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 24961764.58sec, total: 24961764.58sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 235us, total: 1.45ms
      train.py:343:hfe, cpu: 507us, accelerator: 706us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24961764.58sec, total: 24961764.58sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2097.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_184750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 49856064.92sec, total: 49856064.92sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24928032.46sec, total: 24928032.47sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24928032.46sec, total: 24928032.46sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 49856064.93sec, total: 49856064.93sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 24928032.47sec, total: 24928032.47sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 24928032.47sec, total: 24928032.47sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 24928032.47sec, total: 24928032.47sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 24928032.47sec, total: 24928032.47sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 235us, total: 1.45ms
      train.py:343:hfe, cpu: 507us, accelerator: 706us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24928032.47sec, total: 24928032.47sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.32 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_185000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 49788782.78sec, total: 49788782.79sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24894391.39sec, total: 24894391.40sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24894391.39sec, total: 24894391.40sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 49788782.79sec, total: 49788782.79sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 24894391.40sec, total: 24894391.40sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 24894391.40sec, total: 24894391.40sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 24894391.40sec, total: 24894391.40sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 24894391.40sec, total: 24894391.40sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 236us, total: 1.46ms
      train.py:343:hfe, cpu: 507us, accelerator: 707us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24894391.40sec, total: 24894391.40sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_185250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 49721682.00sec, total: 49721682.00sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24860841.00sec, total: 24860841.00sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24860841.00sec, total: 24860841.00sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 49721682.00sec, total: 49721682.01sec
train.py:442:<module>, cpu: 5.48ms, accelerator: 24860841.01sec, total: 24860841.01sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 24860841.00sec, total: 24860841.01sec
    train.py:322:loss_fn, cpu: 2.83ms, accelerator: 24860841.00sec, total: 24860841.01sec
      train.py:349:msssim, cpu: 2.78ms, accelerator: 24860841.00sec, total: 24860841.01sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 236us, total: 1.46ms
      train.py:343:hfe, cpu: 507us, accelerator: 705us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24860841.00sec, total: 24860841.01sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.76 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_185500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 49654761.83sec, total: 49654761.84sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24827380.92sec, total: 24827380.92sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24827380.92sec, total: 24827380.92sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 49654761.84sec, total: 49654761.84sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 24827380.92sec, total: 24827380.93sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 24827380.92sec, total: 24827380.92sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 24827380.92sec, total: 24827380.92sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 24827380.92sec, total: 24827380.92sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 236us, total: 1.45ms
      train.py:343:hfe, cpu: 507us, accelerator: 704us, total: 1.22ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24827380.92sec, total: 24827380.93sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2091.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_185750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 49588021.56sec, total: 49588021.56sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24794010.78sec, total: 24794010.79sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24794010.78sec, total: 24794010.78sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 49588021.57sec, total: 49588021.57sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 24794010.79sec, total: 24794010.79sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 24794010.79sec, total: 24794010.79sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 24794010.79sec, total: 24794010.79sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 24794010.79sec, total: 24794010.79sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 236us, total: 1.45ms
      train.py:343:hfe, cpu: 506us, accelerator: 704us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24794010.79sec, total: 24794010.79sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.24 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_186000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 49521460.46sec, total: 49521460.46sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24760730.23sec, total: 24760730.23sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24760730.23sec, total: 24760730.23sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 49521460.46sec, total: 49521460.47sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 24760730.24sec, total: 24760730.24sec
  train.py:360:image_losses, cpu: 2.84ms, accelerator: 24760730.23sec, total: 24760730.24sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 24760730.23sec, total: 24760730.24sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 24760730.23sec, total: 24760730.24sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 236us, total: 1.45ms
      train.py:343:hfe, cpu: 506us, accelerator: 704us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24760730.23sec, total: 24760730.24sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2105.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_186250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.44ms, accelerator: 49455077.80sec, total: 49455077.81sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24727538.91sec, total: 24727538.91sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24727538.90sec, total: 24727538.91sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 49455077.81sec, total: 49455077.81sec
train.py:442:<module>, cpu: 5.47ms, accelerator: 24727538.91sec, total: 24727538.92sec
  train.py:360:image_losses, cpu: 2.83ms, accelerator: 24727538.91sec, total: 24727538.91sec
    train.py:322:loss_fn, cpu: 2.82ms, accelerator: 24727538.91sec, total: 24727538.91sec
      train.py:349:msssim, cpu: 2.77ms, accelerator: 24727538.91sec, total: 24727538.91sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 236us, total: 1.45ms
      train.py:343:hfe, cpu: 505us, accelerator: 702us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24727538.91sec, total: 24727538.91sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2095.55 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_186500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 49388872.88sec, total: 49388872.88sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24694436.44sec, total: 24694436.44sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24694436.44sec, total: 24694436.44sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 49388872.89sec, total: 49388872.89sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 24694436.45sec, total: 24694436.45sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 24694436.45sec, total: 24694436.45sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24694436.45sec, total: 24694436.45sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24694436.45sec, total: 24694436.45sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.34ms, total: 3.43ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.34ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 236us, total: 1.45ms
      train.py:343:hfe, cpu: 503us, accelerator: 702us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24694436.45sec, total: 24694436.45sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.12 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_186750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 49322844.98sec, total: 49322844.98sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24661422.49sec, total: 24661422.49sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24661422.49sec, total: 24661422.49sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 49322844.98sec, total: 49322844.99sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 24661422.50sec, total: 24661422.50sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24661422.49sec, total: 24661422.50sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24661422.49sec, total: 24661422.50sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24661422.49sec, total: 24661422.50sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.33ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 235us, total: 1.45ms
      train.py:343:hfe, cpu: 502us, accelerator: 700us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24661422.49sec, total: 24661422.50sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.54 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_187000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 49256993.38sec, total: 49256993.38sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24628496.69sec, total: 24628496.69sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24628496.69sec, total: 24628496.69sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 49256993.39sec, total: 49256993.39sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 24628496.70sec, total: 24628496.70sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24628496.70sec, total: 24628496.70sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24628496.70sec, total: 24628496.70sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24628496.70sec, total: 24628496.70sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 235us, total: 1.45ms
      train.py:343:hfe, cpu: 502us, accelerator: 701us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24628496.70sec, total: 24628496.70sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_187250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 49191317.39sec, total: 49191317.39sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24595658.70sec, total: 24595658.70sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24595658.70sec, total: 24595658.70sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 49191317.39sec, total: 49191317.40sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 24595658.70sec, total: 24595658.71sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24595658.70sec, total: 24595658.70sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24595658.70sec, total: 24595658.70sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24595658.70sec, total: 24595658.70sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 235us, total: 1.45ms
      train.py:343:hfe, cpu: 501us, accelerator: 701us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24595658.70sec, total: 24595658.70sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.67 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_187500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 49125816.30sec, total: 49125816.30sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24562908.15sec, total: 24562908.15sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24562908.15sec, total: 24562908.15sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 49125816.31sec, total: 49125816.31sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 24562908.16sec, total: 24562908.16sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24562908.16sec, total: 24562908.16sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24562908.16sec, total: 24562908.16sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24562908.16sec, total: 24562908.16sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.07ms, accelerator: 1.34ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.21ms, accelerator: 235us, total: 1.45ms
      train.py:343:hfe, cpu: 501us, accelerator: 701us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24562908.16sec, total: 24562908.16sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_187750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 49060489.42sec, total: 49060489.42sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24530244.71sec, total: 24530244.71sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24530244.71sec, total: 24530244.71sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 49060489.42sec, total: 49060489.43sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 24530244.72sec, total: 24530244.72sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24530244.71sec, total: 24530244.72sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24530244.71sec, total: 24530244.72sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24530244.71sec, total: 24530244.72sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 235us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 701us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24530244.71sec, total: 24530244.72sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_188000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48995336.05sec, total: 48995336.05sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24497668.03sec, total: 24497668.03sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24497668.02sec, total: 24497668.03sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.19ms, accelerator: 48995336.05sec, total: 48995336.05sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 24497668.03sec, total: 24497668.04sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24497668.03sec, total: 24497668.03sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24497668.03sec, total: 24497668.03sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24497668.03sec, total: 24497668.03sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 701us, total: 1.21ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24497668.03sec, total: 24497668.03sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2115.03 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_188250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48930355.49sec, total: 48930355.50sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24465177.75sec, total: 24465177.75sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24465177.75sec, total: 24465177.75sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48930355.50sec, total: 48930355.50sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 24465177.75sec, total: 24465177.76sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24465177.75sec, total: 24465177.76sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24465177.75sec, total: 24465177.75sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24465177.75sec, total: 24465177.75sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 234us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 700us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24465177.75sec, total: 24465177.76sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2122.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_188500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48865547.08sec, total: 48865547.08sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 24432773.54sec, total: 24432773.54sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24432773.54sec, total: 24432773.54sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48865547.08sec, total: 48865547.08sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 24432773.55sec, total: 24432773.55sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24432773.54sec, total: 24432773.55sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24432773.54sec, total: 24432773.55sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24432773.54sec, total: 24432773.55sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 698us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.12ms, accelerator: 24432773.54sec, total: 24432773.55sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_188750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48800910.11sec, total: 48800910.11sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24400455.06sec, total: 24400455.06sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24400455.05sec, total: 24400455.06sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48800910.11sec, total: 48800910.12sec
train.py:442:<module>, cpu: 5.51ms, accelerator: 24400455.06sec, total: 24400455.07sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24400455.06sec, total: 24400455.06sec
    train.py:322:loss_fn, cpu: 2.86ms, accelerator: 24400455.06sec, total: 24400455.06sec
      train.py:349:msssim, cpu: 2.81ms, accelerator: 24400455.06sec, total: 24400455.06sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 697us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24400455.06sec, total: 24400455.06sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2102.81 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_189000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48736443.91sec, total: 48736443.92sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24368221.96sec, total: 24368221.96sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24368221.96sec, total: 24368221.96sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48736443.92sec, total: 48736443.92sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 24368221.96sec, total: 24368221.97sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 24368221.96sec, total: 24368221.96sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24368221.96sec, total: 24368221.96sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24368221.96sec, total: 24368221.96sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.22ms, accelerator: 232us, total: 1.46ms
      train.py:343:hfe, cpu: 501us, accelerator: 696us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24368221.96sec, total: 24368221.97sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2088.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_189250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48672147.81sec, total: 48672147.82sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24336073.91sec, total: 24336073.91sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 24336073.91sec, total: 24336073.91sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48672147.82sec, total: 48672147.82sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 24336073.91sec, total: 24336073.92sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24336073.91sec, total: 24336073.91sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24336073.91sec, total: 24336073.91sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24336073.91sec, total: 24336073.91sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 232us, total: 1.47ms
      train.py:343:hfe, cpu: 499us, accelerator: 695us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24336073.91sec, total: 24336073.92sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.36 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_189500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48608021.14sec, total: 48608021.14sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24304010.57sec, total: 24304010.57sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24304010.57sec, total: 24304010.57sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48608021.14sec, total: 48608021.14sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 24304010.58sec, total: 24304010.58sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24304010.57sec, total: 24304010.58sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24304010.57sec, total: 24304010.58sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24304010.57sec, total: 24304010.58sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 232us, total: 1.47ms
      train.py:343:hfe, cpu: 499us, accelerator: 695us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24304010.57sec, total: 24304010.58sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2083.80 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_189750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48544063.21sec, total: 48544063.22sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24272031.61sec, total: 24272031.61sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24272031.61sec, total: 24272031.61sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48544063.22sec, total: 48544063.22sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 24272031.61sec, total: 24272031.62sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24272031.61sec, total: 24272031.61sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24272031.61sec, total: 24272031.61sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24272031.61sec, total: 24272031.61sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 232us, total: 1.47ms
      train.py:343:hfe, cpu: 499us, accelerator: 695us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.13ms, accelerator: 24272031.61sec, total: 24272031.62sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2108.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_190000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48480273.38sec, total: 48480273.38sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24240136.69sec, total: 24240136.69sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24240136.69sec, total: 24240136.69sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48480273.38sec, total: 48480273.39sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 24240136.70sec, total: 24240136.70sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 24240136.70sec, total: 24240136.70sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 24240136.70sec, total: 24240136.70sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 24240136.70sec, total: 24240136.70sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.32ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.32ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 232us, total: 1.47ms
      train.py:343:hfe, cpu: 499us, accelerator: 695us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24240136.69sec, total: 24240136.70sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2086.08 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_190250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48416650.97sec, total: 48416650.98sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24208325.49sec, total: 24208325.49sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24208325.49sec, total: 24208325.49sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48416650.98sec, total: 48416650.98sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 24208325.49sec, total: 24208325.50sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 24208325.49sec, total: 24208325.50sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 24208325.49sec, total: 24208325.50sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 24208325.49sec, total: 24208325.50sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 247us, total: 1.48ms
      train.py:343:hfe, cpu: 499us, accelerator: 691us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24208325.49sec, total: 24208325.50sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2096.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_190500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48353195.34sec, total: 48353195.34sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24176597.67sec, total: 24176597.67sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24176597.67sec, total: 24176597.67sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48353195.34sec, total: 48353195.35sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 24176597.68sec, total: 24176597.68sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 24176597.67sec, total: 24176597.68sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 24176597.67sec, total: 24176597.68sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 24176597.67sec, total: 24176597.68sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 250us, total: 1.49ms
      train.py:343:hfe, cpu: 499us, accelerator: 695us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24176597.67sec, total: 24176597.68sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.33 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_190750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48289905.81sec, total: 48289905.82sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24144952.91sec, total: 24144952.91sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24144952.91sec, total: 24144952.91sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48289905.82sec, total: 48289905.82sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 24144952.91sec, total: 24144952.92sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 24144952.91sec, total: 24144952.92sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24144952.91sec, total: 24144952.92sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 24144952.91sec, total: 24144952.92sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 250us, total: 1.49ms
      train.py:343:hfe, cpu: 499us, accelerator: 694us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24144952.91sec, total: 24144952.92sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_191000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48226781.75sec, total: 48226781.76sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24113390.88sec, total: 24113390.88sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24113390.88sec, total: 24113390.88sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48226781.76sec, total: 48226781.76sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 24113390.88sec, total: 24113390.89sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 24113390.88sec, total: 24113390.89sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24113390.88sec, total: 24113390.89sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 24113390.88sec, total: 24113390.89sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 250us, total: 1.49ms
      train.py:343:hfe, cpu: 499us, accelerator: 692us, total: 1.20ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 24113390.88sec, total: 24113390.89sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_191250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48163822.51sec, total: 48163822.51sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24081911.26sec, total: 24081911.26sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24081911.25sec, total: 24081911.26sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48163822.51sec, total: 48163822.52sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 24081911.26sec, total: 24081911.27sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 24081911.26sec, total: 24081911.26sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24081911.26sec, total: 24081911.26sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 24081911.26sec, total: 24081911.26sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 249us, total: 1.49ms
      train.py:343:hfe, cpu: 499us, accelerator: 691us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24081911.26sec, total: 24081911.26sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2080.95 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_191500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48101027.43sec, total: 48101027.44sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24050513.72sec, total: 24050513.72sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24050513.72sec, total: 24050513.72sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48101027.44sec, total: 48101027.44sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 24050513.72sec, total: 24050513.73sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24050513.72sec, total: 24050513.73sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24050513.72sec, total: 24050513.73sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24050513.72sec, total: 24050513.73sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 249us, total: 1.49ms
      train.py:343:hfe, cpu: 498us, accelerator: 691us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24050513.72sec, total: 24050513.73sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.91 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_191750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 48038395.89sec, total: 48038395.89sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 24019197.95sec, total: 24019197.95sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 24019197.94sec, total: 24019197.95sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 48038395.89sec, total: 48038395.90sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 24019197.95sec, total: 24019197.96sec
  train.py:360:image_losses, cpu: 2.88ms, accelerator: 24019197.95sec, total: 24019197.95sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 24019197.95sec, total: 24019197.95sec
      train.py:349:msssim, cpu: 2.82ms, accelerator: 24019197.95sec, total: 24019197.95sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 249us, total: 1.49ms
      train.py:343:hfe, cpu: 498us, accelerator: 690us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 24019197.95sec, total: 24019197.95sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2116.69 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_192000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 47975927.23sec, total: 47975927.24sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23987963.62sec, total: 23987963.62sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 23987963.62sec, total: 23987963.62sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47975927.24sec, total: 47975927.24sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23987963.62sec, total: 23987963.63sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23987963.62sec, total: 23987963.62sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 23987963.62sec, total: 23987963.62sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23987963.62sec, total: 23987963.62sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.33ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 249us, total: 1.50ms
      train.py:343:hfe, cpu: 497us, accelerator: 689us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 23987963.62sec, total: 23987963.63sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_192250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47913620.83sec, total: 47913620.84sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23956810.42sec, total: 23956810.42sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23956810.42sec, total: 23956810.42sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47913620.84sec, total: 47913620.84sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23956810.42sec, total: 23956810.43sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23956810.42sec, total: 23956810.43sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 23956810.42sec, total: 23956810.43sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23956810.42sec, total: 23956810.43sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.50ms
      train.py:343:hfe, cpu: 497us, accelerator: 688us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 23956810.42sec, total: 23956810.43sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2118.09 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_192500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47851476.06sec, total: 47851476.06sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23925738.03sec, total: 23925738.03sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23925738.03sec, total: 23925738.03sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47851476.06sec, total: 47851476.07sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23925738.04sec, total: 23925738.04sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23925738.04sec, total: 23925738.04sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23925738.04sec, total: 23925738.04sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23925738.04sec, total: 23925738.04sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.34ms, total: 3.47ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.50ms
      train.py:343:hfe, cpu: 497us, accelerator: 688us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 23925738.03sec, total: 23925738.04sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.39 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_192750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47789492.28sec, total: 47789492.29sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23894746.14sec, total: 23894746.15sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23894746.14sec, total: 23894746.14sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47789492.29sec, total: 47789492.29sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23894746.15sec, total: 23894746.15sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23894746.15sec, total: 23894746.15sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23894746.15sec, total: 23894746.15sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23894746.15sec, total: 23894746.15sec
  train.py:359:image_losses, cpu: 2.12ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.50ms
      train.py:343:hfe, cpu: 497us, accelerator: 685us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 23894746.15sec, total: 23894746.15sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_193000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47727668.88sec, total: 47727668.88sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23863834.44sec, total: 23863834.44sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23863834.44sec, total: 23863834.44sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47727668.88sec, total: 47727668.89sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23863834.45sec, total: 23863834.45sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23863834.44sec, total: 23863834.45sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23863834.44sec, total: 23863834.45sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23863834.44sec, total: 23863834.45sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 495us, accelerator: 685us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 23863834.44sec, total: 23863834.45sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.17 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_193250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47666005.22sec, total: 47666005.22sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23833002.61sec, total: 23833002.62sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23833002.61sec, total: 23833002.61sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47666005.23sec, total: 47666005.23sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 23833002.62sec, total: 23833002.62sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23833002.62sec, total: 23833002.62sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23833002.62sec, total: 23833002.62sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23833002.62sec, total: 23833002.62sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 495us, accelerator: 684us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.15ms, accelerator: 23833002.62sec, total: 23833002.62sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2109.99 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_193500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47604500.70sec, total: 47604500.70sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23802250.35sec, total: 23802250.35sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.38ms, accelerator: 23802250.35sec, total: 23802250.35sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47604500.70sec, total: 47604500.71sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 23802250.36sec, total: 23802250.36sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23802250.36sec, total: 23802250.36sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23802250.36sec, total: 23802250.36sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23802250.35sec, total: 23802250.36sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 495us, accelerator: 684us, total: 1.19ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 23802250.35sec, total: 23802250.36sec
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2087.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_193750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47543154.69sec, total: 47543154.70sec (28.57%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23771577.35sec, total: 23771577.35sec (14.29%)
top 3 operation type: Conv2D, cpu: 3.38ms, accelerator: 23771577.35sec, total: 23771577.35sec (14.29%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47543154.70sec, total: 47543154.70sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23771577.35sec, total: 23771577.36sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23771577.35sec, total: 23771577.35sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23771577.35sec, total: 23771577.35sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23771577.35sec, total: 23771577.35sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.10ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 495us, accelerator: 684us, total: 1.18ms
train.py:436:<module> (gradient), cpu: 4.14ms, accelerator: 23771577.35sec, total: 23771577.36sec

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.01 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_194000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.50

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47481966.59sec, total: 47481966.59sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23740983.30sec, total: 23740983.30sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.38ms, accelerator: 23740983.30sec, total: 23740983.30sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47481966.60sec, total: 47481966.60sec
train.py:436:<module>, cpu: 5.55ms, accelerator: 47481966.59sec, total: 47481966.60sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 23740983.30sec, total: 23740983.31sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23740983.30sec, total: 23740983.30sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23740983.30sec, total: 23740983.30sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23740983.30sec, total: 23740983.30sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 494us, accelerator: 686us, total: 1.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.74 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_194250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47420935.79sec, total: 47420935.79sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23710467.90sec, total: 23710467.90sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.38ms, accelerator: 23710467.89sec, total: 23710467.90sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47420935.79sec, total: 47420935.80sec
train.py:436:<module>, cpu: 5.55ms, accelerator: 47420935.79sec, total: 47420935.79sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 23710467.90sec, total: 23710467.91sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23710467.90sec, total: 23710467.90sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23710467.90sec, total: 23710467.90sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23710467.90sec, total: 23710467.90sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 495us, accelerator: 686us, total: 1.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2093.87 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_194500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47360061.67sec, total: 47360061.67sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23680030.84sec, total: 23680030.84sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.38ms, accelerator: 23680030.84sec, total: 23680030.84sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47360061.68sec, total: 47360061.68sec
train.py:436:<module>, cpu: 5.54ms, accelerator: 47360061.67sec, total: 47360061.68sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 23680030.84sec, total: 23680030.85sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23680030.84sec, total: 23680030.84sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23680030.84sec, total: 23680030.84sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23680030.84sec, total: 23680030.84sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 258us, total: 1.49ms
      train.py:343:hfe, cpu: 495us, accelerator: 694us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2104.84 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_194750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47299343.64sec, total: 47299343.65sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23649671.82sec, total: 23649671.83sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.38ms, accelerator: 23649671.82sec, total: 23649671.83sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47299343.65sec, total: 47299343.65sec
train.py:436:<module>, cpu: 5.54ms, accelerator: 47299343.64sec, total: 47299343.65sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 23649671.83sec, total: 23649671.83sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23649671.83sec, total: 23649671.83sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23649671.83sec, total: 23649671.83sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23649671.83sec, total: 23649671.83sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 257us, total: 1.49ms
      train.py:343:hfe, cpu: 493us, accelerator: 692us, total: 1.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2089.64 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_195000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.43ms, accelerator: 47238781.10sec, total: 47238781.11sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23619390.55sec, total: 23619390.56sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.38ms, accelerator: 23619390.55sec, total: 23619390.56sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47238781.11sec, total: 47238781.11sec
train.py:436:<module>, cpu: 5.54ms, accelerator: 47238781.10sec, total: 47238781.11sec
train.py:442:<module>, cpu: 5.52ms, accelerator: 23619390.56sec, total: 23619390.56sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23619390.56sec, total: 23619390.56sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23619390.56sec, total: 23619390.56sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23619390.56sec, total: 23619390.56sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 257us, total: 1.49ms
      train.py:343:hfe, cpu: 493us, accelerator: 692us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2081.16 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_195250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47178373.46sec, total: 47178373.46sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23589186.73sec, total: 23589186.73sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.37ms, accelerator: 23589186.73sec, total: 23589186.73sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47178373.46sec, total: 47178373.46sec
train.py:436:<module>, cpu: 5.53ms, accelerator: 47178373.46sec, total: 47178373.46sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23589186.73sec, total: 23589186.74sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23589186.73sec, total: 23589186.74sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23589186.73sec, total: 23589186.74sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23589186.73sec, total: 23589186.74sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 257us, total: 1.49ms
      train.py:343:hfe, cpu: 493us, accelerator: 691us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2099.68 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_195500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47118120.10sec, total: 47118120.11sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23559060.06sec, total: 23559060.06sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.37ms, accelerator: 23559060.05sec, total: 23559060.06sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 47118120.11sec, total: 47118120.11sec
train.py:436:<module>, cpu: 5.53ms, accelerator: 47118120.11sec, total: 47118120.11sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23559060.06sec, total: 23559060.07sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23559060.06sec, total: 23559060.06sec
    train.py:322:loss_fn, cpu: 2.87ms, accelerator: 23559060.06sec, total: 23559060.06sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23559060.06sec, total: 23559060.06sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 257us, total: 1.49ms
      train.py:343:hfe, cpu: 493us, accelerator: 697us, total: 1.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_195750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 47058020.46sec, total: 47058020.46sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23529010.23sec, total: 23529010.24sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.37ms, accelerator: 23529010.23sec, total: 23529010.23sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 47058020.47sec, total: 47058020.47sec
train.py:436:<module>, cpu: 5.53ms, accelerator: 47058020.46sec, total: 47058020.47sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23529010.24sec, total: 23529010.24sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23529010.24sec, total: 23529010.24sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23529010.24sec, total: 23529010.24sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23529010.24sec, total: 23529010.24sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 257us, total: 1.50ms
      train.py:343:hfe, cpu: 493us, accelerator: 697us, total: 1.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2100.59 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_196000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46998073.94sec, total: 46998073.94sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23499036.97sec, total: 23499036.97sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.37ms, accelerator: 23499036.97sec, total: 23499036.97sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 46998073.94sec, total: 46998073.95sec
train.py:436:<module>, cpu: 5.53ms, accelerator: 46998073.94sec, total: 46998073.95sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23499036.98sec, total: 23499036.98sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23499036.97sec, total: 23499036.98sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23499036.97sec, total: 23499036.98sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23499036.97sec, total: 23499036.98sec
  train.py:359:image_losses, cpu: 2.11ms, accelerator: 1.35ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.35ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.24ms, accelerator: 256us, total: 1.50ms
      train.py:343:hfe, cpu: 492us, accelerator: 699us, total: 1.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2106.98 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_196250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46938279.95sec, total: 46938279.95sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23469139.98sec, total: 23469139.98sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.37ms, accelerator: 23469139.98sec, total: 23469139.98sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 46938279.96sec, total: 46938279.96sec
train.py:436:<module>, cpu: 5.53ms, accelerator: 46938279.95sec, total: 46938279.96sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23469139.98sec, total: 23469139.99sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23469139.98sec, total: 23469139.98sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23469139.98sec, total: 23469139.98sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23469139.98sec, total: 23469139.98sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.46ms
    train.py:322:loss_fn, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 256us, total: 1.49ms
      train.py:343:hfe, cpu: 492us, accelerator: 697us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2067.51 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_196500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46878637.92sec, total: 46878637.92sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.29ms, accelerator: 23439318.96sec, total: 23439318.96sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.36ms, accelerator: 23439318.96sec, total: 23439318.96sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 46878637.92sec, total: 46878637.93sec
train.py:436:<module>, cpu: 5.53ms, accelerator: 46878637.92sec, total: 46878637.93sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23439318.97sec, total: 23439318.97sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23439318.96sec, total: 23439318.97sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23439318.96sec, total: 23439318.97sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23439318.96sec, total: 23439318.97sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 491us, accelerator: 697us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2090.21 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_196750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46819147.26sec, total: 46819147.26sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23409573.63sec, total: 23409573.63sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.36ms, accelerator: 23409573.63sec, total: 23409573.63sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 46819147.27sec, total: 46819147.27sec
train.py:436:<module>, cpu: 5.52ms, accelerator: 46819147.26sec, total: 46819147.27sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23409573.64sec, total: 23409573.64sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23409573.64sec, total: 23409573.64sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23409573.64sec, total: 23409573.64sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23409573.64sec, total: 23409573.64sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.44ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 489us, accelerator: 696us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2092.72 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_197000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46759807.40sec, total: 46759807.41sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23379903.71sec, total: 23379903.71sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 23379903.70sec, total: 23379903.71sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 46759807.41sec, total: 46759807.41sec
train.py:436:<module>, cpu: 5.56ms, accelerator: 46759807.41sec, total: 46759807.41sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23379903.71sec, total: 23379903.72sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23379903.71sec, total: 23379903.71sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23379903.71sec, total: 23379903.71sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23379903.71sec, total: 23379903.71sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 489us, accelerator: 696us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2139.45 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_197250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46700617.77sec, total: 46700617.78sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23350308.89sec, total: 23350308.89sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 23350308.89sec, total: 23350308.89sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 46700617.78sec, total: 46700617.78sec
train.py:436:<module>, cpu: 5.56ms, accelerator: 46700617.78sec, total: 46700617.78sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23350308.89sec, total: 23350308.90sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23350308.89sec, total: 23350308.90sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23350308.89sec, total: 23350308.90sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23350308.89sec, total: 23350308.90sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 489us, accelerator: 695us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2101.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_197500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46641577.80sec, total: 46641577.81sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23320788.90sec, total: 23320788.91sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.40ms, accelerator: 23320788.90sec, total: 23320788.91sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 46641577.81sec, total: 46641577.81sec
train.py:436:<module>, cpu: 5.55ms, accelerator: 46641577.80sec, total: 46641577.81sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 23320788.91sec, total: 23320788.91sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23320788.91sec, total: 23320788.91sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23320788.91sec, total: 23320788.91sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23320788.91sec, total: 23320788.91sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 254us, total: 1.49ms
      train.py:343:hfe, cpu: 488us, accelerator: 696us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2103.66 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_197750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46582686.92sec, total: 46582686.92sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23291343.46sec, total: 23291343.47sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23291343.46sec, total: 23291343.46sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 46582686.93sec, total: 46582686.93sec
train.py:436:<module>, cpu: 5.55ms, accelerator: 46582686.92sec, total: 46582686.93sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 23291343.47sec, total: 23291343.47sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23291343.47sec, total: 23291343.47sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23291343.47sec, total: 23291343.47sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23291343.47sec, total: 23291343.47sec
  train.py:359:image_losses, cpu: 2.09ms, accelerator: 1.34ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 254us, total: 1.48ms
      train.py:343:hfe, cpu: 488us, accelerator: 693us, total: 1.19ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2114.83 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_198000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46523944.57sec, total: 46523944.57sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23261972.29sec, total: 23261972.29sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23261972.28sec, total: 23261972.29sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 46523944.57sec, total: 46523944.58sec
train.py:436:<module>, cpu: 5.55ms, accelerator: 46523944.57sec, total: 46523944.57sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 23261972.29sec, total: 23261972.30sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23261972.29sec, total: 23261972.29sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23261972.29sec, total: 23261972.29sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23261972.29sec, total: 23261972.29sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 253us, total: 1.48ms
      train.py:343:hfe, cpu: 488us, accelerator: 693us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2098.86 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_198250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46465350.18sec, total: 46465350.18sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23232675.09sec, total: 23232675.09sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23232675.09sec, total: 23232675.09sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 46465350.18sec, total: 46465350.19sec
train.py:436:<module>, cpu: 5.56ms, accelerator: 46465350.18sec, total: 46465350.19sec
train.py:442:<module>, cpu: 5.54ms, accelerator: 23232675.10sec, total: 23232675.10sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23232675.09sec, total: 23232675.10sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23232675.09sec, total: 23232675.10sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23232675.09sec, total: 23232675.10sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 253us, total: 1.49ms
      train.py:343:hfe, cpu: 488us, accelerator: 692us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2110.52 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_198500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46406903.20sec, total: 46406903.20sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23203451.60sec, total: 23203451.60sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23203451.60sec, total: 23203451.60sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 46406903.20sec, total: 46406903.21sec
train.py:436:<module>, cpu: 5.56ms, accelerator: 46406903.20sec, total: 46406903.20sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 23203451.61sec, total: 23203451.61sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23203451.60sec, total: 23203451.61sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23203451.60sec, total: 23203451.61sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23203451.60sec, total: 23203451.61sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 253us, total: 1.49ms
      train.py:343:hfe, cpu: 488us, accelerator: 691us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2077.71 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_198750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.42ms, accelerator: 46348603.07sec, total: 46348603.07sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23174301.54sec, total: 23174301.54sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23174301.53sec, total: 23174301.54sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.18ms, accelerator: 46348603.07sec, total: 46348603.08sec
train.py:436:<module>, cpu: 5.55ms, accelerator: 46348603.07sec, total: 46348603.07sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 23174301.54sec, total: 23174301.55sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23174301.54sec, total: 23174301.54sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23174301.54sec, total: 23174301.54sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23174301.54sec, total: 23174301.54sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.33ms, total: 3.44ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.33ms, total: 3.42ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 253us, total: 1.49ms
      train.py:343:hfe, cpu: 489us, accelerator: 691us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 2082.13 MB

******************************************************
Timeline file is written to /project/foster/clouds/output/m9_24_tk2_Global_JJA/timelines/t.json_199000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 46290449.24sec, total: 46290449.24sec (25.00%)
top 2 operation type: FusedBatchNormGrad, cpu: 1.28ms, accelerator: 23145224.62sec, total: 23145224.62sec (12.50%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 23145224.62sec, total: 23145224.62sec (12.50%)
top 1 graph node: grad_info, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: image_loss, cpu: 0us, accelerator: 0us, total: 0us
train.py:441:<module> (gradient), cpu: 4.17ms, accelerator: 46290449.24sec, total: 46290449.25sec
train.py:436:<module>, cpu: 5.55ms, accelerator: 46290449.24sec, total: 46290449.24sec
train.py:442:<module>, cpu: 5.53ms, accelerator: 23145224.63sec, total: 23145224.63sec
  train.py:360:image_losses, cpu: 2.89ms, accelerator: 23145224.62sec, total: 23145224.63sec
    train.py:322:loss_fn, cpu: 2.88ms, accelerator: 23145224.62sec, total: 23145224.63sec
      train.py:349:msssim, cpu: 2.83ms, accelerator: 23145224.62sec, total: 23145224.63sec
  train.py:359:image_losses, cpu: 2.10ms, accelerator: 1.34ms, total: 3.45ms
    train.py:322:loss_fn, cpu: 2.08ms, accelerator: 1.34ms, total: 3.43ms
      train.py:342:hfe, cpu: 1.23ms, accelerator: 253us, total: 1.49ms
      train.py:343:hfe, cpu: 489us, accelerator: 695us, total: 1.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
-------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
-------------------------------------------------------
