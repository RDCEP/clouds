Parsing Inputs...
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_0.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 4.04sec, accelerator: 0us, total: 4.04sec (64.67%)
top 2 operation type: Conv2D, cpu: 1.94sec, accelerator: 29.35ms, total: 1.97sec (31.51%)
top 3 operation type: Conv2DBackpropFilter, cpu: 30.05ms, accelerator: 36.17ms, total: 66.22ms (1.06%)
top 1 graph node: IteratorGetNext, cpu: 4.04sec, accelerator: 0us, total: 4.04sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 4.07sec, accelerator: 0us, total: 4.07sec
  iterator_ops.py:373:get_next, cpu: 4.04sec, accelerator: 0us, total: 4.04sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 27.87ms, accelerator: 0us, total: 27.87ms
train2.py:333:<module>, cpu: 1.94sec, accelerator: 37.77ms, total: 1.98sec
train2.py:333:<module> (gradient), cpu: 48.56ms, accelerator: 68.68ms, total: 117.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_1000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_1250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_1500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_1750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 2.06sec, accelerator: 0us, total: 2.06sec (64.53%)
top 2 operation type: Conv2D, cpu: 969.76ms, accelerator: 18.10ms, total: 987.87ms (31.01%)
top 3 operation type: Conv2DBackpropFilter, cpu: 15.64ms, accelerator: 20.67ms, total: 36.32ms (1.14%)
top 1 graph node: IteratorGetNext, cpu: 2.06sec, accelerator: 0us, total: 2.06sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 2.07sec, accelerator: 0us, total: 2.07sec
  iterator_ops.py:373:get_next, cpu: 2.06sec, accelerator: 0us, total: 2.06sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 13.94ms, accelerator: 0us, total: 13.94ms
train2.py:333:<module>, cpu: 972.53ms, accelerator: 26.86ms, total: 999.42ms
train2.py:333:<module> (gradient), cpu: 25.74ms, accelerator: 43.86ms, total: 69.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_2000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_2250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_2500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_2750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 1.39sec, accelerator: 0us, total: 1.39sec (64.35%)
top 2 operation type: Conv2D, cpu: 646.85ms, accelerator: 14.18ms, total: 661.04ms (30.58%)
top 3 operation type: Conv2DBackpropFilter, cpu: 10.84ms, accelerator: 15.90ms, total: 26.75ms (1.24%)
top 1 graph node: IteratorGetNext, cpu: 1.39sec, accelerator: 0us, total: 1.39sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 1.40sec, accelerator: 0us, total: 1.40sec
  iterator_ops.py:373:get_next, cpu: 1.39sec, accelerator: 0us, total: 1.39sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 9.29ms, accelerator: 0us, total: 9.29ms
train2.py:333:<module>, cpu: 648.89ms, accelerator: 21.69ms, total: 670.60ms
train2.py:333:<module> (gradient), cpu: 18.14ms, accelerator: 35.22ms, total: 53.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_3000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_3250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_3500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_3750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 1.06sec, accelerator: 0us, total: 1.06sec (64.11%)
top 2 operation type: Conv2D, cpu: 485.39ms, accelerator: 12.52ms, total: 497.92ms (30.19%)
top 3 operation type: Conv2DBackpropFilter, cpu: 8.43ms, accelerator: 13.81ms, total: 22.25ms (1.35%)
top 1 graph node: IteratorGetNext, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
  iterator_ops.py:373:get_next, cpu: 1.06sec, accelerator: 0us, total: 1.06sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 6.97ms, accelerator: 0us, total: 6.97ms
train2.py:333:<module>, cpu: 487.06ms, accelerator: 20.32ms, total: 507.40ms
train2.py:333:<module> (gradient), cpu: 14.32ms, accelerator: 31.46ms, total: 45.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_4000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_4250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_4500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_4750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 860.10ms, accelerator: 0us, total: 860.10ms (63.96%)
top 2 operation type: Conv2D, cpu: 388.52ms, accelerator: 11.91ms, total: 400.43ms (29.78%)
top 3 operation type: Conv2DBackpropFilter, cpu: 7.00ms, accelerator: 13.31ms, total: 20.31ms (1.51%)
top 1 graph node: IteratorGetNext, cpu: 860.10ms, accelerator: 0us, total: 860.10ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 865.68ms, accelerator: 0us, total: 865.68ms
  iterator_ops.py:373:get_next, cpu: 860.10ms, accelerator: 0us, total: 860.10ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 5.58ms, accelerator: 0us, total: 5.58ms
train2.py:333:<module>, cpu: 389.97ms, accelerator: 18.94ms, total: 408.94ms
train2.py:333:<module> (gradient), cpu: 12.04ms, accelerator: 30.58ms, total: 42.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_5000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_5250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_5500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_5750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 731.70ms, accelerator: 0us, total: 731.70ms (63.92%)
top 2 operation type: Conv2D, cpu: 323.94ms, accelerator: 11.43ms, total: 335.37ms (29.30%)
top 3 operation type: Conv2DBackpropFilter, cpu: 6.03ms, accelerator: 12.69ms, total: 18.73ms (1.64%)
top 1 graph node: IteratorGetNext, cpu: 731.70ms, accelerator: 0us, total: 731.70ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 736.35ms, accelerator: 0us, total: 736.35ms
  iterator_ops.py:373:get_next, cpu: 731.70ms, accelerator: 0us, total: 731.70ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 4.65ms, accelerator: 0us, total: 4.65ms
train2.py:333:<module>, cpu: 325.24ms, accelerator: 18.45ms, total: 343.72ms
train2.py:333:<module> (gradient), cpu: 10.51ms, accelerator: 29.48ms, total: 40.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_6000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_6250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_6500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_6750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 637.12ms, accelerator: 0us, total: 637.12ms (63.77%)
top 2 operation type: Conv2D, cpu: 277.81ms, accelerator: 11.03ms, total: 288.85ms (28.91%)
top 3 operation type: Conv2DBackpropFilter, cpu: 5.35ms, accelerator: 12.07ms, total: 17.43ms (1.74%)
top 1 graph node: IteratorGetNext, cpu: 637.12ms, accelerator: 0us, total: 637.12ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 641.10ms, accelerator: 0us, total: 641.10ms
  iterator_ops.py:373:get_next, cpu: 637.12ms, accelerator: 0us, total: 637.12ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 3.98ms, accelerator: 0us, total: 3.98ms
train2.py:333:<module>, cpu: 279.02ms, accelerator: 18.18ms, total: 297.22ms
train2.py:333:<module> (gradient), cpu: 9.43ms, accelerator: 28.73ms, total: 38.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_7000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_7250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_7500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_7750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 566.04ms, accelerator: 0us, total: 566.04ms (63.63%)
top 2 operation type: Conv2D, cpu: 243.22ms, accelerator: 10.79ms, total: 254.01ms (28.55%)
top 3 operation type: Conv2DBackpropFilter, cpu: 4.84ms, accelerator: 11.81ms, total: 16.65ms (1.87%)
top 1 graph node: IteratorGetNext, cpu: 566.04ms, accelerator: 0us, total: 566.04ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 569.53ms, accelerator: 0us, total: 569.53ms
  iterator_ops.py:373:get_next, cpu: 566.04ms, accelerator: 0us, total: 566.04ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 3.49ms, accelerator: 0us, total: 3.49ms
train2.py:333:<module>, cpu: 244.35ms, accelerator: 17.68ms, total: 262.05ms
train2.py:333:<module> (gradient), cpu: 8.61ms, accelerator: 28.48ms, total: 37.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_8000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_8250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_8500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_8750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 510.01ms, accelerator: 0us, total: 510.01ms (63.46%)
top 2 operation type: Conv2D, cpu: 216.31ms, accelerator: 10.65ms, total: 226.96ms (28.24%)
top 3 operation type: Conv2DBackpropInput, cpu: 3.36ms, accelerator: 12.81ms, total: 16.18ms (2.01%)
top 1 graph node: IteratorGetNext, cpu: 510.01ms, accelerator: 0us, total: 510.01ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 513.11ms, accelerator: 0us, total: 513.11ms
  iterator_ops.py:373:get_next, cpu: 510.01ms, accelerator: 0us, total: 510.01ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 3.10ms, accelerator: 0us, total: 3.10ms
train2.py:333:<module>, cpu: 217.38ms, accelerator: 17.23ms, total: 234.62ms
train2.py:333:<module> (gradient), cpu: 7.97ms, accelerator: 28.21ms, total: 36.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_9000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_9250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_9500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_9750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 465.12ms, accelerator: 0us, total: 465.12ms (63.31%)
top 2 operation type: Conv2D, cpu: 194.78ms, accelerator: 10.14ms, total: 204.93ms (27.89%)
top 3 operation type: Conv2DBackpropInput, cpu: 3.13ms, accelerator: 12.15ms, total: 15.29ms (2.08%)
top 1 graph node: IteratorGetNext, cpu: 465.12ms, accelerator: 0us, total: 465.12ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 467.91ms, accelerator: 0us, total: 467.91ms
  iterator_ops.py:373:get_next, cpu: 465.12ms, accelerator: 0us, total: 465.12ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.79ms, accelerator: 0us, total: 2.79ms
train2.py:333:<module>, cpu: 195.80ms, accelerator: 16.82ms, total: 212.64ms
train2.py:333:<module> (gradient), cpu: 7.46ms, accelerator: 27.16ms, total: 34.65ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_10000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_10250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_10500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_10750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 427.93ms, accelerator: 0us, total: 427.93ms (63.14%)
top 2 operation type: Conv2D, cpu: 177.17ms, accelerator: 9.77ms, total: 186.94ms (27.58%)
top 3 operation type: ResourceApplyAdam, cpu: 5.39ms, accelerator: 9.35ms, total: 14.75ms (2.18%)
top 1 graph node: IteratorGetNext, cpu: 427.93ms, accelerator: 0us, total: 427.93ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 430.47ms, accelerator: 0us, total: 430.47ms
  iterator_ops.py:373:get_next, cpu: 427.93ms, accelerator: 0us, total: 427.93ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.54ms, accelerator: 0us, total: 2.54ms
train2.py:333:<module>, cpu: 178.15ms, accelerator: 16.28ms, total: 194.45ms
train2.py:333:<module> (gradient), cpu: 7.05ms, accelerator: 26.26ms, total: 33.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_11000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_11250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_11500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_11750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 396.91ms, accelerator: 0us, total: 396.91ms (62.96%)
top 2 operation type: Conv2D, cpu: 162.49ms, accelerator: 9.44ms, total: 171.93ms (27.27%)
top 3 operation type: ResourceApplyAdam, cpu: 5.04ms, accelerator: 9.78ms, total: 14.82ms (2.35%)
top 1 graph node: IteratorGetNext, cpu: 396.91ms, accelerator: 0us, total: 396.91ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 399.24ms, accelerator: 0us, total: 399.24ms
  iterator_ops.py:373:get_next, cpu: 396.91ms, accelerator: 0us, total: 396.91ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.33ms, accelerator: 0us, total: 2.33ms
train2.py:333:<module>, cpu: 163.44ms, accelerator: 15.91ms, total: 179.37ms
train2.py:333:<module> (gradient), cpu: 6.70ms, accelerator: 25.68ms, total: 32.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_12000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_12250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_12500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_12750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 371.35ms, accelerator: 0us, total: 371.35ms (62.82%)
top 2 operation type: Conv2D, cpu: 150.07ms, accelerator: 9.24ms, total: 159.32ms (26.95%)
top 3 operation type: ResourceApplyAdam, cpu: 4.74ms, accelerator: 9.96ms, total: 14.71ms (2.49%)
top 1 graph node: IteratorGetNext, cpu: 371.35ms, accelerator: 0us, total: 371.35ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 373.50ms, accelerator: 0us, total: 373.50ms
  iterator_ops.py:373:get_next, cpu: 371.35ms, accelerator: 0us, total: 371.35ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.15ms, accelerator: 0us, total: 2.15ms
train2.py:333:<module>, cpu: 151.00ms, accelerator: 15.64ms, total: 166.66ms
train2.py:333:<module> (gradient), cpu: 6.41ms, accelerator: 25.40ms, total: 31.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_13000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_13250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_13500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_13750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 349.28ms, accelerator: 0us, total: 349.28ms (62.70%)
top 2 operation type: Conv2D, cpu: 139.43ms, accelerator: 8.97ms, total: 148.41ms (26.64%)
top 3 operation type: ResourceApplyAdam, cpu: 4.49ms, accelerator: 10.21ms, total: 14.71ms (2.64%)
top 1 graph node: IteratorGetNext, cpu: 349.28ms, accelerator: 0us, total: 349.28ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 351.27ms, accelerator: 0us, total: 351.27ms
  iterator_ops.py:373:get_next, cpu: 349.28ms, accelerator: 0us, total: 349.28ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.00ms, accelerator: 0us, total: 2.00ms
train2.py:333:<module>, cpu: 140.34ms, accelerator: 15.58ms, total: 155.94ms
train2.py:333:<module> (gradient), cpu: 6.16ms, accelerator: 24.66ms, total: 30.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_14000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_14250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_14500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_14750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 331.15ms, accelerator: 0us, total: 331.15ms (62.64%)
top 2 operation type: Conv2D, cpu: 130.21ms, accelerator: 8.90ms, total: 139.12ms (26.32%)
top 3 operation type: ResourceApplyAdam, cpu: 4.27ms, accelerator: 10.04ms, total: 14.31ms (2.71%)
top 1 graph node: IteratorGetNext, cpu: 331.15ms, accelerator: 0us, total: 331.15ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 333.01ms, accelerator: 0us, total: 333.01ms
  iterator_ops.py:373:get_next, cpu: 331.15ms, accelerator: 0us, total: 331.15ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.86ms, accelerator: 0us, total: 1.86ms
train2.py:333:<module>, cpu: 131.09ms, accelerator: 15.46ms, total: 146.58ms
train2.py:333:<module> (gradient), cpu: 5.95ms, accelerator: 24.65ms, total: 30.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_15000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_15250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_15500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_15750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 315.29ms, accelerator: 0us, total: 315.29ms (62.58%)
top 2 operation type: Conv2D, cpu: 122.13ms, accelerator: 8.78ms, total: 130.93ms (25.99%)
top 3 operation type: ResourceApplyAdam, cpu: 4.07ms, accelerator: 10.26ms, total: 14.34ms (2.85%)
top 1 graph node: IteratorGetNext, cpu: 315.29ms, accelerator: 0us, total: 315.29ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 317.04ms, accelerator: 0us, total: 317.04ms
  iterator_ops.py:373:get_next, cpu: 315.29ms, accelerator: 0us, total: 315.29ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.75ms, accelerator: 0us, total: 1.75ms
train2.py:333:<module>, cpu: 123.00ms, accelerator: 15.34ms, total: 138.36ms
train2.py:333:<module> (gradient), cpu: 5.76ms, accelerator: 24.11ms, total: 29.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_16000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_16250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_16500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_16750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 300.87ms, accelerator: 0us, total: 300.87ms (62.49%)
top 2 operation type: Conv2D, cpu: 115.01ms, accelerator: 8.87ms, total: 123.89ms (25.73%)
top 3 operation type: ResourceApplyAdam, cpu: 3.90ms, accelerator: 10.15ms, total: 14.07ms (2.92%)
top 1 graph node: IteratorGetNext, cpu: 300.87ms, accelerator: 0us, total: 300.87ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 302.52ms, accelerator: 0us, total: 302.52ms
  iterator_ops.py:373:get_next, cpu: 300.87ms, accelerator: 0us, total: 300.87ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.64ms, accelerator: 0us, total: 1.64ms
train2.py:333:<module>, cpu: 115.86ms, accelerator: 15.33ms, total: 131.22ms
train2.py:333:<module> (gradient), cpu: 5.59ms, accelerator: 24.04ms, total: 29.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_17000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_17250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_17500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_17750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 288.37ms, accelerator: 0us, total: 288.37ms (62.41%)
top 2 operation type: Conv2D, cpu: 108.68ms, accelerator: 8.92ms, total: 117.61ms (25.45%)
top 3 operation type: ResourceApplyAdam, cpu: 3.75ms, accelerator: 10.01ms, total: 13.77ms (2.98%)
top 1 graph node: IteratorGetNext, cpu: 288.37ms, accelerator: 0us, total: 288.37ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 289.93ms, accelerator: 0us, total: 289.93ms
  iterator_ops.py:373:get_next, cpu: 288.37ms, accelerator: 0us, total: 288.37ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.55ms, accelerator: 0us, total: 1.55ms
train2.py:333:<module>, cpu: 109.52ms, accelerator: 15.43ms, total: 124.98ms
train2.py:333:<module> (gradient), cpu: 5.44ms, accelerator: 24.01ms, total: 29.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_18000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_18250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_18500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_18750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 276.41ms, accelerator: 0us, total: 276.41ms (62.29%)
top 2 operation type: Conv2D, cpu: 103.02ms, accelerator: 8.85ms, total: 111.87ms (25.21%)
top 3 operation type: ResourceApplyAdam, cpu: 3.61ms, accelerator: 9.99ms, total: 13.61ms (3.07%)
top 1 graph node: IteratorGetNext, cpu: 276.41ms, accelerator: 0us, total: 276.41ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 277.88ms, accelerator: 0us, total: 277.88ms
  iterator_ops.py:373:get_next, cpu: 276.41ms, accelerator: 0us, total: 276.41ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.47ms, accelerator: 0us, total: 1.47ms
train2.py:333:<module>, cpu: 103.84ms, accelerator: 15.22ms, total: 119.08ms
train2.py:333:<module> (gradient), cpu: 5.31ms, accelerator: 24.08ms, total: 29.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_19000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_19250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_19500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_19750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 265.32ms, accelerator: 0us, total: 265.32ms (62.14%)
top 2 operation type: Conv2D, cpu: 97.92ms, accelerator: 8.72ms, total: 106.65ms (24.98%)
top 3 operation type: ResourceApplyAdam, cpu: 3.49ms, accelerator: 10.08ms, total: 13.58ms (3.18%)
top 1 graph node: IteratorGetNext, cpu: 265.32ms, accelerator: 0us, total: 265.32ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 266.71ms, accelerator: 0us, total: 266.71ms
  iterator_ops.py:373:get_next, cpu: 265.32ms, accelerator: 0us, total: 265.32ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.40ms, accelerator: 0us, total: 1.40ms
train2.py:333:<module>, cpu: 98.73ms, accelerator: 15.16ms, total: 113.92ms
train2.py:333:<module> (gradient), cpu: 5.19ms, accelerator: 23.82ms, total: 29.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_20000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_20250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_20500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_20750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 255.17ms, accelerator: 0us, total: 255.17ms (61.99%)
top 2 operation type: Conv2D, cpu: 93.31ms, accelerator: 8.61ms, total: 101.92ms (24.76%)
top 3 operation type: ResourceApplyAdam, cpu: 3.38ms, accelerator: 10.35ms, total: 13.74ms (3.34%)
top 1 graph node: IteratorGetNext, cpu: 255.17ms, accelerator: 0us, total: 255.17ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 256.50ms, accelerator: 0us, total: 256.50ms
  iterator_ops.py:373:get_next, cpu: 255.17ms, accelerator: 0us, total: 255.17ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.33ms, accelerator: 0us, total: 1.33ms
train2.py:333:<module>, cpu: 94.11ms, accelerator: 14.98ms, total: 109.11ms
train2.py:333:<module> (gradient), cpu: 5.08ms, accelerator: 23.50ms, total: 28.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_21000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_21250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_21500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_21750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 246.40ms, accelerator: 0us, total: 246.40ms (61.87%)
top 2 operation type: Conv2D, cpu: 89.11ms, accelerator: 8.58ms, total: 97.70ms (24.53%)
top 3 operation type: ResourceApplyAdam, cpu: 3.28ms, accelerator: 10.43ms, total: 13.72ms (3.44%)
top 1 graph node: IteratorGetNext, cpu: 246.40ms, accelerator: 0us, total: 246.40ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 247.67ms, accelerator: 0us, total: 247.67ms
  iterator_ops.py:373:get_next, cpu: 246.40ms, accelerator: 0us, total: 246.40ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.27ms, accelerator: 0us, total: 1.27ms
train2.py:333:<module>, cpu: 89.91ms, accelerator: 14.97ms, total: 104.90ms
train2.py:333:<module> (gradient), cpu: 4.98ms, accelerator: 23.25ms, total: 28.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_22000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_22250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_22500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_22750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 238.84ms, accelerator: 0us, total: 238.84ms (61.79%)
top 2 operation type: Conv2D, cpu: 85.28ms, accelerator: 8.61ms, total: 93.90ms (24.29%)
top 3 operation type: ResourceApplyAdam, cpu: 3.18ms, accelerator: 10.44ms, total: 13.64ms (3.53%)
top 1 graph node: IteratorGetNext, cpu: 238.84ms, accelerator: 0us, total: 238.84ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 240.06ms, accelerator: 0us, total: 240.06ms
  iterator_ops.py:373:get_next, cpu: 238.84ms, accelerator: 0us, total: 238.84ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.22ms, accelerator: 0us, total: 1.22ms
train2.py:333:<module>, cpu: 86.07ms, accelerator: 14.93ms, total: 101.03ms
train2.py:333:<module> (gradient), cpu: 4.89ms, accelerator: 23.25ms, total: 28.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_23000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_23250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_23500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_23750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 230.98ms, accelerator: 0us, total: 230.98ms (61.65%)
top 2 operation type: Conv2D, cpu: 81.77ms, accelerator: 8.53ms, total: 90.31ms (24.10%)
top 3 operation type: ResourceApplyAdam, cpu: 3.10ms, accelerator: 10.56ms, total: 13.67ms (3.65%)
top 1 graph node: IteratorGetNext, cpu: 230.98ms, accelerator: 0us, total: 230.98ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 232.15ms, accelerator: 0us, total: 232.15ms
  iterator_ops.py:373:get_next, cpu: 230.98ms, accelerator: 0us, total: 230.98ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.17ms, accelerator: 0us, total: 1.17ms
train2.py:333:<module>, cpu: 82.55ms, accelerator: 14.83ms, total: 97.41ms
train2.py:333:<module> (gradient), cpu: 4.80ms, accelerator: 23.02ms, total: 27.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_24000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_24250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_24500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_24750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 224.25ms, accelerator: 0us, total: 224.25ms (61.55%)
top 2 operation type: Conv2D, cpu: 78.54ms, accelerator: 8.46ms, total: 87.01ms (23.88%)
top 3 operation type: ResourceApplyAdam, cpu: 3.02ms, accelerator: 10.60ms, total: 13.64ms (3.74%)
top 1 graph node: IteratorGetNext, cpu: 224.25ms, accelerator: 0us, total: 224.25ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 225.37ms, accelerator: 0us, total: 225.37ms
  iterator_ops.py:373:get_next, cpu: 224.25ms, accelerator: 0us, total: 224.25ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.12ms, accelerator: 0us, total: 1.12ms
train2.py:333:<module>, cpu: 79.31ms, accelerator: 14.79ms, total: 94.14ms
train2.py:333:<module> (gradient), cpu: 4.73ms, accelerator: 22.92ms, total: 27.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_25000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_25250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_25500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_25750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 218.56ms, accelerator: 0us, total: 218.56ms (61.51%)
top 2 operation type: Conv2D, cpu: 75.56ms, accelerator: 8.39ms, total: 83.95ms (23.63%)
top 3 operation type: ResourceApplyAdam, cpu: 2.95ms, accelerator: 10.86ms, total: 13.82ms (3.89%)
top 1 graph node: IteratorGetNext, cpu: 218.56ms, accelerator: 0us, total: 218.56ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 219.64ms, accelerator: 0us, total: 219.64ms
  iterator_ops.py:373:get_next, cpu: 218.56ms, accelerator: 0us, total: 218.56ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.08ms, accelerator: 0us, total: 1.08ms
train2.py:333:<module>, cpu: 76.33ms, accelerator: 14.68ms, total: 91.03ms
train2.py:333:<module> (gradient), cpu: 4.66ms, accelerator: 22.57ms, total: 27.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_26000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_26250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_26500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_26750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 212.33ms, accelerator: 0us, total: 212.33ms (61.37%)
top 2 operation type: Conv2D, cpu: 72.80ms, accelerator: 8.40ms, total: 81.21ms (23.47%)
top 3 operation type: ResourceApplyAdam, cpu: 2.88ms, accelerator: 10.88ms, total: 13.77ms (3.98%)
top 1 graph node: IteratorGetNext, cpu: 212.33ms, accelerator: 0us, total: 212.33ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 213.37ms, accelerator: 0us, total: 213.37ms
  iterator_ops.py:373:get_next, cpu: 212.33ms, accelerator: 0us, total: 212.33ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.04ms, accelerator: 0us, total: 1.04ms
train2.py:333:<module>, cpu: 73.56ms, accelerator: 14.75ms, total: 88.34ms
train2.py:333:<module> (gradient), cpu: 4.59ms, accelerator: 22.37ms, total: 27.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_27000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_27250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_27500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_27750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 206.80ms, accelerator: 0us, total: 206.80ms (61.25%)
top 2 operation type: Conv2D, cpu: 70.24ms, accelerator: 8.35ms, total: 78.60ms (23.28%)
top 3 operation type: ResourceApplyAdam, cpu: 2.82ms, accelerator: 10.88ms, total: 13.71ms (4.06%)
top 1 graph node: IteratorGetNext, cpu: 206.80ms, accelerator: 0us, total: 206.80ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 207.80ms, accelerator: 0us, total: 207.80ms
  iterator_ops.py:373:get_next, cpu: 206.80ms, accelerator: 0us, total: 206.80ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.00ms, accelerator: 0us, total: 1.00ms
train2.py:333:<module>, cpu: 70.99ms, accelerator: 14.70ms, total: 85.72ms
train2.py:333:<module> (gradient), cpu: 4.53ms, accelerator: 22.34ms, total: 26.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_28000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_28250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_28500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_28750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 201.59ms, accelerator: 0us, total: 201.59ms (61.13%)
top 2 operation type: Conv2D, cpu: 67.85ms, accelerator: 8.40ms, total: 76.26ms (23.12%)
top 3 operation type: ResourceApplyAdam, cpu: 2.76ms, accelerator: 10.86ms, total: 13.64ms (4.13%)
top 1 graph node: IteratorGetNext, cpu: 201.59ms, accelerator: 0us, total: 201.59ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 202.55ms, accelerator: 0us, total: 202.55ms
  iterator_ops.py:373:get_next, cpu: 201.59ms, accelerator: 0us, total: 201.59ms
train2.py:333:<module>, cpu: 68.61ms, accelerator: 14.67ms, total: 83.30ms
train2.py:333:<module> (gradient), cpu: 4.48ms, accelerator: 22.35ms, total: 26.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_29000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_29250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_29500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_29750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 196.73ms, accelerator: 0us, total: 196.73ms (61.01%)
top 2 operation type: Conv2D, cpu: 65.63ms, accelerator: 8.37ms, total: 74.00ms (22.95%)
top 3 operation type: ResourceApplyAdam, cpu: 2.71ms, accelerator: 10.85ms, total: 13.58ms (4.21%)
top 1 graph node: IteratorGetNext, cpu: 196.73ms, accelerator: 0us, total: 196.73ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 197.66ms, accelerator: 0us, total: 197.66ms
  iterator_ops.py:373:get_next, cpu: 196.73ms, accelerator: 0us, total: 196.73ms
train2.py:333:<module>, cpu: 66.37ms, accelerator: 14.64ms, total: 81.04ms
train2.py:333:<module> (gradient), cpu: 4.43ms, accelerator: 22.31ms, total: 26.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_30000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_30250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_30500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_30750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 191.88ms, accelerator: 0us, total: 191.88ms (60.84%)
top 2 operation type: Conv2D, cpu: 63.54ms, accelerator: 8.39ms, total: 71.94ms (22.81%)
top 3 operation type: ResourceApplyAdam, cpu: 2.66ms, accelerator: 10.73ms, total: 13.41ms (4.25%)
top 1 graph node: IteratorGetNext, cpu: 191.88ms, accelerator: 0us, total: 191.88ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 192.78ms, accelerator: 0us, total: 192.78ms
  iterator_ops.py:373:get_next, cpu: 191.88ms, accelerator: 0us, total: 191.88ms
train2.py:333:<module>, cpu: 64.29ms, accelerator: 14.73ms, total: 79.04ms
train2.py:333:<module> (gradient), cpu: 4.38ms, accelerator: 22.41ms, total: 26.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.59
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_31000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_31250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_31500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_31750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 187.66ms, accelerator: 0us, total: 187.66ms (60.74%)
top 2 operation type: Conv2D, cpu: 61.59ms, accelerator: 8.36ms, total: 69.96ms (22.64%)
top 3 operation type: ResourceApplyAdam, cpu: 2.61ms, accelerator: 10.77ms, total: 13.40ms (4.34%)
top 1 graph node: IteratorGetNext, cpu: 187.66ms, accelerator: 0us, total: 187.66ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 188.54ms, accelerator: 0us, total: 188.54ms
  iterator_ops.py:373:get_next, cpu: 187.66ms, accelerator: 0us, total: 187.66ms
train2.py:333:<module>, cpu: 62.33ms, accelerator: 14.71ms, total: 77.06ms
train2.py:333:<module> (gradient), cpu: 4.33ms, accelerator: 22.30ms, total: 26.66ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_32000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_32250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_32500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_32750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 183.53ms, accelerator: 0us, total: 183.53ms (60.61%)
top 2 operation type: Conv2D, cpu: 59.75ms, accelerator: 8.35ms, total: 68.11ms (22.49%)
top 3 operation type: ResourceApplyAdam, cpu: 2.57ms, accelerator: 10.78ms, total: 13.37ms (4.41%)
top 1 graph node: IteratorGetNext, cpu: 183.53ms, accelerator: 0us, total: 183.53ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 184.38ms, accelerator: 0us, total: 184.38ms
  iterator_ops.py:373:get_next, cpu: 183.53ms, accelerator: 0us, total: 183.53ms
train2.py:333:<module>, cpu: 60.49ms, accelerator: 14.66ms, total: 75.18ms
train2.py:333:<module> (gradient), cpu: 4.28ms, accelerator: 22.29ms, total: 26.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_33000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_33250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_33500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_33750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 179.94ms, accelerator: 0us, total: 179.94ms (60.52%)
top 2 operation type: Conv2D, cpu: 58.03ms, accelerator: 8.33ms, total: 66.37ms (22.32%)
top 3 operation type: ResourceApplyAdam, cpu: 2.53ms, accelerator: 10.83ms, total: 13.37ms (4.50%)
top 1 graph node: IteratorGetNext, cpu: 179.94ms, accelerator: 0us, total: 179.94ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 180.77ms, accelerator: 0us, total: 180.77ms
  iterator_ops.py:373:get_next, cpu: 179.94ms, accelerator: 0us, total: 179.94ms
train2.py:333:<module>, cpu: 58.76ms, accelerator: 14.71ms, total: 73.48ms
train2.py:333:<module> (gradient), cpu: 4.24ms, accelerator: 22.18ms, total: 26.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_34000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_34250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_34500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_34750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 177.44ms, accelerator: 0us, total: 177.44ms (60.54%)
top 2 operation type: Conv2D, cpu: 56.40ms, accelerator: 8.36ms, total: 64.77ms (22.10%)
top 3 operation type: ResourceApplyAdam, cpu: 2.49ms, accelerator: 10.75ms, total: 13.26ms (4.52%)
top 1 graph node: IteratorGetNext, cpu: 177.44ms, accelerator: 0us, total: 177.44ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 178.24ms, accelerator: 0us, total: 178.24ms
  iterator_ops.py:373:get_next, cpu: 177.44ms, accelerator: 0us, total: 177.44ms
train2.py:333:<module>, cpu: 57.13ms, accelerator: 14.74ms, total: 71.89ms
train2.py:333:<module> (gradient), cpu: 4.20ms, accelerator: 22.24ms, total: 26.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_35000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_35250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_35500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_35750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 175.08ms, accelerator: 0us, total: 175.08ms (60.56%)
top 2 operation type: Conv2D, cpu: 54.86ms, accelerator: 8.39ms, total: 63.26ms (21.88%)
top 3 operation type: ResourceApplyAdam, cpu: 2.45ms, accelerator: 10.68ms, total: 13.14ms (4.55%)
top 1 graph node: IteratorGetNext, cpu: 175.08ms, accelerator: 0us, total: 175.08ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 175.85ms, accelerator: 0us, total: 175.85ms
  iterator_ops.py:373:get_next, cpu: 175.08ms, accelerator: 0us, total: 175.08ms
train2.py:333:<module>, cpu: 55.58ms, accelerator: 14.77ms, total: 70.39ms
train2.py:333:<module> (gradient), cpu: 4.17ms, accelerator: 22.31ms, total: 26.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_36000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_36250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_36500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_36750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 171.73ms, accelerator: 0us, total: 171.73ms (60.44%)
top 2 operation type: Conv2D, cpu: 53.41ms, accelerator: 8.35ms, total: 61.77ms (21.74%)
top 3 operation type: ResourceApplyAdam, cpu: 2.41ms, accelerator: 10.68ms, total: 13.11ms (4.61%)
top 1 graph node: IteratorGetNext, cpu: 171.73ms, accelerator: 0us, total: 171.73ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 172.48ms, accelerator: 0us, total: 172.48ms
  iterator_ops.py:373:get_next, cpu: 171.73ms, accelerator: 0us, total: 171.73ms
train2.py:333:<module>, cpu: 54.13ms, accelerator: 14.81ms, total: 68.97ms
train2.py:333:<module> (gradient), cpu: 4.13ms, accelerator: 22.23ms, total: 26.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_37000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_37250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_37500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_37750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 168.46ms, accelerator: 0us, total: 168.46ms (60.30%)
top 2 operation type: Conv2D, cpu: 52.03ms, accelerator: 8.40ms, total: 60.44ms (21.63%)
top 3 operation type: ResourceApplyAdam, cpu: 2.38ms, accelerator: 10.51ms, total: 12.90ms (4.62%)
top 1 graph node: IteratorGetNext, cpu: 168.46ms, accelerator: 0us, total: 168.46ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 169.20ms, accelerator: 0us, total: 169.20ms
  iterator_ops.py:373:get_next, cpu: 168.46ms, accelerator: 0us, total: 168.46ms
train2.py:333:<module>, cpu: 52.75ms, accelerator: 14.87ms, total: 67.64ms
train2.py:333:<module> (gradient), cpu: 4.10ms, accelerator: 22.38ms, total: 26.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_38000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_38250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_38500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_38750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 166.40ms, accelerator: 0us, total: 166.40ms (60.32%)
top 2 operation type: Conv2D, cpu: 50.72ms, accelerator: 8.39ms, total: 59.12ms (21.43%)
top 3 operation type: ResourceApplyAdam, cpu: 2.35ms, accelerator: 10.54ms, total: 12.91ms (4.68%)
top 1 graph node: IteratorGetNext, cpu: 166.40ms, accelerator: 0us, total: 166.40ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 167.12ms, accelerator: 0us, total: 167.12ms
  iterator_ops.py:373:get_next, cpu: 166.40ms, accelerator: 0us, total: 166.40ms
train2.py:333:<module>, cpu: 51.44ms, accelerator: 14.83ms, total: 66.30ms
train2.py:333:<module> (gradient), cpu: 4.07ms, accelerator: 22.30ms, total: 26.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_39000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_39250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_39500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_39750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 164.18ms, accelerator: 0us, total: 164.18ms (60.30%)
top 2 operation type: Conv2D, cpu: 49.48ms, accelerator: 8.36ms, total: 57.85ms (21.25%)
top 3 operation type: ResourceApplyAdam, cpu: 2.32ms, accelerator: 10.61ms, total: 12.95ms (4.76%)
top 1 graph node: IteratorGetNext, cpu: 164.18ms, accelerator: 0us, total: 164.18ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 164.88ms, accelerator: 0us, total: 164.88ms
  iterator_ops.py:373:get_next, cpu: 164.18ms, accelerator: 0us, total: 164.18ms
train2.py:333:<module>, cpu: 50.20ms, accelerator: 14.81ms, total: 65.02ms
train2.py:333:<module> (gradient), cpu: 4.04ms, accelerator: 22.24ms, total: 26.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_40000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_40250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_40500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_40750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 161.32ms, accelerator: 0us, total: 161.32ms (60.18%)
top 2 operation type: Conv2D, cpu: 48.30ms, accelerator: 8.28ms, total: 56.59ms (21.11%)
top 3 operation type: ResourceApplyAdam, cpu: 2.29ms, accelerator: 10.69ms, total: 12.99ms (4.85%)
top 1 graph node: IteratorGetNext, cpu: 161.32ms, accelerator: 0us, total: 161.32ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 162.01ms, accelerator: 0us, total: 162.01ms
  iterator_ops.py:373:get_next, cpu: 161.32ms, accelerator: 0us, total: 161.32ms
train2.py:333:<module>, cpu: 49.01ms, accelerator: 14.82ms, total: 63.85ms
train2.py:333:<module> (gradient), cpu: 4.01ms, accelerator: 22.05ms, total: 26.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_41000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_41250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_41500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_41750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 158.97ms, accelerator: 0us, total: 158.97ms (60.13%)
top 2 operation type: Conv2D, cpu: 47.17ms, accelerator: 8.20ms, total: 55.38ms (20.95%)
top 3 operation type: ResourceApplyAdam, cpu: 2.27ms, accelerator: 10.75ms, total: 13.03ms (4.93%)
top 1 graph node: IteratorGetNext, cpu: 158.97ms, accelerator: 0us, total: 158.97ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 159.64ms, accelerator: 0us, total: 159.64ms
  iterator_ops.py:373:get_next, cpu: 158.97ms, accelerator: 0us, total: 158.97ms
train2.py:333:<module>, cpu: 47.88ms, accelerator: 14.81ms, total: 62.72ms
train2.py:333:<module> (gradient), cpu: 3.98ms, accelerator: 21.90ms, total: 25.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_42000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_42250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_42500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_42750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 157.00ms, accelerator: 0us, total: 157.00ms (60.09%)
top 2 operation type: Conv2D, cpu: 46.10ms, accelerator: 8.22ms, total: 54.33ms (20.79%)
top 3 operation type: ResourceApplyAdam, cpu: 2.24ms, accelerator: 10.67ms, total: 12.93ms (4.95%)
top 1 graph node: IteratorGetNext, cpu: 157.00ms, accelerator: 0us, total: 157.00ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 157.65ms, accelerator: 0us, total: 157.65ms
  iterator_ops.py:373:get_next, cpu: 157.00ms, accelerator: 0us, total: 157.00ms
train2.py:333:<module>, cpu: 46.81ms, accelerator: 14.86ms, total: 61.69ms
train2.py:333:<module> (gradient), cpu: 3.96ms, accelerator: 21.96ms, total: 25.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_43000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_43250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_43500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_43750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 154.95ms, accelerator: 0us, total: 154.95ms (60.04%)
top 2 operation type: Conv2D, cpu: 45.08ms, accelerator: 8.16ms, total: 53.25ms (20.63%)
top 3 operation type: ResourceApplyAdam, cpu: 2.22ms, accelerator: 10.73ms, total: 12.97ms (5.03%)
top 1 graph node: IteratorGetNext, cpu: 154.95ms, accelerator: 0us, total: 154.95ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 155.59ms, accelerator: 0us, total: 155.59ms
  iterator_ops.py:373:get_next, cpu: 154.95ms, accelerator: 0us, total: 154.95ms
train2.py:333:<module>, cpu: 45.78ms, accelerator: 14.79ms, total: 60.60ms
train2.py:333:<module> (gradient), cpu: 3.94ms, accelerator: 21.90ms, total: 25.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_44000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_44250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_44500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_44750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 152.74ms, accelerator: 0us, total: 152.74ms (59.95%)
top 2 operation type: Conv2D, cpu: 44.10ms, accelerator: 8.14ms, total: 52.25ms (20.51%)
top 3 operation type: ResourceApplyAdam, cpu: 2.20ms, accelerator: 10.73ms, total: 12.95ms (5.08%)
top 1 graph node: IteratorGetNext, cpu: 152.74ms, accelerator: 0us, total: 152.74ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 153.37ms, accelerator: 0us, total: 153.37ms
  iterator_ops.py:373:get_next, cpu: 152.74ms, accelerator: 0us, total: 152.74ms
train2.py:333:<module>, cpu: 44.80ms, accelerator: 14.80ms, total: 59.62ms
train2.py:333:<module> (gradient), cpu: 3.92ms, accelerator: 21.87ms, total: 25.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.59
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_45000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_45250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_45500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_45750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 150.54ms, accelerator: 0us, total: 150.54ms (59.85%)
top 2 operation type: Conv2D, cpu: 43.16ms, accelerator: 8.12ms, total: 51.29ms (20.39%)
top 3 operation type: ResourceApplyAdam, cpu: 2.17ms, accelerator: 10.72ms, total: 12.92ms (5.14%)
top 1 graph node: IteratorGetNext, cpu: 150.54ms, accelerator: 0us, total: 150.54ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 151.15ms, accelerator: 0us, total: 151.15ms
  iterator_ops.py:373:get_next, cpu: 150.54ms, accelerator: 0us, total: 150.54ms
train2.py:333:<module>, cpu: 43.86ms, accelerator: 14.80ms, total: 58.69ms
train2.py:333:<module> (gradient), cpu: 3.90ms, accelerator: 21.82ms, total: 25.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_46000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_46250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_46500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_46750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 148.49ms, accelerator: 0us, total: 148.49ms (59.76%)
top 2 operation type: Conv2D, cpu: 42.27ms, accelerator: 8.12ms, total: 50.40ms (20.28%)
top 3 operation type: ResourceApplyAdam, cpu: 2.15ms, accelerator: 10.76ms, total: 12.93ms (5.20%)
top 1 graph node: IteratorGetNext, cpu: 148.49ms, accelerator: 0us, total: 148.49ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 149.09ms, accelerator: 0us, total: 149.09ms
  iterator_ops.py:373:get_next, cpu: 148.49ms, accelerator: 0us, total: 148.49ms
train2.py:333:<module>, cpu: 42.97ms, accelerator: 14.71ms, total: 57.70ms
train2.py:333:<module> (gradient), cpu: 3.88ms, accelerator: 21.87ms, total: 25.78ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_47000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_47250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_47500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_47750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 146.79ms, accelerator: 0us, total: 146.79ms (59.70%)
top 2 operation type: Conv2D, cpu: 41.41ms, accelerator: 8.17ms, total: 49.59ms (20.17%)
top 3 operation type: ResourceApplyAdam, cpu: 2.13ms, accelerator: 10.62ms, total: 12.77ms (5.19%)
top 1 graph node: IteratorGetNext, cpu: 146.79ms, accelerator: 0us, total: 146.79ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 147.38ms, accelerator: 0us, total: 147.38ms
  iterator_ops.py:373:get_next, cpu: 146.79ms, accelerator: 0us, total: 146.79ms
train2.py:333:<module>, cpu: 42.10ms, accelerator: 14.75ms, total: 56.88ms
train2.py:333:<module> (gradient), cpu: 3.86ms, accelerator: 22.00ms, total: 25.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_48000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_48250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_48500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_48750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 144.99ms, accelerator: 0us, total: 144.99ms (59.64%)
top 2 operation type: Conv2D, cpu: 40.59ms, accelerator: 8.12ms, total: 48.72ms (20.04%)
top 3 operation type: ResourceApplyAdam, cpu: 2.11ms, accelerator: 10.69ms, total: 12.81ms (5.27%)
top 1 graph node: IteratorGetNext, cpu: 144.99ms, accelerator: 0us, total: 144.99ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 145.57ms, accelerator: 0us, total: 145.57ms
  iterator_ops.py:373:get_next, cpu: 144.99ms, accelerator: 0us, total: 144.99ms
train2.py:333:<module>, cpu: 41.28ms, accelerator: 14.71ms, total: 56.01ms
train2.py:333:<module> (gradient), cpu: 3.84ms, accelerator: 21.93ms, total: 25.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_49000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_49250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_49500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_49750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 143.33ms, accelerator: 0us, total: 143.33ms (59.58%)
top 2 operation type: Conv2D, cpu: 39.80ms, accelerator: 8.08ms, total: 47.89ms (19.91%)
top 3 operation type: ResourceApplyAdam, cpu: 2.09ms, accelerator: 10.80ms, total: 12.91ms (5.36%)
top 1 graph node: IteratorGetNext, cpu: 143.33ms, accelerator: 0us, total: 143.33ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 143.89ms, accelerator: 0us, total: 143.89ms
  iterator_ops.py:373:get_next, cpu: 143.33ms, accelerator: 0us, total: 143.33ms
train2.py:333:<module>, cpu: 40.49ms, accelerator: 14.65ms, total: 55.16ms
train2.py:333:<module> (gradient), cpu: 3.82ms, accelerator: 21.83ms, total: 25.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_50000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_50250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_50500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_50750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 90425215.64sec, total: 90425215.64sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 141.77ms, accelerator: 0us, total: 141.77ms (0.00%)
top 3 operation type: Conv2D, cpu: 39.04ms, accelerator: 8.10ms, total: 47.14ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 141.77ms, accelerator: 0us, total: 141.77ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.81ms, accelerator: 90425215.66sec, total: 90425215.66sec
train2.py:307:<module>, cpu: 142.32ms, accelerator: 0us, total: 142.32ms
  iterator_ops.py:373:get_next, cpu: 141.77ms, accelerator: 0us, total: 141.77ms
train2.py:333:<module>, cpu: 39.73ms, accelerator: 14.69ms, total: 54.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_51000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_51250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_51500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_51750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 88686269.19sec, total: 88686269.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 140.29ms, accelerator: 0us, total: 140.29ms (0.00%)
top 3 operation type: Conv2D, cpu: 38.31ms, accelerator: 8.06ms, total: 46.38ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 140.29ms, accelerator: 0us, total: 140.29ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.78ms, accelerator: 88686269.21sec, total: 88686269.21sec
train2.py:307:<module>, cpu: 140.84ms, accelerator: 0us, total: 140.84ms
  iterator_ops.py:373:get_next, cpu: 140.29ms, accelerator: 0us, total: 140.29ms
train2.py:333:<module>, cpu: 38.99ms, accelerator: 14.68ms, total: 53.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_52000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_52250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_52500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_52750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 87012943.35sec, total: 87012943.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 139.10ms, accelerator: 0us, total: 139.10ms (0.00%)
top 3 operation type: Conv2D, cpu: 37.60ms, accelerator: 8.02ms, total: 45.63ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 139.10ms, accelerator: 0us, total: 139.10ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.77ms, accelerator: 87012943.37sec, total: 87012943.38sec
train2.py:307:<module>, cpu: 139.63ms, accelerator: 0us, total: 139.63ms
  iterator_ops.py:373:get_next, cpu: 139.10ms, accelerator: 0us, total: 139.10ms
train2.py:333:<module>, cpu: 38.29ms, accelerator: 14.63ms, total: 52.94ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_53000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_53250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_53500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_53750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 85401592.55sec, total: 85401592.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 137.67ms, accelerator: 0us, total: 137.67ms (0.00%)
top 3 operation type: Conv2D, cpu: 36.93ms, accelerator: 7.99ms, total: 44.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 137.67ms, accelerator: 0us, total: 137.67ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.75ms, accelerator: 85401592.57sec, total: 85401592.57sec
train2.py:307:<module>, cpu: 138.19ms, accelerator: 0us, total: 138.19ms
  iterator_ops.py:373:get_next, cpu: 137.67ms, accelerator: 0us, total: 137.67ms
train2.py:333:<module>, cpu: 37.61ms, accelerator: 14.55ms, total: 52.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_54000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_54250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_54500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_54750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 83848836.32sec, total: 83848836.32sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 136.04ms, accelerator: 0us, total: 136.04ms (0.00%)
top 3 operation type: Conv2D, cpu: 36.27ms, accelerator: 8.01ms, total: 44.29ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 136.04ms, accelerator: 0us, total: 136.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.74ms, accelerator: 83848836.34sec, total: 83848836.34sec
train2.py:307:<module>, cpu: 136.55ms, accelerator: 0us, total: 136.55ms
  iterator_ops.py:373:get_next, cpu: 136.04ms, accelerator: 0us, total: 136.04ms
train2.py:333:<module>, cpu: 36.96ms, accelerator: 14.58ms, total: 51.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_55000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_55250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_55500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_55750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 82351535.67sec, total: 82351535.67sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 134.61ms, accelerator: 0us, total: 134.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 35.65ms, accelerator: 8.00ms, total: 43.66ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 134.61ms, accelerator: 0us, total: 134.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.73ms, accelerator: 82351535.69sec, total: 82351535.70sec
train2.py:307:<module>, cpu: 135.11ms, accelerator: 0us, total: 135.11ms
  iterator_ops.py:373:get_next, cpu: 134.61ms, accelerator: 0us, total: 134.61ms
train2.py:333:<module>, cpu: 36.33ms, accelerator: 14.55ms, total: 50.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_56000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_56250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_56500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_56750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 80906771.89sec, total: 80906771.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 133.82ms, accelerator: 0us, total: 133.82ms (0.00%)
top 3 operation type: Conv2D, cpu: 35.04ms, accelerator: 8.07ms, total: 43.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 133.82ms, accelerator: 0us, total: 133.82ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.71ms, accelerator: 80906771.91sec, total: 80906771.91sec
train2.py:307:<module>, cpu: 134.31ms, accelerator: 0us, total: 134.31ms
  iterator_ops.py:373:get_next, cpu: 133.82ms, accelerator: 0us, total: 133.82ms
train2.py:333:<module>, cpu: 35.72ms, accelerator: 14.60ms, total: 50.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_57000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_57250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_57500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_57750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 79511827.55sec, total: 79511827.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 132.73ms, accelerator: 0us, total: 132.73ms (0.00%)
top 3 operation type: Conv2D, cpu: 34.45ms, accelerator: 8.10ms, total: 42.56ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 132.73ms, accelerator: 0us, total: 132.73ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.69ms, accelerator: 79511827.57sec, total: 79511827.57sec
train2.py:307:<module>, cpu: 133.22ms, accelerator: 0us, total: 133.22ms
  iterator_ops.py:373:get_next, cpu: 132.73ms, accelerator: 0us, total: 132.73ms
train2.py:333:<module>, cpu: 35.13ms, accelerator: 14.59ms, total: 49.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_58000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_58250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_58500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_58750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 78164169.45sec, total: 78164169.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 131.59ms, accelerator: 0us, total: 131.59ms (0.00%)
top 3 operation type: Conv2D, cpu: 33.89ms, accelerator: 8.10ms, total: 41.99ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 131.59ms, accelerator: 0us, total: 131.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.68ms, accelerator: 78164169.47sec, total: 78164169.48sec
train2.py:307:<module>, cpu: 132.07ms, accelerator: 0us, total: 132.07ms
  iterator_ops.py:373:get_next, cpu: 131.59ms, accelerator: 0us, total: 131.59ms
train2.py:333:<module>, cpu: 34.56ms, accelerator: 14.57ms, total: 49.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_59000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_59250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_59500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_59750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 76861433.29sec, total: 76861433.30sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 130.83ms, accelerator: 0us, total: 130.83ms (0.00%)
top 3 operation type: Conv2D, cpu: 33.34ms, accelerator: 8.11ms, total: 41.46ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 130.83ms, accelerator: 0us, total: 130.83ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.66ms, accelerator: 76861433.31sec, total: 76861433.32sec
train2.py:307:<module>, cpu: 131.30ms, accelerator: 0us, total: 131.30ms
  iterator_ops.py:373:get_next, cpu: 130.83ms, accelerator: 0us, total: 130.83ms
train2.py:333:<module>, cpu: 34.01ms, accelerator: 14.60ms, total: 48.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_60000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_60250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_60500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_60750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 75601409.80sec, total: 75601409.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 129.42ms, accelerator: 0us, total: 129.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 32.81ms, accelerator: 8.11ms, total: 40.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 129.42ms, accelerator: 0us, total: 129.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.65ms, accelerator: 75601409.82sec, total: 75601409.82sec
train2.py:307:<module>, cpu: 129.88ms, accelerator: 0us, total: 129.88ms
  iterator_ops.py:373:get_next, cpu: 129.42ms, accelerator: 0us, total: 129.42ms
train2.py:333:<module>, cpu: 33.48ms, accelerator: 14.54ms, total: 48.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_61000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_61250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_61500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_61750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 74382032.22sec, total: 74382032.22sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.43ms, accelerator: 0us, total: 128.43ms (0.00%)
top 3 operation type: Conv2D, cpu: 32.30ms, accelerator: 8.15ms, total: 40.45ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.43ms, accelerator: 0us, total: 128.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.64ms, accelerator: 74382032.24sec, total: 74382032.24sec
train2.py:307:<module>, cpu: 128.88ms, accelerator: 0us, total: 128.88ms
  iterator_ops.py:373:get_next, cpu: 128.43ms, accelerator: 0us, total: 128.43ms
train2.py:333:<module>, cpu: 32.97ms, accelerator: 14.58ms, total: 47.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_62000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_62250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_62500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_62750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 73201365.04sec, total: 73201365.04sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.32ms, accelerator: 0us, total: 127.32ms (0.00%)
top 3 operation type: Conv2D, cpu: 31.80ms, accelerator: 8.12ms, total: 39.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.32ms, accelerator: 0us, total: 127.32ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.63ms, accelerator: 73201365.06sec, total: 73201365.07sec
train2.py:307:<module>, cpu: 127.76ms, accelerator: 0us, total: 127.76ms
  iterator_ops.py:373:get_next, cpu: 127.32ms, accelerator: 0us, total: 127.32ms
train2.py:333:<module>, cpu: 32.47ms, accelerator: 14.57ms, total: 47.07ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_63000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_63250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_63500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_63750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 72057593.71sec, total: 72057593.71sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 126.42ms, accelerator: 0us, total: 126.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 31.32ms, accelerator: 8.13ms, total: 39.46ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 126.42ms, accelerator: 0us, total: 126.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.62ms, accelerator: 72057593.73sec, total: 72057593.74sec
train2.py:307:<module>, cpu: 126.86ms, accelerator: 0us, total: 126.86ms
  iterator_ops.py:373:get_next, cpu: 126.42ms, accelerator: 0us, total: 126.42ms
train2.py:333:<module>, cpu: 31.99ms, accelerator: 14.59ms, total: 46.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_64000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_64250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_64500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_64750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 70949015.35sec, total: 70949015.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 125.63ms, accelerator: 0us, total: 125.63ms (0.00%)
top 3 operation type: Conv2D, cpu: 30.85ms, accelerator: 8.11ms, total: 38.97ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 125.63ms, accelerator: 0us, total: 125.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.61ms, accelerator: 70949015.37sec, total: 70949015.37sec
train2.py:307:<module>, cpu: 126.06ms, accelerator: 0us, total: 126.06ms
  iterator_ops.py:373:get_next, cpu: 125.63ms, accelerator: 0us, total: 125.63ms
train2.py:333:<module>, cpu: 31.52ms, accelerator: 14.53ms, total: 46.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_65000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_65250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_65500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_65750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 69874030.27sec, total: 69874030.27sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 124.76ms, accelerator: 0us, total: 124.76ms (0.00%)
top 3 operation type: Conv2D, cpu: 30.40ms, accelerator: 8.16ms, total: 38.58ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 124.76ms, accelerator: 0us, total: 124.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.59ms, accelerator: 69874030.29sec, total: 69874030.29sec
train2.py:307:<module>, cpu: 125.19ms, accelerator: 0us, total: 125.19ms
  iterator_ops.py:373:get_next, cpu: 124.76ms, accelerator: 0us, total: 124.76ms
train2.py:333:<module>, cpu: 31.07ms, accelerator: 14.58ms, total: 45.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_66000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_66250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_66500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_66750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 68831134.29sec, total: 68831134.29sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 124.35ms, accelerator: 0us, total: 124.35ms (0.00%)
top 3 operation type: Conv2D, cpu: 29.96ms, accelerator: 8.18ms, total: 38.15ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 124.35ms, accelerator: 0us, total: 124.35ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.58ms, accelerator: 68831134.31sec, total: 68831134.32sec
train2.py:307:<module>, cpu: 124.77ms, accelerator: 0us, total: 124.77ms
  iterator_ops.py:373:get_next, cpu: 124.35ms, accelerator: 0us, total: 124.35ms
train2.py:333:<module>, cpu: 30.63ms, accelerator: 14.60ms, total: 45.26ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_67000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_67250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_67500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_67750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 67818911.73sec, total: 67818911.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 123.31ms, accelerator: 0us, total: 123.31ms (0.00%)
top 3 operation type: Conv2D, cpu: 29.54ms, accelerator: 8.17ms, total: 37.72ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 123.31ms, accelerator: 0us, total: 123.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.57ms, accelerator: 67818911.75sec, total: 67818911.75sec
train2.py:307:<module>, cpu: 123.72ms, accelerator: 0us, total: 123.72ms
  iterator_ops.py:373:get_next, cpu: 123.31ms, accelerator: 0us, total: 123.31ms
train2.py:333:<module>, cpu: 30.21ms, accelerator: 14.58ms, total: 44.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_68000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_68250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_68500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_68750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 66836028.95sec, total: 66836028.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 122.13ms, accelerator: 0us, total: 122.13ms (0.00%)
top 3 operation type: Conv2D, cpu: 29.13ms, accelerator: 8.19ms, total: 37.33ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 122.13ms, accelerator: 0us, total: 122.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.56ms, accelerator: 66836028.97sec, total: 66836028.98sec
train2.py:307:<module>, cpu: 122.54ms, accelerator: 0us, total: 122.54ms
  iterator_ops.py:373:get_next, cpu: 122.13ms, accelerator: 0us, total: 122.13ms
train2.py:333:<module>, cpu: 29.79ms, accelerator: 14.58ms, total: 44.40ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_69000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_69250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_69500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_69750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 65881228.54sec, total: 65881228.54sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 121.94ms, accelerator: 0us, total: 121.94ms (0.00%)
top 3 operation type: Conv2D, cpu: 28.73ms, accelerator: 8.24ms, total: 36.98ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 121.94ms, accelerator: 0us, total: 121.94ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.55ms, accelerator: 65881228.56sec, total: 65881228.56sec
train2.py:307:<module>, cpu: 122.34ms, accelerator: 0us, total: 122.34ms
  iterator_ops.py:373:get_next, cpu: 121.94ms, accelerator: 0us, total: 121.94ms
train2.py:333:<module>, cpu: 29.39ms, accelerator: 14.62ms, total: 44.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_70000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_70250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_70500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_70750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 64953323.91sec, total: 64953323.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 121.03ms, accelerator: 0us, total: 121.03ms (0.00%)
top 3 operation type: Conv2D, cpu: 28.33ms, accelerator: 8.25ms, total: 36.59ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 121.03ms, accelerator: 0us, total: 121.03ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.54ms, accelerator: 64953323.93sec, total: 64953323.93sec
train2.py:307:<module>, cpu: 121.43ms, accelerator: 0us, total: 121.43ms
  iterator_ops.py:373:get_next, cpu: 121.03ms, accelerator: 0us, total: 121.03ms
train2.py:333:<module>, cpu: 29.00ms, accelerator: 14.61ms, total: 43.64ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_71000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_71250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_71500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_71750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 64051194.41sec, total: 64051194.41sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 120.05ms, accelerator: 0us, total: 120.05ms (0.00%)
top 3 operation type: Conv2D, cpu: 27.96ms, accelerator: 8.21ms, total: 36.18ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 120.05ms, accelerator: 0us, total: 120.05ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.53ms, accelerator: 64051194.43sec, total: 64051194.44sec
train2.py:307:<module>, cpu: 120.44ms, accelerator: 0us, total: 120.44ms
  iterator_ops.py:373:get_next, cpu: 120.05ms, accelerator: 0us, total: 120.05ms
train2.py:333:<module>, cpu: 28.62ms, accelerator: 14.60ms, total: 43.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_72000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_72250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_72500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_72750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 63173780.79sec, total: 63173780.79sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 119.06ms, accelerator: 0us, total: 119.06ms (0.00%)
top 3 operation type: Conv2D, cpu: 27.58ms, accelerator: 8.21ms, total: 35.81ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 119.06ms, accelerator: 0us, total: 119.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.52ms, accelerator: 63173780.81sec, total: 63173780.81sec
train2.py:307:<module>, cpu: 119.45ms, accelerator: 0us, total: 119.45ms
  iterator_ops.py:373:get_next, cpu: 119.06ms, accelerator: 0us, total: 119.06ms
train2.py:333:<module>, cpu: 28.25ms, accelerator: 14.61ms, total: 42.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_73000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_73250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_73500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_73750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 62320081.05sec, total: 62320081.05sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 118.53ms, accelerator: 0us, total: 118.53ms (0.00%)
top 3 operation type: Conv2D, cpu: 27.23ms, accelerator: 8.21ms, total: 35.45ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 118.53ms, accelerator: 0us, total: 118.53ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.51ms, accelerator: 62320081.07sec, total: 62320081.07sec
train2.py:307:<module>, cpu: 118.91ms, accelerator: 0us, total: 118.91ms
  iterator_ops.py:373:get_next, cpu: 118.53ms, accelerator: 0us, total: 118.53ms
train2.py:333:<module>, cpu: 27.89ms, accelerator: 14.57ms, total: 42.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_74000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_74250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_74500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_74750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 61489146.64sec, total: 61489146.64sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 117.88ms, accelerator: 0us, total: 117.88ms (0.00%)
top 3 operation type: Conv2D, cpu: 26.88ms, accelerator: 8.22ms, total: 35.11ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 117.88ms, accelerator: 0us, total: 117.88ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.50ms, accelerator: 61489146.66sec, total: 61489146.66sec
train2.py:307:<module>, cpu: 118.26ms, accelerator: 0us, total: 118.26ms
  iterator_ops.py:373:get_next, cpu: 117.88ms, accelerator: 0us, total: 117.88ms
train2.py:333:<module>, cpu: 27.54ms, accelerator: 14.59ms, total: 42.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_75000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_75250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_75500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_75750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 60680078.92sec, total: 60680078.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.88ms, accelerator: 0us, total: 116.88ms (0.00%)
top 3 operation type: Conv2D, cpu: 26.54ms, accelerator: 8.19ms, total: 34.73ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.88ms, accelerator: 0us, total: 116.88ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.49ms, accelerator: 60680078.94sec, total: 60680078.94sec
train2.py:307:<module>, cpu: 117.25ms, accelerator: 0us, total: 117.25ms
  iterator_ops.py:373:get_next, cpu: 116.88ms, accelerator: 0us, total: 116.88ms
train2.py:333:<module>, cpu: 27.20ms, accelerator: 14.59ms, total: 41.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_76000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_76250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_76500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_76750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 59892025.94sec, total: 59892025.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.01ms, accelerator: 0us, total: 116.01ms (0.00%)
top 3 operation type: Conv2D, cpu: 26.20ms, accelerator: 8.19ms, total: 34.40ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.01ms, accelerator: 0us, total: 116.01ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.48ms, accelerator: 59892025.96sec, total: 59892025.97sec
train2.py:307:<module>, cpu: 116.38ms, accelerator: 0us, total: 116.38ms
  iterator_ops.py:373:get_next, cpu: 116.01ms, accelerator: 0us, total: 116.01ms
train2.py:333:<module>, cpu: 26.86ms, accelerator: 14.53ms, total: 41.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_77000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_77250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_77500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_77750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 59124179.46sec, total: 59124179.46sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.44ms, accelerator: 0us, total: 115.44ms (0.00%)
top 3 operation type: Conv2D, cpu: 25.88ms, accelerator: 8.17ms, total: 34.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.44ms, accelerator: 0us, total: 115.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.47ms, accelerator: 59124179.48sec, total: 59124179.48sec
train2.py:307:<module>, cpu: 115.80ms, accelerator: 0us, total: 115.80ms
  iterator_ops.py:373:get_next, cpu: 115.44ms, accelerator: 0us, total: 115.44ms
train2.py:333:<module>, cpu: 26.54ms, accelerator: 14.56ms, total: 41.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_78000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_78250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_78500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_78750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 58375772.12sec, total: 58375772.12sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.65ms, accelerator: 0us, total: 114.65ms (0.00%)
top 3 operation type: Conv2D, cpu: 25.57ms, accelerator: 8.14ms, total: 33.72ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.65ms, accelerator: 0us, total: 114.65ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.47ms, accelerator: 58375772.14sec, total: 58375772.15sec
train2.py:307:<module>, cpu: 115.00ms, accelerator: 0us, total: 115.00ms
  iterator_ops.py:373:get_next, cpu: 114.65ms, accelerator: 0us, total: 114.65ms
train2.py:333:<module>, cpu: 26.22ms, accelerator: 14.52ms, total: 40.77ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_79000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_79250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_79500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_79750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 57646074.97sec, total: 57646074.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.06ms, accelerator: 0us, total: 114.06ms (0.00%)
top 3 operation type: Conv2D, cpu: 25.26ms, accelerator: 8.13ms, total: 33.40ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.06ms, accelerator: 0us, total: 114.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.46ms, accelerator: 57646074.99sec, total: 57646074.99sec
train2.py:307:<module>, cpu: 114.42ms, accelerator: 0us, total: 114.42ms
  iterator_ops.py:373:get_next, cpu: 114.06ms, accelerator: 0us, total: 114.06ms
train2.py:333:<module>, cpu: 25.92ms, accelerator: 14.50ms, total: 40.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_80000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_80250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_80500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_80750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 56934395.03sec, total: 56934395.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.35ms, accelerator: 0us, total: 113.35ms (0.00%)
top 3 operation type: Conv2D, cpu: 24.96ms, accelerator: 8.12ms, total: 33.09ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.35ms, accelerator: 0us, total: 113.35ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.45ms, accelerator: 56934395.05sec, total: 56934395.06sec
train2.py:307:<module>, cpu: 113.70ms, accelerator: 0us, total: 113.70ms
  iterator_ops.py:373:get_next, cpu: 113.35ms, accelerator: 0us, total: 113.35ms
train2.py:333:<module>, cpu: 25.62ms, accelerator: 14.52ms, total: 40.16ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_81000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_81250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_81500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_81750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 56240073.14sec, total: 56240073.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.62ms, accelerator: 0us, total: 112.62ms (0.00%)
top 3 operation type: Conv2D, cpu: 24.67ms, accelerator: 8.11ms, total: 32.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.62ms, accelerator: 0us, total: 112.62ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.44ms, accelerator: 56240073.16sec, total: 56240073.17sec
train2.py:307:<module>, cpu: 112.97ms, accelerator: 0us, total: 112.97ms
  iterator_ops.py:373:get_next, cpu: 112.62ms, accelerator: 0us, total: 112.62ms
train2.py:333:<module>, cpu: 25.32ms, accelerator: 14.50ms, total: 39.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_82000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_82250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_82500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_82750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 55562481.90sec, total: 55562481.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.02ms, accelerator: 0us, total: 112.02ms (0.00%)
top 3 operation type: Conv2D, cpu: 24.39ms, accelerator: 8.10ms, total: 32.49ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.02ms, accelerator: 0us, total: 112.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.44ms, accelerator: 55562481.92sec, total: 55562481.92sec
train2.py:307:<module>, cpu: 112.36ms, accelerator: 0us, total: 112.36ms
  iterator_ops.py:373:get_next, cpu: 112.02ms, accelerator: 0us, total: 112.02ms
train2.py:333:<module>, cpu: 25.04ms, accelerator: 14.50ms, total: 39.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_83000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_83250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_83500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_83750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 54901023.78sec, total: 54901023.78sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.34ms, accelerator: 0us, total: 111.34ms (0.00%)
top 3 operation type: Conv2D, cpu: 24.11ms, accelerator: 8.10ms, total: 32.21ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.34ms, accelerator: 0us, total: 111.34ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.43ms, accelerator: 54901023.80sec, total: 54901023.81sec
train2.py:307:<module>, cpu: 111.67ms, accelerator: 0us, total: 111.67ms
  iterator_ops.py:373:get_next, cpu: 111.34ms, accelerator: 0us, total: 111.34ms
train2.py:333:<module>, cpu: 24.76ms, accelerator: 14.43ms, total: 39.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_84000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_84250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_84500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_84750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 54255129.39sec, total: 54255129.39sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.63ms, accelerator: 0us, total: 110.63ms (0.00%)
top 3 operation type: Conv2D, cpu: 23.84ms, accelerator: 8.10ms, total: 31.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.63ms, accelerator: 0us, total: 110.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.42ms, accelerator: 54255129.40sec, total: 54255129.41sec
train2.py:307:<module>, cpu: 110.96ms, accelerator: 0us, total: 110.96ms
  iterator_ops.py:373:get_next, cpu: 110.63ms, accelerator: 0us, total: 110.63ms
train2.py:333:<module>, cpu: 24.49ms, accelerator: 14.43ms, total: 38.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_85000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_85250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_85500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_85750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 53624255.79sec, total: 53624255.79sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.85ms, accelerator: 0us, total: 109.85ms (0.00%)
top 3 operation type: Conv2D, cpu: 23.57ms, accelerator: 8.08ms, total: 31.66ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.85ms, accelerator: 0us, total: 109.85ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.41ms, accelerator: 53624255.81sec, total: 53624255.81sec
train2.py:307:<module>, cpu: 110.17ms, accelerator: 0us, total: 110.17ms
  iterator_ops.py:373:get_next, cpu: 109.85ms, accelerator: 0us, total: 109.85ms
train2.py:333:<module>, cpu: 24.22ms, accelerator: 14.41ms, total: 38.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_86000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_86250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_86500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_86750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 53007885.03sec, total: 53007885.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.24ms, accelerator: 0us, total: 109.24ms (0.00%)
top 3 operation type: Conv2D, cpu: 23.31ms, accelerator: 8.07ms, total: 31.39ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.24ms, accelerator: 0us, total: 109.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.40ms, accelerator: 53007885.05sec, total: 53007885.05sec
train2.py:307:<module>, cpu: 109.57ms, accelerator: 0us, total: 109.57ms
  iterator_ops.py:373:get_next, cpu: 109.24ms, accelerator: 0us, total: 109.24ms
train2.py:333:<module>, cpu: 23.96ms, accelerator: 14.37ms, total: 38.36ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_87000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_87250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_87500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_87750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 52405522.70sec, total: 52405522.70sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.59ms, accelerator: 0us, total: 108.59ms (0.00%)
top 3 operation type: Conv2D, cpu: 23.06ms, accelerator: 8.06ms, total: 31.13ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.59ms, accelerator: 0us, total: 108.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.40ms, accelerator: 52405522.72sec, total: 52405522.72sec
train2.py:307:<module>, cpu: 108.91ms, accelerator: 0us, total: 108.91ms
  iterator_ops.py:373:get_next, cpu: 108.59ms, accelerator: 0us, total: 108.59ms
train2.py:333:<module>, cpu: 23.71ms, accelerator: 14.37ms, total: 38.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_88000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_88250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_88500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_88750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 51816696.60sec, total: 51816696.60sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.04ms, accelerator: 0us, total: 108.04ms (0.00%)
top 3 operation type: Conv2D, cpu: 22.81ms, accelerator: 8.06ms, total: 30.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.04ms, accelerator: 0us, total: 108.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.39ms, accelerator: 51816696.62sec, total: 51816696.63sec
train2.py:307:<module>, cpu: 108.36ms, accelerator: 0us, total: 108.36ms
  iterator_ops.py:373:get_next, cpu: 108.04ms, accelerator: 0us, total: 108.04ms
train2.py:333:<module>, cpu: 23.46ms, accelerator: 14.36ms, total: 37.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_89000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_89250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_89500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_89750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 51240955.53sec, total: 51240955.53sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.61ms, accelerator: 0us, total: 107.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 22.57ms, accelerator: 8.07ms, total: 30.64ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.61ms, accelerator: 0us, total: 107.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.38ms, accelerator: 51240955.55sec, total: 51240955.55sec
train2.py:307:<module>, cpu: 107.93ms, accelerator: 0us, total: 107.93ms
  iterator_ops.py:373:get_next, cpu: 107.61ms, accelerator: 0us, total: 107.61ms
train2.py:333:<module>, cpu: 23.21ms, accelerator: 14.38ms, total: 37.62ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_90000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_90250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_90500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_90750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 50677868.11sec, total: 50677868.11sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.11ms, accelerator: 0us, total: 107.11ms (0.00%)
top 3 operation type: Conv2D, cpu: 22.33ms, accelerator: 8.05ms, total: 30.39ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.11ms, accelerator: 0us, total: 107.11ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.38ms, accelerator: 50677868.13sec, total: 50677868.13sec
train2.py:307:<module>, cpu: 107.42ms, accelerator: 0us, total: 107.42ms
  iterator_ops.py:373:get_next, cpu: 107.11ms, accelerator: 0us, total: 107.11ms
train2.py:333:<module>, cpu: 22.98ms, accelerator: 14.36ms, total: 37.37ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_91000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_91250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_91500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_91750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 50127021.71sec, total: 50127021.72sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.95ms, accelerator: 0us, total: 106.95ms (0.00%)
top 3 operation type: Conv2D, cpu: 22.10ms, accelerator: 8.07ms, total: 30.17ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.95ms, accelerator: 0us, total: 106.95ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.37ms, accelerator: 50127021.73sec, total: 50127021.74sec
train2.py:307:<module>, cpu: 107.26ms, accelerator: 0us, total: 107.26ms
  iterator_ops.py:373:get_next, cpu: 106.95ms, accelerator: 0us, total: 106.95ms
train2.py:333:<module>, cpu: 22.75ms, accelerator: 14.39ms, total: 37.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_92000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_92250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_92500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_92750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 49588021.48sec, total: 49588021.48sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.55ms, accelerator: 0us, total: 106.55ms (0.00%)
top 3 operation type: Conv2D, cpu: 21.87ms, accelerator: 8.07ms, total: 29.95ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.55ms, accelerator: 0us, total: 106.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.36ms, accelerator: 49588021.50sec, total: 49588021.50sec
train2.py:307:<module>, cpu: 106.86ms, accelerator: 0us, total: 106.86ms
  iterator_ops.py:373:get_next, cpu: 106.55ms, accelerator: 0us, total: 106.55ms
train2.py:333:<module>, cpu: 22.52ms, accelerator: 14.39ms, total: 36.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_93000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_93250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_93500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_93750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 49060489.34sec, total: 49060489.34sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.98ms, accelerator: 0us, total: 105.98ms (0.00%)
top 3 operation type: Conv2D, cpu: 21.65ms, accelerator: 8.06ms, total: 29.72ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.98ms, accelerator: 0us, total: 105.98ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.36ms, accelerator: 49060489.36sec, total: 49060489.36sec
train2.py:307:<module>, cpu: 106.28ms, accelerator: 0us, total: 106.28ms
  iterator_ops.py:373:get_next, cpu: 105.98ms, accelerator: 0us, total: 105.98ms
train2.py:333:<module>, cpu: 22.30ms, accelerator: 14.40ms, total: 36.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_94000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_94250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_94500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_94750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 348us, accelerator: 48544063.13sec, total: 48544063.13sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.76ms, accelerator: 0us, total: 105.76ms (0.00%)
top 3 operation type: Conv2D, cpu: 21.43ms, accelerator: 8.09ms, total: 29.53ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.76ms, accelerator: 0us, total: 105.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.35ms, accelerator: 48544063.15sec, total: 48544063.16sec
train2.py:307:<module>, cpu: 106.06ms, accelerator: 0us, total: 106.06ms
  iterator_ops.py:373:get_next, cpu: 105.76ms, accelerator: 0us, total: 105.76ms
train2.py:333:<module>, cpu: 22.08ms, accelerator: 14.40ms, total: 36.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_95000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_95250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_95500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_95750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 348us, accelerator: 48038395.81sec, total: 48038395.81sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.13ms, accelerator: 0us, total: 105.13ms (0.00%)
top 3 operation type: Conv2D, cpu: 21.22ms, accelerator: 8.07ms, total: 29.30ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.13ms, accelerator: 0us, total: 105.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.35ms, accelerator: 48038395.83sec, total: 48038395.83sec
train2.py:307:<module>, cpu: 105.42ms, accelerator: 0us, total: 105.42ms
  iterator_ops.py:373:get_next, cpu: 105.13ms, accelerator: 0us, total: 105.13ms
train2.py:333:<module>, cpu: 21.87ms, accelerator: 14.39ms, total: 36.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_96000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_96250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_96500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_96750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 347us, accelerator: 47543154.62sec, total: 47543154.62sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.44ms, accelerator: 0us, total: 104.44ms (0.00%)
top 3 operation type: Conv2D, cpu: 21.01ms, accelerator: 8.10ms, total: 29.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.44ms, accelerator: 0us, total: 104.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.34ms, accelerator: 47543154.64sec, total: 47543154.64sec
train2.py:307:<module>, cpu: 104.73ms, accelerator: 0us, total: 104.73ms
  iterator_ops.py:373:get_next, cpu: 104.44ms, accelerator: 0us, total: 104.44ms
train2.py:333:<module>, cpu: 21.66ms, accelerator: 14.41ms, total: 36.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_97000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_97250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_97500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_97750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 347us, accelerator: 47058020.39sec, total: 47058020.39sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.25ms, accelerator: 0us, total: 104.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 20.81ms, accelerator: 8.12ms, total: 28.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.25ms, accelerator: 0us, total: 104.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.33ms, accelerator: 47058020.41sec, total: 47058020.41sec
train2.py:307:<module>, cpu: 104.54ms, accelerator: 0us, total: 104.54ms
  iterator_ops.py:373:get_next, cpu: 104.25ms, accelerator: 0us, total: 104.25ms
train2.py:333:<module>, cpu: 21.45ms, accelerator: 14.41ms, total: 35.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_98000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_98250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_98500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_98750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 347us, accelerator: 46582686.85sec, total: 46582686.85sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.93ms, accelerator: 0us, total: 103.93ms (0.00%)
top 3 operation type: Conv2D, cpu: 20.61ms, accelerator: 8.11ms, total: 28.72ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.93ms, accelerator: 0us, total: 103.93ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.33ms, accelerator: 46582686.87sec, total: 46582686.87sec
train2.py:307:<module>, cpu: 104.22ms, accelerator: 0us, total: 104.22ms
  iterator_ops.py:373:get_next, cpu: 103.93ms, accelerator: 0us, total: 103.93ms
train2.py:333:<module>, cpu: 21.25ms, accelerator: 14.43ms, total: 35.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_99000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_99250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_99500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_99750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 347us, accelerator: 46116859.98sec, total: 46116859.98sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.69ms, accelerator: 0us, total: 103.69ms (0.00%)
top 3 operation type: Conv2D, cpu: 20.41ms, accelerator: 8.11ms, total: 28.52ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.69ms, accelerator: 0us, total: 103.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.32ms, accelerator: 46116860.00sec, total: 46116860.00sec
train2.py:307:<module>, cpu: 103.97ms, accelerator: 0us, total: 103.97ms
  iterator_ops.py:373:get_next, cpu: 103.69ms, accelerator: 0us, total: 103.69ms
train2.py:333:<module>, cpu: 21.05ms, accelerator: 14.41ms, total: 35.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_100000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_100250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_100500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_100750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 347us, accelerator: 45660257.40sec, total: 45660257.40sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.35ms, accelerator: 0us, total: 103.35ms (0.00%)
top 3 operation type: Conv2D, cpu: 20.22ms, accelerator: 8.12ms, total: 28.34ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.35ms, accelerator: 0us, total: 103.35ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.32ms, accelerator: 45660257.42sec, total: 45660257.43sec
train2.py:307:<module>, cpu: 103.63ms, accelerator: 0us, total: 103.63ms
  iterator_ops.py:373:get_next, cpu: 103.35ms, accelerator: 0us, total: 103.35ms
train2.py:333:<module>, cpu: 20.86ms, accelerator: 14.41ms, total: 35.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_101000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_101250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_101500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_101750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 348us, accelerator: 45212607.82sec, total: 45212607.82sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.94ms, accelerator: 0us, total: 102.94ms (0.00%)
top 3 operation type: Conv2D, cpu: 20.03ms, accelerator: 8.10ms, total: 28.14ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.94ms, accelerator: 0us, total: 102.94ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.31ms, accelerator: 45212607.84sec, total: 45212607.84sec
train2.py:307:<module>, cpu: 103.22ms, accelerator: 0us, total: 103.22ms
  iterator_ops.py:373:get_next, cpu: 102.94ms, accelerator: 0us, total: 102.94ms
train2.py:333:<module>, cpu: 20.67ms, accelerator: 14.37ms, total: 35.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_102000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_102250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_102500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_102750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 348us, accelerator: 44773650.46sec, total: 44773650.46sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.59ms, accelerator: 0us, total: 102.59ms (0.00%)
top 3 operation type: Conv2D, cpu: 19.85ms, accelerator: 8.13ms, total: 27.98ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.59ms, accelerator: 0us, total: 102.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.31ms, accelerator: 44773650.48sec, total: 44773650.49sec
train2.py:307:<module>, cpu: 102.86ms, accelerator: 0us, total: 102.86ms
  iterator_ops.py:373:get_next, cpu: 102.59ms, accelerator: 0us, total: 102.59ms
train2.py:333:<module>, cpu: 20.49ms, accelerator: 14.39ms, total: 34.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_103000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_103250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_103500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_103750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 348us, accelerator: 44343134.59sec, total: 44343134.59sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.16ms, accelerator: 0us, total: 102.16ms (0.00%)
top 3 operation type: Conv2D, cpu: 19.67ms, accelerator: 8.11ms, total: 27.78ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.16ms, accelerator: 0us, total: 102.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.30ms, accelerator: 44343134.61sec, total: 44343134.62sec
train2.py:307:<module>, cpu: 102.43ms, accelerator: 0us, total: 102.43ms
  iterator_ops.py:373:get_next, cpu: 102.16ms, accelerator: 0us, total: 102.16ms
train2.py:333:<module>, cpu: 20.31ms, accelerator: 14.38ms, total: 34.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_104000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_104250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_104500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_104750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 43920819.03sec, total: 43920819.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.92ms, accelerator: 0us, total: 101.92ms (0.00%)
top 3 operation type: Conv2D, cpu: 19.49ms, accelerator: 8.10ms, total: 27.59ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.92ms, accelerator: 0us, total: 101.92ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.30ms, accelerator: 43920819.05sec, total: 43920819.05sec
train2.py:307:<module>, cpu: 102.19ms, accelerator: 0us, total: 102.19ms
  iterator_ops.py:373:get_next, cpu: 101.92ms, accelerator: 0us, total: 101.92ms
train2.py:333:<module>, cpu: 20.13ms, accelerator: 14.38ms, total: 34.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_105000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_105250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_105500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_105750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 43506471.68sec, total: 43506471.68sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.60ms, accelerator: 0us, total: 101.60ms (0.00%)
top 3 operation type: Conv2D, cpu: 19.32ms, accelerator: 8.10ms, total: 27.43ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.60ms, accelerator: 0us, total: 101.60ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.30ms, accelerator: 43506471.70sec, total: 43506471.70sec
train2.py:307:<module>, cpu: 101.87ms, accelerator: 0us, total: 101.87ms
  iterator_ops.py:373:get_next, cpu: 101.60ms, accelerator: 0us, total: 101.60ms
train2.py:333:<module>, cpu: 19.96ms, accelerator: 14.41ms, total: 34.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_106000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_106250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_106500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_106750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 43099869.14sec, total: 43099869.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.13ms, accelerator: 0us, total: 101.13ms (0.00%)
top 3 operation type: Conv2D, cpu: 19.14ms, accelerator: 8.08ms, total: 27.24ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.13ms, accelerator: 0us, total: 101.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.29ms, accelerator: 43099869.16sec, total: 43099869.16sec
train2.py:307:<module>, cpu: 101.39ms, accelerator: 0us, total: 101.39ms
  iterator_ops.py:373:get_next, cpu: 101.13ms, accelerator: 0us, total: 101.13ms
train2.py:333:<module>, cpu: 19.79ms, accelerator: 14.40ms, total: 34.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_107000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_107250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_107500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_107750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 42700796.28sec, total: 42700796.28sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.70ms, accelerator: 0us, total: 100.70ms (0.00%)
top 3 operation type: Conv2D, cpu: 18.98ms, accelerator: 8.09ms, total: 27.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.70ms, accelerator: 0us, total: 100.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.29ms, accelerator: 42700796.30sec, total: 42700796.30sec
train2.py:307:<module>, cpu: 100.96ms, accelerator: 0us, total: 100.96ms
  iterator_ops.py:373:get_next, cpu: 100.70ms, accelerator: 0us, total: 100.70ms
train2.py:333:<module>, cpu: 19.62ms, accelerator: 14.42ms, total: 34.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_108000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_108250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_108500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_108750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 42309045.85sec, total: 42309045.85sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.24ms, accelerator: 0us, total: 100.24ms (0.00%)
top 3 operation type: Conv2D, cpu: 18.81ms, accelerator: 8.09ms, total: 26.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.24ms, accelerator: 0us, total: 100.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.29ms, accelerator: 42309045.87sec, total: 42309045.87sec
train2.py:307:<module>, cpu: 100.50ms, accelerator: 0us, total: 100.50ms
  iterator_ops.py:373:get_next, cpu: 100.24ms, accelerator: 0us, total: 100.24ms
train2.py:333:<module>, cpu: 19.45ms, accelerator: 14.39ms, total: 33.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_109000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_109250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_109500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_109750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 41924418.16sec, total: 41924418.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.87ms, accelerator: 0us, total: 99.87ms (0.00%)
top 3 operation type: Conv2D, cpu: 18.65ms, accelerator: 8.08ms, total: 26.74ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.87ms, accelerator: 0us, total: 99.87ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.28ms, accelerator: 41924418.18sec, total: 41924418.18sec
train2.py:307:<module>, cpu: 100.12ms, accelerator: 0us, total: 100.12ms
  iterator_ops.py:373:get_next, cpu: 99.87ms, accelerator: 0us, total: 99.87ms
train2.py:333:<module>, cpu: 19.29ms, accelerator: 14.38ms, total: 33.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_110000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_110250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_110500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_110750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 41546720.70sec, total: 41546720.70sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.81ms, accelerator: 0us, total: 99.81ms (0.00%)
top 3 operation type: Conv2D, cpu: 18.50ms, accelerator: 8.10ms, total: 26.61ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.81ms, accelerator: 0us, total: 99.81ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.28ms, accelerator: 41546720.72sec, total: 41546720.72sec
train2.py:307:<module>, cpu: 100.06ms, accelerator: 0us, total: 100.06ms
  iterator_ops.py:373:get_next, cpu: 99.81ms, accelerator: 0us, total: 99.81ms
train2.py:333:<module>, cpu: 19.14ms, accelerator: 14.39ms, total: 33.55ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_111000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_111250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_111500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_111750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 41175767.84sec, total: 41175767.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.51ms, accelerator: 0us, total: 99.51ms (0.00%)
top 3 operation type: Conv2D, cpu: 18.34ms, accelerator: 8.10ms, total: 26.44ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.51ms, accelerator: 0us, total: 99.51ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.28ms, accelerator: 41175767.86sec, total: 41175767.86sec
train2.py:307:<module>, cpu: 99.76ms, accelerator: 0us, total: 99.76ms
  iterator_ops.py:373:get_next, cpu: 99.51ms, accelerator: 0us, total: 99.51ms
train2.py:333:<module>, cpu: 18.98ms, accelerator: 14.35ms, total: 33.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_112000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_112250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_112500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_112750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 40811380.51sec, total: 40811380.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.10ms, accelerator: 0us, total: 99.10ms (0.00%)
top 3 operation type: Conv2D, cpu: 18.18ms, accelerator: 8.08ms, total: 26.28ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.10ms, accelerator: 0us, total: 99.10ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.28ms, accelerator: 40811380.53sec, total: 40811380.53sec
train2.py:307:<module>, cpu: 99.35ms, accelerator: 0us, total: 99.35ms
  iterator_ops.py:373:get_next, cpu: 99.10ms, accelerator: 0us, total: 99.10ms
train2.py:333:<module>, cpu: 18.82ms, accelerator: 14.36ms, total: 33.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_113000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_113250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_113500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_113750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 40453385.95sec, total: 40453385.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.76ms, accelerator: 0us, total: 98.76ms (0.00%)
top 3 operation type: Conv2D, cpu: 18.03ms, accelerator: 8.06ms, total: 26.10ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.76ms, accelerator: 0us, total: 98.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.27ms, accelerator: 40453385.97sec, total: 40453385.97sec
train2.py:307:<module>, cpu: 99.01ms, accelerator: 0us, total: 99.01ms
  iterator_ops.py:373:get_next, cpu: 98.76ms, accelerator: 0us, total: 98.76ms
train2.py:333:<module>, cpu: 18.68ms, accelerator: 14.33ms, total: 33.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_114000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_114250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_114500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_114750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 40101617.37sec, total: 40101617.37sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.38ms, accelerator: 0us, total: 98.38ms (0.00%)
top 3 operation type: Conv2D, cpu: 17.89ms, accelerator: 8.05ms, total: 25.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.38ms, accelerator: 0us, total: 98.38ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.27ms, accelerator: 40101617.39sec, total: 40101617.40sec
train2.py:307:<module>, cpu: 98.63ms, accelerator: 0us, total: 98.63ms
  iterator_ops.py:373:get_next, cpu: 98.38ms, accelerator: 0us, total: 98.38ms
train2.py:333:<module>, cpu: 18.53ms, accelerator: 14.35ms, total: 32.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_115000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_115250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_115500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_115750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 39755913.77sec, total: 39755913.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.14ms, accelerator: 0us, total: 98.14ms (0.00%)
top 3 operation type: Conv2D, cpu: 17.74ms, accelerator: 8.06ms, total: 25.81ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.14ms, accelerator: 0us, total: 98.14ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.27ms, accelerator: 39755913.79sec, total: 39755913.80sec
train2.py:307:<module>, cpu: 98.38ms, accelerator: 0us, total: 98.38ms
  iterator_ops.py:373:get_next, cpu: 98.14ms, accelerator: 0us, total: 98.14ms
train2.py:333:<module>, cpu: 18.38ms, accelerator: 14.36ms, total: 32.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_116000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_116250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_116500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_116750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 39416119.64sec, total: 39416119.64sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.75ms, accelerator: 0us, total: 97.75ms (0.00%)
top 3 operation type: Conv2D, cpu: 17.60ms, accelerator: 8.05ms, total: 25.66ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.75ms, accelerator: 0us, total: 97.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.26ms, accelerator: 39416119.66sec, total: 39416119.66sec
train2.py:307:<module>, cpu: 97.99ms, accelerator: 0us, total: 97.99ms
  iterator_ops.py:373:get_next, cpu: 97.75ms, accelerator: 0us, total: 97.75ms
train2.py:333:<module>, cpu: 18.24ms, accelerator: 14.37ms, total: 32.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_117000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_117250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_117500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_117750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 39082084.73sec, total: 39082084.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.41ms, accelerator: 0us, total: 97.41ms (0.00%)
top 3 operation type: Conv2D, cpu: 17.46ms, accelerator: 8.06ms, total: 25.53ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.41ms, accelerator: 0us, total: 97.41ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.26ms, accelerator: 39082084.75sec, total: 39082084.75sec
train2.py:307:<module>, cpu: 97.65ms, accelerator: 0us, total: 97.65ms
  iterator_ops.py:373:get_next, cpu: 97.41ms, accelerator: 0us, total: 97.41ms
train2.py:333:<module>, cpu: 18.10ms, accelerator: 14.38ms, total: 32.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_118000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_118250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_118500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_118750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 38753663.85sec, total: 38753663.85sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.26ms, accelerator: 0us, total: 97.26ms (0.00%)
top 3 operation type: Conv2D, cpu: 17.32ms, accelerator: 8.07ms, total: 25.40ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.26ms, accelerator: 0us, total: 97.26ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.26ms, accelerator: 38753663.87sec, total: 38753663.87sec
train2.py:307:<module>, cpu: 97.50ms, accelerator: 0us, total: 97.50ms
  iterator_ops.py:373:get_next, cpu: 97.26ms, accelerator: 0us, total: 97.26ms
train2.py:333:<module>, cpu: 17.96ms, accelerator: 14.39ms, total: 32.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_119000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_119250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_119500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_119750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 38430716.65sec, total: 38430716.65sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.99ms, accelerator: 0us, total: 96.99ms (0.00%)
top 3 operation type: Conv2D, cpu: 17.19ms, accelerator: 8.05ms, total: 25.24ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.99ms, accelerator: 0us, total: 96.99ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.26ms, accelerator: 38430716.67sec, total: 38430716.67sec
train2.py:307:<module>, cpu: 97.22ms, accelerator: 0us, total: 97.22ms
  iterator_ops.py:373:get_next, cpu: 96.99ms, accelerator: 0us, total: 96.99ms
train2.py:333:<module>, cpu: 17.83ms, accelerator: 14.37ms, total: 32.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_120000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_120250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_120500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_120750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 38113107.42sec, total: 38113107.42sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.63ms, accelerator: 0us, total: 96.63ms (0.00%)
top 3 operation type: Conv2D, cpu: 17.05ms, accelerator: 8.04ms, total: 25.10ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.63ms, accelerator: 0us, total: 96.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.25ms, accelerator: 38113107.44sec, total: 38113107.44sec
train2.py:307:<module>, cpu: 96.87ms, accelerator: 0us, total: 96.87ms
  iterator_ops.py:373:get_next, cpu: 96.63ms, accelerator: 0us, total: 96.63ms
train2.py:333:<module>, cpu: 17.69ms, accelerator: 14.37ms, total: 32.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_121000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_121250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_121500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_121750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 37800704.90sec, total: 37800704.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.54ms, accelerator: 0us, total: 96.54ms (0.00%)
top 3 operation type: Conv2D, cpu: 16.92ms, accelerator: 8.03ms, total: 24.96ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.54ms, accelerator: 0us, total: 96.54ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.25ms, accelerator: 37800704.92sec, total: 37800704.92sec
train2.py:307:<module>, cpu: 96.78ms, accelerator: 0us, total: 96.78ms
  iterator_ops.py:373:get_next, cpu: 96.54ms, accelerator: 0us, total: 96.54ms
train2.py:333:<module>, cpu: 17.56ms, accelerator: 14.34ms, total: 31.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_122000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_122250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_122500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_122750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 37493382.10sec, total: 37493382.10sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.23ms, accelerator: 0us, total: 96.23ms (0.00%)
top 3 operation type: Conv2D, cpu: 16.79ms, accelerator: 8.01ms, total: 24.81ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.23ms, accelerator: 0us, total: 96.23ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.25ms, accelerator: 37493382.12sec, total: 37493382.12sec
train2.py:307:<module>, cpu: 96.47ms, accelerator: 0us, total: 96.47ms
  iterator_ops.py:373:get_next, cpu: 96.23ms, accelerator: 0us, total: 96.23ms
train2.py:333:<module>, cpu: 17.43ms, accelerator: 14.31ms, total: 31.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_123000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_123250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_123500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_123750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 37191016.11sec, total: 37191016.11sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.73ms, accelerator: 0us, total: 96.73ms (0.00%)
top 3 operation type: Conv2D, cpu: 16.67ms, accelerator: 8.03ms, total: 24.71ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.73ms, accelerator: 0us, total: 96.73ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.25ms, accelerator: 37191016.13sec, total: 37191016.13sec
train2.py:307:<module>, cpu: 96.96ms, accelerator: 0us, total: 96.96ms
  iterator_ops.py:373:get_next, cpu: 96.73ms, accelerator: 0us, total: 96.73ms
train2.py:333:<module>, cpu: 17.30ms, accelerator: 14.33ms, total: 31.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_124000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_124250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_124500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_124750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 36893487.98sec, total: 36893487.98sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.36ms, accelerator: 0us, total: 96.36ms (0.00%)
top 3 operation type: Conv2D, cpu: 16.54ms, accelerator: 8.05ms, total: 24.59ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.36ms, accelerator: 0us, total: 96.36ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.24ms, accelerator: 36893488.00sec, total: 36893488.01sec
train2.py:307:<module>, cpu: 96.58ms, accelerator: 0us, total: 96.58ms
  iterator_ops.py:373:get_next, cpu: 96.36ms, accelerator: 0us, total: 96.36ms
train2.py:333:<module>, cpu: 17.18ms, accelerator: 14.35ms, total: 31.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_125000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_125250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_125500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_125750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 36600682.52sec, total: 36600682.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.75ms, accelerator: 0us, total: 104.75ms (0.00%)
top 3 operation type: Conv2D, cpu: 16.42ms, accelerator: 8.07ms, total: 24.50ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.75ms, accelerator: 0us, total: 104.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.24ms, accelerator: 36600682.54sec, total: 36600682.55sec
train2.py:307:<module>, cpu: 104.97ms, accelerator: 0us, total: 104.97ms
  iterator_ops.py:373:get_next, cpu: 104.75ms, accelerator: 0us, total: 104.75ms
train2.py:333:<module>, cpu: 17.05ms, accelerator: 14.34ms, total: 31.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_126000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_126250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_126500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_126750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 36312488.17sec, total: 36312488.17sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.58ms, accelerator: 0us, total: 104.58ms (0.00%)
top 3 operation type: Conv2D, cpu: 16.30ms, accelerator: 8.09ms, total: 24.40ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.58ms, accelerator: 0us, total: 104.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.24ms, accelerator: 36312488.19sec, total: 36312488.19sec
train2.py:307:<module>, cpu: 104.80ms, accelerator: 0us, total: 104.80ms
  iterator_ops.py:373:get_next, cpu: 104.58ms, accelerator: 0us, total: 104.58ms
train2.py:333:<module>, cpu: 16.93ms, accelerator: 14.35ms, total: 31.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_127000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_127250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_127500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_127750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 36028796.86sec, total: 36028796.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.42ms, accelerator: 0us, total: 104.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 16.18ms, accelerator: 8.09ms, total: 24.27ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.42ms, accelerator: 0us, total: 104.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.23ms, accelerator: 36028796.88sec, total: 36028796.88sec
train2.py:307:<module>, cpu: 104.64ms, accelerator: 0us, total: 104.64ms
  iterator_ops.py:373:get_next, cpu: 104.42ms, accelerator: 0us, total: 104.42ms
train2.py:333:<module>, cpu: 16.82ms, accelerator: 14.35ms, total: 31.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_128000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_128250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_128500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_128750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 35749503.86sec, total: 35749503.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.15ms, accelerator: 0us, total: 104.15ms (0.00%)
top 3 operation type: Conv2D, cpu: 16.06ms, accelerator: 8.08ms, total: 24.15ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.15ms, accelerator: 0us, total: 104.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.23ms, accelerator: 35749503.88sec, total: 35749503.88sec
train2.py:307:<module>, cpu: 104.37ms, accelerator: 0us, total: 104.37ms
  iterator_ops.py:373:get_next, cpu: 104.15ms, accelerator: 0us, total: 104.15ms
train2.py:333:<module>, cpu: 16.70ms, accelerator: 14.34ms, total: 31.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_129000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_129250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_129500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_129750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 35474507.68sec, total: 35474507.68sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.77ms, accelerator: 0us, total: 103.77ms (0.00%)
top 3 operation type: Conv2D, cpu: 15.95ms, accelerator: 8.07ms, total: 24.02ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.77ms, accelerator: 0us, total: 103.77ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.23ms, accelerator: 35474507.70sec, total: 35474507.70sec
train2.py:307:<module>, cpu: 103.99ms, accelerator: 0us, total: 103.99ms
  iterator_ops.py:373:get_next, cpu: 103.77ms, accelerator: 0us, total: 103.77ms
train2.py:333:<module>, cpu: 16.58ms, accelerator: 14.32ms, total: 30.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_130000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_130250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_130500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_130750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 35203709.91sec, total: 35203709.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.56ms, accelerator: 0us, total: 103.56ms (0.00%)
top 3 operation type: Conv2D, cpu: 15.83ms, accelerator: 8.07ms, total: 23.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.56ms, accelerator: 0us, total: 103.56ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.23ms, accelerator: 35203709.93sec, total: 35203709.93sec
train2.py:307:<module>, cpu: 103.78ms, accelerator: 0us, total: 103.78ms
  iterator_ops.py:373:get_next, cpu: 103.56ms, accelerator: 0us, total: 103.56ms
train2.py:333:<module>, cpu: 16.47ms, accelerator: 14.34ms, total: 30.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_131000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_131250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_131500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_131750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 34937015.14sec, total: 34937015.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.24ms, accelerator: 0us, total: 103.24ms (0.00%)
top 3 operation type: Conv2D, cpu: 15.72ms, accelerator: 8.07ms, total: 23.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.24ms, accelerator: 0us, total: 103.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.23ms, accelerator: 34937015.15sec, total: 34937015.16sec
train2.py:307:<module>, cpu: 103.46ms, accelerator: 0us, total: 103.46ms
  iterator_ops.py:373:get_next, cpu: 103.24ms, accelerator: 0us, total: 103.24ms
train2.py:333:<module>, cpu: 16.36ms, accelerator: 14.33ms, total: 30.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_132000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_132250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_132500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_132750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 34674330.81sec, total: 34674330.81sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.83ms, accelerator: 0us, total: 102.83ms (0.00%)
top 3 operation type: Conv2D, cpu: 15.61ms, accelerator: 8.07ms, total: 23.69ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.83ms, accelerator: 0us, total: 102.83ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.22ms, accelerator: 34674330.83sec, total: 34674330.83sec
train2.py:307:<module>, cpu: 103.05ms, accelerator: 0us, total: 103.05ms
  iterator_ops.py:373:get_next, cpu: 102.83ms, accelerator: 0us, total: 102.83ms
train2.py:333:<module>, cpu: 16.25ms, accelerator: 14.33ms, total: 30.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_133000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_133250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_133500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_133750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 34415567.15sec, total: 34415567.15sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.52ms, accelerator: 0us, total: 102.52ms (0.00%)
top 3 operation type: Conv2D, cpu: 15.50ms, accelerator: 8.07ms, total: 23.57ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.52ms, accelerator: 0us, total: 102.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.22ms, accelerator: 34415567.17sec, total: 34415567.17sec
train2.py:307:<module>, cpu: 102.74ms, accelerator: 0us, total: 102.74ms
  iterator_ops.py:373:get_next, cpu: 102.52ms, accelerator: 0us, total: 102.52ms
train2.py:333:<module>, cpu: 16.14ms, accelerator: 14.31ms, total: 30.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_134000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_134250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_134500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_134750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 34160637.02sec, total: 34160637.02sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.11ms, accelerator: 0us, total: 102.11ms (0.00%)
top 3 operation type: Conv2D, cpu: 15.39ms, accelerator: 8.07ms, total: 23.47ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.11ms, accelerator: 0us, total: 102.11ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.22ms, accelerator: 34160637.04sec, total: 34160637.04sec
train2.py:307:<module>, cpu: 102.32ms, accelerator: 0us, total: 102.32ms
  iterator_ops.py:373:get_next, cpu: 102.11ms, accelerator: 0us, total: 102.11ms
train2.py:333:<module>, cpu: 16.03ms, accelerator: 14.31ms, total: 30.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_135000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_135250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_135500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_135750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 33909455.87sec, total: 33909455.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.92ms, accelerator: 0us, total: 101.92ms (0.00%)
top 3 operation type: Conv2D, cpu: 15.29ms, accelerator: 8.06ms, total: 23.36ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.92ms, accelerator: 0us, total: 101.92ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.22ms, accelerator: 33909455.89sec, total: 33909455.89sec
train2.py:307:<module>, cpu: 102.13ms, accelerator: 0us, total: 102.13ms
  iterator_ops.py:373:get_next, cpu: 101.92ms, accelerator: 0us, total: 101.92ms
train2.py:333:<module>, cpu: 15.93ms, accelerator: 14.30ms, total: 30.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_136000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_136250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_136500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_136750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 33661941.59sec, total: 33661941.59sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.84ms, accelerator: 0us, total: 101.84ms (0.00%)
top 3 operation type: Conv2D, cpu: 15.19ms, accelerator: 8.07ms, total: 23.27ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.84ms, accelerator: 0us, total: 101.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.21ms, accelerator: 33661941.61sec, total: 33661941.61sec
train2.py:307:<module>, cpu: 102.05ms, accelerator: 0us, total: 102.05ms
  iterator_ops.py:373:get_next, cpu: 101.84ms, accelerator: 0us, total: 101.84ms
train2.py:333:<module>, cpu: 15.82ms, accelerator: 14.31ms, total: 30.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_137000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_137250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_137500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_137750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 33418014.48sec, total: 33418014.48sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.96ms, accelerator: 0us, total: 101.96ms (0.00%)
top 3 operation type: Conv2D, cpu: 15.08ms, accelerator: 8.08ms, total: 23.18ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.96ms, accelerator: 0us, total: 101.96ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.21ms, accelerator: 33418014.50sec, total: 33418014.50sec
train2.py:307:<module>, cpu: 102.17ms, accelerator: 0us, total: 102.17ms
  iterator_ops.py:373:get_next, cpu: 101.96ms, accelerator: 0us, total: 101.96ms
train2.py:333:<module>, cpu: 15.72ms, accelerator: 14.31ms, total: 30.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_138000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_138250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_138500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_138750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 33177597.11sec, total: 33177597.11sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.68ms, accelerator: 0us, total: 101.68ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.98ms, accelerator: 8.10ms, total: 23.09ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.68ms, accelerator: 0us, total: 101.68ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.21ms, accelerator: 33177597.13sec, total: 33177597.13sec
train2.py:307:<module>, cpu: 101.88ms, accelerator: 0us, total: 101.88ms
  iterator_ops.py:373:get_next, cpu: 101.68ms, accelerator: 0us, total: 101.68ms
train2.py:333:<module>, cpu: 15.62ms, accelerator: 14.32ms, total: 29.96ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_139000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_139250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_139500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_139750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 32940614.27sec, total: 32940614.27sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.39ms, accelerator: 0us, total: 101.39ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.88ms, accelerator: 8.11ms, total: 23.00ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.39ms, accelerator: 0us, total: 101.39ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.21ms, accelerator: 32940614.29sec, total: 32940614.29sec
train2.py:307:<module>, cpu: 101.60ms, accelerator: 0us, total: 101.60ms
  iterator_ops.py:373:get_next, cpu: 101.39ms, accelerator: 0us, total: 101.39ms
train2.py:333:<module>, cpu: 15.52ms, accelerator: 14.34ms, total: 29.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_140000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_140250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_140500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_140750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 32706992.89sec, total: 32706992.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.24ms, accelerator: 0us, total: 101.24ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.79ms, accelerator: 8.11ms, total: 22.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.24ms, accelerator: 0us, total: 101.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.21ms, accelerator: 32706992.91sec, total: 32706992.92sec
train2.py:307:<module>, cpu: 101.44ms, accelerator: 0us, total: 101.44ms
  iterator_ops.py:373:get_next, cpu: 101.24ms, accelerator: 0us, total: 101.24ms
train2.py:333:<module>, cpu: 15.42ms, accelerator: 14.35ms, total: 29.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_141000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_141250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_141500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_141750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 32476661.96sec, total: 32476661.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.94ms, accelerator: 0us, total: 100.94ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.69ms, accelerator: 8.10ms, total: 22.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.94ms, accelerator: 0us, total: 100.94ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.21ms, accelerator: 32476661.98sec, total: 32476661.98sec
train2.py:307:<module>, cpu: 101.14ms, accelerator: 0us, total: 101.14ms
  iterator_ops.py:373:get_next, cpu: 100.94ms, accelerator: 0us, total: 100.94ms
train2.py:333:<module>, cpu: 15.33ms, accelerator: 14.34ms, total: 29.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_142000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_142250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_142500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_142750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 32249552.43sec, total: 32249552.43sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.66ms, accelerator: 0us, total: 100.66ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.59ms, accelerator: 8.08ms, total: 22.68ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.66ms, accelerator: 0us, total: 100.66ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.20ms, accelerator: 32249552.45sec, total: 32249552.46sec
train2.py:307:<module>, cpu: 100.85ms, accelerator: 0us, total: 100.85ms
  iterator_ops.py:373:get_next, cpu: 100.66ms, accelerator: 0us, total: 100.66ms
train2.py:333:<module>, cpu: 15.23ms, accelerator: 14.35ms, total: 29.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_143000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_143250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_143500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_143750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 32025597.21sec, total: 32025597.21sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.27ms, accelerator: 0us, total: 100.27ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.50ms, accelerator: 8.06ms, total: 22.57ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.27ms, accelerator: 0us, total: 100.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.20ms, accelerator: 32025597.23sec, total: 32025597.23sec
train2.py:307:<module>, cpu: 100.47ms, accelerator: 0us, total: 100.47ms
  iterator_ops.py:373:get_next, cpu: 100.27ms, accelerator: 0us, total: 100.27ms
train2.py:333:<module>, cpu: 15.13ms, accelerator: 14.35ms, total: 29.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_144000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_144250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_144500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_144750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 31804731.02sec, total: 31804731.02sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.98ms, accelerator: 0us, total: 99.98ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.41ms, accelerator: 8.06ms, total: 22.48ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.98ms, accelerator: 0us, total: 99.98ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.20ms, accelerator: 31804731.04sec, total: 31804731.04sec
train2.py:307:<module>, cpu: 100.17ms, accelerator: 0us, total: 100.17ms
  iterator_ops.py:373:get_next, cpu: 99.98ms, accelerator: 0us, total: 99.98ms
train2.py:333:<module>, cpu: 15.04ms, accelerator: 14.36ms, total: 29.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_145000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_145250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_145500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_145750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 31586890.40sec, total: 31586890.40sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.67ms, accelerator: 0us, total: 99.67ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.31ms, accelerator: 8.06ms, total: 22.39ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.67ms, accelerator: 0us, total: 99.67ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.20ms, accelerator: 31586890.42sec, total: 31586890.42sec
train2.py:307:<module>, cpu: 99.86ms, accelerator: 0us, total: 99.86ms
  iterator_ops.py:373:get_next, cpu: 99.67ms, accelerator: 0us, total: 99.67ms
train2.py:333:<module>, cpu: 14.95ms, accelerator: 14.34ms, total: 29.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_146000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_146250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_146500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_146750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 31372013.59sec, total: 31372013.59sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.42ms, accelerator: 0us, total: 99.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.22ms, accelerator: 8.08ms, total: 22.31ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.42ms, accelerator: 0us, total: 99.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.20ms, accelerator: 31372013.61sec, total: 31372013.61sec
train2.py:307:<module>, cpu: 99.61ms, accelerator: 0us, total: 99.61ms
  iterator_ops.py:373:get_next, cpu: 99.42ms, accelerator: 0us, total: 99.42ms
train2.py:333:<module>, cpu: 14.86ms, accelerator: 14.34ms, total: 29.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_147000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_147250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_147500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_147750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 31160040.53sec, total: 31160040.53sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.19ms, accelerator: 0us, total: 99.19ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.14ms, accelerator: 8.07ms, total: 22.22ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.19ms, accelerator: 0us, total: 99.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.20ms, accelerator: 31160040.55sec, total: 31160040.55sec
train2.py:307:<module>, cpu: 99.38ms, accelerator: 0us, total: 99.38ms
  iterator_ops.py:373:get_next, cpu: 99.19ms, accelerator: 0us, total: 99.19ms
train2.py:333:<module>, cpu: 14.77ms, accelerator: 14.34ms, total: 29.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_148000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_148250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_148500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_148750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 30950912.74sec, total: 30950912.74sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.12ms, accelerator: 0us, total: 99.12ms (0.00%)
top 3 operation type: Conv2D, cpu: 14.05ms, accelerator: 8.09ms, total: 22.15ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.12ms, accelerator: 0us, total: 99.12ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.19ms, accelerator: 30950912.76sec, total: 30950912.76sec
train2.py:307:<module>, cpu: 99.32ms, accelerator: 0us, total: 99.32ms
  iterator_ops.py:373:get_next, cpu: 99.12ms, accelerator: 0us, total: 99.12ms
train2.py:333:<module>, cpu: 14.69ms, accelerator: 14.36ms, total: 29.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_149000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_149250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_149500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_149750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 30744573.32sec, total: 30744573.32sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.90ms, accelerator: 0us, total: 98.90ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.96ms, accelerator: 8.09ms, total: 22.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.90ms, accelerator: 0us, total: 98.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.19ms, accelerator: 30744573.34sec, total: 30744573.34sec
train2.py:307:<module>, cpu: 99.09ms, accelerator: 0us, total: 99.09ms
  iterator_ops.py:373:get_next, cpu: 98.90ms, accelerator: 0us, total: 98.90ms
train2.py:333:<module>, cpu: 14.60ms, accelerator: 14.36ms, total: 28.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_150000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_150250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_150500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_150750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 30540966.87sec, total: 30540966.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.57ms, accelerator: 0us, total: 98.57ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.88ms, accelerator: 8.09ms, total: 21.97ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.57ms, accelerator: 0us, total: 98.57ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.19ms, accelerator: 30540966.89sec, total: 30540966.90sec
train2.py:307:<module>, cpu: 98.76ms, accelerator: 0us, total: 98.76ms
  iterator_ops.py:373:get_next, cpu: 98.57ms, accelerator: 0us, total: 98.57ms
train2.py:333:<module>, cpu: 14.51ms, accelerator: 14.37ms, total: 28.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_151000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_151250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_151500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_151750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 30340039.46sec, total: 30340039.46sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.48ms, accelerator: 0us, total: 98.48ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.79ms, accelerator: 8.10ms, total: 21.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.48ms, accelerator: 0us, total: 98.48ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.19ms, accelerator: 30340039.48sec, total: 30340039.48sec
train2.py:307:<module>, cpu: 98.67ms, accelerator: 0us, total: 98.67ms
  iterator_ops.py:373:get_next, cpu: 98.48ms, accelerator: 0us, total: 98.48ms
train2.py:333:<module>, cpu: 14.43ms, accelerator: 14.37ms, total: 28.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_152000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_152250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_152500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_152750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 30141738.55sec, total: 30141738.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.38ms, accelerator: 0us, total: 98.38ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.71ms, accelerator: 8.10ms, total: 21.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.38ms, accelerator: 0us, total: 98.38ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.19ms, accelerator: 30141738.57sec, total: 30141738.57sec
train2.py:307:<module>, cpu: 98.57ms, accelerator: 0us, total: 98.57ms
  iterator_ops.py:373:get_next, cpu: 98.38ms, accelerator: 0us, total: 98.38ms
train2.py:333:<module>, cpu: 14.34ms, accelerator: 14.37ms, total: 28.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_153000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_153250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_153500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_153750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 29946012.97sec, total: 29946012.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.74ms, accelerator: 0us, total: 99.74ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.63ms, accelerator: 8.10ms, total: 21.73ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.74ms, accelerator: 0us, total: 99.74ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.18ms, accelerator: 29946012.99sec, total: 29946013.00sec
train2.py:307:<module>, cpu: 99.93ms, accelerator: 0us, total: 99.93ms
  iterator_ops.py:373:get_next, cpu: 99.74ms, accelerator: 0us, total: 99.74ms
train2.py:333:<module>, cpu: 14.26ms, accelerator: 14.36ms, total: 28.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_154000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_154250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_154500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_154750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 29752812.89sec, total: 29752812.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.52ms, accelerator: 0us, total: 99.52ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.54ms, accelerator: 8.10ms, total: 21.65ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.52ms, accelerator: 0us, total: 99.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.18ms, accelerator: 29752812.91sec, total: 29752812.91sec
train2.py:307:<module>, cpu: 99.70ms, accelerator: 0us, total: 99.70ms
  iterator_ops.py:373:get_next, cpu: 99.52ms, accelerator: 0us, total: 99.52ms
train2.py:333:<module>, cpu: 14.18ms, accelerator: 14.37ms, total: 28.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_155000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_155250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_155500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_155750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 29562089.73sec, total: 29562089.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.47ms, accelerator: 0us, total: 99.47ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.46ms, accelerator: 8.10ms, total: 21.57ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.47ms, accelerator: 0us, total: 99.47ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.18ms, accelerator: 29562089.75sec, total: 29562089.75sec
train2.py:307:<module>, cpu: 99.65ms, accelerator: 0us, total: 99.65ms
  iterator_ops.py:373:get_next, cpu: 99.47ms, accelerator: 0us, total: 99.47ms
train2.py:333:<module>, cpu: 14.10ms, accelerator: 14.38ms, total: 28.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_156000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_156250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_156500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_156750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 29373796.17sec, total: 29373796.17sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.28ms, accelerator: 0us, total: 99.28ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.38ms, accelerator: 8.09ms, total: 21.48ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.28ms, accelerator: 0us, total: 99.28ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.18ms, accelerator: 29373796.18sec, total: 29373796.19sec
train2.py:307:<module>, cpu: 99.46ms, accelerator: 0us, total: 99.46ms
  iterator_ops.py:373:get_next, cpu: 99.28ms, accelerator: 0us, total: 99.28ms
train2.py:333:<module>, cpu: 14.02ms, accelerator: 14.35ms, total: 28.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_157000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_157250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_157500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_157750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 29187886.06sec, total: 29187886.06sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.71ms, accelerator: 0us, total: 105.71ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.31ms, accelerator: 8.08ms, total: 21.39ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.71ms, accelerator: 0us, total: 105.71ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.18ms, accelerator: 29187886.08sec, total: 29187886.09sec
train2.py:307:<module>, cpu: 105.89ms, accelerator: 0us, total: 105.89ms
  iterator_ops.py:373:get_next, cpu: 105.71ms, accelerator: 0us, total: 105.71ms
train2.py:333:<module>, cpu: 13.94ms, accelerator: 14.35ms, total: 28.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_158000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_158250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_158500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_158750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 29004314.45sec, total: 29004314.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.54ms, accelerator: 0us, total: 105.54ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.23ms, accelerator: 8.08ms, total: 21.32ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.54ms, accelerator: 0us, total: 105.54ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.18ms, accelerator: 29004314.47sec, total: 29004314.48sec
train2.py:307:<module>, cpu: 105.72ms, accelerator: 0us, total: 105.72ms
  iterator_ops.py:373:get_next, cpu: 105.54ms, accelerator: 0us, total: 105.54ms
train2.py:333:<module>, cpu: 13.87ms, accelerator: 14.34ms, total: 28.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_159000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_159250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_159500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_159750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 28823037.49sec, total: 28823037.49sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.35ms, accelerator: 0us, total: 105.35ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.16ms, accelerator: 8.08ms, total: 21.24ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.35ms, accelerator: 0us, total: 105.35ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.17ms, accelerator: 28823037.51sec, total: 28823037.51sec
train2.py:307:<module>, cpu: 105.53ms, accelerator: 0us, total: 105.53ms
  iterator_ops.py:373:get_next, cpu: 105.35ms, accelerator: 0us, total: 105.35ms
train2.py:333:<module>, cpu: 13.79ms, accelerator: 14.34ms, total: 28.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_160000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_160250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_160500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_160750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 28644012.41sec, total: 28644012.41sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.16ms, accelerator: 0us, total: 105.16ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.08ms, accelerator: 8.08ms, total: 21.17ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.16ms, accelerator: 0us, total: 105.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.17ms, accelerator: 28644012.43sec, total: 28644012.43sec
train2.py:307:<module>, cpu: 105.33ms, accelerator: 0us, total: 105.33ms
  iterator_ops.py:373:get_next, cpu: 105.16ms, accelerator: 0us, total: 105.16ms
train2.py:333:<module>, cpu: 13.72ms, accelerator: 14.34ms, total: 28.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_161000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_161250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_161500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_161750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 28467197.52sec, total: 28467197.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.14ms, accelerator: 0us, total: 105.14ms (0.00%)
top 3 operation type: Conv2D, cpu: 13.01ms, accelerator: 8.07ms, total: 21.09ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.14ms, accelerator: 0us, total: 105.14ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.17ms, accelerator: 28467197.54sec, total: 28467197.54sec
train2.py:307:<module>, cpu: 105.32ms, accelerator: 0us, total: 105.32ms
  iterator_ops.py:373:get_next, cpu: 105.14ms, accelerator: 0us, total: 105.14ms
train2.py:333:<module>, cpu: 13.64ms, accelerator: 14.34ms, total: 28.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_162000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_162250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_162500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_162750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 28292552.13sec, total: 28292552.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.91ms, accelerator: 0us, total: 104.91ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.93ms, accelerator: 8.08ms, total: 21.02ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.91ms, accelerator: 0us, total: 104.91ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.17ms, accelerator: 28292552.15sec, total: 28292552.16sec
train2.py:307:<module>, cpu: 105.09ms, accelerator: 0us, total: 105.09ms
  iterator_ops.py:373:get_next, cpu: 104.91ms, accelerator: 0us, total: 104.91ms
train2.py:333:<module>, cpu: 13.57ms, accelerator: 14.35ms, total: 27.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_163000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_163250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_163500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_163750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 28120036.57sec, total: 28120036.57sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.59ms, accelerator: 0us, total: 104.59ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.86ms, accelerator: 8.07ms, total: 20.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.59ms, accelerator: 0us, total: 104.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.17ms, accelerator: 28120036.59sec, total: 28120036.60sec
train2.py:307:<module>, cpu: 104.77ms, accelerator: 0us, total: 104.77ms
  iterator_ops.py:373:get_next, cpu: 104.59ms, accelerator: 0us, total: 104.59ms
train2.py:333:<module>, cpu: 13.50ms, accelerator: 14.34ms, total: 27.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_164000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_164250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_164500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_164750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 27949612.11sec, total: 27949612.11sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.31ms, accelerator: 0us, total: 104.31ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.79ms, accelerator: 8.07ms, total: 20.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.31ms, accelerator: 0us, total: 104.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.17ms, accelerator: 27949612.13sec, total: 27949612.13sec
train2.py:307:<module>, cpu: 104.49ms, accelerator: 0us, total: 104.49ms
  iterator_ops.py:373:get_next, cpu: 104.31ms, accelerator: 0us, total: 104.31ms
train2.py:333:<module>, cpu: 13.43ms, accelerator: 14.35ms, total: 27.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_165000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_165250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_165500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_165750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 27781240.95sec, total: 27781240.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.13ms, accelerator: 0us, total: 104.13ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.72ms, accelerator: 8.05ms, total: 20.77ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.13ms, accelerator: 0us, total: 104.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.16ms, accelerator: 27781240.97sec, total: 27781240.97sec
train2.py:307:<module>, cpu: 104.30ms, accelerator: 0us, total: 104.30ms
  iterator_ops.py:373:get_next, cpu: 104.13ms, accelerator: 0us, total: 104.13ms
train2.py:333:<module>, cpu: 13.36ms, accelerator: 14.33ms, total: 27.71ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_166000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_166250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_166500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_166750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 27614886.22sec, total: 27614886.22sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.79ms, accelerator: 0us, total: 109.79ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.65ms, accelerator: 8.05ms, total: 20.70ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.79ms, accelerator: 0us, total: 109.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.16ms, accelerator: 27614886.23sec, total: 27614886.24sec
train2.py:307:<module>, cpu: 109.96ms, accelerator: 0us, total: 109.96ms
  iterator_ops.py:373:get_next, cpu: 109.79ms, accelerator: 0us, total: 109.79ms
train2.py:333:<module>, cpu: 13.29ms, accelerator: 14.33ms, total: 27.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_167000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_167250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_167500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_167750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 27450511.89sec, total: 27450511.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.47ms, accelerator: 0us, total: 109.47ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.58ms, accelerator: 8.05ms, total: 20.64ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.47ms, accelerator: 0us, total: 109.47ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.16ms, accelerator: 27450511.91sec, total: 27450511.92sec
train2.py:307:<module>, cpu: 109.64ms, accelerator: 0us, total: 109.64ms
  iterator_ops.py:373:get_next, cpu: 109.47ms, accelerator: 0us, total: 109.47ms
train2.py:333:<module>, cpu: 13.22ms, accelerator: 14.33ms, total: 27.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_168000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_168250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_168500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_168750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 27288082.83sec, total: 27288082.83sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.25ms, accelerator: 0us, total: 109.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.51ms, accelerator: 8.05ms, total: 20.57ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.25ms, accelerator: 0us, total: 109.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.16ms, accelerator: 27288082.85sec, total: 27288082.85sec
train2.py:307:<module>, cpu: 109.42ms, accelerator: 0us, total: 109.42ms
  iterator_ops.py:373:get_next, cpu: 109.25ms, accelerator: 0us, total: 109.25ms
train2.py:333:<module>, cpu: 13.15ms, accelerator: 14.33ms, total: 27.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_169000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_169250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_169500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_169750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 27127564.69sec, total: 27127564.69sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.99ms, accelerator: 0us, total: 108.99ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.44ms, accelerator: 8.06ms, total: 20.51ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.99ms, accelerator: 0us, total: 108.99ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.16ms, accelerator: 27127564.71sec, total: 27127564.72sec
train2.py:307:<module>, cpu: 109.16ms, accelerator: 0us, total: 109.16ms
  iterator_ops.py:373:get_next, cpu: 108.99ms, accelerator: 0us, total: 108.99ms
train2.py:333:<module>, cpu: 13.08ms, accelerator: 14.34ms, total: 27.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_170000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_170250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_170500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_170750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 26968923.96sec, total: 26968923.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.78ms, accelerator: 0us, total: 108.78ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.38ms, accelerator: 8.07ms, total: 20.45ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.78ms, accelerator: 0us, total: 108.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.16ms, accelerator: 26968923.98sec, total: 26968923.99sec
train2.py:307:<module>, cpu: 108.95ms, accelerator: 0us, total: 108.95ms
  iterator_ops.py:373:get_next, cpu: 108.78ms, accelerator: 0us, total: 108.78ms
train2.py:333:<module>, cpu: 13.01ms, accelerator: 14.34ms, total: 27.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_171000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_171250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_171500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_171750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 26812127.90sec, total: 26812127.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.49ms, accelerator: 0us, total: 108.49ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.31ms, accelerator: 8.05ms, total: 20.37ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.49ms, accelerator: 0us, total: 108.49ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.16ms, accelerator: 26812127.91sec, total: 26812127.92sec
train2.py:307:<module>, cpu: 108.66ms, accelerator: 0us, total: 108.66ms
  iterator_ops.py:373:get_next, cpu: 108.49ms, accelerator: 0us, total: 108.49ms
train2.py:333:<module>, cpu: 12.95ms, accelerator: 14.32ms, total: 27.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_172000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_172250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_172500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_172750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 26657144.50sec, total: 26657144.50sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.23ms, accelerator: 0us, total: 108.23ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.25ms, accelerator: 8.04ms, total: 20.29ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.23ms, accelerator: 0us, total: 108.23ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.16ms, accelerator: 26657144.52sec, total: 26657144.52sec
train2.py:307:<module>, cpu: 108.40ms, accelerator: 0us, total: 108.40ms
  iterator_ops.py:373:get_next, cpu: 108.23ms, accelerator: 0us, total: 108.23ms
train2.py:333:<module>, cpu: 12.88ms, accelerator: 14.32ms, total: 27.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_173000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_173250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_173500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_173750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 26503942.52sec, total: 26503942.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.02ms, accelerator: 0us, total: 108.02ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.18ms, accelerator: 8.02ms, total: 20.21ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.02ms, accelerator: 0us, total: 108.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 26503942.54sec, total: 26503942.54sec
train2.py:307:<module>, cpu: 108.19ms, accelerator: 0us, total: 108.19ms
  iterator_ops.py:373:get_next, cpu: 108.02ms, accelerator: 0us, total: 108.02ms
train2.py:333:<module>, cpu: 12.82ms, accelerator: 14.30ms, total: 27.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_174000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_174250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_174500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_174750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 26352491.42sec, total: 26352491.42sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.79ms, accelerator: 0us, total: 107.79ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.12ms, accelerator: 8.00ms, total: 20.13ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.79ms, accelerator: 0us, total: 107.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 26352491.44sec, total: 26352491.44sec
train2.py:307:<module>, cpu: 107.95ms, accelerator: 0us, total: 107.95ms
  iterator_ops.py:373:get_next, cpu: 107.79ms, accelerator: 0us, total: 107.79ms
train2.py:333:<module>, cpu: 12.76ms, accelerator: 14.29ms, total: 27.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_175000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_175250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_175500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_175750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 26202761.35sec, total: 26202761.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.19ms, accelerator: 0us, total: 114.19ms (0.00%)
top 3 operation type: Conv2D, cpu: 12.06ms, accelerator: 7.99ms, total: 20.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.19ms, accelerator: 0us, total: 114.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 26202761.37sec, total: 26202761.37sec
train2.py:307:<module>, cpu: 114.36ms, accelerator: 0us, total: 114.36ms
  iterator_ops.py:373:get_next, cpu: 114.19ms, accelerator: 0us, total: 114.19ms
train2.py:333:<module>, cpu: 12.69ms, accelerator: 14.29ms, total: 27.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_176000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_176250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_176500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_176750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 26054723.15sec, total: 26054723.15sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.88ms, accelerator: 0us, total: 113.88ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.99ms, accelerator: 7.99ms, total: 19.99ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.88ms, accelerator: 0us, total: 113.88ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 26054723.17sec, total: 26054723.18sec
train2.py:307:<module>, cpu: 114.04ms, accelerator: 0us, total: 114.04ms
  iterator_ops.py:373:get_next, cpu: 113.88ms, accelerator: 0us, total: 113.88ms
train2.py:333:<module>, cpu: 12.63ms, accelerator: 14.29ms, total: 26.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_177000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_177250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_177500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_177750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 25908348.30sec, total: 25908348.30sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.56ms, accelerator: 0us, total: 113.56ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.93ms, accelerator: 7.98ms, total: 19.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.56ms, accelerator: 0us, total: 113.56ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 25908348.32sec, total: 25908348.33sec
train2.py:307:<module>, cpu: 113.73ms, accelerator: 0us, total: 113.73ms
  iterator_ops.py:373:get_next, cpu: 113.56ms, accelerator: 0us, total: 113.56ms
train2.py:333:<module>, cpu: 12.57ms, accelerator: 14.27ms, total: 26.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_178000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_178250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_178500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_178750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 25763608.93sec, total: 25763608.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.34ms, accelerator: 0us, total: 113.34ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.87ms, accelerator: 7.98ms, total: 19.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.34ms, accelerator: 0us, total: 113.34ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 25763608.95sec, total: 25763608.95sec
train2.py:307:<module>, cpu: 113.50ms, accelerator: 0us, total: 113.50ms
  iterator_ops.py:373:get_next, cpu: 113.34ms, accelerator: 0us, total: 113.34ms
train2.py:333:<module>, cpu: 12.51ms, accelerator: 14.26ms, total: 26.78ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_179000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_179250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_179500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_179750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 25620477.77sec, total: 25620477.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.15ms, accelerator: 0us, total: 113.15ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.81ms, accelerator: 7.98ms, total: 19.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.15ms, accelerator: 0us, total: 113.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 25620477.79sec, total: 25620477.79sec
train2.py:307:<module>, cpu: 113.31ms, accelerator: 0us, total: 113.31ms
  iterator_ops.py:373:get_next, cpu: 113.15ms, accelerator: 0us, total: 113.15ms
train2.py:333:<module>, cpu: 12.45ms, accelerator: 14.25ms, total: 26.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_180000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_180250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_180500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_180750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 25478928.17sec, total: 25478928.17sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.84ms, accelerator: 0us, total: 112.84ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.75ms, accelerator: 7.99ms, total: 19.75ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.84ms, accelerator: 0us, total: 112.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 25478928.19sec, total: 25478928.19sec
train2.py:307:<module>, cpu: 113.00ms, accelerator: 0us, total: 113.00ms
  iterator_ops.py:373:get_next, cpu: 112.84ms, accelerator: 0us, total: 112.84ms
train2.py:333:<module>, cpu: 12.39ms, accelerator: 14.25ms, total: 26.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_181000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_181250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_181500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_181750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 25338934.06sec, total: 25338934.06sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.69ms, accelerator: 0us, total: 112.69ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.69ms, accelerator: 7.99ms, total: 19.69ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.69ms, accelerator: 0us, total: 112.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 25338934.07sec, total: 25338934.08sec
train2.py:307:<module>, cpu: 112.85ms, accelerator: 0us, total: 112.85ms
  iterator_ops.py:373:get_next, cpu: 112.69ms, accelerator: 0us, total: 112.69ms
train2.py:333:<module>, cpu: 12.33ms, accelerator: 14.26ms, total: 26.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_182000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_182250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_182500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_182750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 25200469.93sec, total: 25200469.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.37ms, accelerator: 0us, total: 112.37ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.64ms, accelerator: 7.98ms, total: 19.62ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.37ms, accelerator: 0us, total: 112.37ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 25200469.95sec, total: 25200469.96sec
train2.py:307:<module>, cpu: 112.53ms, accelerator: 0us, total: 112.53ms
  iterator_ops.py:373:get_next, cpu: 112.37ms, accelerator: 0us, total: 112.37ms
train2.py:333:<module>, cpu: 12.27ms, accelerator: 14.25ms, total: 26.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_183000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_183250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_183500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_183750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 25063510.86sec, total: 25063510.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.10ms, accelerator: 0us, total: 112.10ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.58ms, accelerator: 7.97ms, total: 19.56ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.10ms, accelerator: 0us, total: 112.10ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 25063510.88sec, total: 25063510.88sec
train2.py:307:<module>, cpu: 112.25ms, accelerator: 0us, total: 112.25ms
  iterator_ops.py:373:get_next, cpu: 112.10ms, accelerator: 0us, total: 112.10ms
train2.py:333:<module>, cpu: 12.21ms, accelerator: 14.25ms, total: 26.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_184000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_184250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_184500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_184750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 24928032.42sec, total: 24928032.42sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.86ms, accelerator: 0us, total: 111.86ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.52ms, accelerator: 7.96ms, total: 19.49ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.86ms, accelerator: 0us, total: 111.86ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.15ms, accelerator: 24928032.44sec, total: 24928032.44sec
train2.py:307:<module>, cpu: 112.01ms, accelerator: 0us, total: 112.01ms
  iterator_ops.py:373:get_next, cpu: 111.86ms, accelerator: 0us, total: 111.86ms
train2.py:333:<module>, cpu: 12.16ms, accelerator: 14.24ms, total: 26.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_185000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_185250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_185500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_185750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 24794010.74sec, total: 24794010.74sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.67ms, accelerator: 0us, total: 111.67ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.47ms, accelerator: 7.96ms, total: 19.44ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.67ms, accelerator: 0us, total: 111.67ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.14ms, accelerator: 24794010.76sec, total: 24794010.76sec
train2.py:307:<module>, cpu: 111.82ms, accelerator: 0us, total: 111.82ms
  iterator_ops.py:373:get_next, cpu: 111.67ms, accelerator: 0us, total: 111.67ms
train2.py:333:<module>, cpu: 12.10ms, accelerator: 14.24ms, total: 26.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_186000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_186250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_186500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_186750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 24661422.45sec, total: 24661422.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.39ms, accelerator: 0us, total: 111.39ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.41ms, accelerator: 7.96ms, total: 19.38ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.39ms, accelerator: 0us, total: 111.39ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.14ms, accelerator: 24661422.47sec, total: 24661422.47sec
train2.py:307:<module>, cpu: 111.55ms, accelerator: 0us, total: 111.55ms
  iterator_ops.py:373:get_next, cpu: 111.39ms, accelerator: 0us, total: 111.39ms
train2.py:333:<module>, cpu: 12.05ms, accelerator: 14.23ms, total: 26.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_187000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_187250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_187500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_187750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 24530244.67sec, total: 24530244.67sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.11ms, accelerator: 0us, total: 111.11ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.36ms, accelerator: 7.96ms, total: 19.32ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.11ms, accelerator: 0us, total: 111.11ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.14ms, accelerator: 24530244.69sec, total: 24530244.69sec
train2.py:307:<module>, cpu: 111.26ms, accelerator: 0us, total: 111.26ms
  iterator_ops.py:373:get_next, cpu: 111.11ms, accelerator: 0us, total: 111.11ms
train2.py:333:<module>, cpu: 11.99ms, accelerator: 14.24ms, total: 26.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_188000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_188250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_188500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_188750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 24400455.02sec, total: 24400455.02sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.83ms, accelerator: 0us, total: 110.83ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.30ms, accelerator: 7.95ms, total: 19.26ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.83ms, accelerator: 0us, total: 110.83ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.14ms, accelerator: 24400455.04sec, total: 24400455.04sec
train2.py:307:<module>, cpu: 110.98ms, accelerator: 0us, total: 110.98ms
  iterator_ops.py:373:get_next, cpu: 110.83ms, accelerator: 0us, total: 110.83ms
train2.py:333:<module>, cpu: 11.94ms, accelerator: 14.24ms, total: 26.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_189000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_189250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_189500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_189750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 24272031.57sec, total: 24272031.57sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.63ms, accelerator: 0us, total: 110.63ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.25ms, accelerator: 7.94ms, total: 19.20ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.63ms, accelerator: 0us, total: 110.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.14ms, accelerator: 24272031.59sec, total: 24272031.59sec
train2.py:307:<module>, cpu: 110.78ms, accelerator: 0us, total: 110.78ms
  iterator_ops.py:373:get_next, cpu: 110.63ms, accelerator: 0us, total: 110.63ms
train2.py:333:<module>, cpu: 11.88ms, accelerator: 14.25ms, total: 26.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_190000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_190250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_190500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_190750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 24144952.87sec, total: 24144952.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.54ms, accelerator: 0us, total: 110.54ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.19ms, accelerator: 7.95ms, total: 19.16ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.54ms, accelerator: 0us, total: 110.54ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.14ms, accelerator: 24144952.89sec, total: 24144952.89sec
train2.py:307:<module>, cpu: 110.69ms, accelerator: 0us, total: 110.69ms
  iterator_ops.py:373:get_next, cpu: 110.54ms, accelerator: 0us, total: 110.54ms
train2.py:333:<module>, cpu: 11.83ms, accelerator: 14.26ms, total: 26.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_191000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_191250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_191500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_191750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 24019197.91sec, total: 24019197.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.21ms, accelerator: 0us, total: 110.21ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.14ms, accelerator: 7.94ms, total: 19.09ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.21ms, accelerator: 0us, total: 110.21ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.14ms, accelerator: 24019197.93sec, total: 24019197.93sec
train2.py:307:<module>, cpu: 110.36ms, accelerator: 0us, total: 110.36ms
  iterator_ops.py:373:get_next, cpu: 110.21ms, accelerator: 0us, total: 110.21ms
train2.py:333:<module>, cpu: 11.78ms, accelerator: 14.26ms, total: 26.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_192000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_192250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_192500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_192750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 23894746.10sec, total: 23894746.10sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.91ms, accelerator: 0us, total: 109.91ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.09ms, accelerator: 7.94ms, total: 19.04ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.91ms, accelerator: 0us, total: 109.91ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.14ms, accelerator: 23894746.12sec, total: 23894746.13sec
train2.py:307:<module>, cpu: 110.06ms, accelerator: 0us, total: 110.06ms
  iterator_ops.py:373:get_next, cpu: 109.91ms, accelerator: 0us, total: 109.91ms
train2.py:333:<module>, cpu: 11.73ms, accelerator: 14.26ms, total: 26.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_193000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_193250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_193500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_193750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 23771577.31sec, total: 23771577.31sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.72ms, accelerator: 0us, total: 109.72ms (0.00%)
top 3 operation type: Conv2D, cpu: 11.04ms, accelerator: 7.96ms, total: 19.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.72ms, accelerator: 0us, total: 109.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.14ms, accelerator: 23771577.33sec, total: 23771577.33sec
train2.py:307:<module>, cpu: 109.87ms, accelerator: 0us, total: 109.87ms
  iterator_ops.py:373:get_next, cpu: 109.72ms, accelerator: 0us, total: 109.72ms
train2.py:333:<module>, cpu: 11.68ms, accelerator: 14.27ms, total: 25.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_194000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_194250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_194500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_194750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 23649671.78sec, total: 23649671.79sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.48ms, accelerator: 0us, total: 109.48ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.99ms, accelerator: 7.95ms, total: 18.95ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.48ms, accelerator: 0us, total: 109.48ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.14ms, accelerator: 23649671.80sec, total: 23649671.81sec
train2.py:307:<module>, cpu: 109.63ms, accelerator: 0us, total: 109.63ms
  iterator_ops.py:373:get_next, cpu: 109.48ms, accelerator: 0us, total: 109.48ms
train2.py:333:<module>, cpu: 11.62ms, accelerator: 14.27ms, total: 25.93ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_195000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_195250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_195500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_195750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 23529010.19sec, total: 23529010.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.29ms, accelerator: 0us, total: 109.29ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.94ms, accelerator: 7.96ms, total: 18.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.29ms, accelerator: 0us, total: 109.29ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.13ms, accelerator: 23529010.21sec, total: 23529010.22sec
train2.py:307:<module>, cpu: 109.44ms, accelerator: 0us, total: 109.44ms
  iterator_ops.py:373:get_next, cpu: 109.29ms, accelerator: 0us, total: 109.29ms
train2.py:333:<module>, cpu: 11.57ms, accelerator: 14.28ms, total: 25.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_196000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_196250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_196500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_196750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 23409573.59sec, total: 23409573.59sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.05ms, accelerator: 0us, total: 109.05ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.89ms, accelerator: 7.95ms, total: 18.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.05ms, accelerator: 0us, total: 109.05ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.13ms, accelerator: 23409573.61sec, total: 23409573.62sec
train2.py:307:<module>, cpu: 109.20ms, accelerator: 0us, total: 109.20ms
  iterator_ops.py:373:get_next, cpu: 109.05ms, accelerator: 0us, total: 109.05ms
train2.py:333:<module>, cpu: 11.52ms, accelerator: 14.27ms, total: 25.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_197000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_197250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_197500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_197750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 23291343.42sec, total: 23291343.42sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.80ms, accelerator: 0us, total: 108.80ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.84ms, accelerator: 7.95ms, total: 18.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.80ms, accelerator: 0us, total: 108.80ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.13ms, accelerator: 23291343.44sec, total: 23291343.45sec
train2.py:307:<module>, cpu: 108.94ms, accelerator: 0us, total: 108.94ms
  iterator_ops.py:373:get_next, cpu: 108.80ms, accelerator: 0us, total: 108.80ms
train2.py:333:<module>, cpu: 11.47ms, accelerator: 14.28ms, total: 25.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_198000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_198250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_198500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_198750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 23174301.50sec, total: 23174301.50sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.66ms, accelerator: 0us, total: 108.66ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.79ms, accelerator: 7.96ms, total: 18.76ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.66ms, accelerator: 0us, total: 108.66ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.13ms, accelerator: 23174301.52sec, total: 23174301.52sec
train2.py:307:<module>, cpu: 108.81ms, accelerator: 0us, total: 108.81ms
  iterator_ops.py:373:get_next, cpu: 108.66ms, accelerator: 0us, total: 108.66ms
train2.py:333:<module>, cpu: 11.43ms, accelerator: 14.28ms, total: 25.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_199000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_199250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_199500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_199750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 23058429.99sec, total: 23058429.99sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.40ms, accelerator: 0us, total: 108.40ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.74ms, accelerator: 7.96ms, total: 18.70ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.40ms, accelerator: 0us, total: 108.40ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.13ms, accelerator: 23058430.01sec, total: 23058430.01sec
train2.py:307:<module>, cpu: 108.54ms, accelerator: 0us, total: 108.54ms
  iterator_ops.py:373:get_next, cpu: 108.40ms, accelerator: 0us, total: 108.40ms
train2.py:333:<module>, cpu: 11.38ms, accelerator: 14.28ms, total: 25.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_200000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_200250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_200500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_200750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 22943711.43sec, total: 22943711.43sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.25ms, accelerator: 0us, total: 108.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.69ms, accelerator: 7.96ms, total: 18.66ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.25ms, accelerator: 0us, total: 108.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.13ms, accelerator: 22943711.45sec, total: 22943711.46sec
train2.py:307:<module>, cpu: 108.39ms, accelerator: 0us, total: 108.39ms
  iterator_ops.py:373:get_next, cpu: 108.25ms, accelerator: 0us, total: 108.25ms
train2.py:333:<module>, cpu: 11.33ms, accelerator: 14.27ms, total: 25.63ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_201000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_201250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_201500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_201750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 22830128.70sec, total: 22830128.70sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.05ms, accelerator: 0us, total: 108.05ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.64ms, accelerator: 7.96ms, total: 18.61ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.05ms, accelerator: 0us, total: 108.05ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.13ms, accelerator: 22830128.72sec, total: 22830128.73sec
train2.py:307:<module>, cpu: 108.19ms, accelerator: 0us, total: 108.19ms
  iterator_ops.py:373:get_next, cpu: 108.05ms, accelerator: 0us, total: 108.05ms
train2.py:333:<module>, cpu: 11.28ms, accelerator: 14.27ms, total: 25.57ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_202000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_202250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_202500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_202750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 22717665.02sec, total: 22717665.02sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.79ms, accelerator: 0us, total: 107.79ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.60ms, accelerator: 7.96ms, total: 18.57ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.79ms, accelerator: 0us, total: 107.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.13ms, accelerator: 22717665.03sec, total: 22717665.04sec
train2.py:307:<module>, cpu: 107.93ms, accelerator: 0us, total: 107.93ms
  iterator_ops.py:373:get_next, cpu: 107.79ms, accelerator: 0us, total: 107.79ms
train2.py:333:<module>, cpu: 11.23ms, accelerator: 14.26ms, total: 25.52ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_203000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_203250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_203500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_203750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 22606303.91sec, total: 22606303.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.56ms, accelerator: 0us, total: 107.56ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.55ms, accelerator: 7.96ms, total: 18.52ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.56ms, accelerator: 0us, total: 107.56ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.13ms, accelerator: 22606303.93sec, total: 22606303.93sec
train2.py:307:<module>, cpu: 107.70ms, accelerator: 0us, total: 107.70ms
  iterator_ops.py:373:get_next, cpu: 107.56ms, accelerator: 0us, total: 107.56ms
train2.py:333:<module>, cpu: 11.19ms, accelerator: 14.26ms, total: 25.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_204000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_204250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_204500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_204750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 22496029.26sec, total: 22496029.26sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.35ms, accelerator: 0us, total: 107.35ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.51ms, accelerator: 7.96ms, total: 18.47ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.35ms, accelerator: 0us, total: 107.35ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.13ms, accelerator: 22496029.28sec, total: 22496029.28sec
train2.py:307:<module>, cpu: 107.49ms, accelerator: 0us, total: 107.49ms
  iterator_ops.py:373:get_next, cpu: 107.35ms, accelerator: 0us, total: 107.35ms
train2.py:333:<module>, cpu: 11.14ms, accelerator: 14.26ms, total: 25.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_205000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_205250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_205500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_205750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 22386825.23sec, total: 22386825.23sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.31ms, accelerator: 0us, total: 107.31ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.46ms, accelerator: 7.96ms, total: 18.43ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.31ms, accelerator: 0us, total: 107.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.12ms, accelerator: 22386825.25sec, total: 22386825.26sec
train2.py:307:<module>, cpu: 107.45ms, accelerator: 0us, total: 107.45ms
  iterator_ops.py:373:get_next, cpu: 107.31ms, accelerator: 0us, total: 107.31ms
train2.py:333:<module>, cpu: 11.10ms, accelerator: 14.25ms, total: 25.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_206000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_206250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_206500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_206750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 22278676.32sec, total: 22278676.32sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.18ms, accelerator: 0us, total: 107.18ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.41ms, accelerator: 7.96ms, total: 18.38ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.18ms, accelerator: 0us, total: 107.18ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.12ms, accelerator: 22278676.34sec, total: 22278676.34sec
train2.py:307:<module>, cpu: 107.32ms, accelerator: 0us, total: 107.32ms
  iterator_ops.py:373:get_next, cpu: 107.18ms, accelerator: 0us, total: 107.18ms
train2.py:333:<module>, cpu: 11.05ms, accelerator: 14.24ms, total: 25.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_207000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_207250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_207500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_207750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 22171567.30sec, total: 22171567.30sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.91ms, accelerator: 0us, total: 106.91ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.37ms, accelerator: 7.96ms, total: 18.33ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.91ms, accelerator: 0us, total: 106.91ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.12ms, accelerator: 22171567.32sec, total: 22171567.32sec
train2.py:307:<module>, cpu: 107.05ms, accelerator: 0us, total: 107.05ms
  iterator_ops.py:373:get_next, cpu: 106.91ms, accelerator: 0us, total: 106.91ms
train2.py:333:<module>, cpu: 11.01ms, accelerator: 14.23ms, total: 25.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_208000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_208250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_208500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_208750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 22065483.24sec, total: 22065483.24sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.75ms, accelerator: 0us, total: 106.75ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.33ms, accelerator: 7.96ms, total: 18.29ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.75ms, accelerator: 0us, total: 106.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.12ms, accelerator: 22065483.26sec, total: 22065483.27sec
train2.py:307:<module>, cpu: 106.89ms, accelerator: 0us, total: 106.89ms
  iterator_ops.py:373:get_next, cpu: 106.75ms, accelerator: 0us, total: 106.75ms
train2.py:333:<module>, cpu: 10.96ms, accelerator: 14.23ms, total: 25.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_209000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_209250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_209500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_209750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 21960409.51sec, total: 21960409.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.54ms, accelerator: 0us, total: 106.54ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.28ms, accelerator: 7.95ms, total: 18.24ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.54ms, accelerator: 0us, total: 106.54ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.12ms, accelerator: 21960409.53sec, total: 21960409.54sec
train2.py:307:<module>, cpu: 106.68ms, accelerator: 0us, total: 106.68ms
  iterator_ops.py:373:get_next, cpu: 106.54ms, accelerator: 0us, total: 106.54ms
train2.py:333:<module>, cpu: 10.92ms, accelerator: 14.22ms, total: 25.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_210000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_210250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_210500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_210750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 21856331.74sec, total: 21856331.74sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.25ms, accelerator: 0us, total: 106.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.24ms, accelerator: 7.95ms, total: 18.19ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.25ms, accelerator: 0us, total: 106.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.12ms, accelerator: 21856331.76sec, total: 21856331.77sec
train2.py:307:<module>, cpu: 106.39ms, accelerator: 0us, total: 106.39ms
  iterator_ops.py:373:get_next, cpu: 106.25ms, accelerator: 0us, total: 106.25ms
train2.py:333:<module>, cpu: 10.87ms, accelerator: 14.23ms, total: 25.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_211000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_211250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_211500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_211750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 21753235.84sec, total: 21753235.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.13ms, accelerator: 0us, total: 106.13ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.20ms, accelerator: 7.94ms, total: 18.14ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.13ms, accelerator: 0us, total: 106.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.12ms, accelerator: 21753235.86sec, total: 21753235.86sec
train2.py:307:<module>, cpu: 106.26ms, accelerator: 0us, total: 106.26ms
  iterator_ops.py:373:get_next, cpu: 106.13ms, accelerator: 0us, total: 106.13ms
train2.py:333:<module>, cpu: 10.83ms, accelerator: 14.22ms, total: 25.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_212000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_212250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_212500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_212750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 21651107.97sec, total: 21651107.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.93ms, accelerator: 0us, total: 105.93ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.15ms, accelerator: 7.93ms, total: 18.09ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.93ms, accelerator: 0us, total: 105.93ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.12ms, accelerator: 21651107.99sec, total: 21651107.99sec
train2.py:307:<module>, cpu: 106.06ms, accelerator: 0us, total: 106.06ms
  iterator_ops.py:373:get_next, cpu: 105.93ms, accelerator: 0us, total: 105.93ms
train2.py:333:<module>, cpu: 10.79ms, accelerator: 14.22ms, total: 25.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_213000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_213250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_213500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_213750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 21549934.57sec, total: 21549934.57sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.74ms, accelerator: 0us, total: 105.74ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.11ms, accelerator: 7.93ms, total: 18.04ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.74ms, accelerator: 0us, total: 105.74ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.12ms, accelerator: 21549934.59sec, total: 21549934.59sec
train2.py:307:<module>, cpu: 105.88ms, accelerator: 0us, total: 105.88ms
  iterator_ops.py:373:get_next, cpu: 105.74ms, accelerator: 0us, total: 105.74ms
train2.py:333:<module>, cpu: 10.74ms, accelerator: 14.21ms, total: 24.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_214000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_214250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_214500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_214750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 21449702.32sec, total: 21449702.32sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.61ms, accelerator: 0us, total: 105.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.07ms, accelerator: 7.92ms, total: 18.00ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.61ms, accelerator: 0us, total: 105.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.12ms, accelerator: 21449702.34sec, total: 21449702.34sec
train2.py:307:<module>, cpu: 105.74ms, accelerator: 0us, total: 105.74ms
  iterator_ops.py:373:get_next, cpu: 105.61ms, accelerator: 0us, total: 105.61ms
train2.py:333:<module>, cpu: 10.70ms, accelerator: 14.22ms, total: 24.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_215000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_215250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_215500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_215750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 21350398.14sec, total: 21350398.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.46ms, accelerator: 0us, total: 105.46ms (0.00%)
top 3 operation type: Conv2D, cpu: 10.02ms, accelerator: 7.93ms, total: 17.96ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.46ms, accelerator: 0us, total: 105.46ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 21350398.16sec, total: 21350398.16sec
train2.py:307:<module>, cpu: 105.59ms, accelerator: 0us, total: 105.59ms
  iterator_ops.py:373:get_next, cpu: 105.46ms, accelerator: 0us, total: 105.46ms
train2.py:333:<module>, cpu: 10.66ms, accelerator: 14.23ms, total: 24.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_216000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_216250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_216500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_216750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 21252009.21sec, total: 21252009.21sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.24ms, accelerator: 0us, total: 105.24ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.98ms, accelerator: 7.93ms, total: 17.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.24ms, accelerator: 0us, total: 105.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 21252009.23sec, total: 21252009.23sec
train2.py:307:<module>, cpu: 105.37ms, accelerator: 0us, total: 105.37ms
  iterator_ops.py:373:get_next, cpu: 105.24ms, accelerator: 0us, total: 105.24ms
train2.py:333:<module>, cpu: 10.62ms, accelerator: 14.23ms, total: 24.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_217000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_217250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_217500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_217750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 21154522.93sec, total: 21154522.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.97ms, accelerator: 0us, total: 104.97ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.94ms, accelerator: 7.94ms, total: 17.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.97ms, accelerator: 0us, total: 104.97ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 21154522.95sec, total: 21154522.95sec
train2.py:307:<module>, cpu: 105.11ms, accelerator: 0us, total: 105.11ms
  iterator_ops.py:373:get_next, cpu: 104.97ms, accelerator: 0us, total: 104.97ms
train2.py:333:<module>, cpu: 10.58ms, accelerator: 14.24ms, total: 24.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_218000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_218250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_218500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_218750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 21057926.93sec, total: 21057926.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.78ms, accelerator: 0us, total: 104.78ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.90ms, accelerator: 7.95ms, total: 17.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.78ms, accelerator: 0us, total: 104.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 21057926.95sec, total: 21057926.95sec
train2.py:307:<module>, cpu: 104.91ms, accelerator: 0us, total: 104.91ms
  iterator_ops.py:373:get_next, cpu: 104.78ms, accelerator: 0us, total: 104.78ms
train2.py:333:<module>, cpu: 10.54ms, accelerator: 14.23ms, total: 24.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_219000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_219250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_219500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_219750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20962209.08sec, total: 20962209.08sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.80ms, accelerator: 0us, total: 104.80ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.86ms, accelerator: 7.97ms, total: 17.83ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.80ms, accelerator: 0us, total: 104.80ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 20962209.10sec, total: 20962209.10sec
train2.py:307:<module>, cpu: 104.93ms, accelerator: 0us, total: 104.93ms
  iterator_ops.py:373:get_next, cpu: 104.80ms, accelerator: 0us, total: 104.80ms
train2.py:333:<module>, cpu: 10.50ms, accelerator: 14.25ms, total: 24.77ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_220000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_220250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_220500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_220750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20867357.46sec, total: 20867357.46sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.61ms, accelerator: 0us, total: 104.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.82ms, accelerator: 7.96ms, total: 17.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.61ms, accelerator: 0us, total: 104.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 20867357.48sec, total: 20867357.48sec
train2.py:307:<module>, cpu: 104.74ms, accelerator: 0us, total: 104.74ms
  iterator_ops.py:373:get_next, cpu: 104.61ms, accelerator: 0us, total: 104.61ms
train2.py:333:<module>, cpu: 10.46ms, accelerator: 14.25ms, total: 24.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_221000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_221250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_221500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_221750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20773360.35sec, total: 20773360.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.37ms, accelerator: 0us, total: 104.37ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.78ms, accelerator: 7.96ms, total: 17.75ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.37ms, accelerator: 0us, total: 104.37ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 20773360.37sec, total: 20773360.37sec
train2.py:307:<module>, cpu: 104.50ms, accelerator: 0us, total: 104.50ms
  iterator_ops.py:373:get_next, cpu: 104.37ms, accelerator: 0us, total: 104.37ms
train2.py:333:<module>, cpu: 10.42ms, accelerator: 14.23ms, total: 24.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_222000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_222250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_222500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_222750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20680206.27sec, total: 20680206.27sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.21ms, accelerator: 0us, total: 104.21ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.74ms, accelerator: 7.95ms, total: 17.70ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.21ms, accelerator: 0us, total: 104.21ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 20680206.29sec, total: 20680206.29sec
train2.py:307:<module>, cpu: 104.34ms, accelerator: 0us, total: 104.34ms
  iterator_ops.py:373:get_next, cpu: 104.21ms, accelerator: 0us, total: 104.21ms
train2.py:333:<module>, cpu: 10.38ms, accelerator: 14.23ms, total: 24.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_223000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_223250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_223500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_223750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20587883.92sec, total: 20587883.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.03ms, accelerator: 0us, total: 104.03ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.71ms, accelerator: 7.95ms, total: 17.66ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.03ms, accelerator: 0us, total: 104.03ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 20587883.94sec, total: 20587883.94sec
train2.py:307:<module>, cpu: 104.16ms, accelerator: 0us, total: 104.16ms
  iterator_ops.py:373:get_next, cpu: 104.03ms, accelerator: 0us, total: 104.03ms
train2.py:333:<module>, cpu: 10.34ms, accelerator: 14.22ms, total: 24.59ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_224000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_224250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_224500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_224750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20496382.21sec, total: 20496382.21sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.07ms, accelerator: 0us, total: 104.07ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.67ms, accelerator: 7.96ms, total: 17.63ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.07ms, accelerator: 0us, total: 104.07ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 20496382.23sec, total: 20496382.24sec
train2.py:307:<module>, cpu: 104.20ms, accelerator: 0us, total: 104.20ms
  iterator_ops.py:373:get_next, cpu: 104.07ms, accelerator: 0us, total: 104.07ms
train2.py:333:<module>, cpu: 10.30ms, accelerator: 14.23ms, total: 24.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_225000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_225250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_225500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_225750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20405690.26sec, total: 20405690.26sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.40ms, accelerator: 0us, total: 108.40ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.63ms, accelerator: 7.95ms, total: 17.59ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.40ms, accelerator: 0us, total: 108.40ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 20405690.28sec, total: 20405690.28sec
train2.py:307:<module>, cpu: 108.53ms, accelerator: 0us, total: 108.53ms
  iterator_ops.py:373:get_next, cpu: 108.40ms, accelerator: 0us, total: 108.40ms
train2.py:333:<module>, cpu: 10.27ms, accelerator: 14.23ms, total: 24.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_226000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_226250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_226500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_226750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20315797.35sec, total: 20315797.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.14ms, accelerator: 0us, total: 108.14ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.59ms, accelerator: 7.96ms, total: 17.55ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.14ms, accelerator: 0us, total: 108.14ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 20315797.37sec, total: 20315797.37sec
train2.py:307:<module>, cpu: 108.27ms, accelerator: 0us, total: 108.27ms
  iterator_ops.py:373:get_next, cpu: 108.14ms, accelerator: 0us, total: 108.14ms
train2.py:333:<module>, cpu: 10.23ms, accelerator: 14.22ms, total: 24.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_227000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_227250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_227500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_227750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20226692.97sec, total: 20226692.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.98ms, accelerator: 0us, total: 107.98ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.55ms, accelerator: 7.96ms, total: 17.52ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.98ms, accelerator: 0us, total: 107.98ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.11ms, accelerator: 20226692.99sec, total: 20226693.00sec
train2.py:307:<module>, cpu: 108.11ms, accelerator: 0us, total: 108.11ms
  iterator_ops.py:373:get_next, cpu: 107.98ms, accelerator: 0us, total: 107.98ms
train2.py:333:<module>, cpu: 10.19ms, accelerator: 14.23ms, total: 24.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_228000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_228250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_228500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_228750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20138366.80sec, total: 20138366.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.85ms, accelerator: 0us, total: 107.85ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.52ms, accelerator: 7.96ms, total: 17.48ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.85ms, accelerator: 0us, total: 107.85ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 20138366.82sec, total: 20138366.83sec
train2.py:307:<module>, cpu: 107.98ms, accelerator: 0us, total: 107.98ms
  iterator_ops.py:373:get_next, cpu: 107.85ms, accelerator: 0us, total: 107.85ms
train2.py:333:<module>, cpu: 10.15ms, accelerator: 14.24ms, total: 24.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_229000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_229250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_229500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_229750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 20050808.69sec, total: 20050808.69sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.63ms, accelerator: 0us, total: 107.63ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.48ms, accelerator: 7.96ms, total: 17.44ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.63ms, accelerator: 0us, total: 107.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 20050808.71sec, total: 20050808.71sec
train2.py:307:<module>, cpu: 107.75ms, accelerator: 0us, total: 107.75ms
  iterator_ops.py:373:get_next, cpu: 107.63ms, accelerator: 0us, total: 107.63ms
train2.py:333:<module>, cpu: 10.12ms, accelerator: 14.24ms, total: 24.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_230000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_230250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_230500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_230750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19964008.65sec, total: 19964008.65sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.58ms, accelerator: 0us, total: 107.58ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.44ms, accelerator: 7.96ms, total: 17.41ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.58ms, accelerator: 0us, total: 107.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19964008.67sec, total: 19964008.67sec
train2.py:307:<module>, cpu: 107.70ms, accelerator: 0us, total: 107.70ms
  iterator_ops.py:373:get_next, cpu: 107.58ms, accelerator: 0us, total: 107.58ms
train2.py:333:<module>, cpu: 10.08ms, accelerator: 14.25ms, total: 24.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_231000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_231250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_231500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_231750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19877956.89sec, total: 19877956.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.39ms, accelerator: 0us, total: 107.39ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.41ms, accelerator: 7.96ms, total: 17.37ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.39ms, accelerator: 0us, total: 107.39ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19877956.91sec, total: 19877956.91sec
train2.py:307:<module>, cpu: 107.51ms, accelerator: 0us, total: 107.51ms
  iterator_ops.py:373:get_next, cpu: 107.39ms, accelerator: 0us, total: 107.39ms
train2.py:333:<module>, cpu: 10.05ms, accelerator: 14.25ms, total: 24.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_232000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_232250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_232500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_232750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19792643.77sec, total: 19792643.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.27ms, accelerator: 0us, total: 107.27ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.37ms, accelerator: 7.96ms, total: 17.34ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.27ms, accelerator: 0us, total: 107.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19792643.79sec, total: 19792643.79sec
train2.py:307:<module>, cpu: 107.39ms, accelerator: 0us, total: 107.39ms
  iterator_ops.py:373:get_next, cpu: 107.27ms, accelerator: 0us, total: 107.27ms
train2.py:333:<module>, cpu: 10.01ms, accelerator: 14.24ms, total: 24.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_233000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_233250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_233500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_233750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19708059.82sec, total: 19708059.82sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.08ms, accelerator: 0us, total: 107.08ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.34ms, accelerator: 7.96ms, total: 17.30ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.08ms, accelerator: 0us, total: 107.08ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19708059.84sec, total: 19708059.84sec
train2.py:307:<module>, cpu: 107.20ms, accelerator: 0us, total: 107.20ms
  iterator_ops.py:373:get_next, cpu: 107.08ms, accelerator: 0us, total: 107.08ms
train2.py:333:<module>, cpu: 9.98ms, accelerator: 14.24ms, total: 24.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_234000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_234250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_234500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_234750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19624195.74sec, total: 19624195.74sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.89ms, accelerator: 0us, total: 106.89ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.30ms, accelerator: 7.97ms, total: 17.28ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.89ms, accelerator: 0us, total: 106.89ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19624195.76sec, total: 19624195.76sec
train2.py:307:<module>, cpu: 107.01ms, accelerator: 0us, total: 107.01ms
  iterator_ops.py:373:get_next, cpu: 106.89ms, accelerator: 0us, total: 106.89ms
train2.py:333:<module>, cpu: 9.94ms, accelerator: 14.25ms, total: 24.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_235000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_235250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_235500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_235750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19541042.37sec, total: 19541042.37sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.75ms, accelerator: 0us, total: 106.75ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.27ms, accelerator: 7.97ms, total: 17.25ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.75ms, accelerator: 0us, total: 106.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19541042.38sec, total: 19541042.39sec
train2.py:307:<module>, cpu: 106.87ms, accelerator: 0us, total: 106.87ms
  iterator_ops.py:373:get_next, cpu: 106.75ms, accelerator: 0us, total: 106.75ms
train2.py:333:<module>, cpu: 9.91ms, accelerator: 14.26ms, total: 24.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_236000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_236250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_236500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_236750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19458590.71sec, total: 19458590.71sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.50ms, accelerator: 0us, total: 106.50ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.23ms, accelerator: 7.97ms, total: 17.21ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.50ms, accelerator: 0us, total: 106.50ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19458590.73sec, total: 19458590.73sec
train2.py:307:<module>, cpu: 106.62ms, accelerator: 0us, total: 106.62ms
  iterator_ops.py:373:get_next, cpu: 106.50ms, accelerator: 0us, total: 106.50ms
train2.py:333:<module>, cpu: 9.87ms, accelerator: 14.26ms, total: 24.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_237000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_237250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_237500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_237750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19376831.93sec, total: 19376831.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.31ms, accelerator: 0us, total: 106.31ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.20ms, accelerator: 7.97ms, total: 17.17ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.31ms, accelerator: 0us, total: 106.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19376831.94sec, total: 19376831.95sec
train2.py:307:<module>, cpu: 106.43ms, accelerator: 0us, total: 106.43ms
  iterator_ops.py:373:get_next, cpu: 106.31ms, accelerator: 0us, total: 106.31ms
train2.py:333:<module>, cpu: 9.84ms, accelerator: 14.27ms, total: 24.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_238000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_238250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_238500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_238750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19295757.31sec, total: 19295757.31sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.08ms, accelerator: 0us, total: 106.08ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.16ms, accelerator: 7.97ms, total: 17.14ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.08ms, accelerator: 0us, total: 106.08ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19295757.33sec, total: 19295757.34sec
train2.py:307:<module>, cpu: 106.20ms, accelerator: 0us, total: 106.20ms
  iterator_ops.py:373:get_next, cpu: 106.08ms, accelerator: 0us, total: 106.08ms
train2.py:333:<module>, cpu: 9.80ms, accelerator: 14.26ms, total: 24.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_239000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_239250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_239500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_239750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19215358.33sec, total: 19215358.33sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.89ms, accelerator: 0us, total: 105.89ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.13ms, accelerator: 7.96ms, total: 17.10ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.89ms, accelerator: 0us, total: 105.89ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19215358.34sec, total: 19215358.35sec
train2.py:307:<module>, cpu: 106.01ms, accelerator: 0us, total: 106.01ms
  iterator_ops.py:373:get_next, cpu: 105.89ms, accelerator: 0us, total: 105.89ms
train2.py:333:<module>, cpu: 9.77ms, accelerator: 14.26ms, total: 24.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_240000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_240250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_240500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_240750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19135626.55sec, total: 19135626.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.77ms, accelerator: 0us, total: 105.77ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.10ms, accelerator: 7.96ms, total: 17.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.77ms, accelerator: 0us, total: 105.77ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19135626.57sec, total: 19135626.57sec
train2.py:307:<module>, cpu: 105.89ms, accelerator: 0us, total: 105.89ms
  iterator_ops.py:373:get_next, cpu: 105.77ms, accelerator: 0us, total: 105.77ms
train2.py:333:<module>, cpu: 9.73ms, accelerator: 14.26ms, total: 24.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_241000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_241250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_241500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_241750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 19056553.71sec, total: 19056553.71sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.56ms, accelerator: 0us, total: 105.56ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.06ms, accelerator: 7.96ms, total: 17.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.56ms, accelerator: 0us, total: 105.56ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 19056553.73sec, total: 19056553.73sec
train2.py:307:<module>, cpu: 105.67ms, accelerator: 0us, total: 105.67ms
  iterator_ops.py:373:get_next, cpu: 105.56ms, accelerator: 0us, total: 105.56ms
train2.py:333:<module>, cpu: 9.70ms, accelerator: 14.27ms, total: 23.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_242000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_242250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_242500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_242750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 18978131.68sec, total: 18978131.68sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.43ms, accelerator: 0us, total: 105.43ms (0.00%)
top 3 operation type: Conv2D, cpu: 9.03ms, accelerator: 7.96ms, total: 17.00ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.43ms, accelerator: 0us, total: 105.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.10ms, accelerator: 18978131.70sec, total: 18978131.70sec
train2.py:307:<module>, cpu: 105.55ms, accelerator: 0us, total: 105.55ms
  iterator_ops.py:373:get_next, cpu: 105.43ms, accelerator: 0us, total: 105.43ms
train2.py:333:<module>, cpu: 9.67ms, accelerator: 14.28ms, total: 23.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_243000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_243250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_243500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_243750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 18900352.45sec, total: 18900352.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.28ms, accelerator: 0us, total: 105.28ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.99ms, accelerator: 7.97ms, total: 16.97ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.28ms, accelerator: 0us, total: 105.28ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18900352.47sec, total: 18900352.47sec
train2.py:307:<module>, cpu: 105.40ms, accelerator: 0us, total: 105.40ms
  iterator_ops.py:373:get_next, cpu: 105.28ms, accelerator: 0us, total: 105.28ms
train2.py:333:<module>, cpu: 9.63ms, accelerator: 14.29ms, total: 23.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_244000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_244250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_244500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_244750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 18823208.16sec, total: 18823208.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.12ms, accelerator: 0us, total: 105.12ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.96ms, accelerator: 7.96ms, total: 16.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.12ms, accelerator: 0us, total: 105.12ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18823208.18sec, total: 18823208.18sec
train2.py:307:<module>, cpu: 105.24ms, accelerator: 0us, total: 105.24ms
  iterator_ops.py:373:get_next, cpu: 105.12ms, accelerator: 0us, total: 105.12ms
train2.py:333:<module>, cpu: 9.60ms, accelerator: 14.29ms, total: 23.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_245000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_245250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_245500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_245750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 18746691.05sec, total: 18746691.05sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.97ms, accelerator: 0us, total: 104.97ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.93ms, accelerator: 7.95ms, total: 16.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.97ms, accelerator: 0us, total: 104.97ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18746691.07sec, total: 18746691.07sec
train2.py:307:<module>, cpu: 105.08ms, accelerator: 0us, total: 105.08ms
  iterator_ops.py:373:get_next, cpu: 104.97ms, accelerator: 0us, total: 104.97ms
train2.py:333:<module>, cpu: 9.57ms, accelerator: 14.28ms, total: 23.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_246000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_246250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_246500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_246750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 18670793.51sec, total: 18670793.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.75ms, accelerator: 0us, total: 104.75ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.90ms, accelerator: 7.96ms, total: 16.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.75ms, accelerator: 0us, total: 104.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18670793.53sec, total: 18670793.54sec
train2.py:307:<module>, cpu: 104.87ms, accelerator: 0us, total: 104.87ms
  iterator_ops.py:373:get_next, cpu: 104.75ms, accelerator: 0us, total: 104.75ms
train2.py:333:<module>, cpu: 9.54ms, accelerator: 14.29ms, total: 23.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_247000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_247250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_247500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_247750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 18595508.06sec, total: 18595508.06sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.54ms, accelerator: 0us, total: 104.54ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.87ms, accelerator: 7.95ms, total: 16.83ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.54ms, accelerator: 0us, total: 104.54ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18595508.08sec, total: 18595508.08sec
train2.py:307:<module>, cpu: 104.66ms, accelerator: 0us, total: 104.66ms
  iterator_ops.py:373:get_next, cpu: 104.54ms, accelerator: 0us, total: 104.54ms
train2.py:333:<module>, cpu: 9.51ms, accelerator: 14.28ms, total: 23.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_248000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_248250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_248500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_248750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 18520827.30sec, total: 18520827.30sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.43ms, accelerator: 0us, total: 104.43ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.84ms, accelerator: 7.95ms, total: 16.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.43ms, accelerator: 0us, total: 104.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18520827.32sec, total: 18520827.32sec
train2.py:307:<module>, cpu: 104.55ms, accelerator: 0us, total: 104.55ms
  iterator_ops.py:373:get_next, cpu: 104.43ms, accelerator: 0us, total: 104.43ms
train2.py:333:<module>, cpu: 9.48ms, accelerator: 14.27ms, total: 23.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_249000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_249250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_249500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_249750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 18446743.99sec, total: 18446743.99sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.60ms, accelerator: 0us, total: 108.60ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.80ms, accelerator: 7.96ms, total: 16.77ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.60ms, accelerator: 0us, total: 108.60ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18446744.01sec, total: 18446744.02sec
train2.py:307:<module>, cpu: 108.71ms, accelerator: 0us, total: 108.71ms
  iterator_ops.py:373:get_next, cpu: 108.60ms, accelerator: 0us, total: 108.60ms
train2.py:333:<module>, cpu: 9.45ms, accelerator: 14.28ms, total: 23.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_250000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_250250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_250500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_250750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 18373250.99sec, total: 18373250.99sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.42ms, accelerator: 0us, total: 108.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.78ms, accelerator: 7.96ms, total: 16.74ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.42ms, accelerator: 0us, total: 108.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18373251.01sec, total: 18373251.01sec
train2.py:307:<module>, cpu: 108.54ms, accelerator: 0us, total: 108.54ms
  iterator_ops.py:373:get_next, cpu: 108.42ms, accelerator: 0us, total: 108.42ms
train2.py:333:<module>, cpu: 9.42ms, accelerator: 14.28ms, total: 23.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_251000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_251250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_251500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_251750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 18300341.26sec, total: 18300341.26sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.43ms, accelerator: 0us, total: 108.43ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.74ms, accelerator: 7.97ms, total: 16.72ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.43ms, accelerator: 0us, total: 108.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18300341.28sec, total: 18300341.29sec
train2.py:307:<module>, cpu: 108.55ms, accelerator: 0us, total: 108.55ms
  iterator_ops.py:373:get_next, cpu: 108.43ms, accelerator: 0us, total: 108.43ms
train2.py:333:<module>, cpu: 9.38ms, accelerator: 14.29ms, total: 23.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_252000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_252250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_252500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_252750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 18228007.90sec, total: 18228007.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.19ms, accelerator: 0us, total: 108.19ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.71ms, accelerator: 7.96ms, total: 16.68ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.19ms, accelerator: 0us, total: 108.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18228007.92sec, total: 18228007.92sec
train2.py:307:<module>, cpu: 108.31ms, accelerator: 0us, total: 108.31ms
  iterator_ops.py:373:get_next, cpu: 108.19ms, accelerator: 0us, total: 108.19ms
train2.py:333:<module>, cpu: 9.35ms, accelerator: 14.28ms, total: 23.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_253000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_253250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_253500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_253750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 18156244.09sec, total: 18156244.09sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.02ms, accelerator: 0us, total: 108.02ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.69ms, accelerator: 7.95ms, total: 16.64ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.02ms, accelerator: 0us, total: 108.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18156244.11sec, total: 18156244.11sec
train2.py:307:<module>, cpu: 108.14ms, accelerator: 0us, total: 108.14ms
  iterator_ops.py:373:get_next, cpu: 108.02ms, accelerator: 0us, total: 108.02ms
train2.py:333:<module>, cpu: 9.32ms, accelerator: 14.28ms, total: 23.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_254000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_254250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_254500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_254750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 18085043.13sec, total: 18085043.13sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.91ms, accelerator: 0us, total: 107.91ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.65ms, accelerator: 7.95ms, total: 16.61ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.91ms, accelerator: 0us, total: 107.91ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18085043.15sec, total: 18085043.15sec
train2.py:307:<module>, cpu: 108.02ms, accelerator: 0us, total: 108.02ms
  iterator_ops.py:373:get_next, cpu: 107.91ms, accelerator: 0us, total: 107.91ms
train2.py:333:<module>, cpu: 9.29ms, accelerator: 14.27ms, total: 23.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_255000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_255250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_255500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_255750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 18014398.43sec, total: 18014398.43sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.75ms, accelerator: 0us, total: 107.75ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.63ms, accelerator: 7.95ms, total: 16.58ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.75ms, accelerator: 0us, total: 107.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 18014398.45sec, total: 18014398.45sec
train2.py:307:<module>, cpu: 107.86ms, accelerator: 0us, total: 107.86ms
  iterator_ops.py:373:get_next, cpu: 107.75ms, accelerator: 0us, total: 107.75ms
train2.py:333:<module>, cpu: 9.27ms, accelerator: 14.27ms, total: 23.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_256000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_256250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_256500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_256750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17944303.49sec, total: 17944303.50sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.61ms, accelerator: 0us, total: 107.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.60ms, accelerator: 7.95ms, total: 16.55ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.61ms, accelerator: 0us, total: 107.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 17944303.51sec, total: 17944303.52sec
train2.py:307:<module>, cpu: 107.73ms, accelerator: 0us, total: 107.73ms
  iterator_ops.py:373:get_next, cpu: 107.61ms, accelerator: 0us, total: 107.61ms
train2.py:333:<module>, cpu: 9.23ms, accelerator: 14.27ms, total: 23.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_257000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_257250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_257500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_257750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17874751.93sec, total: 17874751.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.42ms, accelerator: 0us, total: 107.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.57ms, accelerator: 7.96ms, total: 16.53ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.42ms, accelerator: 0us, total: 107.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 17874751.95sec, total: 17874751.95sec
train2.py:307:<module>, cpu: 107.53ms, accelerator: 0us, total: 107.53ms
  iterator_ops.py:373:get_next, cpu: 107.42ms, accelerator: 0us, total: 107.42ms
train2.py:333:<module>, cpu: 9.21ms, accelerator: 14.27ms, total: 23.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_258000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_258250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_258500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_258750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17805737.44sec, total: 17805737.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.25ms, accelerator: 0us, total: 107.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.54ms, accelerator: 7.95ms, total: 16.50ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.25ms, accelerator: 0us, total: 107.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 17805737.46sec, total: 17805737.47sec
train2.py:307:<module>, cpu: 107.36ms, accelerator: 0us, total: 107.36ms
  iterator_ops.py:373:get_next, cpu: 107.25ms, accelerator: 0us, total: 107.25ms
train2.py:333:<module>, cpu: 9.18ms, accelerator: 14.26ms, total: 23.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_259000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_259250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_259500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_259750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17737253.84sec, total: 17737253.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.07ms, accelerator: 0us, total: 107.07ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.51ms, accelerator: 7.95ms, total: 16.47ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.07ms, accelerator: 0us, total: 107.07ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.09ms, accelerator: 17737253.86sec, total: 17737253.86sec
train2.py:307:<module>, cpu: 107.18ms, accelerator: 0us, total: 107.18ms
  iterator_ops.py:373:get_next, cpu: 107.07ms, accelerator: 0us, total: 107.07ms
train2.py:333:<module>, cpu: 9.15ms, accelerator: 14.25ms, total: 23.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_260000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_260250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_260500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_260750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17669295.01sec, total: 17669295.01sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.94ms, accelerator: 0us, total: 106.94ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.48ms, accelerator: 7.95ms, total: 16.44ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.94ms, accelerator: 0us, total: 106.94ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17669295.03sec, total: 17669295.03sec
train2.py:307:<module>, cpu: 107.05ms, accelerator: 0us, total: 107.05ms
  iterator_ops.py:373:get_next, cpu: 106.94ms, accelerator: 0us, total: 106.94ms
train2.py:333:<module>, cpu: 9.12ms, accelerator: 14.25ms, total: 23.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_261000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_261250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_261500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_261750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17601854.96sec, total: 17601854.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.84ms, accelerator: 0us, total: 106.84ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.45ms, accelerator: 7.95ms, total: 16.41ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.84ms, accelerator: 0us, total: 106.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17601854.97sec, total: 17601854.98sec
train2.py:307:<module>, cpu: 106.95ms, accelerator: 0us, total: 106.95ms
  iterator_ops.py:373:get_next, cpu: 106.84ms, accelerator: 0us, total: 106.84ms
train2.py:333:<module>, cpu: 9.09ms, accelerator: 14.25ms, total: 23.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_262000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_262250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_262500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_262750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17534927.75sec, total: 17534927.75sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.73ms, accelerator: 0us, total: 106.73ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.42ms, accelerator: 7.95ms, total: 16.38ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.73ms, accelerator: 0us, total: 106.73ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17534927.77sec, total: 17534927.77sec
train2.py:307:<module>, cpu: 106.84ms, accelerator: 0us, total: 106.84ms
  iterator_ops.py:373:get_next, cpu: 106.73ms, accelerator: 0us, total: 106.73ms
train2.py:333:<module>, cpu: 9.06ms, accelerator: 14.25ms, total: 23.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_263000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_263250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_263500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_263750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17468507.57sec, total: 17468507.57sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.55ms, accelerator: 0us, total: 106.55ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.40ms, accelerator: 7.95ms, total: 16.35ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.55ms, accelerator: 0us, total: 106.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17468507.59sec, total: 17468507.59sec
train2.py:307:<module>, cpu: 106.66ms, accelerator: 0us, total: 106.66ms
  iterator_ops.py:373:get_next, cpu: 106.55ms, accelerator: 0us, total: 106.55ms
train2.py:333:<module>, cpu: 9.04ms, accelerator: 14.23ms, total: 23.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_264000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_264250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_264500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_264750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17402588.67sec, total: 17402588.67sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.40ms, accelerator: 0us, total: 106.40ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.37ms, accelerator: 7.93ms, total: 16.31ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.40ms, accelerator: 0us, total: 106.40ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17402588.69sec, total: 17402588.69sec
train2.py:307:<module>, cpu: 106.51ms, accelerator: 0us, total: 106.51ms
  iterator_ops.py:373:get_next, cpu: 106.40ms, accelerator: 0us, total: 106.40ms
train2.py:333:<module>, cpu: 9.01ms, accelerator: 14.22ms, total: 23.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_265000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_265250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_265500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_265750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17337165.41sec, total: 17337165.41sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.22ms, accelerator: 0us, total: 106.22ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.34ms, accelerator: 7.93ms, total: 16.27ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.22ms, accelerator: 0us, total: 106.22ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17337165.43sec, total: 17337165.43sec
train2.py:307:<module>, cpu: 106.33ms, accelerator: 0us, total: 106.33ms
  iterator_ops.py:373:get_next, cpu: 106.22ms, accelerator: 0us, total: 106.22ms
train2.py:333:<module>, cpu: 8.98ms, accelerator: 14.21ms, total: 23.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_266000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_266250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_266500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_266750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17272232.20sec, total: 17272232.20sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.09ms, accelerator: 0us, total: 106.09ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.31ms, accelerator: 7.92ms, total: 16.25ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.09ms, accelerator: 0us, total: 106.09ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17272232.22sec, total: 17272232.23sec
train2.py:307:<module>, cpu: 106.20ms, accelerator: 0us, total: 106.20ms
  iterator_ops.py:373:get_next, cpu: 106.09ms, accelerator: 0us, total: 106.09ms
train2.py:333:<module>, cpu: 8.96ms, accelerator: 14.21ms, total: 23.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_267000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_267250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_267500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_267750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17207783.58sec, total: 17207783.58sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.98ms, accelerator: 0us, total: 105.98ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.29ms, accelerator: 7.93ms, total: 16.22ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.98ms, accelerator: 0us, total: 105.98ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17207783.59sec, total: 17207783.60sec
train2.py:307:<module>, cpu: 106.08ms, accelerator: 0us, total: 106.08ms
  iterator_ops.py:373:get_next, cpu: 105.98ms, accelerator: 0us, total: 105.98ms
train2.py:333:<module>, cpu: 8.93ms, accelerator: 14.22ms, total: 23.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_268000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_268250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_268500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_268750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17143814.12sec, total: 17143814.12sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.80ms, accelerator: 0us, total: 105.80ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.26ms, accelerator: 7.93ms, total: 16.19ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.80ms, accelerator: 0us, total: 105.80ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17143814.14sec, total: 17143814.14sec
train2.py:307:<module>, cpu: 105.91ms, accelerator: 0us, total: 105.91ms
  iterator_ops.py:373:get_next, cpu: 105.80ms, accelerator: 0us, total: 105.80ms
train2.py:333:<module>, cpu: 8.90ms, accelerator: 14.22ms, total: 23.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_269000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_269250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_269500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_269750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17080318.51sec, total: 17080318.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.70ms, accelerator: 0us, total: 105.70ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.23ms, accelerator: 7.93ms, total: 16.17ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.70ms, accelerator: 0us, total: 105.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17080318.53sec, total: 17080318.53sec
train2.py:307:<module>, cpu: 105.81ms, accelerator: 0us, total: 105.81ms
  iterator_ops.py:373:get_next, cpu: 105.70ms, accelerator: 0us, total: 105.70ms
train2.py:333:<module>, cpu: 8.87ms, accelerator: 14.22ms, total: 23.12ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_270000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_270250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_270500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_270750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 17017291.51sec, total: 17017291.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.52ms, accelerator: 0us, total: 105.52ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.21ms, accelerator: 7.94ms, total: 16.15ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.52ms, accelerator: 0us, total: 105.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 17017291.53sec, total: 17017291.53sec
train2.py:307:<module>, cpu: 105.62ms, accelerator: 0us, total: 105.62ms
  iterator_ops.py:373:get_next, cpu: 105.52ms, accelerator: 0us, total: 105.52ms
train2.py:333:<module>, cpu: 8.85ms, accelerator: 14.23ms, total: 23.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_271000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_271250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_271500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_271750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16954727.93sec, total: 16954727.94sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.41ms, accelerator: 0us, total: 105.41ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.18ms, accelerator: 7.94ms, total: 16.13ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.41ms, accelerator: 0us, total: 105.41ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16954727.95sec, total: 16954727.96sec
train2.py:307:<module>, cpu: 105.52ms, accelerator: 0us, total: 105.52ms
  iterator_ops.py:373:get_next, cpu: 105.41ms, accelerator: 0us, total: 105.41ms
train2.py:333:<module>, cpu: 8.82ms, accelerator: 14.23ms, total: 23.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_272000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_272250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_272500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_272750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16892622.70sec, total: 16892622.70sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.22ms, accelerator: 0us, total: 105.22ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.15ms, accelerator: 7.93ms, total: 16.09ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.22ms, accelerator: 0us, total: 105.22ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16892622.72sec, total: 16892622.73sec
train2.py:307:<module>, cpu: 105.33ms, accelerator: 0us, total: 105.33ms
  iterator_ops.py:373:get_next, cpu: 105.22ms, accelerator: 0us, total: 105.22ms
train2.py:333:<module>, cpu: 8.79ms, accelerator: 14.23ms, total: 23.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_273000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_273250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_273500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_273750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16830970.80sec, total: 16830970.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.13ms, accelerator: 0us, total: 105.13ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.13ms, accelerator: 7.93ms, total: 16.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.13ms, accelerator: 0us, total: 105.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16830970.82sec, total: 16830970.82sec
train2.py:307:<module>, cpu: 105.24ms, accelerator: 0us, total: 105.24ms
  iterator_ops.py:373:get_next, cpu: 105.13ms, accelerator: 0us, total: 105.13ms
train2.py:333:<module>, cpu: 8.77ms, accelerator: 14.23ms, total: 23.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_274000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_274250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_274500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_274750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16769767.27sec, total: 16769767.27sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.96ms, accelerator: 0us, total: 104.96ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.10ms, accelerator: 7.94ms, total: 16.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.96ms, accelerator: 0us, total: 104.96ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16769767.29sec, total: 16769767.29sec
train2.py:307:<module>, cpu: 105.06ms, accelerator: 0us, total: 105.06ms
  iterator_ops.py:373:get_next, cpu: 104.96ms, accelerator: 0us, total: 104.96ms
train2.py:333:<module>, cpu: 8.74ms, accelerator: 14.24ms, total: 23.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_275000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_275250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_275500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_275750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16709007.24sec, total: 16709007.24sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.92ms, accelerator: 0us, total: 104.92ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.08ms, accelerator: 7.95ms, total: 16.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.92ms, accelerator: 0us, total: 104.92ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16709007.26sec, total: 16709007.26sec
train2.py:307:<module>, cpu: 105.02ms, accelerator: 0us, total: 105.02ms
  iterator_ops.py:373:get_next, cpu: 104.92ms, accelerator: 0us, total: 104.92ms
train2.py:333:<module>, cpu: 8.72ms, accelerator: 14.23ms, total: 22.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_276000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_276250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_276500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_276750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16648685.91sec, total: 16648685.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.77ms, accelerator: 0us, total: 104.77ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.05ms, accelerator: 7.94ms, total: 16.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.77ms, accelerator: 0us, total: 104.77ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16648685.93sec, total: 16648685.94sec
train2.py:307:<module>, cpu: 104.88ms, accelerator: 0us, total: 104.88ms
  iterator_ops.py:373:get_next, cpu: 104.77ms, accelerator: 0us, total: 104.77ms
train2.py:333:<module>, cpu: 8.69ms, accelerator: 14.23ms, total: 22.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_277000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_277250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_277500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_277750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16588798.55sec, total: 16588798.56sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.67ms, accelerator: 0us, total: 104.67ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.03ms, accelerator: 7.94ms, total: 15.97ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.67ms, accelerator: 0us, total: 104.67ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16588798.57sec, total: 16588798.58sec
train2.py:307:<module>, cpu: 104.78ms, accelerator: 0us, total: 104.78ms
  iterator_ops.py:373:get_next, cpu: 104.67ms, accelerator: 0us, total: 104.67ms
train2.py:333:<module>, cpu: 8.67ms, accelerator: 14.23ms, total: 22.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_278000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_278250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_278500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_278750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16529340.50sec, total: 16529340.50sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.62ms, accelerator: 0us, total: 104.62ms (0.00%)
top 3 operation type: Conv2D, cpu: 8.00ms, accelerator: 7.95ms, total: 15.96ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.62ms, accelerator: 0us, total: 104.62ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16529340.51sec, total: 16529340.52sec
train2.py:307:<module>, cpu: 104.72ms, accelerator: 0us, total: 104.72ms
  iterator_ops.py:373:get_next, cpu: 104.62ms, accelerator: 0us, total: 104.62ms
train2.py:333:<module>, cpu: 8.64ms, accelerator: 14.24ms, total: 22.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_279000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_279250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_279500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_279750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16470307.14sec, total: 16470307.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.43ms, accelerator: 0us, total: 104.43ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.98ms, accelerator: 7.94ms, total: 15.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.43ms, accelerator: 0us, total: 104.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16470307.16sec, total: 16470307.16sec
train2.py:307:<module>, cpu: 104.53ms, accelerator: 0us, total: 104.53ms
  iterator_ops.py:373:get_next, cpu: 104.43ms, accelerator: 0us, total: 104.43ms
train2.py:333:<module>, cpu: 8.62ms, accelerator: 14.23ms, total: 22.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_280000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_280250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_280500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_280750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16411693.94sec, total: 16411693.94sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.33ms, accelerator: 0us, total: 104.33ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.95ms, accelerator: 7.94ms, total: 15.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.33ms, accelerator: 0us, total: 104.33ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16411693.96sec, total: 16411693.97sec
train2.py:307:<module>, cpu: 104.43ms, accelerator: 0us, total: 104.43ms
  iterator_ops.py:373:get_next, cpu: 104.33ms, accelerator: 0us, total: 104.33ms
train2.py:333:<module>, cpu: 8.59ms, accelerator: 14.23ms, total: 22.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_281000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_281250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_281500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_281750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16353496.45sec, total: 16353496.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.16ms, accelerator: 0us, total: 104.16ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.93ms, accelerator: 7.95ms, total: 15.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.16ms, accelerator: 0us, total: 104.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16353496.47sec, total: 16353496.47sec
train2.py:307:<module>, cpu: 104.27ms, accelerator: 0us, total: 104.27ms
  iterator_ops.py:373:get_next, cpu: 104.16ms, accelerator: 0us, total: 104.16ms
train2.py:333:<module>, cpu: 8.57ms, accelerator: 14.24ms, total: 22.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_282000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_282250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_282500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_282750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16295710.24sec, total: 16295710.24sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.11ms, accelerator: 0us, total: 104.11ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.90ms, accelerator: 7.95ms, total: 15.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.11ms, accelerator: 0us, total: 104.11ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16295710.26sec, total: 16295710.26sec
train2.py:307:<module>, cpu: 104.21ms, accelerator: 0us, total: 104.21ms
  iterator_ops.py:373:get_next, cpu: 104.11ms, accelerator: 0us, total: 104.11ms
train2.py:333:<module>, cpu: 8.54ms, accelerator: 14.24ms, total: 22.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_283000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_283250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_283500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_283750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16238330.98sec, total: 16238330.98sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.07ms, accelerator: 0us, total: 104.07ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.88ms, accelerator: 7.95ms, total: 15.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.07ms, accelerator: 0us, total: 104.07ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16238331.00sec, total: 16238331.00sec
train2.py:307:<module>, cpu: 104.17ms, accelerator: 0us, total: 104.17ms
  iterator_ops.py:373:get_next, cpu: 104.07ms, accelerator: 0us, total: 104.07ms
train2.py:333:<module>, cpu: 8.52ms, accelerator: 14.24ms, total: 22.79ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_284000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_284250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_284500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_284750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16181354.38sec, total: 16181354.38sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.07ms, accelerator: 0us, total: 104.07ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.86ms, accelerator: 7.96ms, total: 15.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.07ms, accelerator: 0us, total: 104.07ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16181354.40sec, total: 16181354.40sec
train2.py:307:<module>, cpu: 104.17ms, accelerator: 0us, total: 104.17ms
  iterator_ops.py:373:get_next, cpu: 104.07ms, accelerator: 0us, total: 104.07ms
train2.py:333:<module>, cpu: 8.50ms, accelerator: 14.25ms, total: 22.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_285000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_285250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_285500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_285750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16124776.22sec, total: 16124776.22sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.59ms, accelerator: 0us, total: 107.59ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.83ms, accelerator: 7.96ms, total: 15.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.59ms, accelerator: 0us, total: 107.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16124776.24sec, total: 16124776.24sec
train2.py:307:<module>, cpu: 107.70ms, accelerator: 0us, total: 107.70ms
  iterator_ops.py:373:get_next, cpu: 107.59ms, accelerator: 0us, total: 107.59ms
train2.py:333:<module>, cpu: 8.47ms, accelerator: 14.25ms, total: 22.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_286000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_286250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_286500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_286750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16068592.33sec, total: 16068592.33sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.43ms, accelerator: 0us, total: 107.43ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.81ms, accelerator: 7.95ms, total: 15.77ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.43ms, accelerator: 0us, total: 107.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.08ms, accelerator: 16068592.35sec, total: 16068592.35sec
train2.py:307:<module>, cpu: 107.53ms, accelerator: 0us, total: 107.53ms
  iterator_ops.py:373:get_next, cpu: 107.43ms, accelerator: 0us, total: 107.43ms
train2.py:333:<module>, cpu: 8.45ms, accelerator: 14.25ms, total: 22.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_287000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_287250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_287500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_287750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 16012798.61sec, total: 16012798.61sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.25ms, accelerator: 0us, total: 107.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.79ms, accelerator: 7.95ms, total: 15.74ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.25ms, accelerator: 0us, total: 107.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 16012798.62sec, total: 16012798.63sec
train2.py:307:<module>, cpu: 107.35ms, accelerator: 0us, total: 107.35ms
  iterator_ops.py:373:get_next, cpu: 107.25ms, accelerator: 0us, total: 107.25ms
train2.py:333:<module>, cpu: 8.43ms, accelerator: 14.25ms, total: 22.71ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_288000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_288250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_288500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_288750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15957391.00sec, total: 15957391.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.06ms, accelerator: 0us, total: 107.06ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.76ms, accelerator: 7.94ms, total: 15.71ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.06ms, accelerator: 0us, total: 107.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15957391.02sec, total: 15957391.02sec
train2.py:307:<module>, cpu: 107.16ms, accelerator: 0us, total: 107.16ms
  iterator_ops.py:373:get_next, cpu: 107.06ms, accelerator: 0us, total: 107.06ms
train2.py:333:<module>, cpu: 8.40ms, accelerator: 14.25ms, total: 22.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_289000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_289250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_289500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_289750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15902365.51sec, total: 15902365.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.93ms, accelerator: 0us, total: 106.93ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.74ms, accelerator: 7.94ms, total: 15.69ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.93ms, accelerator: 0us, total: 106.93ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15902365.53sec, total: 15902365.53sec
train2.py:307:<module>, cpu: 107.03ms, accelerator: 0us, total: 107.03ms
  iterator_ops.py:373:get_next, cpu: 106.93ms, accelerator: 0us, total: 106.93ms
train2.py:333:<module>, cpu: 8.38ms, accelerator: 14.26ms, total: 22.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_290000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_290250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_290500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_290750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15847718.21sec, total: 15847718.21sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.83ms, accelerator: 0us, total: 106.83ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.72ms, accelerator: 7.94ms, total: 15.66ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.83ms, accelerator: 0us, total: 106.83ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15847718.23sec, total: 15847718.23sec
train2.py:307:<module>, cpu: 106.93ms, accelerator: 0us, total: 106.93ms
  iterator_ops.py:373:get_next, cpu: 106.83ms, accelerator: 0us, total: 106.83ms
train2.py:333:<module>, cpu: 8.36ms, accelerator: 14.26ms, total: 22.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_291000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_291250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_291500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_291750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15793445.20sec, total: 15793445.20sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.76ms, accelerator: 0us, total: 106.76ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.69ms, accelerator: 7.94ms, total: 15.64ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.76ms, accelerator: 0us, total: 106.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15793445.22sec, total: 15793445.22sec
train2.py:307:<module>, cpu: 106.86ms, accelerator: 0us, total: 106.86ms
  iterator_ops.py:373:get_next, cpu: 106.76ms, accelerator: 0us, total: 106.76ms
train2.py:333:<module>, cpu: 8.33ms, accelerator: 14.25ms, total: 22.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_292000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_292250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_292500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_292750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15739542.66sec, total: 15739542.66sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.68ms, accelerator: 0us, total: 106.68ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.67ms, accelerator: 7.94ms, total: 15.62ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.68ms, accelerator: 0us, total: 106.68ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15739542.68sec, total: 15739542.68sec
train2.py:307:<module>, cpu: 106.78ms, accelerator: 0us, total: 106.78ms
  iterator_ops.py:373:get_next, cpu: 106.68ms, accelerator: 0us, total: 106.68ms
train2.py:333:<module>, cpu: 8.31ms, accelerator: 14.26ms, total: 22.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_293000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_293250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_293500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_293750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15686006.80sec, total: 15686006.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.51ms, accelerator: 0us, total: 106.51ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.65ms, accelerator: 7.93ms, total: 15.59ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.51ms, accelerator: 0us, total: 106.51ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15686006.82sec, total: 15686006.82sec
train2.py:307:<module>, cpu: 106.61ms, accelerator: 0us, total: 106.61ms
  iterator_ops.py:373:get_next, cpu: 106.51ms, accelerator: 0us, total: 106.51ms
train2.py:333:<module>, cpu: 8.29ms, accelerator: 14.26ms, total: 22.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_294000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_294250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_294500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_294750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15632833.89sec, total: 15632833.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.42ms, accelerator: 0us, total: 106.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.63ms, accelerator: 7.93ms, total: 15.56ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.42ms, accelerator: 0us, total: 106.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15632833.91sec, total: 15632833.91sec
train2.py:307:<module>, cpu: 106.52ms, accelerator: 0us, total: 106.52ms
  iterator_ops.py:373:get_next, cpu: 106.42ms, accelerator: 0us, total: 106.42ms
train2.py:333:<module>, cpu: 8.27ms, accelerator: 14.25ms, total: 22.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_295000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_295250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_295500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_295750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15580020.26sec, total: 15580020.26sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.29ms, accelerator: 0us, total: 106.29ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.60ms, accelerator: 7.92ms, total: 15.54ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.29ms, accelerator: 0us, total: 106.29ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15580020.28sec, total: 15580020.29sec
train2.py:307:<module>, cpu: 106.39ms, accelerator: 0us, total: 106.39ms
  iterator_ops.py:373:get_next, cpu: 106.29ms, accelerator: 0us, total: 106.29ms
train2.py:333:<module>, cpu: 8.24ms, accelerator: 14.25ms, total: 22.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_296000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_296250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_296500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_296750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15527562.28sec, total: 15527562.28sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.16ms, accelerator: 0us, total: 106.16ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.58ms, accelerator: 7.92ms, total: 15.51ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.16ms, accelerator: 0us, total: 106.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15527562.30sec, total: 15527562.31sec
train2.py:307:<module>, cpu: 106.25ms, accelerator: 0us, total: 106.25ms
  iterator_ops.py:373:get_next, cpu: 106.16ms, accelerator: 0us, total: 106.16ms
train2.py:333:<module>, cpu: 8.22ms, accelerator: 14.26ms, total: 22.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_297000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_297250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_297500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_297750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15475456.37sec, total: 15475456.37sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 106.04ms, accelerator: 0us, total: 106.04ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.56ms, accelerator: 7.93ms, total: 15.50ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 106.04ms, accelerator: 0us, total: 106.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15475456.39sec, total: 15475456.39sec
train2.py:307:<module>, cpu: 106.14ms, accelerator: 0us, total: 106.14ms
  iterator_ops.py:373:get_next, cpu: 106.04ms, accelerator: 0us, total: 106.04ms
train2.py:333:<module>, cpu: 8.20ms, accelerator: 14.25ms, total: 22.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_298000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_298250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_298500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_298750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15423698.99sec, total: 15423698.99sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.95ms, accelerator: 0us, total: 105.95ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.54ms, accelerator: 7.93ms, total: 15.47ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.95ms, accelerator: 0us, total: 105.95ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15423699.01sec, total: 15423699.01sec
train2.py:307:<module>, cpu: 106.05ms, accelerator: 0us, total: 106.05ms
  iterator_ops.py:373:get_next, cpu: 105.95ms, accelerator: 0us, total: 105.95ms
train2.py:333:<module>, cpu: 8.18ms, accelerator: 14.25ms, total: 22.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_299000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_299250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_299500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_299750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15372286.66sec, total: 15372286.66sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.78ms, accelerator: 0us, total: 105.78ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.52ms, accelerator: 7.93ms, total: 15.45ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.78ms, accelerator: 0us, total: 105.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15372286.68sec, total: 15372286.68sec
train2.py:307:<module>, cpu: 105.88ms, accelerator: 0us, total: 105.88ms
  iterator_ops.py:373:get_next, cpu: 105.78ms, accelerator: 0us, total: 105.78ms
train2.py:333:<module>, cpu: 8.16ms, accelerator: 14.24ms, total: 22.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_300000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_300250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_300500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_300750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15321215.94sec, total: 15321215.94sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.70ms, accelerator: 0us, total: 105.70ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.50ms, accelerator: 7.92ms, total: 15.43ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.70ms, accelerator: 0us, total: 105.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15321215.96sec, total: 15321215.96sec
train2.py:307:<module>, cpu: 105.80ms, accelerator: 0us, total: 105.80ms
  iterator_ops.py:373:get_next, cpu: 105.70ms, accelerator: 0us, total: 105.70ms
train2.py:333:<module>, cpu: 8.14ms, accelerator: 14.24ms, total: 22.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_301000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_301250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_301500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_301750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15270483.44sec, total: 15270483.44sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.61ms, accelerator: 0us, total: 105.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.47ms, accelerator: 7.92ms, total: 15.40ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.61ms, accelerator: 0us, total: 105.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15270483.46sec, total: 15270483.46sec
train2.py:307:<module>, cpu: 105.70ms, accelerator: 0us, total: 105.70ms
  iterator_ops.py:373:get_next, cpu: 105.61ms, accelerator: 0us, total: 105.61ms
train2.py:333:<module>, cpu: 8.12ms, accelerator: 14.24ms, total: 22.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_302000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_302250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_302500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_302750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15220085.80sec, total: 15220085.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.52ms, accelerator: 0us, total: 105.52ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.45ms, accelerator: 7.92ms, total: 15.38ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.52ms, accelerator: 0us, total: 105.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15220085.82sec, total: 15220085.83sec
train2.py:307:<module>, cpu: 105.62ms, accelerator: 0us, total: 105.62ms
  iterator_ops.py:373:get_next, cpu: 105.52ms, accelerator: 0us, total: 105.52ms
train2.py:333:<module>, cpu: 8.10ms, accelerator: 14.23ms, total: 22.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_303000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_303250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_303500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_303750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15170019.73sec, total: 15170019.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.42ms, accelerator: 0us, total: 105.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.43ms, accelerator: 7.92ms, total: 15.36ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.42ms, accelerator: 0us, total: 105.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15170019.75sec, total: 15170019.75sec
train2.py:307:<module>, cpu: 105.52ms, accelerator: 0us, total: 105.52ms
  iterator_ops.py:373:get_next, cpu: 105.42ms, accelerator: 0us, total: 105.42ms
train2.py:333:<module>, cpu: 8.07ms, accelerator: 14.24ms, total: 22.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_304000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_304250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_304500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_304750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15120281.96sec, total: 15120281.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.31ms, accelerator: 0us, total: 105.31ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.41ms, accelerator: 7.91ms, total: 15.33ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.31ms, accelerator: 0us, total: 105.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15120281.98sec, total: 15120281.98sec
train2.py:307:<module>, cpu: 105.41ms, accelerator: 0us, total: 105.41ms
  iterator_ops.py:373:get_next, cpu: 105.31ms, accelerator: 0us, total: 105.31ms
train2.py:333:<module>, cpu: 8.05ms, accelerator: 14.23ms, total: 22.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_305000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_305250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_305500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_305750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15070869.28sec, total: 15070869.28sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.21ms, accelerator: 0us, total: 105.21ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.39ms, accelerator: 7.91ms, total: 15.31ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.21ms, accelerator: 0us, total: 105.21ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.07ms, accelerator: 15070869.29sec, total: 15070869.30sec
train2.py:307:<module>, cpu: 105.31ms, accelerator: 0us, total: 105.31ms
  iterator_ops.py:373:get_next, cpu: 105.21ms, accelerator: 0us, total: 105.21ms
train2.py:333:<module>, cpu: 8.03ms, accelerator: 14.24ms, total: 22.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_306000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_306250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_306500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_306750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 15021778.50sec, total: 15021778.50sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.11ms, accelerator: 0us, total: 105.11ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.37ms, accelerator: 7.91ms, total: 15.28ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.11ms, accelerator: 0us, total: 105.11ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 15021778.52sec, total: 15021778.52sec
train2.py:307:<module>, cpu: 105.20ms, accelerator: 0us, total: 105.20ms
  iterator_ops.py:373:get_next, cpu: 105.11ms, accelerator: 0us, total: 105.11ms
train2.py:333:<module>, cpu: 8.02ms, accelerator: 14.23ms, total: 22.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_307000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_307250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_307500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_307750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14973006.49sec, total: 14973006.49sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 105.05ms, accelerator: 0us, total: 105.05ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.35ms, accelerator: 7.91ms, total: 15.26ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 105.05ms, accelerator: 0us, total: 105.05ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14973006.51sec, total: 14973006.51sec
train2.py:307:<module>, cpu: 105.14ms, accelerator: 0us, total: 105.14ms
  iterator_ops.py:373:get_next, cpu: 105.05ms, accelerator: 0us, total: 105.05ms
train2.py:333:<module>, cpu: 7.99ms, accelerator: 14.23ms, total: 22.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_308000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_308250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_308500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_308750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14924550.16sec, total: 14924550.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.91ms, accelerator: 0us, total: 104.91ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.33ms, accelerator: 7.90ms, total: 15.23ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.91ms, accelerator: 0us, total: 104.91ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14924550.18sec, total: 14924550.18sec
train2.py:307:<module>, cpu: 105.00ms, accelerator: 0us, total: 105.00ms
  iterator_ops.py:373:get_next, cpu: 104.91ms, accelerator: 0us, total: 104.91ms
train2.py:333:<module>, cpu: 7.97ms, accelerator: 14.24ms, total: 22.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_309000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_309250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_309500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_309750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14876406.45sec, total: 14876406.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.80ms, accelerator: 0us, total: 104.80ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.31ms, accelerator: 7.89ms, total: 15.21ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.80ms, accelerator: 0us, total: 104.80ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14876406.47sec, total: 14876406.47sec
train2.py:307:<module>, cpu: 104.90ms, accelerator: 0us, total: 104.90ms
  iterator_ops.py:373:get_next, cpu: 104.80ms, accelerator: 0us, total: 104.80ms
train2.py:333:<module>, cpu: 7.95ms, accelerator: 14.22ms, total: 22.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_310000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_310250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_310500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_310750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14828572.34sec, total: 14828572.34sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.77ms, accelerator: 0us, total: 104.77ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.29ms, accelerator: 7.90ms, total: 15.20ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.77ms, accelerator: 0us, total: 104.77ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14828572.36sec, total: 14828572.36sec
train2.py:307:<module>, cpu: 104.87ms, accelerator: 0us, total: 104.87ms
  iterator_ops.py:373:get_next, cpu: 104.77ms, accelerator: 0us, total: 104.77ms
train2.py:333:<module>, cpu: 7.93ms, accelerator: 14.23ms, total: 22.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_311000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_311250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_311500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_311750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14781044.87sec, total: 14781044.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.61ms, accelerator: 0us, total: 104.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.27ms, accelerator: 7.90ms, total: 15.18ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.61ms, accelerator: 0us, total: 104.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14781044.89sec, total: 14781044.89sec
train2.py:307:<module>, cpu: 104.70ms, accelerator: 0us, total: 104.70ms
  iterator_ops.py:373:get_next, cpu: 104.61ms, accelerator: 0us, total: 104.61ms
train2.py:333:<module>, cpu: 7.91ms, accelerator: 14.23ms, total: 22.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_312000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_312250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_312500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_312750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14733821.08sec, total: 14733821.08sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.45ms, accelerator: 0us, total: 104.45ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.25ms, accelerator: 7.90ms, total: 15.16ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.45ms, accelerator: 0us, total: 104.45ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14733821.10sec, total: 14733821.10sec
train2.py:307:<module>, cpu: 104.54ms, accelerator: 0us, total: 104.54ms
  iterator_ops.py:373:get_next, cpu: 104.45ms, accelerator: 0us, total: 104.45ms
train2.py:333:<module>, cpu: 7.89ms, accelerator: 14.22ms, total: 22.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_313000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_313250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_313500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_313750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14686898.08sec, total: 14686898.08sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.33ms, accelerator: 0us, total: 104.33ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.23ms, accelerator: 7.90ms, total: 15.14ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.33ms, accelerator: 0us, total: 104.33ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14686898.10sec, total: 14686898.11sec
train2.py:307:<module>, cpu: 104.42ms, accelerator: 0us, total: 104.42ms
  iterator_ops.py:373:get_next, cpu: 104.33ms, accelerator: 0us, total: 104.33ms
train2.py:333:<module>, cpu: 7.87ms, accelerator: 14.23ms, total: 22.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_314000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_314250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_314500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_314750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14640273.01sec, total: 14640273.01sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.24ms, accelerator: 0us, total: 104.24ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.21ms, accelerator: 7.90ms, total: 15.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.24ms, accelerator: 0us, total: 104.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14640273.03sec, total: 14640273.03sec
train2.py:307:<module>, cpu: 104.33ms, accelerator: 0us, total: 104.33ms
  iterator_ops.py:373:get_next, cpu: 104.24ms, accelerator: 0us, total: 104.24ms
train2.py:333:<module>, cpu: 7.85ms, accelerator: 14.23ms, total: 22.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_315000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_315250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_315500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_315750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14593943.03sec, total: 14593943.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.27ms, accelerator: 0us, total: 104.27ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.19ms, accelerator: 7.91ms, total: 15.11ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.27ms, accelerator: 0us, total: 104.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14593943.05sec, total: 14593943.06sec
train2.py:307:<module>, cpu: 104.37ms, accelerator: 0us, total: 104.37ms
  iterator_ops.py:373:get_next, cpu: 104.27ms, accelerator: 0us, total: 104.27ms
train2.py:333:<module>, cpu: 7.83ms, accelerator: 14.24ms, total: 22.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_316000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_316250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_316500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_316750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14547905.36sec, total: 14547905.36sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.14ms, accelerator: 0us, total: 104.14ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.17ms, accelerator: 7.91ms, total: 15.09ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.14ms, accelerator: 0us, total: 104.14ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14547905.38sec, total: 14547905.38sec
train2.py:307:<module>, cpu: 104.23ms, accelerator: 0us, total: 104.23ms
  iterator_ops.py:373:get_next, cpu: 104.14ms, accelerator: 0us, total: 104.14ms
train2.py:333:<module>, cpu: 7.81ms, accelerator: 14.22ms, total: 22.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_317000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_317250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_317500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_317750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14502157.23sec, total: 14502157.23sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.98ms, accelerator: 0us, total: 103.98ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.15ms, accelerator: 7.90ms, total: 15.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.98ms, accelerator: 0us, total: 103.98ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14502157.25sec, total: 14502157.25sec
train2.py:307:<module>, cpu: 104.08ms, accelerator: 0us, total: 104.08ms
  iterator_ops.py:373:get_next, cpu: 103.98ms, accelerator: 0us, total: 103.98ms
train2.py:333:<module>, cpu: 7.79ms, accelerator: 14.23ms, total: 22.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_318000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_318250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_318500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_318750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14456695.92sec, total: 14456695.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.84ms, accelerator: 0us, total: 103.84ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.13ms, accelerator: 7.90ms, total: 15.04ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.84ms, accelerator: 0us, total: 103.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14456695.94sec, total: 14456695.94sec
train2.py:307:<module>, cpu: 103.94ms, accelerator: 0us, total: 103.94ms
  iterator_ops.py:373:get_next, cpu: 103.84ms, accelerator: 0us, total: 103.84ms
train2.py:333:<module>, cpu: 7.77ms, accelerator: 14.22ms, total: 22.02ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_319000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_319250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_319500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_319750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14411518.74sec, total: 14411518.75sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.76ms, accelerator: 0us, total: 103.76ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.11ms, accelerator: 7.90ms, total: 15.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.76ms, accelerator: 0us, total: 103.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14411518.76sec, total: 14411518.77sec
train2.py:307:<module>, cpu: 103.85ms, accelerator: 0us, total: 103.85ms
  iterator_ops.py:373:get_next, cpu: 103.76ms, accelerator: 0us, total: 103.76ms
train2.py:333:<module>, cpu: 7.75ms, accelerator: 14.23ms, total: 22.01ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_320000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_320250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_320500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_320750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14366623.05sec, total: 14366623.05sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.61ms, accelerator: 0us, total: 103.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.09ms, accelerator: 7.90ms, total: 15.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.61ms, accelerator: 0us, total: 103.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14366623.07sec, total: 14366623.07sec
train2.py:307:<module>, cpu: 103.70ms, accelerator: 0us, total: 103.70ms
  iterator_ops.py:373:get_next, cpu: 103.61ms, accelerator: 0us, total: 103.61ms
train2.py:333:<module>, cpu: 7.74ms, accelerator: 14.24ms, total: 22.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_321000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_321250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_321500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_321750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14322006.21sec, total: 14322006.21sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.46ms, accelerator: 0us, total: 103.46ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.08ms, accelerator: 7.89ms, total: 14.97ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.46ms, accelerator: 0us, total: 103.46ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14322006.23sec, total: 14322006.23sec
train2.py:307:<module>, cpu: 103.55ms, accelerator: 0us, total: 103.55ms
  iterator_ops.py:373:get_next, cpu: 103.46ms, accelerator: 0us, total: 103.46ms
train2.py:333:<module>, cpu: 7.72ms, accelerator: 14.22ms, total: 21.96ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_322000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_322250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_322500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_322750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14277665.63sec, total: 14277665.63sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.33ms, accelerator: 0us, total: 103.33ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.06ms, accelerator: 7.89ms, total: 14.96ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.33ms, accelerator: 0us, total: 103.33ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14277665.65sec, total: 14277665.65sec
train2.py:307:<module>, cpu: 103.42ms, accelerator: 0us, total: 103.42ms
  iterator_ops.py:373:get_next, cpu: 103.33ms, accelerator: 0us, total: 103.33ms
train2.py:333:<module>, cpu: 7.70ms, accelerator: 14.21ms, total: 21.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_323000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_323250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_323500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_323750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14233598.76sec, total: 14233598.76sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.25ms, accelerator: 0us, total: 103.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.04ms, accelerator: 7.89ms, total: 14.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.25ms, accelerator: 0us, total: 103.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14233598.78sec, total: 14233598.78sec
train2.py:307:<module>, cpu: 103.34ms, accelerator: 0us, total: 103.34ms
  iterator_ops.py:373:get_next, cpu: 103.25ms, accelerator: 0us, total: 103.25ms
train2.py:333:<module>, cpu: 7.68ms, accelerator: 14.21ms, total: 21.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_324000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_324250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_324500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_324750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14189803.07sec, total: 14189803.07sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.17ms, accelerator: 0us, total: 103.17ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.02ms, accelerator: 7.89ms, total: 14.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.17ms, accelerator: 0us, total: 103.17ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14189803.09sec, total: 14189803.09sec
train2.py:307:<module>, cpu: 103.26ms, accelerator: 0us, total: 103.26ms
  iterator_ops.py:373:get_next, cpu: 103.17ms, accelerator: 0us, total: 103.17ms
train2.py:333:<module>, cpu: 7.66ms, accelerator: 14.20ms, total: 21.89ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_325000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_325250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_325500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_325750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14146276.07sec, total: 14146276.07sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.04ms, accelerator: 0us, total: 103.04ms (0.00%)
top 3 operation type: Conv2D, cpu: 7.00ms, accelerator: 7.89ms, total: 14.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.04ms, accelerator: 0us, total: 103.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14146276.09sec, total: 14146276.09sec
train2.py:307:<module>, cpu: 103.13ms, accelerator: 0us, total: 103.13ms
  iterator_ops.py:373:get_next, cpu: 103.04ms, accelerator: 0us, total: 103.04ms
train2.py:333:<module>, cpu: 7.64ms, accelerator: 14.19ms, total: 21.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_326000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_326250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_326500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_326750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14103015.29sec, total: 14103015.29sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.99ms, accelerator: 0us, total: 102.99ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.99ms, accelerator: 7.89ms, total: 14.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.99ms, accelerator: 0us, total: 102.99ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14103015.30sec, total: 14103015.31sec
train2.py:307:<module>, cpu: 103.08ms, accelerator: 0us, total: 103.08ms
  iterator_ops.py:373:get_next, cpu: 102.99ms, accelerator: 0us, total: 102.99ms
train2.py:333:<module>, cpu: 7.63ms, accelerator: 14.20ms, total: 21.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_327000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_327250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_327500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_327750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14060018.29sec, total: 14060018.29sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.88ms, accelerator: 0us, total: 102.88ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.97ms, accelerator: 7.89ms, total: 14.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.88ms, accelerator: 0us, total: 102.88ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14060018.31sec, total: 14060018.31sec
train2.py:307:<module>, cpu: 102.97ms, accelerator: 0us, total: 102.97ms
  iterator_ops.py:373:get_next, cpu: 102.88ms, accelerator: 0us, total: 102.88ms
train2.py:333:<module>, cpu: 7.61ms, accelerator: 14.21ms, total: 21.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_328000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_328250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_328500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_328750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 14017282.67sec, total: 14017282.67sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.77ms, accelerator: 0us, total: 102.77ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.95ms, accelerator: 7.89ms, total: 14.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.77ms, accelerator: 0us, total: 102.77ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 14017282.69sec, total: 14017282.69sec
train2.py:307:<module>, cpu: 102.86ms, accelerator: 0us, total: 102.86ms
  iterator_ops.py:373:get_next, cpu: 102.77ms, accelerator: 0us, total: 102.77ms
train2.py:333:<module>, cpu: 7.59ms, accelerator: 14.20ms, total: 21.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_329000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_329250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_329500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_329750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13974806.06sec, total: 13974806.06sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.61ms, accelerator: 0us, total: 102.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.93ms, accelerator: 7.89ms, total: 14.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.61ms, accelerator: 0us, total: 102.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.06ms, accelerator: 13974806.07sec, total: 13974806.08sec
train2.py:307:<module>, cpu: 102.70ms, accelerator: 0us, total: 102.70ms
  iterator_ops.py:373:get_next, cpu: 102.61ms, accelerator: 0us, total: 102.61ms
train2.py:333:<module>, cpu: 7.57ms, accelerator: 14.20ms, total: 21.79ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_330000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_330250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_330500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_330750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13932586.10sec, total: 13932586.10sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.55ms, accelerator: 0us, total: 102.55ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.91ms, accelerator: 7.88ms, total: 14.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.55ms, accelerator: 0us, total: 102.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13932586.12sec, total: 13932586.12sec
train2.py:307:<module>, cpu: 102.64ms, accelerator: 0us, total: 102.64ms
  iterator_ops.py:373:get_next, cpu: 102.55ms, accelerator: 0us, total: 102.55ms
train2.py:333:<module>, cpu: 7.55ms, accelerator: 14.20ms, total: 21.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_331000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_331250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_331500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_331750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13890620.48sec, total: 13890620.48sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.39ms, accelerator: 0us, total: 102.39ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.90ms, accelerator: 7.88ms, total: 14.78ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.39ms, accelerator: 0us, total: 102.39ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13890620.50sec, total: 13890620.50sec
train2.py:307:<module>, cpu: 102.48ms, accelerator: 0us, total: 102.48ms
  iterator_ops.py:373:get_next, cpu: 102.39ms, accelerator: 0us, total: 102.39ms
train2.py:333:<module>, cpu: 7.54ms, accelerator: 14.20ms, total: 21.76ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_332000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_332250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_332500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_332750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13848906.90sec, total: 13848906.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.25ms, accelerator: 0us, total: 102.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.88ms, accelerator: 7.88ms, total: 14.77ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.25ms, accelerator: 0us, total: 102.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13848906.92sec, total: 13848906.92sec
train2.py:307:<module>, cpu: 102.34ms, accelerator: 0us, total: 102.34ms
  iterator_ops.py:373:get_next, cpu: 102.25ms, accelerator: 0us, total: 102.25ms
train2.py:333:<module>, cpu: 7.52ms, accelerator: 14.21ms, total: 21.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_333000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_333250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_333500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_333750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13807443.11sec, total: 13807443.11sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.16ms, accelerator: 0us, total: 102.16ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.86ms, accelerator: 7.89ms, total: 14.76ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.16ms, accelerator: 0us, total: 102.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13807443.13sec, total: 13807443.13sec
train2.py:307:<module>, cpu: 102.24ms, accelerator: 0us, total: 102.24ms
  iterator_ops.py:373:get_next, cpu: 102.16ms, accelerator: 0us, total: 102.16ms
train2.py:333:<module>, cpu: 7.50ms, accelerator: 14.21ms, total: 21.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_334000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_334250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_334500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_334750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13766226.86sec, total: 13766226.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.01ms, accelerator: 0us, total: 102.01ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.84ms, accelerator: 7.89ms, total: 14.74ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.01ms, accelerator: 0us, total: 102.01ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13766226.88sec, total: 13766226.88sec
train2.py:307:<module>, cpu: 102.10ms, accelerator: 0us, total: 102.10ms
  iterator_ops.py:373:get_next, cpu: 102.01ms, accelerator: 0us, total: 102.01ms
train2.py:333:<module>, cpu: 7.48ms, accelerator: 14.21ms, total: 21.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_335000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_335250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_335500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_335750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13725255.95sec, total: 13725255.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.99ms, accelerator: 0us, total: 101.99ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.83ms, accelerator: 7.90ms, total: 14.73ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.99ms, accelerator: 0us, total: 101.99ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13725255.97sec, total: 13725255.97sec
train2.py:307:<module>, cpu: 102.08ms, accelerator: 0us, total: 102.08ms
  iterator_ops.py:373:get_next, cpu: 101.99ms, accelerator: 0us, total: 101.99ms
train2.py:333:<module>, cpu: 7.46ms, accelerator: 14.21ms, total: 21.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_336000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_336250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_336500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_336750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13684528.19sec, total: 13684528.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.92ms, accelerator: 0us, total: 101.92ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.81ms, accelerator: 7.90ms, total: 14.72ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.92ms, accelerator: 0us, total: 101.92ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13684528.20sec, total: 13684528.21sec
train2.py:307:<module>, cpu: 102.01ms, accelerator: 0us, total: 102.01ms
  iterator_ops.py:373:get_next, cpu: 101.92ms, accelerator: 0us, total: 101.92ms
train2.py:333:<module>, cpu: 7.45ms, accelerator: 14.21ms, total: 21.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_337000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_337250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_337500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_337750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13644041.42sec, total: 13644041.42sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.82ms, accelerator: 0us, total: 102.82ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.79ms, accelerator: 7.89ms, total: 14.69ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.82ms, accelerator: 0us, total: 102.82ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13644041.43sec, total: 13644041.44sec
train2.py:307:<module>, cpu: 102.91ms, accelerator: 0us, total: 102.91ms
  iterator_ops.py:373:get_next, cpu: 102.82ms, accelerator: 0us, total: 102.82ms
train2.py:333:<module>, cpu: 7.43ms, accelerator: 14.21ms, total: 21.67ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_338000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_338250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_338500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_338750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13603793.51sec, total: 13603793.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.73ms, accelerator: 0us, total: 102.73ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.77ms, accelerator: 7.90ms, total: 14.68ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.73ms, accelerator: 0us, total: 102.73ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13603793.52sec, total: 13603793.53sec
train2.py:307:<module>, cpu: 102.81ms, accelerator: 0us, total: 102.81ms
  iterator_ops.py:373:get_next, cpu: 102.73ms, accelerator: 0us, total: 102.73ms
train2.py:333:<module>, cpu: 7.41ms, accelerator: 14.21ms, total: 21.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_339000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_339250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_339500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_339750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13563782.35sec, total: 13563782.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.58ms, accelerator: 0us, total: 102.58ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.76ms, accelerator: 7.89ms, total: 14.66ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.58ms, accelerator: 0us, total: 102.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13563782.37sec, total: 13563782.37sec
train2.py:307:<module>, cpu: 102.67ms, accelerator: 0us, total: 102.67ms
  iterator_ops.py:373:get_next, cpu: 102.58ms, accelerator: 0us, total: 102.58ms
train2.py:333:<module>, cpu: 7.40ms, accelerator: 14.21ms, total: 21.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_340000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_340250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_340500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_340750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13524005.86sec, total: 13524005.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.45ms, accelerator: 0us, total: 102.45ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.74ms, accelerator: 7.90ms, total: 14.64ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.45ms, accelerator: 0us, total: 102.45ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13524005.88sec, total: 13524005.88sec
train2.py:307:<module>, cpu: 102.53ms, accelerator: 0us, total: 102.53ms
  iterator_ops.py:373:get_next, cpu: 102.45ms, accelerator: 0us, total: 102.45ms
train2.py:333:<module>, cpu: 7.38ms, accelerator: 14.21ms, total: 21.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_341000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_341250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_341500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_341750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13484461.98sec, total: 13484461.98sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.32ms, accelerator: 0us, total: 102.32ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.72ms, accelerator: 7.90ms, total: 14.63ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.32ms, accelerator: 0us, total: 102.32ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13484462.00sec, total: 13484462.01sec
train2.py:307:<module>, cpu: 102.41ms, accelerator: 0us, total: 102.41ms
  iterator_ops.py:373:get_next, cpu: 102.32ms, accelerator: 0us, total: 102.32ms
train2.py:333:<module>, cpu: 7.36ms, accelerator: 14.21ms, total: 21.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_342000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_342250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_342500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_342750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13445148.68sec, total: 13445148.68sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.18ms, accelerator: 0us, total: 102.18ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.71ms, accelerator: 7.89ms, total: 14.61ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.18ms, accelerator: 0us, total: 102.18ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13445148.70sec, total: 13445148.71sec
train2.py:307:<module>, cpu: 102.27ms, accelerator: 0us, total: 102.27ms
  iterator_ops.py:373:get_next, cpu: 102.18ms, accelerator: 0us, total: 102.18ms
train2.py:333:<module>, cpu: 7.34ms, accelerator: 14.22ms, total: 21.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_343000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_343250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_343500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_343750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13406063.95sec, total: 13406063.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.07ms, accelerator: 0us, total: 102.07ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.69ms, accelerator: 7.89ms, total: 14.59ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.07ms, accelerator: 0us, total: 102.07ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13406063.97sec, total: 13406063.97sec
train2.py:307:<module>, cpu: 102.15ms, accelerator: 0us, total: 102.15ms
  iterator_ops.py:373:get_next, cpu: 102.07ms, accelerator: 0us, total: 102.07ms
train2.py:333:<module>, cpu: 7.33ms, accelerator: 14.21ms, total: 21.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_344000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_344250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_344500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_344750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 13367205.79sec, total: 13367205.79sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.02ms, accelerator: 0us, total: 102.02ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.67ms, accelerator: 7.89ms, total: 14.57ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.02ms, accelerator: 0us, total: 102.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.05ms, accelerator: 13367205.81sec, total: 13367205.81sec
train2.py:307:<module>, cpu: 102.10ms, accelerator: 0us, total: 102.10ms
  iterator_ops.py:373:get_next, cpu: 102.02ms, accelerator: 0us, total: 102.02ms
train2.py:333:<module>, cpu: 7.31ms, accelerator: 14.20ms, total: 21.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_345000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_345250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_345500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_345750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 13328572.25sec, total: 13328572.25sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.88ms, accelerator: 0us, total: 101.88ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.66ms, accelerator: 7.89ms, total: 14.56ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.88ms, accelerator: 0us, total: 101.88ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 13328572.27sec, total: 13328572.27sec
train2.py:307:<module>, cpu: 101.97ms, accelerator: 0us, total: 101.97ms
  iterator_ops.py:373:get_next, cpu: 101.88ms, accelerator: 0us, total: 101.88ms
train2.py:333:<module>, cpu: 7.30ms, accelerator: 14.21ms, total: 21.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_346000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_346250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_346500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_346750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 13290161.38sec, total: 13290161.38sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.73ms, accelerator: 0us, total: 101.73ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.64ms, accelerator: 7.89ms, total: 14.54ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.73ms, accelerator: 0us, total: 101.73ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 13290161.40sec, total: 13290161.40sec
train2.py:307:<module>, cpu: 101.82ms, accelerator: 0us, total: 101.82ms
  iterator_ops.py:373:get_next, cpu: 101.73ms, accelerator: 0us, total: 101.73ms
train2.py:333:<module>, cpu: 7.28ms, accelerator: 14.20ms, total: 21.50ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_347000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_347250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_347500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_347750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 13251971.26sec, total: 13251971.26sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.61ms, accelerator: 0us, total: 101.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.62ms, accelerator: 7.89ms, total: 14.52ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.61ms, accelerator: 0us, total: 101.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 13251971.28sec, total: 13251971.28sec
train2.py:307:<module>, cpu: 101.70ms, accelerator: 0us, total: 101.70ms
  iterator_ops.py:373:get_next, cpu: 101.61ms, accelerator: 0us, total: 101.61ms
train2.py:333:<module>, cpu: 7.26ms, accelerator: 14.20ms, total: 21.49ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_348000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_348250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_348500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_348750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 13214000.00sec, total: 13214000.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.49ms, accelerator: 0us, total: 101.49ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.61ms, accelerator: 7.89ms, total: 14.51ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.49ms, accelerator: 0us, total: 101.49ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 13214000.01sec, total: 13214000.02sec
train2.py:307:<module>, cpu: 101.57ms, accelerator: 0us, total: 101.57ms
  iterator_ops.py:373:get_next, cpu: 101.49ms, accelerator: 0us, total: 101.49ms
train2.py:333:<module>, cpu: 7.25ms, accelerator: 14.19ms, total: 21.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.60
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_349000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_349250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_349500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_349750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 13176245.71sec, total: 13176245.71sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.42ms, accelerator: 0us, total: 101.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.59ms, accelerator: 7.88ms, total: 14.49ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.42ms, accelerator: 0us, total: 101.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 13176245.73sec, total: 13176245.73sec
train2.py:307:<module>, cpu: 101.50ms, accelerator: 0us, total: 101.50ms
  iterator_ops.py:373:get_next, cpu: 101.42ms, accelerator: 0us, total: 101.42ms
train2.py:333:<module>, cpu: 7.23ms, accelerator: 14.20ms, total: 21.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_350000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_350250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_350500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_350750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 13138706.55sec, total: 13138706.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.35ms, accelerator: 0us, total: 101.35ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.58ms, accelerator: 7.89ms, total: 14.47ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.35ms, accelerator: 0us, total: 101.35ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 13138706.57sec, total: 13138706.57sec
train2.py:307:<module>, cpu: 101.44ms, accelerator: 0us, total: 101.44ms
  iterator_ops.py:373:get_next, cpu: 101.35ms, accelerator: 0us, total: 101.35ms
train2.py:333:<module>, cpu: 7.21ms, accelerator: 14.20ms, total: 21.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_351000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_351250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_351500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_351750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 13101380.68sec, total: 13101380.68sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.24ms, accelerator: 0us, total: 101.24ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.56ms, accelerator: 7.90ms, total: 14.47ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.24ms, accelerator: 0us, total: 101.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 13101380.70sec, total: 13101380.70sec
train2.py:307:<module>, cpu: 101.32ms, accelerator: 0us, total: 101.32ms
  iterator_ops.py:373:get_next, cpu: 101.24ms, accelerator: 0us, total: 101.24ms
train2.py:333:<module>, cpu: 7.20ms, accelerator: 14.21ms, total: 21.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_352000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_352250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_352500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_352750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 13064266.28sec, total: 13064266.28sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.14ms, accelerator: 0us, total: 101.14ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.54ms, accelerator: 7.89ms, total: 14.45ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.14ms, accelerator: 0us, total: 101.14ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 13064266.30sec, total: 13064266.31sec
train2.py:307:<module>, cpu: 101.22ms, accelerator: 0us, total: 101.22ms
  iterator_ops.py:373:get_next, cpu: 101.14ms, accelerator: 0us, total: 101.14ms
train2.py:333:<module>, cpu: 7.18ms, accelerator: 14.20ms, total: 21.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_353000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_353250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_353500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_353750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 13027361.58sec, total: 13027361.58sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 101.03ms, accelerator: 0us, total: 101.03ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.53ms, accelerator: 7.89ms, total: 14.43ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 101.03ms, accelerator: 0us, total: 101.03ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 13027361.60sec, total: 13027361.60sec
train2.py:307:<module>, cpu: 101.11ms, accelerator: 0us, total: 101.11ms
  iterator_ops.py:373:get_next, cpu: 101.03ms, accelerator: 0us, total: 101.03ms
train2.py:333:<module>, cpu: 7.17ms, accelerator: 14.20ms, total: 21.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_354000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_354250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_354500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_354750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12990664.78sec, total: 12990664.78sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.86ms, accelerator: 0us, total: 100.86ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.51ms, accelerator: 7.89ms, total: 14.41ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.86ms, accelerator: 0us, total: 100.86ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 12990664.80sec, total: 12990664.81sec
train2.py:307:<module>, cpu: 100.95ms, accelerator: 0us, total: 100.95ms
  iterator_ops.py:373:get_next, cpu: 100.86ms, accelerator: 0us, total: 100.86ms
train2.py:333:<module>, cpu: 7.15ms, accelerator: 14.19ms, total: 21.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_355000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_355250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_355500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_355750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12954174.15sec, total: 12954174.15sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.79ms, accelerator: 0us, total: 100.79ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.50ms, accelerator: 7.88ms, total: 14.39ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.79ms, accelerator: 0us, total: 100.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 12954174.17sec, total: 12954174.18sec
train2.py:307:<module>, cpu: 100.87ms, accelerator: 0us, total: 100.87ms
  iterator_ops.py:373:get_next, cpu: 100.79ms, accelerator: 0us, total: 100.79ms
train2.py:333:<module>, cpu: 7.14ms, accelerator: 14.20ms, total: 21.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_356000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_356250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_356500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_356750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12917887.95sec, total: 12917887.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.72ms, accelerator: 0us, total: 100.72ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.49ms, accelerator: 7.89ms, total: 14.38ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.72ms, accelerator: 0us, total: 100.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 12917887.97sec, total: 12917887.97sec
train2.py:307:<module>, cpu: 100.81ms, accelerator: 0us, total: 100.81ms
  iterator_ops.py:373:get_next, cpu: 100.72ms, accelerator: 0us, total: 100.72ms
train2.py:333:<module>, cpu: 7.12ms, accelerator: 14.20ms, total: 21.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_357000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_357250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_357500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_357750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12881804.46sec, total: 12881804.47sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.67ms, accelerator: 0us, total: 100.67ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.47ms, accelerator: 7.88ms, total: 14.36ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.67ms, accelerator: 0us, total: 100.67ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 12881804.48sec, total: 12881804.49sec
train2.py:307:<module>, cpu: 100.75ms, accelerator: 0us, total: 100.75ms
  iterator_ops.py:373:get_next, cpu: 100.67ms, accelerator: 0us, total: 100.67ms
train2.py:333:<module>, cpu: 7.11ms, accelerator: 14.20ms, total: 21.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_358000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_358250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_358500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_358750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12845922.00sec, total: 12845922.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.55ms, accelerator: 0us, total: 100.55ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.45ms, accelerator: 7.88ms, total: 14.35ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.55ms, accelerator: 0us, total: 100.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 12845922.02sec, total: 12845922.02sec
train2.py:307:<module>, cpu: 100.63ms, accelerator: 0us, total: 100.63ms
  iterator_ops.py:373:get_next, cpu: 100.55ms, accelerator: 0us, total: 100.55ms
train2.py:333:<module>, cpu: 7.09ms, accelerator: 14.20ms, total: 21.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_359000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_359250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_359500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_359750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12810238.88sec, total: 12810238.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.44ms, accelerator: 0us, total: 100.44ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.44ms, accelerator: 7.88ms, total: 14.33ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.44ms, accelerator: 0us, total: 100.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 12810238.90sec, total: 12810238.91sec
train2.py:307:<module>, cpu: 100.53ms, accelerator: 0us, total: 100.53ms
  iterator_ops.py:373:get_next, cpu: 100.44ms, accelerator: 0us, total: 100.44ms
train2.py:333:<module>, cpu: 7.08ms, accelerator: 14.19ms, total: 21.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_360000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_360250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_360500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_360750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12774753.46sec, total: 12774753.46sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.39ms, accelerator: 0us, total: 100.39ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.42ms, accelerator: 7.88ms, total: 14.32ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.39ms, accelerator: 0us, total: 100.39ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.04ms, accelerator: 12774753.48sec, total: 12774753.48sec
train2.py:307:<module>, cpu: 100.47ms, accelerator: 0us, total: 100.47ms
  iterator_ops.py:373:get_next, cpu: 100.39ms, accelerator: 0us, total: 100.39ms
train2.py:333:<module>, cpu: 7.06ms, accelerator: 14.19ms, total: 21.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_361000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_361250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_361500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_361750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12739464.08sec, total: 12739464.08sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.28ms, accelerator: 0us, total: 100.28ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.41ms, accelerator: 7.89ms, total: 14.31ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.28ms, accelerator: 0us, total: 100.28ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12739464.10sec, total: 12739464.11sec
train2.py:307:<module>, cpu: 100.36ms, accelerator: 0us, total: 100.36ms
  iterator_ops.py:373:get_next, cpu: 100.28ms, accelerator: 0us, total: 100.28ms
train2.py:333:<module>, cpu: 7.04ms, accelerator: 14.20ms, total: 21.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_362000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_362250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_362500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_362750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12704369.14sec, total: 12704369.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.14ms, accelerator: 0us, total: 100.14ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.39ms, accelerator: 7.89ms, total: 14.29ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.14ms, accelerator: 0us, total: 100.14ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12704369.16sec, total: 12704369.16sec
train2.py:307:<module>, cpu: 100.22ms, accelerator: 0us, total: 100.22ms
  iterator_ops.py:373:get_next, cpu: 100.14ms, accelerator: 0us, total: 100.14ms
train2.py:333:<module>, cpu: 7.03ms, accelerator: 14.20ms, total: 21.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_363000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_363250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_363500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_363750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12669467.03sec, total: 12669467.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.06ms, accelerator: 0us, total: 100.06ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.38ms, accelerator: 7.89ms, total: 14.28ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.06ms, accelerator: 0us, total: 100.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12669467.05sec, total: 12669467.05sec
train2.py:307:<module>, cpu: 100.14ms, accelerator: 0us, total: 100.14ms
  iterator_ops.py:373:get_next, cpu: 100.06ms, accelerator: 0us, total: 100.06ms
train2.py:333:<module>, cpu: 7.02ms, accelerator: 14.20ms, total: 21.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_364000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_364250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_364500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_364750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12634756.16sec, total: 12634756.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.96ms, accelerator: 0us, total: 99.96ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.37ms, accelerator: 7.89ms, total: 14.27ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.96ms, accelerator: 0us, total: 99.96ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12634756.18sec, total: 12634756.18sec
train2.py:307:<module>, cpu: 100.04ms, accelerator: 0us, total: 100.04ms
  iterator_ops.py:373:get_next, cpu: 99.96ms, accelerator: 0us, total: 99.96ms
train2.py:333:<module>, cpu: 7.00ms, accelerator: 14.21ms, total: 21.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_365000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_365250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_365500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_365750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12600234.97sec, total: 12600234.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.89ms, accelerator: 0us, total: 99.89ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.35ms, accelerator: 7.89ms, total: 14.25ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.89ms, accelerator: 0us, total: 99.89ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12600234.99sec, total: 12600234.99sec
train2.py:307:<module>, cpu: 99.97ms, accelerator: 0us, total: 99.97ms
  iterator_ops.py:373:get_next, cpu: 99.89ms, accelerator: 0us, total: 99.89ms
train2.py:333:<module>, cpu: 6.99ms, accelerator: 14.21ms, total: 21.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_366000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_366250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_366500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_366750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12565901.90sec, total: 12565901.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.90ms, accelerator: 0us, total: 99.90ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.34ms, accelerator: 7.88ms, total: 14.23ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.90ms, accelerator: 0us, total: 99.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12565901.92sec, total: 12565901.93sec
train2.py:307:<module>, cpu: 99.98ms, accelerator: 0us, total: 99.98ms
  iterator_ops.py:373:get_next, cpu: 99.90ms, accelerator: 0us, total: 99.90ms
train2.py:333:<module>, cpu: 6.97ms, accelerator: 14.20ms, total: 21.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_367000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_367250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_367500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_367750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12531755.43sec, total: 12531755.43sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.88ms, accelerator: 0us, total: 99.88ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.32ms, accelerator: 7.88ms, total: 14.21ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.88ms, accelerator: 0us, total: 99.88ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12531755.45sec, total: 12531755.45sec
train2.py:307:<module>, cpu: 99.96ms, accelerator: 0us, total: 99.96ms
  iterator_ops.py:373:get_next, cpu: 99.88ms, accelerator: 0us, total: 99.88ms
train2.py:333:<module>, cpu: 6.96ms, accelerator: 14.20ms, total: 21.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_368000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_368250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_368500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_368750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12497794.03sec, total: 12497794.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.77ms, accelerator: 0us, total: 99.77ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.31ms, accelerator: 7.88ms, total: 14.20ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.77ms, accelerator: 0us, total: 99.77ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12497794.05sec, total: 12497794.06sec
train2.py:307:<module>, cpu: 99.85ms, accelerator: 0us, total: 99.85ms
  iterator_ops.py:373:get_next, cpu: 99.77ms, accelerator: 0us, total: 99.77ms
train2.py:333:<module>, cpu: 6.95ms, accelerator: 14.20ms, total: 21.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_369000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_369250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_369500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_369750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 12464016.21sec, total: 12464016.21sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.65ms, accelerator: 0us, total: 99.65ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.29ms, accelerator: 7.88ms, total: 14.18ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.65ms, accelerator: 0us, total: 99.65ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12464016.23sec, total: 12464016.23sec
train2.py:307:<module>, cpu: 99.73ms, accelerator: 0us, total: 99.73ms
  iterator_ops.py:373:get_next, cpu: 99.65ms, accelerator: 0us, total: 99.65ms
train2.py:333:<module>, cpu: 6.93ms, accelerator: 14.20ms, total: 21.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_370000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_370250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_370500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_370750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 12430420.48sec, total: 12430420.48sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.53ms, accelerator: 0us, total: 99.53ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.28ms, accelerator: 7.88ms, total: 14.16ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.53ms, accelerator: 0us, total: 99.53ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12430420.50sec, total: 12430420.50sec
train2.py:307:<module>, cpu: 99.60ms, accelerator: 0us, total: 99.60ms
  iterator_ops.py:373:get_next, cpu: 99.53ms, accelerator: 0us, total: 99.53ms
train2.py:333:<module>, cpu: 6.92ms, accelerator: 14.20ms, total: 21.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_371000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_371250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_371500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_371750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 12397005.37sec, total: 12397005.37sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.47ms, accelerator: 0us, total: 99.47ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.27ms, accelerator: 7.87ms, total: 14.15ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.47ms, accelerator: 0us, total: 99.47ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12397005.39sec, total: 12397005.39sec
train2.py:307:<module>, cpu: 99.54ms, accelerator: 0us, total: 99.54ms
  iterator_ops.py:373:get_next, cpu: 99.47ms, accelerator: 0us, total: 99.47ms
train2.py:333:<module>, cpu: 6.90ms, accelerator: 14.19ms, total: 21.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_372000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_372250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_372500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_372750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 12363769.43sec, total: 12363769.43sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.39ms, accelerator: 0us, total: 99.39ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.25ms, accelerator: 7.88ms, total: 14.13ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.39ms, accelerator: 0us, total: 99.39ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12363769.45sec, total: 12363769.46sec
train2.py:307:<module>, cpu: 99.47ms, accelerator: 0us, total: 99.47ms
  iterator_ops.py:373:get_next, cpu: 99.39ms, accelerator: 0us, total: 99.39ms
train2.py:333:<module>, cpu: 6.89ms, accelerator: 14.20ms, total: 21.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_373000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_373250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_373500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_373750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12330711.23sec, total: 12330711.23sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.27ms, accelerator: 0us, total: 99.27ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.24ms, accelerator: 7.88ms, total: 14.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.27ms, accelerator: 0us, total: 99.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12330711.25sec, total: 12330711.25sec
train2.py:307:<module>, cpu: 99.34ms, accelerator: 0us, total: 99.34ms
  iterator_ops.py:373:get_next, cpu: 99.27ms, accelerator: 0us, total: 99.27ms
train2.py:333:<module>, cpu: 6.88ms, accelerator: 14.20ms, total: 21.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_374000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_374250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_374500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_374750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12297829.33sec, total: 12297829.33sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.19ms, accelerator: 0us, total: 99.19ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.22ms, accelerator: 7.88ms, total: 14.11ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.19ms, accelerator: 0us, total: 99.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.03ms, accelerator: 12297829.35sec, total: 12297829.35sec
train2.py:307:<module>, cpu: 99.27ms, accelerator: 0us, total: 99.27ms
  iterator_ops.py:373:get_next, cpu: 99.19ms, accelerator: 0us, total: 99.19ms
train2.py:333:<module>, cpu: 6.86ms, accelerator: 14.19ms, total: 21.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_375000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_375250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_375500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_375750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 353us, accelerator: 12265122.34sec, total: 12265122.34sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.09ms, accelerator: 0us, total: 99.09ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.21ms, accelerator: 7.88ms, total: 14.10ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.09ms, accelerator: 0us, total: 99.09ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 12265122.36sec, total: 12265122.36sec
train2.py:307:<module>, cpu: 99.17ms, accelerator: 0us, total: 99.17ms
  iterator_ops.py:373:get_next, cpu: 99.09ms, accelerator: 0us, total: 99.09ms
train2.py:333:<module>, cpu: 6.85ms, accelerator: 14.19ms, total: 21.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_376000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_376250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_376500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_376750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12232588.86sec, total: 12232588.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.00ms, accelerator: 0us, total: 99.00ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.20ms, accelerator: 7.88ms, total: 14.08ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.00ms, accelerator: 0us, total: 99.00ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 12232588.87sec, total: 12232588.88sec
train2.py:307:<module>, cpu: 99.08ms, accelerator: 0us, total: 99.08ms
  iterator_ops.py:373:get_next, cpu: 99.00ms, accelerator: 0us, total: 99.00ms
train2.py:333:<module>, cpu: 6.83ms, accelerator: 14.20ms, total: 21.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_377000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_377250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_377500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_377750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12200227.51sec, total: 12200227.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.94ms, accelerator: 0us, total: 98.94ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.18ms, accelerator: 7.88ms, total: 14.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.94ms, accelerator: 0us, total: 98.94ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 12200227.53sec, total: 12200227.53sec
train2.py:307:<module>, cpu: 99.02ms, accelerator: 0us, total: 99.02ms
  iterator_ops.py:373:get_next, cpu: 98.94ms, accelerator: 0us, total: 98.94ms
train2.py:333:<module>, cpu: 6.82ms, accelerator: 14.19ms, total: 21.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_378000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_378250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_378500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_378750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12168036.94sec, total: 12168036.94sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.82ms, accelerator: 0us, total: 98.82ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.17ms, accelerator: 7.88ms, total: 14.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.82ms, accelerator: 0us, total: 98.82ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 12168036.95sec, total: 12168036.96sec
train2.py:307:<module>, cpu: 98.90ms, accelerator: 0us, total: 98.90ms
  iterator_ops.py:373:get_next, cpu: 98.82ms, accelerator: 0us, total: 98.82ms
train2.py:333:<module>, cpu: 6.80ms, accelerator: 14.18ms, total: 21.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_379000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_379250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_379500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_379750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12136015.79sec, total: 12136015.79sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.69ms, accelerator: 0us, total: 98.69ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.16ms, accelerator: 7.87ms, total: 14.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.69ms, accelerator: 0us, total: 98.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 12136015.80sec, total: 12136015.81sec
train2.py:307:<module>, cpu: 98.77ms, accelerator: 0us, total: 98.77ms
  iterator_ops.py:373:get_next, cpu: 98.69ms, accelerator: 0us, total: 98.69ms
train2.py:333:<module>, cpu: 6.79ms, accelerator: 14.17ms, total: 20.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_380000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_380250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_380500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_380750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 12104162.73sec, total: 12104162.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.58ms, accelerator: 0us, total: 98.58ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.14ms, accelerator: 7.87ms, total: 14.02ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.58ms, accelerator: 0us, total: 98.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 12104162.74sec, total: 12104162.75sec
train2.py:307:<module>, cpu: 98.65ms, accelerator: 0us, total: 98.65ms
  iterator_ops.py:373:get_next, cpu: 98.58ms, accelerator: 0us, total: 98.58ms
train2.py:333:<module>, cpu: 6.78ms, accelerator: 14.17ms, total: 20.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_381000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_381250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_381500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_381750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 12072476.44sec, total: 12072476.44sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.51ms, accelerator: 0us, total: 98.51ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.13ms, accelerator: 7.88ms, total: 14.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.51ms, accelerator: 0us, total: 98.51ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 12072476.45sec, total: 12072476.46sec
train2.py:307:<module>, cpu: 98.59ms, accelerator: 0us, total: 98.59ms
  iterator_ops.py:373:get_next, cpu: 98.51ms, accelerator: 0us, total: 98.51ms
train2.py:333:<module>, cpu: 6.77ms, accelerator: 14.18ms, total: 20.97ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_382000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_382250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_382500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_382750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12040955.61sec, total: 12040955.61sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.44ms, accelerator: 0us, total: 98.44ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.12ms, accelerator: 7.87ms, total: 13.99ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.44ms, accelerator: 0us, total: 98.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 12040955.63sec, total: 12040955.63sec
train2.py:307:<module>, cpu: 98.52ms, accelerator: 0us, total: 98.52ms
  iterator_ops.py:373:get_next, cpu: 98.44ms, accelerator: 0us, total: 98.44ms
train2.py:333:<module>, cpu: 6.75ms, accelerator: 14.17ms, total: 20.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_383000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_383250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_383500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_383750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 352us, accelerator: 12009598.95sec, total: 12009598.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.40ms, accelerator: 0us, total: 98.40ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.10ms, accelerator: 7.87ms, total: 13.98ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.40ms, accelerator: 0us, total: 98.40ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 12009598.97sec, total: 12009598.98sec
train2.py:307:<module>, cpu: 98.47ms, accelerator: 0us, total: 98.47ms
  iterator_ops.py:373:get_next, cpu: 98.40ms, accelerator: 0us, total: 98.40ms
train2.py:333:<module>, cpu: 6.74ms, accelerator: 14.18ms, total: 20.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_384000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_384250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_384500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_384750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11978405.19sec, total: 11978405.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.41ms, accelerator: 0us, total: 98.41ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.09ms, accelerator: 7.87ms, total: 13.97ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.41ms, accelerator: 0us, total: 98.41ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11978405.21sec, total: 11978405.21sec
train2.py:307:<module>, cpu: 98.48ms, accelerator: 0us, total: 98.48ms
  iterator_ops.py:373:get_next, cpu: 98.41ms, accelerator: 0us, total: 98.41ms
train2.py:333:<module>, cpu: 6.73ms, accelerator: 14.18ms, total: 20.92ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_385000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_385250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_385500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_385750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11947373.05sec, total: 11947373.05sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.38ms, accelerator: 0us, total: 98.38ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.08ms, accelerator: 7.88ms, total: 13.96ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.38ms, accelerator: 0us, total: 98.38ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11947373.07sec, total: 11947373.08sec
train2.py:307:<module>, cpu: 98.46ms, accelerator: 0us, total: 98.46ms
  iterator_ops.py:373:get_next, cpu: 98.38ms, accelerator: 0us, total: 98.38ms
train2.py:333:<module>, cpu: 6.71ms, accelerator: 14.19ms, total: 20.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_386000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_386250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_386500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_386750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11916501.29sec, total: 11916501.29sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.33ms, accelerator: 0us, total: 98.33ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.06ms, accelerator: 7.87ms, total: 13.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.33ms, accelerator: 0us, total: 98.33ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11916501.31sec, total: 11916501.31sec
train2.py:307:<module>, cpu: 98.40ms, accelerator: 0us, total: 98.40ms
  iterator_ops.py:373:get_next, cpu: 98.33ms, accelerator: 0us, total: 98.33ms
train2.py:333:<module>, cpu: 6.70ms, accelerator: 14.17ms, total: 20.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_387000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_387250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_387500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_387750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11885788.66sec, total: 11885788.66sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.24ms, accelerator: 0us, total: 98.24ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.05ms, accelerator: 7.87ms, total: 13.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.24ms, accelerator: 0us, total: 98.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11885788.68sec, total: 11885788.68sec
train2.py:307:<module>, cpu: 98.32ms, accelerator: 0us, total: 98.32ms
  iterator_ops.py:373:get_next, cpu: 98.24ms, accelerator: 0us, total: 98.24ms
train2.py:333:<module>, cpu: 6.68ms, accelerator: 14.17ms, total: 20.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_388000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_388250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_388500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_388750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11855233.93sec, total: 11855233.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.19ms, accelerator: 0us, total: 98.19ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.03ms, accelerator: 7.87ms, total: 13.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.19ms, accelerator: 0us, total: 98.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11855233.95sec, total: 11855233.95sec
train2.py:307:<module>, cpu: 98.27ms, accelerator: 0us, total: 98.27ms
  iterator_ops.py:373:get_next, cpu: 98.19ms, accelerator: 0us, total: 98.19ms
train2.py:333:<module>, cpu: 6.67ms, accelerator: 14.17ms, total: 20.86ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_389000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_389250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_389500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_389750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11824835.89sec, total: 11824835.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.10ms, accelerator: 0us, total: 98.10ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.02ms, accelerator: 7.87ms, total: 13.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.10ms, accelerator: 0us, total: 98.10ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11824835.91sec, total: 11824835.92sec
train2.py:307:<module>, cpu: 98.18ms, accelerator: 0us, total: 98.18ms
  iterator_ops.py:373:get_next, cpu: 98.10ms, accelerator: 0us, total: 98.10ms
train2.py:333:<module>, cpu: 6.66ms, accelerator: 14.18ms, total: 20.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_390000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_390250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_390500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_390750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11794593.35sec, total: 11794593.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 98.00ms, accelerator: 0us, total: 98.00ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.01ms, accelerator: 7.87ms, total: 13.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 98.00ms, accelerator: 0us, total: 98.00ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11794593.37sec, total: 11794593.37sec
train2.py:307:<module>, cpu: 98.08ms, accelerator: 0us, total: 98.08ms
  iterator_ops.py:373:get_next, cpu: 98.00ms, accelerator: 0us, total: 98.00ms
train2.py:333:<module>, cpu: 6.65ms, accelerator: 14.17ms, total: 20.84ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_391000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_391250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_391500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_391750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11764505.10sec, total: 11764505.10sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.90ms, accelerator: 0us, total: 97.90ms (0.00%)
top 3 operation type: Conv2D, cpu: 6.00ms, accelerator: 7.87ms, total: 13.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.90ms, accelerator: 0us, total: 97.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11764505.12sec, total: 11764505.12sec
train2.py:307:<module>, cpu: 97.97ms, accelerator: 0us, total: 97.97ms
  iterator_ops.py:373:get_next, cpu: 97.90ms, accelerator: 0us, total: 97.90ms
train2.py:333:<module>, cpu: 6.63ms, accelerator: 14.17ms, total: 20.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_392000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_392250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_392500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_392750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11734569.97sec, total: 11734569.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.84ms, accelerator: 0us, total: 97.84ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.98ms, accelerator: 7.87ms, total: 13.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.84ms, accelerator: 0us, total: 97.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11734569.99sec, total: 11734569.99sec
train2.py:307:<module>, cpu: 97.91ms, accelerator: 0us, total: 97.91ms
  iterator_ops.py:373:get_next, cpu: 97.84ms, accelerator: 0us, total: 97.84ms
train2.py:333:<module>, cpu: 6.62ms, accelerator: 14.16ms, total: 20.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_393000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_393250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_393500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_393750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11704786.80sec, total: 11704786.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.78ms, accelerator: 0us, total: 97.78ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.97ms, accelerator: 7.87ms, total: 13.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.78ms, accelerator: 0us, total: 97.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11704786.82sec, total: 11704786.82sec
train2.py:307:<module>, cpu: 97.86ms, accelerator: 0us, total: 97.86ms
  iterator_ops.py:373:get_next, cpu: 97.78ms, accelerator: 0us, total: 97.78ms
train2.py:333:<module>, cpu: 6.61ms, accelerator: 14.16ms, total: 20.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_394000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_394250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_394500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_394750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11675154.43sec, total: 11675154.43sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.66ms, accelerator: 0us, total: 97.66ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.96ms, accelerator: 7.87ms, total: 13.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.66ms, accelerator: 0us, total: 97.66ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.02ms, accelerator: 11675154.45sec, total: 11675154.45sec
train2.py:307:<module>, cpu: 97.74ms, accelerator: 0us, total: 97.74ms
  iterator_ops.py:373:get_next, cpu: 97.66ms, accelerator: 0us, total: 97.66ms
train2.py:333:<module>, cpu: 6.59ms, accelerator: 14.16ms, total: 20.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_395000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_395250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_395500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_395750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11645671.71sec, total: 11645671.71sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.63ms, accelerator: 0us, total: 97.63ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.95ms, accelerator: 7.87ms, total: 13.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.63ms, accelerator: 0us, total: 97.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11645671.73sec, total: 11645671.74sec
train2.py:307:<module>, cpu: 97.70ms, accelerator: 0us, total: 97.70ms
  iterator_ops.py:373:get_next, cpu: 97.63ms, accelerator: 0us, total: 97.63ms
train2.py:333:<module>, cpu: 6.58ms, accelerator: 14.16ms, total: 20.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_396000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_396250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_396500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_396750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11616337.53sec, total: 11616337.53sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.52ms, accelerator: 0us, total: 97.52ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.93ms, accelerator: 7.87ms, total: 13.81ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.52ms, accelerator: 0us, total: 97.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11616337.55sec, total: 11616337.55sec
train2.py:307:<module>, cpu: 97.59ms, accelerator: 0us, total: 97.59ms
  iterator_ops.py:373:get_next, cpu: 97.52ms, accelerator: 0us, total: 97.52ms
train2.py:333:<module>, cpu: 6.57ms, accelerator: 14.15ms, total: 20.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_397000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_397250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_397500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_397750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11587150.75sec, total: 11587150.75sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.43ms, accelerator: 0us, total: 97.43ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.92ms, accelerator: 7.86ms, total: 13.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.43ms, accelerator: 0us, total: 97.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11587150.77sec, total: 11587150.77sec
train2.py:307:<module>, cpu: 97.51ms, accelerator: 0us, total: 97.51ms
  iterator_ops.py:373:get_next, cpu: 97.43ms, accelerator: 0us, total: 97.43ms
train2.py:333:<module>, cpu: 6.56ms, accelerator: 14.15ms, total: 20.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_398000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_398250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_398500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_398750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11558110.27sec, total: 11558110.27sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.32ms, accelerator: 0us, total: 97.32ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.91ms, accelerator: 7.86ms, total: 13.78ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.32ms, accelerator: 0us, total: 97.32ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11558110.29sec, total: 11558110.29sec
train2.py:307:<module>, cpu: 97.40ms, accelerator: 0us, total: 97.40ms
  iterator_ops.py:373:get_next, cpu: 97.32ms, accelerator: 0us, total: 97.32ms
train2.py:333:<module>, cpu: 6.54ms, accelerator: 14.15ms, total: 20.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_399000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_399250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_399500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_399750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11529215.00sec, total: 11529215.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.20ms, accelerator: 0us, total: 97.20ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.90ms, accelerator: 7.86ms, total: 13.77ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.20ms, accelerator: 0us, total: 97.20ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11529215.02sec, total: 11529215.02sec
train2.py:307:<module>, cpu: 97.28ms, accelerator: 0us, total: 97.28ms
  iterator_ops.py:373:get_next, cpu: 97.20ms, accelerator: 0us, total: 97.20ms
train2.py:333:<module>, cpu: 6.53ms, accelerator: 14.15ms, total: 20.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_400000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_400250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_400500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_400750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11500463.84sec, total: 11500463.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.22ms, accelerator: 0us, total: 97.22ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.88ms, accelerator: 7.87ms, total: 13.76ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.22ms, accelerator: 0us, total: 97.22ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11500463.86sec, total: 11500463.86sec
train2.py:307:<module>, cpu: 97.29ms, accelerator: 0us, total: 97.29ms
  iterator_ops.py:373:get_next, cpu: 97.22ms, accelerator: 0us, total: 97.22ms
train2.py:333:<module>, cpu: 6.52ms, accelerator: 14.15ms, total: 20.70ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_401000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_401250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_401500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_401750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11471855.72sec, total: 11471855.72sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.16ms, accelerator: 0us, total: 97.16ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.87ms, accelerator: 7.88ms, total: 13.76ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.16ms, accelerator: 0us, total: 97.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11471855.74sec, total: 11471855.74sec
train2.py:307:<module>, cpu: 97.24ms, accelerator: 0us, total: 97.24ms
  iterator_ops.py:373:get_next, cpu: 97.16ms, accelerator: 0us, total: 97.16ms
train2.py:333:<module>, cpu: 6.51ms, accelerator: 14.16ms, total: 20.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_402000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_402250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_402500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_402750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11443389.57sec, total: 11443389.57sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.04ms, accelerator: 0us, total: 97.04ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.86ms, accelerator: 7.87ms, total: 13.74ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.04ms, accelerator: 0us, total: 97.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11443389.59sec, total: 11443389.60sec
train2.py:307:<module>, cpu: 97.11ms, accelerator: 0us, total: 97.11ms
  iterator_ops.py:373:get_next, cpu: 97.04ms, accelerator: 0us, total: 97.04ms
train2.py:333:<module>, cpu: 6.50ms, accelerator: 14.16ms, total: 20.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_403000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_403250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_403500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_403750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11415064.35sec, total: 11415064.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.01ms, accelerator: 0us, total: 97.01ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.85ms, accelerator: 7.87ms, total: 13.73ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.01ms, accelerator: 0us, total: 97.01ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11415064.37sec, total: 11415064.38sec
train2.py:307:<module>, cpu: 97.08ms, accelerator: 0us, total: 97.08ms
  iterator_ops.py:373:get_next, cpu: 97.01ms, accelerator: 0us, total: 97.01ms
train2.py:333:<module>, cpu: 6.48ms, accelerator: 14.15ms, total: 20.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_404000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_404250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_404500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_404750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11386879.01sec, total: 11386879.01sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.90ms, accelerator: 0us, total: 96.90ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.83ms, accelerator: 7.87ms, total: 13.72ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.90ms, accelerator: 0us, total: 96.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11386879.03sec, total: 11386879.03sec
train2.py:307:<module>, cpu: 96.97ms, accelerator: 0us, total: 96.97ms
  iterator_ops.py:373:get_next, cpu: 96.90ms, accelerator: 0us, total: 96.90ms
train2.py:333:<module>, cpu: 6.47ms, accelerator: 14.16ms, total: 20.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_405000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_405250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_405500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_405750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11358832.51sec, total: 11358832.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.90ms, accelerator: 0us, total: 96.90ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.82ms, accelerator: 7.88ms, total: 13.71ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.90ms, accelerator: 0us, total: 96.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11358832.53sec, total: 11358832.53sec
train2.py:307:<module>, cpu: 96.98ms, accelerator: 0us, total: 96.98ms
  iterator_ops.py:373:get_next, cpu: 96.90ms, accelerator: 0us, total: 96.90ms
train2.py:333:<module>, cpu: 6.46ms, accelerator: 14.16ms, total: 20.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_406000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_406250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_406500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_406750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11330923.83sec, total: 11330923.83sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.84ms, accelerator: 0us, total: 96.84ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.81ms, accelerator: 7.88ms, total: 13.70ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.84ms, accelerator: 0us, total: 96.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11330923.85sec, total: 11330923.85sec
train2.py:307:<module>, cpu: 96.92ms, accelerator: 0us, total: 96.92ms
  iterator_ops.py:373:get_next, cpu: 96.84ms, accelerator: 0us, total: 96.84ms
train2.py:333:<module>, cpu: 6.45ms, accelerator: 14.16ms, total: 20.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_407000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_407250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_407500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_407750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11303151.96sec, total: 11303151.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.79ms, accelerator: 0us, total: 96.79ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.80ms, accelerator: 7.87ms, total: 13.68ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.79ms, accelerator: 0us, total: 96.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11303151.98sec, total: 11303151.98sec
train2.py:307:<module>, cpu: 96.87ms, accelerator: 0us, total: 96.87ms
  iterator_ops.py:373:get_next, cpu: 96.79ms, accelerator: 0us, total: 96.79ms
train2.py:333:<module>, cpu: 6.44ms, accelerator: 14.16ms, total: 20.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_408000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_408250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_408500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_408750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11275515.89sec, total: 11275515.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.78ms, accelerator: 0us, total: 96.78ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.79ms, accelerator: 7.87ms, total: 13.67ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.78ms, accelerator: 0us, total: 96.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11275515.91sec, total: 11275515.91sec
train2.py:307:<module>, cpu: 96.85ms, accelerator: 0us, total: 96.85ms
  iterator_ops.py:373:get_next, cpu: 96.78ms, accelerator: 0us, total: 96.78ms
train2.py:333:<module>, cpu: 6.42ms, accelerator: 14.16ms, total: 20.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_409000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_409250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_409500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_409750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11248014.63sec, total: 11248014.63sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.72ms, accelerator: 0us, total: 96.72ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.78ms, accelerator: 7.88ms, total: 13.67ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.72ms, accelerator: 0us, total: 96.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11248014.65sec, total: 11248014.65sec
train2.py:307:<module>, cpu: 96.79ms, accelerator: 0us, total: 96.79ms
  iterator_ops.py:373:get_next, cpu: 96.72ms, accelerator: 0us, total: 96.72ms
train2.py:333:<module>, cpu: 6.41ms, accelerator: 14.16ms, total: 20.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_410000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_410250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_410500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_410750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11220647.20sec, total: 11220647.20sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.66ms, accelerator: 0us, total: 96.66ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.76ms, accelerator: 7.88ms, total: 13.65ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.66ms, accelerator: 0us, total: 96.66ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11220647.22sec, total: 11220647.22sec
train2.py:307:<module>, cpu: 96.73ms, accelerator: 0us, total: 96.73ms
  iterator_ops.py:373:get_next, cpu: 96.66ms, accelerator: 0us, total: 96.66ms
train2.py:333:<module>, cpu: 6.40ms, accelerator: 14.16ms, total: 20.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_411000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_411250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_411500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_411750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11193412.62sec, total: 11193412.62sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.55ms, accelerator: 0us, total: 96.55ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.75ms, accelerator: 7.88ms, total: 13.64ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.55ms, accelerator: 0us, total: 96.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11193412.64sec, total: 11193412.64sec
train2.py:307:<module>, cpu: 96.62ms, accelerator: 0us, total: 96.62ms
  iterator_ops.py:373:get_next, cpu: 96.55ms, accelerator: 0us, total: 96.55ms
train2.py:333:<module>, cpu: 6.39ms, accelerator: 14.16ms, total: 20.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_412000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_412250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_412500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_412750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11166309.92sec, total: 11166309.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.46ms, accelerator: 0us, total: 96.46ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.74ms, accelerator: 7.87ms, total: 13.63ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.46ms, accelerator: 0us, total: 96.46ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11166309.94sec, total: 11166309.95sec
train2.py:307:<module>, cpu: 96.53ms, accelerator: 0us, total: 96.53ms
  iterator_ops.py:373:get_next, cpu: 96.46ms, accelerator: 0us, total: 96.46ms
train2.py:333:<module>, cpu: 6.38ms, accelerator: 14.16ms, total: 20.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_413000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_413250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_413500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_413750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11139338.16sec, total: 11139338.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.42ms, accelerator: 0us, total: 96.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.74ms, accelerator: 7.87ms, total: 13.62ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.42ms, accelerator: 0us, total: 96.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11139338.18sec, total: 11139338.18sec
train2.py:307:<module>, cpu: 96.50ms, accelerator: 0us, total: 96.50ms
  iterator_ops.py:373:get_next, cpu: 96.42ms, accelerator: 0us, total: 96.42ms
train2.py:333:<module>, cpu: 6.37ms, accelerator: 14.16ms, total: 20.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_414000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_414250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_414500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_414750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11112496.38sec, total: 11112496.38sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.36ms, accelerator: 0us, total: 96.36ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.72ms, accelerator: 7.87ms, total: 13.61ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.36ms, accelerator: 0us, total: 96.36ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11112496.40sec, total: 11112496.40sec
train2.py:307:<module>, cpu: 96.43ms, accelerator: 0us, total: 96.43ms
  iterator_ops.py:373:get_next, cpu: 96.36ms, accelerator: 0us, total: 96.36ms
train2.py:333:<module>, cpu: 6.36ms, accelerator: 14.16ms, total: 20.54ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_415000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_415250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_415500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_415750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 351us, accelerator: 11085783.65sec, total: 11085783.65sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.27ms, accelerator: 0us, total: 96.27ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.71ms, accelerator: 7.87ms, total: 13.59ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.27ms, accelerator: 0us, total: 96.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11085783.67sec, total: 11085783.67sec
train2.py:307:<module>, cpu: 96.34ms, accelerator: 0us, total: 96.34ms
  iterator_ops.py:373:get_next, cpu: 96.27ms, accelerator: 0us, total: 96.27ms
train2.py:333:<module>, cpu: 6.34ms, accelerator: 14.16ms, total: 20.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_416000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_416250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_416500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_416750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 11059199.04sec, total: 11059199.04sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.18ms, accelerator: 0us, total: 96.18ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.70ms, accelerator: 7.86ms, total: 13.57ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.18ms, accelerator: 0us, total: 96.18ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11059199.06sec, total: 11059199.06sec
train2.py:307:<module>, cpu: 96.25ms, accelerator: 0us, total: 96.25ms
  iterator_ops.py:373:get_next, cpu: 96.18ms, accelerator: 0us, total: 96.18ms
train2.py:333:<module>, cpu: 6.33ms, accelerator: 14.16ms, total: 20.52ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_417000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_417250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_417500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_417750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 11032741.62sec, total: 11032741.62sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.11ms, accelerator: 0us, total: 96.11ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.69ms, accelerator: 7.86ms, total: 13.56ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.11ms, accelerator: 0us, total: 96.11ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11032741.64sec, total: 11032741.65sec
train2.py:307:<module>, cpu: 96.18ms, accelerator: 0us, total: 96.18ms
  iterator_ops.py:373:get_next, cpu: 96.11ms, accelerator: 0us, total: 96.11ms
train2.py:333:<module>, cpu: 6.32ms, accelerator: 14.16ms, total: 20.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_418000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_418250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_418500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_418750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 11006410.50sec, total: 11006410.50sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 96.02ms, accelerator: 0us, total: 96.02ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.68ms, accelerator: 7.86ms, total: 13.54ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 96.02ms, accelerator: 0us, total: 96.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 11006410.52sec, total: 11006410.52sec
train2.py:307:<module>, cpu: 96.09ms, accelerator: 0us, total: 96.09ms
  iterator_ops.py:373:get_next, cpu: 96.02ms, accelerator: 0us, total: 96.02ms
train2.py:333:<module>, cpu: 6.31ms, accelerator: 14.15ms, total: 20.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_419000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_419250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_419500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_419750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10980204.76sec, total: 10980204.76sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 95.91ms, accelerator: 0us, total: 95.91ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.67ms, accelerator: 7.85ms, total: 13.53ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 95.91ms, accelerator: 0us, total: 95.91ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 10980204.78sec, total: 10980204.78sec
train2.py:307:<module>, cpu: 95.98ms, accelerator: 0us, total: 95.98ms
  iterator_ops.py:373:get_next, cpu: 95.91ms, accelerator: 0us, total: 95.91ms
train2.py:333:<module>, cpu: 6.30ms, accelerator: 14.15ms, total: 20.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_420000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_420250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_420500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_420750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10954123.51sec, total: 10954123.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 95.86ms, accelerator: 0us, total: 95.86ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.66ms, accelerator: 7.86ms, total: 13.52ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 95.86ms, accelerator: 0us, total: 95.86ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 10954123.53sec, total: 10954123.53sec
train2.py:307:<module>, cpu: 95.93ms, accelerator: 0us, total: 95.93ms
  iterator_ops.py:373:get_next, cpu: 95.86ms, accelerator: 0us, total: 95.86ms
train2.py:333:<module>, cpu: 6.29ms, accelerator: 14.16ms, total: 20.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_421000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_421250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_421500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_421750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10928165.87sec, total: 10928165.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 95.77ms, accelerator: 0us, total: 95.77ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.65ms, accelerator: 7.86ms, total: 13.52ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 95.77ms, accelerator: 0us, total: 95.77ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 10928165.89sec, total: 10928165.90sec
train2.py:307:<module>, cpu: 95.83ms, accelerator: 0us, total: 95.83ms
  iterator_ops.py:373:get_next, cpu: 95.77ms, accelerator: 0us, total: 95.77ms
train2.py:333:<module>, cpu: 6.28ms, accelerator: 14.16ms, total: 20.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_422000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_422250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_422500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_422750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10902330.97sec, total: 10902330.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 95.68ms, accelerator: 0us, total: 95.68ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.64ms, accelerator: 7.86ms, total: 13.50ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 95.68ms, accelerator: 0us, total: 95.68ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.01ms, accelerator: 10902330.99sec, total: 10902330.99sec
train2.py:307:<module>, cpu: 95.75ms, accelerator: 0us, total: 95.75ms
  iterator_ops.py:373:get_next, cpu: 95.68ms, accelerator: 0us, total: 95.68ms
train2.py:333:<module>, cpu: 6.27ms, accelerator: 14.16ms, total: 20.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_423000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_423250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_423500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_423750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10876617.92sec, total: 10876617.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 95.58ms, accelerator: 0us, total: 95.58ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.62ms, accelerator: 7.86ms, total: 13.49ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 95.58ms, accelerator: 0us, total: 95.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10876617.94sec, total: 10876617.94sec
train2.py:307:<module>, cpu: 95.65ms, accelerator: 0us, total: 95.65ms
  iterator_ops.py:373:get_next, cpu: 95.58ms, accelerator: 0us, total: 95.58ms
train2.py:333:<module>, cpu: 6.26ms, accelerator: 14.17ms, total: 20.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_424000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_424250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_424500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_424750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10851025.88sec, total: 10851025.88sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 95.50ms, accelerator: 0us, total: 95.50ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.62ms, accelerator: 7.86ms, total: 13.49ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 95.50ms, accelerator: 0us, total: 95.50ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10851025.90sec, total: 10851025.90sec
train2.py:307:<module>, cpu: 95.57ms, accelerator: 0us, total: 95.57ms
  iterator_ops.py:373:get_next, cpu: 95.50ms, accelerator: 0us, total: 95.50ms
train2.py:333:<module>, cpu: 6.25ms, accelerator: 14.17ms, total: 20.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_425000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_425250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_425500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_425750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10825553.99sec, total: 10825553.99sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 95.42ms, accelerator: 0us, total: 95.42ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.60ms, accelerator: 7.86ms, total: 13.47ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 95.42ms, accelerator: 0us, total: 95.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10825554.01sec, total: 10825554.01sec
train2.py:307:<module>, cpu: 95.48ms, accelerator: 0us, total: 95.48ms
  iterator_ops.py:373:get_next, cpu: 95.42ms, accelerator: 0us, total: 95.42ms
train2.py:333:<module>, cpu: 6.24ms, accelerator: 14.16ms, total: 20.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_426000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_426250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_426500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_426750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10800201.40sec, total: 10800201.40sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 95.31ms, accelerator: 0us, total: 95.31ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.59ms, accelerator: 7.85ms, total: 13.46ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 95.31ms, accelerator: 0us, total: 95.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10800201.42sec, total: 10800201.42sec
train2.py:307:<module>, cpu: 95.38ms, accelerator: 0us, total: 95.38ms
  iterator_ops.py:373:get_next, cpu: 95.31ms, accelerator: 0us, total: 95.31ms
train2.py:333:<module>, cpu: 6.22ms, accelerator: 14.17ms, total: 20.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_427000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_427250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_427500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_427750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10774967.29sec, total: 10774967.29sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 95.21ms, accelerator: 0us, total: 95.21ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.58ms, accelerator: 7.85ms, total: 13.44ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 95.21ms, accelerator: 0us, total: 95.21ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10774967.31sec, total: 10774967.31sec
train2.py:307:<module>, cpu: 95.28ms, accelerator: 0us, total: 95.28ms
  iterator_ops.py:373:get_next, cpu: 95.21ms, accelerator: 0us, total: 95.21ms
train2.py:333:<module>, cpu: 6.21ms, accelerator: 14.16ms, total: 20.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_428000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_428250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_428500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_428750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10749850.81sec, total: 10749850.81sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.76ms, accelerator: 0us, total: 97.76ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.57ms, accelerator: 7.85ms, total: 13.43ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.76ms, accelerator: 0us, total: 97.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10749850.83sec, total: 10749850.83sec
train2.py:307:<module>, cpu: 97.83ms, accelerator: 0us, total: 97.83ms
  iterator_ops.py:373:get_next, cpu: 97.76ms, accelerator: 0us, total: 97.76ms
train2.py:333:<module>, cpu: 6.20ms, accelerator: 14.16ms, total: 20.39ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_429000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_429250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_429500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_429750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10724851.16sec, total: 10724851.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.70ms, accelerator: 0us, total: 97.70ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.56ms, accelerator: 7.85ms, total: 13.42ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.70ms, accelerator: 0us, total: 97.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10724851.18sec, total: 10724851.18sec
train2.py:307:<module>, cpu: 97.77ms, accelerator: 0us, total: 97.77ms
  iterator_ops.py:373:get_next, cpu: 97.70ms, accelerator: 0us, total: 97.70ms
train2.py:333:<module>, cpu: 6.19ms, accelerator: 14.16ms, total: 20.38ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_430000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_430250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_430500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_430750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10699967.51sec, total: 10699967.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.57ms, accelerator: 0us, total: 97.57ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.55ms, accelerator: 7.86ms, total: 13.41ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.57ms, accelerator: 0us, total: 97.57ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10699967.53sec, total: 10699967.54sec
train2.py:307:<module>, cpu: 97.64ms, accelerator: 0us, total: 97.64ms
  iterator_ops.py:373:get_next, cpu: 97.57ms, accelerator: 0us, total: 97.57ms
train2.py:333:<module>, cpu: 6.18ms, accelerator: 14.17ms, total: 20.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_431000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_431250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_431500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_431750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10675199.07sec, total: 10675199.07sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.49ms, accelerator: 0us, total: 97.49ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.54ms, accelerator: 7.85ms, total: 13.40ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.49ms, accelerator: 0us, total: 97.49ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10675199.09sec, total: 10675199.09sec
train2.py:307:<module>, cpu: 97.56ms, accelerator: 0us, total: 97.56ms
  iterator_ops.py:373:get_next, cpu: 97.49ms, accelerator: 0us, total: 97.49ms
train2.py:333:<module>, cpu: 6.17ms, accelerator: 14.17ms, total: 20.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_432000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_432250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_432500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_432750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10650545.03sec, total: 10650545.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.39ms, accelerator: 0us, total: 97.39ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.53ms, accelerator: 7.85ms, total: 13.39ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.39ms, accelerator: 0us, total: 97.39ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10650545.05sec, total: 10650545.05sec
train2.py:307:<module>, cpu: 97.46ms, accelerator: 0us, total: 97.46ms
  iterator_ops.py:373:get_next, cpu: 97.39ms, accelerator: 0us, total: 97.39ms
train2.py:333:<module>, cpu: 6.16ms, accelerator: 14.17ms, total: 20.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_433000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_433250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_433500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_433750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10626004.61sec, total: 10626004.61sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.25ms, accelerator: 0us, total: 97.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.52ms, accelerator: 7.85ms, total: 13.38ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.25ms, accelerator: 0us, total: 97.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10626004.62sec, total: 10626004.63sec
train2.py:307:<module>, cpu: 97.32ms, accelerator: 0us, total: 97.32ms
  iterator_ops.py:373:get_next, cpu: 97.25ms, accelerator: 0us, total: 97.25ms
train2.py:333:<module>, cpu: 6.15ms, accelerator: 14.17ms, total: 20.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_434000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_434250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_434500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_434750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10601577.01sec, total: 10601577.01sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 97.22ms, accelerator: 0us, total: 97.22ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.51ms, accelerator: 7.86ms, total: 13.38ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 97.22ms, accelerator: 0us, total: 97.22ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10601577.03sec, total: 10601577.03sec
train2.py:307:<module>, cpu: 97.28ms, accelerator: 0us, total: 97.28ms
  iterator_ops.py:373:get_next, cpu: 97.22ms, accelerator: 0us, total: 97.22ms
train2.py:333:<module>, cpu: 6.14ms, accelerator: 14.17ms, total: 20.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_435000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_435250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_435500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_435750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10577261.46sec, total: 10577261.47sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.25ms, accelerator: 0us, total: 100.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.50ms, accelerator: 7.86ms, total: 13.37ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.25ms, accelerator: 0us, total: 100.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10577261.48sec, total: 10577261.49sec
train2.py:307:<module>, cpu: 100.32ms, accelerator: 0us, total: 100.32ms
  iterator_ops.py:373:get_next, cpu: 100.25ms, accelerator: 0us, total: 100.25ms
train2.py:333:<module>, cpu: 6.13ms, accelerator: 14.17ms, total: 20.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_436000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_436250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_436500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_436750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10553057.21sec, total: 10553057.21sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.25ms, accelerator: 0us, total: 100.25ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.49ms, accelerator: 7.86ms, total: 13.36ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.25ms, accelerator: 0us, total: 100.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10553057.22sec, total: 10553057.23sec
train2.py:307:<module>, cpu: 100.31ms, accelerator: 0us, total: 100.31ms
  iterator_ops.py:373:get_next, cpu: 100.25ms, accelerator: 0us, total: 100.25ms
train2.py:333:<module>, cpu: 6.12ms, accelerator: 14.17ms, total: 20.32ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_437000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_437250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_437500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_437750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10528963.47sec, total: 10528963.47sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.15ms, accelerator: 0us, total: 100.15ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.48ms, accelerator: 7.86ms, total: 13.35ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.15ms, accelerator: 0us, total: 100.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10528963.49sec, total: 10528963.49sec
train2.py:307:<module>, cpu: 100.21ms, accelerator: 0us, total: 100.21ms
  iterator_ops.py:373:get_next, cpu: 100.15ms, accelerator: 0us, total: 100.15ms
train2.py:333:<module>, cpu: 6.11ms, accelerator: 14.16ms, total: 20.30ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_438000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_438250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_438500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_438750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10504979.50sec, total: 10504979.50sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.07ms, accelerator: 0us, total: 100.07ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.47ms, accelerator: 7.86ms, total: 13.33ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.07ms, accelerator: 0us, total: 100.07ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10504979.51sec, total: 10504979.52sec
train2.py:307:<module>, cpu: 100.14ms, accelerator: 0us, total: 100.14ms
  iterator_ops.py:373:get_next, cpu: 100.07ms, accelerator: 0us, total: 100.07ms
train2.py:333:<module>, cpu: 6.10ms, accelerator: 14.16ms, total: 20.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_439000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_439250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_439500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_439750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10481104.54sec, total: 10481104.54sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 100.00ms, accelerator: 0us, total: 100.00ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.46ms, accelerator: 7.86ms, total: 13.33ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 100.00ms, accelerator: 0us, total: 100.00ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10481104.56sec, total: 10481104.56sec
train2.py:307:<module>, cpu: 100.07ms, accelerator: 0us, total: 100.07ms
  iterator_ops.py:373:get_next, cpu: 100.00ms, accelerator: 0us, total: 100.00ms
train2.py:333:<module>, cpu: 6.09ms, accelerator: 14.15ms, total: 20.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_440000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_440250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_440500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_440750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10457337.87sec, total: 10457337.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.90ms, accelerator: 0us, total: 99.90ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.45ms, accelerator: 7.86ms, total: 13.32ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.90ms, accelerator: 0us, total: 99.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10457337.88sec, total: 10457337.89sec
train2.py:307:<module>, cpu: 99.97ms, accelerator: 0us, total: 99.97ms
  iterator_ops.py:373:get_next, cpu: 99.90ms, accelerator: 0us, total: 99.90ms
train2.py:333:<module>, cpu: 6.08ms, accelerator: 14.15ms, total: 20.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_441000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_441250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_441500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_441750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10433678.73sec, total: 10433678.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.83ms, accelerator: 0us, total: 99.83ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.44ms, accelerator: 7.86ms, total: 13.31ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.83ms, accelerator: 0us, total: 99.83ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10433678.75sec, total: 10433678.75sec
train2.py:307:<module>, cpu: 99.90ms, accelerator: 0us, total: 99.90ms
  iterator_ops.py:373:get_next, cpu: 99.83ms, accelerator: 0us, total: 99.83ms
train2.py:333:<module>, cpu: 6.07ms, accelerator: 14.16ms, total: 20.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_442000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_442250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_442500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_442750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10410126.41sec, total: 10410126.41sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.74ms, accelerator: 0us, total: 99.74ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.43ms, accelerator: 7.86ms, total: 13.29ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.74ms, accelerator: 0us, total: 99.74ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10410126.43sec, total: 10410126.43sec
train2.py:307:<module>, cpu: 99.81ms, accelerator: 0us, total: 99.81ms
  iterator_ops.py:373:get_next, cpu: 99.74ms, accelerator: 0us, total: 99.74ms
train2.py:333:<module>, cpu: 6.06ms, accelerator: 14.15ms, total: 20.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_443000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_443250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_443500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_443750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10386680.18sec, total: 10386680.18sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.65ms, accelerator: 0us, total: 99.65ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.42ms, accelerator: 7.85ms, total: 13.28ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.65ms, accelerator: 0us, total: 99.65ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10386680.20sec, total: 10386680.20sec
train2.py:307:<module>, cpu: 99.72ms, accelerator: 0us, total: 99.72ms
  iterator_ops.py:373:get_next, cpu: 99.65ms, accelerator: 0us, total: 99.65ms
train2.py:333:<module>, cpu: 6.05ms, accelerator: 14.15ms, total: 20.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_444000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_444250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_444500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_444750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10363339.32sec, total: 10363339.32sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.62ms, accelerator: 0us, total: 99.62ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.41ms, accelerator: 7.86ms, total: 13.28ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.62ms, accelerator: 0us, total: 99.62ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10363339.34sec, total: 10363339.35sec
train2.py:307:<module>, cpu: 99.69ms, accelerator: 0us, total: 99.69ms
  iterator_ops.py:373:get_next, cpu: 99.62ms, accelerator: 0us, total: 99.62ms
train2.py:333:<module>, cpu: 6.04ms, accelerator: 14.16ms, total: 20.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_445000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_445250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_445500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_445750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10340103.14sec, total: 10340103.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 99.54ms, accelerator: 0us, total: 99.54ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.40ms, accelerator: 7.86ms, total: 13.27ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 99.54ms, accelerator: 0us, total: 99.54ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10340103.16sec, total: 10340103.16sec
train2.py:307:<module>, cpu: 99.61ms, accelerator: 0us, total: 99.61ms
  iterator_ops.py:373:get_next, cpu: 99.54ms, accelerator: 0us, total: 99.54ms
train2.py:333:<module>, cpu: 6.03ms, accelerator: 14.15ms, total: 20.21ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_446000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_446250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_446500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_446750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10316970.91sec, total: 10316970.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.67ms, accelerator: 0us, total: 102.67ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.39ms, accelerator: 7.86ms, total: 13.26ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.67ms, accelerator: 0us, total: 102.67ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10316970.93sec, total: 10316970.94sec
train2.py:307:<module>, cpu: 102.74ms, accelerator: 0us, total: 102.74ms
  iterator_ops.py:373:get_next, cpu: 102.67ms, accelerator: 0us, total: 102.67ms
train2.py:333:<module>, cpu: 6.02ms, accelerator: 14.16ms, total: 20.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_447000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_447250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_447500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_447750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10293941.96sec, total: 10293941.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.60ms, accelerator: 0us, total: 102.60ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.38ms, accelerator: 7.86ms, total: 13.25ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.60ms, accelerator: 0us, total: 102.60ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10293941.98sec, total: 10293941.98sec
train2.py:307:<module>, cpu: 102.67ms, accelerator: 0us, total: 102.67ms
  iterator_ops.py:373:get_next, cpu: 102.60ms, accelerator: 0us, total: 102.60ms
train2.py:333:<module>, cpu: 6.01ms, accelerator: 14.16ms, total: 20.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_448000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_448250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_448500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_448750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10271015.59sec, total: 10271015.59sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.52ms, accelerator: 0us, total: 102.52ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.37ms, accelerator: 7.86ms, total: 13.24ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.52ms, accelerator: 0us, total: 102.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10271015.61sec, total: 10271015.61sec
train2.py:307:<module>, cpu: 102.58ms, accelerator: 0us, total: 102.58ms
  iterator_ops.py:373:get_next, cpu: 102.52ms, accelerator: 0us, total: 102.52ms
train2.py:333:<module>, cpu: 6.00ms, accelerator: 14.16ms, total: 20.19ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_449000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_449250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_449500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_449750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10248191.11sec, total: 10248191.11sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.45ms, accelerator: 0us, total: 102.45ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.36ms, accelerator: 7.86ms, total: 13.23ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.45ms, accelerator: 0us, total: 102.45ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 3.00ms, accelerator: 10248191.13sec, total: 10248191.13sec
train2.py:307:<module>, cpu: 102.52ms, accelerator: 0us, total: 102.52ms
  iterator_ops.py:373:get_next, cpu: 102.45ms, accelerator: 0us, total: 102.45ms
train2.py:333:<module>, cpu: 5.99ms, accelerator: 14.17ms, total: 20.18ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_450000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_450250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_450500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_450750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10225467.85sec, total: 10225467.85sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.39ms, accelerator: 0us, total: 102.39ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.35ms, accelerator: 7.86ms, total: 13.22ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.39ms, accelerator: 0us, total: 102.39ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10225467.87sec, total: 10225467.87sec
train2.py:307:<module>, cpu: 102.45ms, accelerator: 0us, total: 102.45ms
  iterator_ops.py:373:get_next, cpu: 102.39ms, accelerator: 0us, total: 102.39ms
train2.py:333:<module>, cpu: 5.98ms, accelerator: 14.16ms, total: 20.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_451000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_451250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_451500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_451750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10202845.13sec, total: 10202845.13sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.36ms, accelerator: 0us, total: 102.36ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.34ms, accelerator: 7.87ms, total: 13.21ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.36ms, accelerator: 0us, total: 102.36ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10202845.15sec, total: 10202845.15sec
train2.py:307:<module>, cpu: 102.42ms, accelerator: 0us, total: 102.42ms
  iterator_ops.py:373:get_next, cpu: 102.36ms, accelerator: 0us, total: 102.36ms
train2.py:333:<module>, cpu: 5.97ms, accelerator: 14.17ms, total: 20.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_452000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_452250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_452500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_452750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 350us, accelerator: 10180322.29sec, total: 10180322.29sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.71ms, accelerator: 0us, total: 104.71ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.33ms, accelerator: 7.87ms, total: 13.21ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.71ms, accelerator: 0us, total: 104.71ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10180322.31sec, total: 10180322.32sec
train2.py:307:<module>, cpu: 104.77ms, accelerator: 0us, total: 104.77ms
  iterator_ops.py:373:get_next, cpu: 104.71ms, accelerator: 0us, total: 104.71ms
train2.py:333:<module>, cpu: 5.96ms, accelerator: 14.18ms, total: 20.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_453000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_453250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_453500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_453750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 10157898.68sec, total: 10157898.68sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.61ms, accelerator: 0us, total: 104.61ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.32ms, accelerator: 7.87ms, total: 13.20ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.61ms, accelerator: 0us, total: 104.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10157898.69sec, total: 10157898.70sec
train2.py:307:<module>, cpu: 104.67ms, accelerator: 0us, total: 104.67ms
  iterator_ops.py:373:get_next, cpu: 104.61ms, accelerator: 0us, total: 104.61ms
train2.py:333:<module>, cpu: 5.95ms, accelerator: 14.17ms, total: 20.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_454000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_454250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_454500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_454750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 10135573.62sec, total: 10135573.62sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.50ms, accelerator: 0us, total: 104.50ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.31ms, accelerator: 7.88ms, total: 13.19ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.50ms, accelerator: 0us, total: 104.50ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10135573.64sec, total: 10135573.65sec
train2.py:307:<module>, cpu: 104.56ms, accelerator: 0us, total: 104.56ms
  iterator_ops.py:373:get_next, cpu: 104.50ms, accelerator: 0us, total: 104.50ms
train2.py:333:<module>, cpu: 5.94ms, accelerator: 14.18ms, total: 20.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_455000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_455250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_455500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_455750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 10113346.49sec, total: 10113346.49sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.38ms, accelerator: 0us, total: 104.38ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.30ms, accelerator: 7.87ms, total: 13.18ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.38ms, accelerator: 0us, total: 104.38ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10113346.51sec, total: 10113346.51sec
train2.py:307:<module>, cpu: 104.45ms, accelerator: 0us, total: 104.45ms
  iterator_ops.py:373:get_next, cpu: 104.38ms, accelerator: 0us, total: 104.38ms
train2.py:333:<module>, cpu: 5.93ms, accelerator: 14.17ms, total: 20.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_456000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_456250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_456500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_456750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 10091216.63sec, total: 10091216.63sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.27ms, accelerator: 0us, total: 104.27ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.29ms, accelerator: 7.87ms, total: 13.18ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.27ms, accelerator: 0us, total: 104.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10091216.65sec, total: 10091216.65sec
train2.py:307:<module>, cpu: 104.33ms, accelerator: 0us, total: 104.33ms
  iterator_ops.py:373:get_next, cpu: 104.27ms, accelerator: 0us, total: 104.27ms
train2.py:333:<module>, cpu: 5.92ms, accelerator: 14.18ms, total: 20.13ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_457000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_457250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_457500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_457750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 10069183.40sec, total: 10069183.40sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.19ms, accelerator: 0us, total: 104.19ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.29ms, accelerator: 7.87ms, total: 13.16ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.19ms, accelerator: 0us, total: 104.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10069183.42sec, total: 10069183.43sec
train2.py:307:<module>, cpu: 104.26ms, accelerator: 0us, total: 104.26ms
  iterator_ops.py:373:get_next, cpu: 104.19ms, accelerator: 0us, total: 104.19ms
train2.py:333:<module>, cpu: 5.91ms, accelerator: 14.18ms, total: 20.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_458000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_458250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_458500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_458750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 10047246.18sec, total: 10047246.18sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.16ms, accelerator: 0us, total: 104.16ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.28ms, accelerator: 7.88ms, total: 13.16ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.16ms, accelerator: 0us, total: 104.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10047246.20sec, total: 10047246.21sec
train2.py:307:<module>, cpu: 104.23ms, accelerator: 0us, total: 104.23ms
  iterator_ops.py:373:get_next, cpu: 104.16ms, accelerator: 0us, total: 104.16ms
train2.py:333:<module>, cpu: 5.91ms, accelerator: 14.18ms, total: 20.11ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_459000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_459250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_459500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_459750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 10025404.35sec, total: 10025404.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.12ms, accelerator: 0us, total: 104.12ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.27ms, accelerator: 7.88ms, total: 13.15ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.12ms, accelerator: 0us, total: 104.12ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10025404.36sec, total: 10025404.37sec
train2.py:307:<module>, cpu: 104.18ms, accelerator: 0us, total: 104.18ms
  iterator_ops.py:373:get_next, cpu: 104.12ms, accelerator: 0us, total: 104.12ms
train2.py:333:<module>, cpu: 5.90ms, accelerator: 14.18ms, total: 20.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_460000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_460250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_460500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_460750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 10003657.26sec, total: 10003657.26sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.02ms, accelerator: 0us, total: 104.02ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.26ms, accelerator: 7.87ms, total: 13.14ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.02ms, accelerator: 0us, total: 104.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 10003657.28sec, total: 10003657.29sec
train2.py:307:<module>, cpu: 104.08ms, accelerator: 0us, total: 104.08ms
  iterator_ops.py:373:get_next, cpu: 104.02ms, accelerator: 0us, total: 104.02ms
train2.py:333:<module>, cpu: 5.89ms, accelerator: 14.17ms, total: 20.09ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_461000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_461250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_461500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_461750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9982004.33sec, total: 9982004.33sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.93ms, accelerator: 0us, total: 103.93ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.25ms, accelerator: 7.87ms, total: 13.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.93ms, accelerator: 0us, total: 103.93ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9982004.35sec, total: 9982004.35sec
train2.py:307:<module>, cpu: 103.99ms, accelerator: 0us, total: 103.99ms
  iterator_ops.py:373:get_next, cpu: 103.93ms, accelerator: 0us, total: 103.93ms
train2.py:333:<module>, cpu: 5.88ms, accelerator: 14.17ms, total: 20.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_462000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_462250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_462500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_462750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9960444.92sec, total: 9960444.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.83ms, accelerator: 0us, total: 103.83ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.24ms, accelerator: 7.87ms, total: 13.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.83ms, accelerator: 0us, total: 103.83ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9960444.94sec, total: 9960444.94sec
train2.py:307:<module>, cpu: 103.90ms, accelerator: 0us, total: 103.90ms
  iterator_ops.py:373:get_next, cpu: 103.83ms, accelerator: 0us, total: 103.83ms
train2.py:333:<module>, cpu: 5.87ms, accelerator: 14.17ms, total: 20.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_463000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_463250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_463500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_463750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9938978.45sec, total: 9938978.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.79ms, accelerator: 0us, total: 103.79ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.23ms, accelerator: 7.86ms, total: 13.10ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.79ms, accelerator: 0us, total: 103.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9938978.46sec, total: 9938978.47sec
train2.py:307:<module>, cpu: 103.86ms, accelerator: 0us, total: 103.86ms
  iterator_ops.py:373:get_next, cpu: 103.79ms, accelerator: 0us, total: 103.79ms
train2.py:333:<module>, cpu: 5.86ms, accelerator: 14.16ms, total: 20.05ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_464000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_464250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_464500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_464750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9917604.30sec, total: 9917604.30sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.72ms, accelerator: 0us, total: 103.72ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.22ms, accelerator: 7.86ms, total: 13.09ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.72ms, accelerator: 0us, total: 103.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9917604.32sec, total: 9917604.32sec
train2.py:307:<module>, cpu: 103.78ms, accelerator: 0us, total: 103.78ms
  iterator_ops.py:373:get_next, cpu: 103.72ms, accelerator: 0us, total: 103.72ms
train2.py:333:<module>, cpu: 5.85ms, accelerator: 14.16ms, total: 20.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_465000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_465250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_465500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_465750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9896321.89sec, total: 9896321.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.62ms, accelerator: 0us, total: 103.62ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.21ms, accelerator: 7.86ms, total: 13.08ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.62ms, accelerator: 0us, total: 103.62ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9896321.90sec, total: 9896321.91sec
train2.py:307:<module>, cpu: 103.68ms, accelerator: 0us, total: 103.68ms
  iterator_ops.py:373:get_next, cpu: 103.62ms, accelerator: 0us, total: 103.62ms
train2.py:333:<module>, cpu: 5.84ms, accelerator: 14.16ms, total: 20.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_466000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_466250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_466500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_466750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9875130.62sec, total: 9875130.62sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.50ms, accelerator: 0us, total: 103.50ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.21ms, accelerator: 7.86ms, total: 13.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.50ms, accelerator: 0us, total: 103.50ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9875130.64sec, total: 9875130.64sec
train2.py:307:<module>, cpu: 103.56ms, accelerator: 0us, total: 103.56ms
  iterator_ops.py:373:get_next, cpu: 103.50ms, accelerator: 0us, total: 103.50ms
train2.py:333:<module>, cpu: 5.83ms, accelerator: 14.17ms, total: 20.03ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_467000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_467250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_467500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_467750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9854029.91sec, total: 9854029.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.38ms, accelerator: 0us, total: 103.38ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.20ms, accelerator: 7.86ms, total: 13.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.38ms, accelerator: 0us, total: 103.38ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9854029.93sec, total: 9854029.93sec
train2.py:307:<module>, cpu: 103.45ms, accelerator: 0us, total: 103.45ms
  iterator_ops.py:373:get_next, cpu: 103.38ms, accelerator: 0us, total: 103.38ms
train2.py:333:<module>, cpu: 5.83ms, accelerator: 14.16ms, total: 20.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_468000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_468250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_468500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_468750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9833019.19sec, total: 9833019.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.29ms, accelerator: 0us, total: 103.29ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.19ms, accelerator: 7.86ms, total: 13.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.29ms, accelerator: 0us, total: 103.29ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9833019.21sec, total: 9833019.21sec
train2.py:307:<module>, cpu: 103.36ms, accelerator: 0us, total: 103.36ms
  iterator_ops.py:373:get_next, cpu: 103.29ms, accelerator: 0us, total: 103.29ms
train2.py:333:<module>, cpu: 5.82ms, accelerator: 14.17ms, total: 20.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_469000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_469250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_469500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_469750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9812097.87sec, total: 9812097.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.23ms, accelerator: 0us, total: 103.23ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.18ms, accelerator: 7.87ms, total: 13.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.23ms, accelerator: 0us, total: 103.23ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9812097.89sec, total: 9812097.89sec
train2.py:307:<module>, cpu: 103.29ms, accelerator: 0us, total: 103.29ms
  iterator_ops.py:373:get_next, cpu: 103.23ms, accelerator: 0us, total: 103.23ms
train2.py:333:<module>, cpu: 5.81ms, accelerator: 14.17ms, total: 20.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_470000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_470250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_470500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_470750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9791265.39sec, total: 9791265.39sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.22ms, accelerator: 0us, total: 103.22ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.17ms, accelerator: 7.87ms, total: 13.04ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.22ms, accelerator: 0us, total: 103.22ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9791265.41sec, total: 9791265.41sec
train2.py:307:<module>, cpu: 103.29ms, accelerator: 0us, total: 103.29ms
  iterator_ops.py:373:get_next, cpu: 103.22ms, accelerator: 0us, total: 103.22ms
train2.py:333:<module>, cpu: 5.80ms, accelerator: 14.17ms, total: 19.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_471000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_471250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_471500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_471750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9770521.18sec, total: 9770521.18sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.20ms, accelerator: 0us, total: 103.20ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.16ms, accelerator: 7.86ms, total: 13.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.20ms, accelerator: 0us, total: 103.20ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9770521.20sec, total: 9770521.21sec
train2.py:307:<module>, cpu: 103.26ms, accelerator: 0us, total: 103.26ms
  iterator_ops.py:373:get_next, cpu: 103.20ms, accelerator: 0us, total: 103.20ms
train2.py:333:<module>, cpu: 5.79ms, accelerator: 14.16ms, total: 19.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_472000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_472250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_472500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_472750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9749864.69sec, total: 9749864.69sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.12ms, accelerator: 0us, total: 103.12ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.15ms, accelerator: 7.86ms, total: 13.02ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.12ms, accelerator: 0us, total: 103.12ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9749864.71sec, total: 9749864.71sec
train2.py:307:<module>, cpu: 103.18ms, accelerator: 0us, total: 103.18ms
  iterator_ops.py:373:get_next, cpu: 103.12ms, accelerator: 0us, total: 103.12ms
train2.py:333:<module>, cpu: 5.78ms, accelerator: 14.16ms, total: 19.97ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_473000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_473250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_473500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_473750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9729295.36sec, total: 9729295.36sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.05ms, accelerator: 0us, total: 103.05ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.14ms, accelerator: 7.86ms, total: 13.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.05ms, accelerator: 0us, total: 103.05ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9729295.38sec, total: 9729295.38sec
train2.py:307:<module>, cpu: 103.11ms, accelerator: 0us, total: 103.11ms
  iterator_ops.py:373:get_next, cpu: 103.05ms, accelerator: 0us, total: 103.05ms
train2.py:333:<module>, cpu: 5.77ms, accelerator: 14.16ms, total: 19.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_474000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_474250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_474500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_474750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9708812.63sec, total: 9708812.63sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.98ms, accelerator: 0us, total: 102.98ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.14ms, accelerator: 7.85ms, total: 13.00ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.98ms, accelerator: 0us, total: 102.98ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9708812.65sec, total: 9708812.65sec
train2.py:307:<module>, cpu: 103.04ms, accelerator: 0us, total: 103.04ms
  iterator_ops.py:373:get_next, cpu: 102.98ms, accelerator: 0us, total: 102.98ms
train2.py:333:<module>, cpu: 5.76ms, accelerator: 14.16ms, total: 19.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_475000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_475250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_475500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_475750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9688415.96sec, total: 9688415.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.89ms, accelerator: 0us, total: 102.89ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.13ms, accelerator: 7.85ms, total: 12.98ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.89ms, accelerator: 0us, total: 102.89ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9688415.98sec, total: 9688415.99sec
train2.py:307:<module>, cpu: 102.95ms, accelerator: 0us, total: 102.95ms
  iterator_ops.py:373:get_next, cpu: 102.89ms, accelerator: 0us, total: 102.89ms
train2.py:333:<module>, cpu: 5.76ms, accelerator: 14.15ms, total: 19.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_476000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_476250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_476500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_476750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9668104.82sec, total: 9668104.82sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.82ms, accelerator: 0us, total: 102.82ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.12ms, accelerator: 7.85ms, total: 12.98ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.82ms, accelerator: 0us, total: 102.82ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9668104.84sec, total: 9668104.84sec
train2.py:307:<module>, cpu: 102.88ms, accelerator: 0us, total: 102.88ms
  iterator_ops.py:373:get_next, cpu: 102.82ms, accelerator: 0us, total: 102.82ms
train2.py:333:<module>, cpu: 5.75ms, accelerator: 14.15ms, total: 19.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_477000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_477250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_477500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_477750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9647878.66sec, total: 9647878.66sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.78ms, accelerator: 0us, total: 102.78ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.11ms, accelerator: 7.85ms, total: 12.97ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.78ms, accelerator: 0us, total: 102.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9647878.68sec, total: 9647878.68sec
train2.py:307:<module>, cpu: 102.84ms, accelerator: 0us, total: 102.84ms
  iterator_ops.py:373:get_next, cpu: 102.78ms, accelerator: 0us, total: 102.78ms
train2.py:333:<module>, cpu: 5.74ms, accelerator: 14.15ms, total: 19.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_478000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_478250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_478500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_478750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9627736.95sec, total: 9627736.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.71ms, accelerator: 0us, total: 102.71ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.10ms, accelerator: 7.85ms, total: 12.96ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.71ms, accelerator: 0us, total: 102.71ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9627736.97sec, total: 9627736.97sec
train2.py:307:<module>, cpu: 102.77ms, accelerator: 0us, total: 102.77ms
  iterator_ops.py:373:get_next, cpu: 102.71ms, accelerator: 0us, total: 102.71ms
train2.py:333:<module>, cpu: 5.73ms, accelerator: 14.15ms, total: 19.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_479000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_479250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_479500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_479750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9607679.16sec, total: 9607679.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.68ms, accelerator: 0us, total: 102.68ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.09ms, accelerator: 7.85ms, total: 12.95ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.68ms, accelerator: 0us, total: 102.68ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9607679.18sec, total: 9607679.19sec
train2.py:307:<module>, cpu: 102.74ms, accelerator: 0us, total: 102.74ms
  iterator_ops.py:373:get_next, cpu: 102.68ms, accelerator: 0us, total: 102.68ms
train2.py:333:<module>, cpu: 5.72ms, accelerator: 14.15ms, total: 19.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_480000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_480250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_480500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_480750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9587704.78sec, total: 9587704.78sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.58ms, accelerator: 0us, total: 102.58ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.08ms, accelerator: 7.84ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.58ms, accelerator: 0us, total: 102.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9587704.80sec, total: 9587704.80sec
train2.py:307:<module>, cpu: 102.64ms, accelerator: 0us, total: 102.64ms
  iterator_ops.py:373:get_next, cpu: 102.58ms, accelerator: 0us, total: 102.58ms
train2.py:333:<module>, cpu: 5.71ms, accelerator: 14.15ms, total: 19.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_481000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_481250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_481500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_481750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9567813.28sec, total: 9567813.28sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 102.47ms, accelerator: 0us, total: 102.47ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.08ms, accelerator: 7.85ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 102.47ms, accelerator: 0us, total: 102.47ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9567813.29sec, total: 9567813.30sec
train2.py:307:<module>, cpu: 102.53ms, accelerator: 0us, total: 102.53ms
  iterator_ops.py:373:get_next, cpu: 102.47ms, accelerator: 0us, total: 102.47ms
train2.py:333:<module>, cpu: 5.71ms, accelerator: 14.15ms, total: 19.88ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_482000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_482250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_482500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_482750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9548004.14sec, total: 9548004.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.50ms, accelerator: 0us, total: 104.50ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.07ms, accelerator: 7.85ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.50ms, accelerator: 0us, total: 104.50ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9548004.16sec, total: 9548004.16sec
train2.py:307:<module>, cpu: 104.56ms, accelerator: 0us, total: 104.56ms
  iterator_ops.py:373:get_next, cpu: 104.50ms, accelerator: 0us, total: 104.50ms
train2.py:333:<module>, cpu: 5.70ms, accelerator: 14.15ms, total: 19.88ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_483000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_483250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_483500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_483750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9528276.86sec, total: 9528276.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.46ms, accelerator: 0us, total: 104.46ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.06ms, accelerator: 7.85ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.46ms, accelerator: 0us, total: 104.46ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9528276.88sec, total: 9528276.88sec
train2.py:307:<module>, cpu: 104.52ms, accelerator: 0us, total: 104.52ms
  iterator_ops.py:373:get_next, cpu: 104.46ms, accelerator: 0us, total: 104.46ms
train2.py:333:<module>, cpu: 5.69ms, accelerator: 14.16ms, total: 19.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_484000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_484250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_484500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_484750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9508630.93sec, total: 9508630.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.36ms, accelerator: 0us, total: 104.36ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.05ms, accelerator: 7.85ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.36ms, accelerator: 0us, total: 104.36ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9508630.94sec, total: 9508630.95sec
train2.py:307:<module>, cpu: 104.42ms, accelerator: 0us, total: 104.42ms
  iterator_ops.py:373:get_next, cpu: 104.36ms, accelerator: 0us, total: 104.36ms
train2.py:333:<module>, cpu: 5.68ms, accelerator: 14.16ms, total: 19.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_485000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_485250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_485500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_485750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9489065.84sec, total: 9489065.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.31ms, accelerator: 0us, total: 104.31ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.04ms, accelerator: 7.85ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.31ms, accelerator: 0us, total: 104.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.99ms, accelerator: 9489065.86sec, total: 9489065.86sec
train2.py:307:<module>, cpu: 104.37ms, accelerator: 0us, total: 104.37ms
  iterator_ops.py:373:get_next, cpu: 104.31ms, accelerator: 0us, total: 104.31ms
train2.py:333:<module>, cpu: 5.67ms, accelerator: 14.17ms, total: 19.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_486000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_486250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_486500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_486750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9469581.11sec, total: 9469581.11sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.28ms, accelerator: 0us, total: 104.28ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.04ms, accelerator: 7.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.28ms, accelerator: 0us, total: 104.28ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9469581.13sec, total: 9469581.13sec
train2.py:307:<module>, cpu: 104.34ms, accelerator: 0us, total: 104.34ms
  iterator_ops.py:373:get_next, cpu: 104.28ms, accelerator: 0us, total: 104.28ms
train2.py:333:<module>, cpu: 5.67ms, accelerator: 14.17ms, total: 19.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_487000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_487250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_487500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_487750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9450176.23sec, total: 9450176.23sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.17ms, accelerator: 0us, total: 104.17ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.03ms, accelerator: 7.85ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.17ms, accelerator: 0us, total: 104.17ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9450176.25sec, total: 9450176.25sec
train2.py:307:<module>, cpu: 104.23ms, accelerator: 0us, total: 104.23ms
  iterator_ops.py:373:get_next, cpu: 104.17ms, accelerator: 0us, total: 104.17ms
train2.py:333:<module>, cpu: 5.66ms, accelerator: 14.16ms, total: 19.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_488000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_488250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_488500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_488750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9430850.71sec, total: 9430850.71sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.07ms, accelerator: 0us, total: 104.07ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.02ms, accelerator: 7.84ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.07ms, accelerator: 0us, total: 104.07ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9430850.73sec, total: 9430850.74sec
train2.py:307:<module>, cpu: 104.13ms, accelerator: 0us, total: 104.13ms
  iterator_ops.py:373:get_next, cpu: 104.07ms, accelerator: 0us, total: 104.07ms
train2.py:333:<module>, cpu: 5.65ms, accelerator: 14.16ms, total: 19.84ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_489000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_489250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_489500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_489750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9411604.08sec, total: 9411604.08sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 104.00ms, accelerator: 0us, total: 104.00ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.01ms, accelerator: 7.84ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 104.00ms, accelerator: 0us, total: 104.00ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9411604.10sec, total: 9411604.10sec
train2.py:307:<module>, cpu: 104.06ms, accelerator: 0us, total: 104.06ms
  iterator_ops.py:373:get_next, cpu: 104.00ms, accelerator: 0us, total: 104.00ms
train2.py:333:<module>, cpu: 5.64ms, accelerator: 14.16ms, total: 19.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_490000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_490250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_490500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_490750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9392435.84sec, total: 9392435.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.90ms, accelerator: 0us, total: 103.90ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.00ms, accelerator: 7.84ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.90ms, accelerator: 0us, total: 103.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9392435.86sec, total: 9392435.86sec
train2.py:307:<module>, cpu: 103.96ms, accelerator: 0us, total: 103.96ms
  iterator_ops.py:373:get_next, cpu: 103.90ms, accelerator: 0us, total: 103.90ms
train2.py:333:<module>, cpu: 5.63ms, accelerator: 14.16ms, total: 19.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_491000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_491250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_491500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_491750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9373345.53sec, total: 9373345.53sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.84ms, accelerator: 0us, total: 103.84ms (0.00%)
top 3 operation type: Conv2D, cpu: 5.00ms, accelerator: 7.84ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.84ms, accelerator: 0us, total: 103.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9373345.55sec, total: 9373345.55sec
train2.py:307:<module>, cpu: 103.90ms, accelerator: 0us, total: 103.90ms
  iterator_ops.py:373:get_next, cpu: 103.84ms, accelerator: 0us, total: 103.84ms
train2.py:333:<module>, cpu: 5.62ms, accelerator: 14.17ms, total: 19.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_492000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_492250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_492500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_492750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9354332.65sec, total: 9354332.66sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.76ms, accelerator: 0us, total: 103.76ms (0.00%)
top 3 operation type: Conv2D, cpu: 4.99ms, accelerator: 7.84ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.76ms, accelerator: 0us, total: 103.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9354332.67sec, total: 9354332.68sec
train2.py:307:<module>, cpu: 103.82ms, accelerator: 0us, total: 103.82ms
  iterator_ops.py:373:get_next, cpu: 103.76ms, accelerator: 0us, total: 103.76ms
train2.py:333:<module>, cpu: 5.62ms, accelerator: 14.17ms, total: 19.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_493000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_493250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_493500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_493750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9335396.76sec, total: 9335396.76sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.70ms, accelerator: 0us, total: 103.70ms (0.00%)
top 3 operation type: Conv2D, cpu: 4.98ms, accelerator: 7.85ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.70ms, accelerator: 0us, total: 103.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9335396.78sec, total: 9335396.78sec
train2.py:307:<module>, cpu: 103.76ms, accelerator: 0us, total: 103.76ms
  iterator_ops.py:373:get_next, cpu: 103.70ms, accelerator: 0us, total: 103.70ms
train2.py:333:<module>, cpu: 5.61ms, accelerator: 14.17ms, total: 19.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_494000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_494250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_494500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_494750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9316537.37sec, total: 9316537.37sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.62ms, accelerator: 0us, total: 103.62ms (0.00%)
top 3 operation type: Conv2D, cpu: 4.97ms, accelerator: 7.84ms, total: 12.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.62ms, accelerator: 0us, total: 103.62ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9316537.39sec, total: 9316537.39sec
train2.py:307:<module>, cpu: 103.68ms, accelerator: 0us, total: 103.68ms
  iterator_ops.py:373:get_next, cpu: 103.62ms, accelerator: 0us, total: 103.62ms
train2.py:333:<module>, cpu: 5.60ms, accelerator: 14.18ms, total: 19.80ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_495000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_495250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_495500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_495750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9297754.03sec, total: 9297754.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.52ms, accelerator: 0us, total: 103.52ms (0.00%)
top 3 operation type: Conv2D, cpu: 4.96ms, accelerator: 7.84ms, total: 12.81ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.52ms, accelerator: 0us, total: 103.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9297754.05sec, total: 9297754.05sec
train2.py:307:<module>, cpu: 103.58ms, accelerator: 0us, total: 103.58ms
  iterator_ops.py:373:get_next, cpu: 103.52ms, accelerator: 0us, total: 103.52ms
train2.py:333:<module>, cpu: 5.59ms, accelerator: 14.16ms, total: 19.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_496000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_496250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_496500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_496750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9279046.28sec, total: 9279046.28sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.40ms, accelerator: 0us, total: 103.40ms (0.00%)
top 3 operation type: Conv2D, cpu: 4.96ms, accelerator: 7.84ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.40ms, accelerator: 0us, total: 103.40ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9279046.29sec, total: 9279046.30sec
train2.py:307:<module>, cpu: 103.46ms, accelerator: 0us, total: 103.46ms
  iterator_ops.py:373:get_next, cpu: 103.40ms, accelerator: 0us, total: 103.40ms
train2.py:333:<module>, cpu: 5.59ms, accelerator: 14.17ms, total: 19.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_497000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_497250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_497500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_497750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9260413.65sec, total: 9260413.65sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.33ms, accelerator: 0us, total: 103.33ms (0.00%)
top 3 operation type: Conv2D, cpu: 4.95ms, accelerator: 7.84ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.33ms, accelerator: 0us, total: 103.33ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9260413.67sec, total: 9260413.67sec
train2.py:307:<module>, cpu: 103.39ms, accelerator: 0us, total: 103.39ms
  iterator_ops.py:373:get_next, cpu: 103.33ms, accelerator: 0us, total: 103.33ms
train2.py:333:<module>, cpu: 5.58ms, accelerator: 14.16ms, total: 19.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_498000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_498250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_498500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_498750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9241855.71sec, total: 9241855.71sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.22ms, accelerator: 0us, total: 103.22ms (0.00%)
top 3 operation type: Conv2D, cpu: 4.94ms, accelerator: 7.84ms, total: 12.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.22ms, accelerator: 0us, total: 103.22ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9241855.73sec, total: 9241855.73sec
train2.py:307:<module>, cpu: 103.28ms, accelerator: 0us, total: 103.28ms
  iterator_ops.py:373:get_next, cpu: 103.22ms, accelerator: 0us, total: 103.22ms
train2.py:333:<module>, cpu: 5.57ms, accelerator: 14.16ms, total: 19.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_499000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_499250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_499500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 113.92 MB

******************************************************
Timeline file is written to out/hdf/m18vae/timelines/t.json_499750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: BiasAddGrad, cpu: 349us, accelerator: 9223372.00sec, total: 9223372.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 103.16ms, accelerator: 0us, total: 103.16ms (0.00%)
top 3 operation type: Conv2D, cpu: 4.93ms, accelerator: 7.84ms, total: 12.78ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 103.16ms, accelerator: 0us, total: 103.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:333:<module> (gradient), cpu: 2.98ms, accelerator: 9223372.02sec, total: 9223372.02sec
train2.py:307:<module>, cpu: 103.22ms, accelerator: 0us, total: 103.22ms
  iterator_ops.py:373:get_next, cpu: 103.16ms, accelerator: 0us, total: 103.16ms
train2.py:333:<module>, cpu: 5.56ms, accelerator: 14.16ms, total: 19.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
Tensorflow version: 1.9.0
Current Git Commit: b'79f1c92'
Flags:
	data:                      ['/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0000.061.2017312163938.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0005.061.2017312164120.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0010.061.2017312163717.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0015.061.2017312163647.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0020.061.2017312164026.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0025.061.2017312170014.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0030.061.2017312170322.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0035.061.2017312170308.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0040.061.2017312170906.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0045.061.2017312170007.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0050.061.2017312170825.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0055.061.2017312170034.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0100.061.2017312164411.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0105.061.2017312164429.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0110.061.2017312164415.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0115.061.2017312163804.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0120.061.2017312163833.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0125.061.2017312163816.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0130.061.2017312163931.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0135.061.2017312164019.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0140.061.2017312164010.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0145.061.2017312163913.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0150.061.2017312163742.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0155.061.2017312163752.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0200.061.2017312164207.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0205.061.2017312170745.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0210.061.2017312165925.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0215.061.2017312170645.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0220.061.2017312170213.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0225.061.2017312165117.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0230.061.2017312170320.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0235.061.2017312171514.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0240.061.2017312164710.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0245.061.2017312164508.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0250.061.2017312164113.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0255.061.2017312163752.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0300.061.2017312164019.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0305.061.2017312164025.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0310.061.2017312163928.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0315.061.2017312164106.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0320.061.2017312164215.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0325.061.2017312164104.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0330.061.2017312163820.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0335.061.2017312163810.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0340.061.2017312164555.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0345.061.2017312165645.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0350.061.2017312170229.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0355.061.2017312170104.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0400.061.2017312170319.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0405.061.2017312170209.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0410.061.2017312171142.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0415.061.2017312165945.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0420.061.2017312164312.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0425.061.2017312164627.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0430.061.2017312163906.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0435.061.2017312163953.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0440.061.2017312164003.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0445.061.2017312163932.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0450.061.2017312163851.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0455.061.2017312164002.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0500.061.2017312163941.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0505.061.2017312163903.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0510.061.2017312163825.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0515.061.2017312164057.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0520.061.2017312165037.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0525.061.2017312165647.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0530.061.2017312165508.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0535.061.2017312170404.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0540.061.2017312170047.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0545.061.2017312170440.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0550.061.2017312170941.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0555.061.2017312165627.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0600.061.2017312164727.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0605.061.2017312164446.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0610.061.2017312163945.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0615.061.2017312164229.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0620.061.2017312163953.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0625.061.2017312163945.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0630.061.2017312164321.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0635.061.2017312164422.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0640.061.2017312164046.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0645.061.2017312163919.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0650.061.2017312163924.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0655.061.2017312164141.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0700.061.2017312165939.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0705.061.2017312170047.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0710.061.2017312165209.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0715.061.2017312165157.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0720.061.2017312165856.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0725.061.2017312170224.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0730.061.2017312170909.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0735.061.2017312165412.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0740.061.2017312165106.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0745.061.2017312164453.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0750.061.2017312164017.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0755.061.2017312164325.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0800.061.2017312164433.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0805.061.2017312164024.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0810.061.2017312164157.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0815.061.2017312164150.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0820.061.2017312164235.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0825.061.2017312163951.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0830.061.2017312164023.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0835.061.2017312164454.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0840.061.2017312170341.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0845.061.2017312170040.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0850.061.2017312170531.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0855.061.2017312171316.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0900.061.2017312170952.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0905.061.2017312171148.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0910.061.2017312171737.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0915.061.2017312170633.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0920.061.2017312170210.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0925.061.2017312165628.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0930.061.2017312165116.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0935.061.2017312165151.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0940.061.2017312165436.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0945.061.2017312165509.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0950.061.2017312165523.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0955.061.2017312165710.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1000.061.2017312165350.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1005.061.2017312165249.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1010.061.2017312165232.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1015.061.2017312170003.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1020.061.2017312171051.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1025.061.2017312170946.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1030.061.2017312171310.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1035.061.2017312171221.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1040.061.2017312170826.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1045.061.2017312172343.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1050.061.2017312171554.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1055.061.2017312170459.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1100.061.2017312170512.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1105.061.2017312165519.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1110.061.2017312165331.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1115.061.2017312165432.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1120.061.2017312165255.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1125.061.2017312165618.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1130.061.2017312165317.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1135.061.2017312165610.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1140.061.2017312165334.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1145.061.2017312165151.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1150.061.2017312165725.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1155.061.2017312170346.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1200.061.2017312171747.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1205.061.2017312172245.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1210.061.2017312172746.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1215.061.2017312170557.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1220.061.2017312171239.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1225.061.2017312172007.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1230.061.2017312171025.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1235.061.2017312170453.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1240.061.2017312171012.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1245.061.2017312165433.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1250.061.2017312165537.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1255.061.2017312165427.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1300.061.2017312165750.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1305.061.2017312165721.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1310.061.2017312165638.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1315.061.2017312165452.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1320.061.2017312165300.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1325.061.2017312165315.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1330.061.2017312170038.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1335.061.2017312172349.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1340.061.2017312171741.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1345.061.2017312172416.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1350.061.2017312173112.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1355.061.2017312171910.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1400.061.2017312170659.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1405.061.2017312171619.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1410.061.2017312171331.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1415.061.2017312170522.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1420.061.2017312165756.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1425.061.2017312165457.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1430.061.2017312165644.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1435.061.2017312165416.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1440.061.2017312165554.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1445.061.2017312165632.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1450.061.2017312165349.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1455.061.2017312165621.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1500.061.2017312165434.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1505.061.2017312165353.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1510.061.2017312165641.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1515.061.2017312172418.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1520.061.2017312173034.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1525.061.2017312170737.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1530.061.2017312171445.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1535.061.2017312171139.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1540.061.2017312171127.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1545.061.2017312172152.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1550.061.2017312171147.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1555.061.2017312171122.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1600.061.2017312170116.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1605.061.2017312165607.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1610.061.2017312165451.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1615.061.2017312165759.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1620.061.2017312165745.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1625.061.2017312165346.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1630.061.2017312165538.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1635.061.2017312165610.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1640.061.2017312165510.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1645.061.2017312165515.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1650.061.2017312170108.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1655.061.2017312170757.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1700.061.2017312171226.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1705.061.2017312171028.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1710.061.2017312172330.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1715.061.2017312171534.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1720.061.2017312171925.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1725.061.2017312173551.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1730.061.2017312171859.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1735.061.2017312170717.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1740.061.2017312165852.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1745.061.2017312165641.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1750.061.2017312165440.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1755.061.2017312165547.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1800.061.2017312165635.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1805.061.2017312165542.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1810.061.2017312165711.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1815.061.2017312165548.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1820.061.2017312165503.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1825.061.2017312165358.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1830.061.2017312170059.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1835.061.2017312172323.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1840.061.2017312173037.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1845.061.2017312171646.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1850.061.2017312170757.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1855.061.2017312171840.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1900.061.2017312172902.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1905.061.2017312173141.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1910.061.2017312170742.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1915.061.2017312165744.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1920.061.2017312165507.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1925.061.2017312170007.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1930.061.2017312165941.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1935.061.2017312165738.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1940.061.2017312165514.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1945.061.2017312165726.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1950.061.2017312165747.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.1955.061.2017312165648.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2000.061.2017312165734.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2005.061.2017312165815.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2010.061.2017312171118.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2015.061.2017312173902.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2020.061.2017312172611.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2025.061.2017312171055.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2030.061.2017312171239.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2035.061.2017312171943.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2040.061.2017312172036.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2045.061.2017312172041.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2050.061.2017312170259.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2055.061.2017312165807.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2100.061.2017312165634.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2105.061.2017312165830.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2110.061.2017312165734.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2115.061.2017312165701.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2120.061.2017312165622.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2125.061.2017312165803.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2130.061.2017312165846.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2135.061.2017312165700.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2140.061.2017312165534.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2145.061.2017312165905.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2150.061.2017312172819.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2155.061.2017312173201.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2200.061.2017312172149.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2205.061.2017312172636.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2210.061.2017312171822.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2215.061.2017312171310.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2220.061.2017312172247.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2225.061.2017312170916.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2230.061.2017312170049.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2235.061.2017312165827.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2240.061.2017312165627.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2245.061.2017312165756.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2250.061.2017312165721.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2255.061.2017312165820.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2300.061.2017312165616.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2305.061.2017312165713.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2310.061.2017312165815.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2315.061.2017312165720.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2320.061.2017312165639.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2325.061.2017312170032.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2330.061.2017312171440.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2335.061.2017312171515.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2340.061.2017312171516.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2345.061.2017312172715.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2350.061.2017312171342.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.2355.061.2017312172203.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0000.061.2017312161233.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0005.061.2017312154955.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0010.061.2017312154137.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0015.061.2017312154513.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0020.061.2017312154921.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0025.061.2017312154535.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0030.061.2017312154947.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0035.061.2017312155158.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0040.061.2017312154613.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0045.061.2017312154754.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0050.061.2017312154802.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0055.061.2017312154818.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0100.061.2017312154415.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0105.061.2017312155948.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0110.061.2017312160938.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0115.061.2017312160533.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0120.061.2017312161008.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0125.061.2017312160947.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0130.061.2017312160015.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0135.061.2017312160311.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0140.061.2017312160325.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0145.061.2017312154847.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0150.061.2017312154749.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0155.061.2017312154809.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0200.061.2017312154440.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0205.061.2017312154539.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0210.061.2017312154204.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0215.061.2017312154517.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0220.061.2017312154532.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0225.061.2017312154521.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0230.061.2017312154425.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0235.061.2017312154145.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0240.061.2017312154252.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0245.061.2017312155202.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0250.061.2017312160123.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0255.061.2017312160656.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0300.061.2017312160723.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0305.061.2017312160134.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0310.061.2017312155926.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0315.061.2017312160804.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0320.061.2017312155927.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0325.061.2017312154432.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0330.061.2017312154633.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0335.061.2017312154404.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0340.061.2017312154211.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0345.061.2017312154112.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0350.061.2017312154323.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0355.061.2017312154136.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0400.061.2017312154454.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0405.061.2017312154303.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0410.061.2017312154247.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0415.061.2017312155218.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0420.061.2017312154312.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0425.061.2017312155752.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0430.061.2017312160533.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0435.061.2017312161400.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0440.061.2017312162238.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0445.061.2017312160609.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0450.061.2017312161717.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0455.061.2017312162834.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0500.061.2017312160647.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0505.061.2017312155448.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0510.061.2017312155125.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0515.061.2017312154453.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0520.061.2017312154641.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0525.061.2017312154703.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0530.061.2017312154655.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0535.061.2017312154636.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0540.061.2017312155050.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0545.061.2017312154727.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0550.061.2017312154733.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0555.061.2017312154416.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0600.061.2017312154321.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0605.061.2017312155822.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0610.061.2017312155911.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0615.061.2017312155128.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0620.061.2017312155346.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0625.061.2017312155820.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0630.061.2017312160623.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0635.061.2017312160842.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0640.061.2017312155332.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0645.061.2017312155121.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0650.061.2017312154514.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0655.061.2017312154458.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0700.061.2017312154429.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0705.061.2017312154422.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0710.061.2017312154223.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0715.061.2017312154305.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0720.061.2017312154212.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0725.061.2017312154300.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0730.061.2017312154110.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0735.061.2017312154125.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0740.061.2017312154518.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0745.061.2017312155835.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0750.061.2017312155651.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0755.061.2017312155019.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0800.061.2017312155728.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0805.061.2017312155409.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0810.061.2017312161042.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0815.061.2017312160934.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0820.061.2017312154914.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0825.061.2017312154706.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0830.061.2017312154318.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0835.061.2017312154103.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0840.061.2017312154103.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0845.061.2017312154054.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0850.061.2017312154212.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0855.061.2017312154631.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0900.061.2017312153916.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0905.061.2017312154140.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0910.061.2017312154104.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0915.061.2017312154054.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0920.061.2017312155703.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0925.061.2017312155105.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0930.061.2017312155848.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0935.061.2017312160840.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0940.061.2017312161815.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0945.061.2017312160925.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0950.061.2017312161326.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.0955.061.2017312161210.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1000.061.2017312155504.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1005.061.2017312155622.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1010.061.2017312154233.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1015.061.2017312154323.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1020.061.2017312153721.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1025.061.2017312154540.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1030.061.2017312154604.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1035.061.2017312154712.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1040.061.2017312154556.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1045.061.2017312154404.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1050.061.2017312154342.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1055.061.2017312154717.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1100.061.2017312160646.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1105.061.2017312161447.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1110.061.2017312160124.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1115.061.2017312160308.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1120.061.2017312160110.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1125.061.2017312160822.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1130.061.2017312160506.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1135.061.2017312160205.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1140.061.2017312155127.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1145.061.2017312155059.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1150.061.2017312154308.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1155.061.2017312154128.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1200.061.2017312154437.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1205.061.2017312154408.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1210.061.2017312154134.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1215.061.2017312154432.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1220.061.2017312154342.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1225.061.2017312154206.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1230.061.2017312153821.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1235.061.2017312154417.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1240.061.2017312160305.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1245.061.2017312160645.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1250.061.2017312160903.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1255.061.2017312160622.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1300.061.2017312155114.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1305.061.2017312155621.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1310.061.2017312160704.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1315.061.2017312155459.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1320.061.2017312154940.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1325.061.2017312154129.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1330.061.2017312154102.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1335.061.2017312154106.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1340.061.2017312154249.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1345.061.2017312154425.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1350.061.2017312153458.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1355.061.2017312154117.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1400.061.2017312153856.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1405.061.2017312154040.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1410.061.2017312153752.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1415.061.2017312154250.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1420.061.2017312161229.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1425.061.2017312160910.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1430.061.2017312155417.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1435.061.2017312160002.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1440.061.2017312155537.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1445.061.2017312160043.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1450.061.2017312160820.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1455.061.2017312155344.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1500.061.2017312155710.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1505.061.2017312154459.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1510.061.2017312154307.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1515.061.2017312154134.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1520.061.2017312154141.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1525.061.2017312154416.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1530.061.2017312154416.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1535.061.2017312154310.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1540.061.2017312154205.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1545.061.2017312154345.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1550.061.2017312154144.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1555.061.2017312155501.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1600.061.2017312161314.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1605.061.2017312161010.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1610.061.2017312160541.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1615.061.2017312161006.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1620.061.2017312160928.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1625.061.2017312162203.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1630.061.2017312162318.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1635.061.2017312160614.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1640.061.2017312154600.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1645.061.2017312154412.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1650.061.2017312154505.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1655.061.2017312153946.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1700.061.2017312154224.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1705.061.2017312154059.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1710.061.2017312154024.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1715.061.2017312154250.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1720.061.2017312154125.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1725.061.2017312154020.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1730.061.2017312154038.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1735.061.2017312154811.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1740.061.2017312160442.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1745.061.2017312155121.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1750.061.2017312155836.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1755.061.2017312155503.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1800.061.2017312160509.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1805.061.2017312160151.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1810.061.2017312160003.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1815.061.2017312155006.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1820.061.2017312154114.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1825.061.2017312153644.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1830.061.2017312154044.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1835.061.2017312153913.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1840.061.2017312154046.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1845.061.2017312153947.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1850.061.2017312154214.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1855.061.2017312154205.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1900.061.2017312154049.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1905.061.2017312153822.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1910.061.2017312154256.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1915.061.2017312155024.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1920.061.2017312160631.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1925.061.2017312161242.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1930.061.2017312155223.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1935.061.2017312154509.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1940.061.2017312160432.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1945.061.2017312160030.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1950.061.2017312160236.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.1955.061.2017312154155.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2000.061.2017312154302.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2005.061.2017312154118.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2010.061.2017312153831.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2015.061.2017312155021.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2020.061.2017312153243.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2025.061.2017312154034.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2030.061.2017312154058.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2035.061.2017312154007.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2040.061.2017312154446.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2045.061.2017312154236.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2050.061.2017312154548.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2055.061.2017312161053.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2100.061.2017312160551.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2105.061.2017312155832.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2110.061.2017312155716.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2115.061.2017312161536.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2120.061.2017312161433.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2125.061.2017312162116.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2130.061.2017312160049.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2135.061.2017312154618.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2140.061.2017312154556.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2145.061.2017312154313.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2150.061.2017312153601.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2155.061.2017312154409.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2200.061.2017312154204.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2205.061.2017312154042.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2210.061.2017312154119.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2215.061.2017312154100.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2220.061.2017312153824.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2225.061.2017312153811.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2230.061.2017312154549.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2235.061.2017312160505.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2240.061.2017312160024.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2245.061.2017312160133.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2250.061.2017312160129.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2255.061.2017312155140.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2300.061.2017312160836.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2305.061.2017312160239.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2310.061.2017312154800.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2315.061.2017312154200.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2320.061.2017312154120.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2325.061.2017312154023.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2330.061.2017312153420.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2335.061.2017312153519.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2340.061.2017312153726.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2345.061.2017312153906.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2350.061.2017312154046.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_02/MOD06_L2.A2017002.2355.061.2017312153503.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0000.061.2017312153748.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0005.061.2017312153626.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0010.061.2017312154655.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0015.061.2017312155910.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0020.061.2017312155648.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0025.061.2017312160024.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0030.061.2017312160249.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0035.061.2017312155454.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0040.061.2017312155825.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0045.061.2017312155407.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0050.061.2017312154926.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0055.061.2017312153656.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0100.061.2017312153453.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0105.061.2017312154123.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0110.061.2017312153700.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0115.061.2017312153724.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0120.061.2017312154137.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0125.061.2017312153620.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0130.061.2017312153606.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0135.061.2017312154046.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0140.061.2017312153740.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0145.061.2017312154658.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0150.061.2017312154320.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0155.061.2017312155506.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0200.061.2017312161156.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0205.061.2017312160839.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0210.061.2017312160707.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0215.061.2017312155859.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0220.061.2017312161725.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0225.061.2017312155801.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0230.061.2017312154609.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0235.061.2017312154431.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0240.061.2017312153639.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0245.061.2017312153952.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0250.061.2017312153808.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0255.061.2017312154346.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0300.061.2017312154156.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0305.061.2017312154024.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0310.061.2017312153623.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0315.061.2017312154027.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0320.061.2017312154219.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0325.061.2017312154410.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0330.061.2017312155728.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0335.061.2017312161336.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0340.061.2017312160106.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0345.061.2017312160503.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0350.061.2017312155321.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0355.061.2017312160130.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0400.061.2017312160634.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0405.061.2017312154711.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0410.061.2017312154133.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0415.061.2017312154212.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0420.061.2017312153643.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0425.061.2017312153714.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0430.061.2017312154120.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0435.061.2017312153849.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0440.061.2017312154046.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0445.061.2017312154159.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0450.061.2017312153916.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0455.061.2017312154030.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0500.061.2017312153815.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0505.061.2017312153720.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0510.061.2017312155012.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0515.061.2017312155016.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0520.061.2017312155154.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0525.061.2017312155621.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0530.061.2017312154733.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0535.061.2017312155636.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0540.061.2017312155951.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0545.061.2017312154428.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0550.061.2017312153912.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0555.061.2017312153708.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0600.061.2017312153510.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0605.061.2017312153705.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0610.061.2017312153503.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0615.061.2017312153654.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0620.061.2017312154232.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0625.061.2017312153611.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0630.061.2017312153408.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0635.061.2017312154047.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0640.061.2017312153358.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0645.061.2017312154446.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0650.061.2017312155648.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0655.061.2017312154609.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0700.061.2017312154636.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0705.061.2017312154427.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0710.061.2017312155217.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0715.061.2017312160640.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0720.061.2017312160346.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0725.061.2017312154411.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0730.061.2017312154538.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0735.061.2017312153857.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0740.061.2017312153902.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0745.061.2017312153622.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0750.061.2017312153606.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0755.061.2017312153658.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0800.061.2017312153707.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0805.061.2017312153757.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0810.061.2017312154221.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0815.061.2017312153726.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0820.061.2017312154230.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0825.061.2017312155454.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0830.061.2017312155828.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0835.061.2017312155721.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0840.061.2017312155344.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0845.061.2017312160433.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0850.061.2017312160345.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0855.061.2017312161853.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0900.061.2017312160814.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0905.061.2017312154733.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0910.061.2017312154330.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0915.061.2017312154105.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0920.061.2017312153717.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0925.061.2017312153401.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0930.061.2017312154059.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0935.061.2017312153614.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0940.061.2017312153510.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0945.061.2017312153548.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0950.061.2017312153555.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.0955.061.2017312153331.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1000.061.2017312154744.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1005.061.2017312155006.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1010.061.2017312155135.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1015.061.2017312154753.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1020.061.2017312155401.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1025.061.2017312155226.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1030.061.2017312155544.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1035.061.2017312160726.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1040.061.2017312155202.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1045.061.2017312154607.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1050.061.2017312154000.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1055.061.2017312153510.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1100.061.2017312153511.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1105.061.2017312153627.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1110.061.2017312153632.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1115.061.2017312153556.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1120.061.2017312154246.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1125.061.2017312153824.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1130.061.2017312153501.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1135.061.2017312153450.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1140.061.2017312153714.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1145.061.2017312155801.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1150.061.2017312155357.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1155.061.2017312154655.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1200.061.2017312155458.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1205.061.2017312160008.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1210.061.2017312155353.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1215.061.2017312160446.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1220.061.2017312154720.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1225.061.2017312155043.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1230.061.2017312154036.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1235.061.2017312153504.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1240.061.2017312153655.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1245.061.2017312154155.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1250.061.2017312154131.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1255.061.2017312153428.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1300.061.2017312153752.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1305.061.2017312153553.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1310.061.2017312153638.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1315.061.2017312153452.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1320.061.2017312154240.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1325.061.2017312161329.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1330.061.2017312160724.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1335.061.2017312161439.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1340.061.2017312160521.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1345.061.2017312160336.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1350.061.2017312160252.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1355.061.2017312162001.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1400.061.2017312160110.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1405.061.2017312155600.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1410.061.2017312155016.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1415.061.2017312154827.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1420.061.2017312154714.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1425.061.2017312154851.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1430.061.2017312155123.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1435.061.2017312154618.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1440.061.2017312154746.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1445.061.2017312154533.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1450.061.2017312154659.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1455.061.2017312154658.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1500.061.2017312155714.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1505.061.2017312161439.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1510.061.2017312160529.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1515.061.2017312160617.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1520.061.2017312160344.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1525.061.2017312155924.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1530.061.2017312161151.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1535.061.2017312161125.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1540.061.2017312160832.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1545.061.2017312155008.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1550.061.2017312154746.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1555.061.2017312154801.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1600.061.2017312154659.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1605.061.2017312155052.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1610.061.2017312154657.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1615.061.2017312154810.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1620.061.2017312154959.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1625.061.2017312154556.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1630.061.2017312154734.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1635.061.2017312154707.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1640.061.2017312160100.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1645.061.2017312161001.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1650.061.2017312160155.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1655.061.2017312160513.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1700.061.2017312160422.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1705.061.2017312160637.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1710.061.2017312161700.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1715.061.2017312161104.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1720.061.2017312155819.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1725.061.2017312154836.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1730.061.2017312155009.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1735.061.2017312154637.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1740.061.2017312154736.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1745.061.2017312154612.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1750.061.2017312154727.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1755.061.2017312154802.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1800.061.2017312154720.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1805.061.2017312154746.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1810.061.2017312154724.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1815.061.2017312155046.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1820.061.2017312161115.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1825.061.2017312160737.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1830.061.2017312161130.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1835.061.2017312160731.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1840.061.2017312160701.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1845.061.2017312161442.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1850.061.2017312161047.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1855.061.2017312160557.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1900.061.2017312155418.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1905.061.2017312155054.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1910.061.2017312154819.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1915.061.2017312154808.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1920.061.2017312154948.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1925.061.2017312154914.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1930.061.2017312154746.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1935.061.2017312155022.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1940.061.2017312155006.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1945.061.2017312154908.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1950.061.2017312154844.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.1955.061.2017312155247.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2000.061.2017312160926.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2005.061.2017312161123.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2010.061.2017312161009.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2015.061.2017312160329.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2020.061.2017312161237.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2025.061.2017312161554.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2030.061.2017312161536.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2035.061.2017312160816.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2040.061.2017312155101.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2045.061.2017312154953.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2050.061.2017312155122.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2055.061.2017312154839.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2100.061.2017312154904.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2105.061.2017312154839.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2110.061.2017312154649.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2115.061.2017312155035.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2120.061.2017312155105.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2125.061.2017312154738.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2130.061.2017312154849.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2135.061.2017312160333.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2140.061.2017312161717.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2145.061.2017312161030.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2150.061.2017312162057.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2155.061.2017312160940.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2200.061.2017312160920.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2205.061.2017312161546.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2210.061.2017312162558.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2215.061.2017312155542.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2220.061.2017312155005.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2225.061.2017312155043.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2230.061.2017312154750.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2235.061.2017312155020.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2240.061.2017312154822.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2245.061.2017312154829.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2250.061.2017312154811.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2255.061.2017312154941.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2300.061.2017312154848.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2305.061.2017312154858.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2310.061.2017312154806.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2315.061.2017312160346.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2320.061.2017312162956.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2325.061.2017312161338.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2330.061.2017312161317.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2335.061.2017312161856.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2340.061.2017312160641.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2345.061.2017312162205.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2350.061.2017312161236.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_03/MOD06_L2.A2017003.2355.061.2017312155857.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0000.061.2017312155229.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0005.061.2017312154911.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0010.061.2017312155417.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0015.061.2017312155016.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0020.061.2017312155145.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0025.061.2017312155124.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0030.061.2017312155100.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0035.061.2017312155114.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0040.061.2017312154905.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0045.061.2017312155048.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0050.061.2017312155300.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0055.061.2017312161415.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0100.061.2017312162654.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0105.061.2017312162314.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0110.061.2017312161237.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0115.061.2017312160547.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0120.061.2017312160753.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0125.061.2017312161749.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0130.061.2017312155956.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0135.061.2017312155452.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0140.061.2017312155638.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0145.061.2017312155317.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0150.061.2017312155103.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0155.061.2017312155018.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0200.061.2017312155116.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0205.061.2017312155021.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0210.061.2017312155128.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0215.061.2017312155114.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0220.061.2017312155221.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0225.061.2017312155028.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0230.061.2017312155246.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0235.061.2017312160911.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0240.061.2017312162157.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0245.061.2017312162103.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0250.061.2017312162656.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0255.061.2017312160510.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0300.061.2017312162831.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0305.061.2017312162457.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0310.061.2017312160023.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0315.061.2017312155520.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0320.061.2017312155221.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0325.061.2017312154828.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0330.061.2017312154945.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0335.061.2017312155109.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0340.061.2017312155024.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0345.061.2017312155107.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0350.061.2017312155507.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0355.061.2017312155057.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0400.061.2017312154919.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0405.061.2017312154958.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0410.061.2017312155456.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0415.061.2017312160401.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0420.061.2017312160611.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0425.061.2017312162005.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0430.061.2017312162928.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0435.061.2017312161509.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0440.061.2017312161502.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0445.061.2017312161617.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0450.061.2017312155708.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0455.061.2017312155728.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0500.061.2017312155445.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0505.061.2017312155019.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0510.061.2017312155348.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0515.061.2017312155146.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0520.061.2017312155034.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0525.061.2017312155112.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0530.061.2017312155342.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0535.061.2017312155248.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0540.061.2017312155340.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0545.061.2017312154924.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0550.061.2017312160535.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0555.061.2017312161733.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0600.061.2017312161152.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0605.061.2017312161244.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0610.061.2017312161414.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0615.061.2017312160722.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0620.061.2017312161622.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0625.061.2017312161204.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0630.061.2017312160001.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0635.061.2017312155634.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0640.061.2017312155052.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0645.061.2017312155123.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0650.061.2017312155600.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0655.061.2017312155120.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0700.061.2017312155345.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0705.061.2017312155210.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0710.061.2017312155137.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0715.061.2017312155433.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0720.061.2017312155305.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0725.061.2017312155429.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0730.061.2017312160552.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0735.061.2017312160651.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0740.061.2017312160753.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0745.061.2017312160428.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0750.061.2017312160715.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0755.061.2017312161439.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0800.061.2017312162226.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0805.061.2017312161801.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0810.061.2017312155927.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0815.061.2017312155926.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0820.061.2017312155534.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0825.061.2017312155150.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0830.061.2017312155259.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0835.061.2017312155241.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0840.061.2017312155240.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0845.061.2017312155446.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0850.061.2017312155202.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0855.061.2017312155302.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0900.061.2017312155439.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0905.061.2017312155645.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0910.061.2017312160721.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0915.061.2017312160838.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0920.061.2017312160655.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0925.061.2017312161056.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0930.061.2017312162103.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0935.061.2017312161134.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0940.061.2017312161807.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0945.061.2017312160717.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0950.061.2017312160020.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.0955.061.2017312155503.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1000.061.2017312155325.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1005.061.2017312155329.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1010.061.2017312155241.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1015.061.2017312155454.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1020.061.2017312155315.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1025.061.2017312155455.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1030.061.2017312155408.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1035.061.2017312155250.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1040.061.2017312155249.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1045.061.2017312160036.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1050.061.2017312162018.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1055.061.2017312161318.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1100.061.2017312160746.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1105.061.2017312161650.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1110.061.2017312160808.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1115.061.2017312163349.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1120.061.2017312161920.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1125.061.2017312160857.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1130.061.2017312160523.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1135.061.2017312155647.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1140.061.2017312155403.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1145.061.2017312155418.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1150.061.2017312155333.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1155.061.2017312155335.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1200.061.2017312155338.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1205.061.2017312155413.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1210.061.2017312155225.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1215.061.2017312155213.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1220.061.2017312155330.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1225.061.2017312160400.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1230.061.2017312162012.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1235.061.2017312161746.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1240.061.2017312161626.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1245.061.2017312161824.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1250.061.2017312161918.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1255.061.2017312162756.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1300.061.2017312161656.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1305.061.2017312160359.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1310.061.2017312160310.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1315.061.2017312155222.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1320.061.2017312155231.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1325.061.2017312155242.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1330.061.2017312155455.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1335.061.2017312155357.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1340.061.2017312155343.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1345.061.2017312155351.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1350.061.2017312155311.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1355.061.2017312155405.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1400.061.2017312155307.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1405.061.2017312161139.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1410.061.2017312161926.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1415.061.2017312160834.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1420.061.2017312161354.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1425.061.2017312161125.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1430.061.2017312160445.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1435.061.2017312161533.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1440.061.2017312162739.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1445.061.2017312160731.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1450.061.2017312155916.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1455.061.2017312155434.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1500.061.2017312155229.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1505.061.2017312155335.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1510.061.2017312155537.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1515.061.2017312155554.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1520.061.2017312155540.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1525.061.2017312155651.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1530.061.2017312155142.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1535.061.2017312155336.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1540.061.2017312155445.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1545.061.2017312160836.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1550.061.2017312162157.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1555.061.2017312160748.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1600.061.2017312161329.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1605.061.2017312161615.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1610.061.2017312161706.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1615.061.2017312162152.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1620.061.2017312161720.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1625.061.2017312161459.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1630.061.2017312155759.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1635.061.2017312155340.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1640.061.2017312155431.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1645.061.2017312155421.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1650.061.2017312155705.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1655.061.2017312155446.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1700.061.2017312155624.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1705.061.2017312155450.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1710.061.2017312155314.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1715.061.2017312155413.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1720.061.2017312155629.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1725.061.2017312161029.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1730.061.2017312161355.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1735.061.2017312161020.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1740.061.2017312161508.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1745.061.2017312161419.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1750.061.2017312161810.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1755.061.2017312162532.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1800.061.2017312161520.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1805.061.2017312160106.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1810.061.2017312155611.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1815.061.2017312155623.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1820.061.2017312155639.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1825.061.2017312155620.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1830.061.2017312155614.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1835.061.2017312155421.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1840.061.2017312155645.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1845.061.2017312155458.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1850.061.2017312155426.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1855.061.2017312155422.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1900.061.2017312155937.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1905.061.2017312161154.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1910.061.2017312162300.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1915.061.2017312161225.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1920.061.2017312160840.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1925.061.2017312161602.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1930.061.2017312161938.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1935.061.2017312163008.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1940.061.2017312162257.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1945.061.2017312155927.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1950.061.2017312155850.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.1955.061.2017312155720.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2000.061.2017312155745.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2005.061.2017312155459.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2010.061.2017312155532.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2015.061.2017312155458.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2020.061.2017312155709.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2025.061.2017312155649.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2030.061.2017312155626.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2035.061.2017312155627.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2040.061.2017312161345.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2045.061.2017312162124.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2050.061.2017312161401.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2055.061.2017312161245.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2100.061.2017312161009.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2105.061.2017312161308.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2110.061.2017312162308.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2115.061.2017312161848.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2120.061.2017312161103.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2125.061.2017312155855.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2130.061.2017312155507.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2135.061.2017312155542.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2140.061.2017312155715.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2145.061.2017312155727.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2150.061.2017312155648.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2155.061.2017312155418.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2200.061.2017312155601.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2205.061.2017312155722.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2210.061.2017312155443.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2215.061.2017312155637.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2220.061.2017312161217.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2225.061.2017312162218.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2230.061.2017312161151.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2235.061.2017312161531.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2240.061.2017312162130.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2245.061.2017312161735.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2250.061.2017312162449.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2255.061.2017312162220.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2300.061.2017312160139.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2305.061.2017312160057.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2310.061.2017312155600.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2315.061.2017312155732.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2320.061.2017312155703.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2325.061.2017312155609.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2330.061.2017312155546.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2335.061.2017312155627.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2340.061.2017312155632.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2345.061.2017312155524.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2350.061.2017312155558.tfrecord', '/project/foster/clouds/nasa_laads/mod06_l2//2017_01_04/MOD06_L2.A2017004.2355.061.2017312155741.tfrecord']
	hdf_fields:                ['Cloud_Optical_Thickness', 'Cloud_Water_Path', 'Cirrus_Reflectance']
	meta_json:                 /project/foster/clouds/nasa_laads/mod06_l2//2017_01_01/MOD06_L2.A2017001.0625.061.2017312163945.json
	batch_size:                32
	model_dir:                 out/hdf/m18vae/
	optimizer:                 adam
	steps_per_epoch:           1000
	n_layers:                  3
	epochs:                    500
	summary_every:             250
	new_model:                 
	shape:                     (64, 64, 7)
	variational:               True
	vae_beta:                  1.0
	discriminator:             None
	lambda_disc:               0.01
	lambda_gradient_penalty:   10
	n_critic:                  5
	lambda_per:                1.0
	perceptual:                False
	display_imgs:              8
	red_bands:                 [0]
	green_bands:               [2]
	blue_bands:                [1]


WARNING: provided channels do not match hdf choices. Correcting to 3 channels...
Starting epoch 0
Starting epoch 1
Starting epoch 2
Starting epoch 3
Starting epoch 4
Starting epoch 5
Starting epoch 6
Starting epoch 7
Starting epoch 8
Starting epoch 9
Starting epoch 10
Starting epoch 11
Starting epoch 12
Starting epoch 13
Starting epoch 14
Starting epoch 15
Starting epoch 16
Starting epoch 17
Starting epoch 18
Starting epoch 19
Starting epoch 20
Starting epoch 21
Starting epoch 22
Starting epoch 23
Starting epoch 24
Starting epoch 25
Starting epoch 26
Starting epoch 27
Starting epoch 28
Starting epoch 29
Starting epoch 30
Starting epoch 31
Starting epoch 32
Starting epoch 33
Starting epoch 34
Starting epoch 35
Starting epoch 36
Starting epoch 37
Starting epoch 38
Starting epoch 39
Starting epoch 40
Starting epoch 41
Starting epoch 42
Starting epoch 43
Starting epoch 44
Starting epoch 45
Starting epoch 46
Starting epoch 47
Starting epoch 48
Starting epoch 49
Starting epoch 50
Starting epoch 51
Starting epoch 52
Starting epoch 53
Starting epoch 54
Starting epoch 55
Starting epoch 56
Starting epoch 57
Starting epoch 58
Starting epoch 59
Starting epoch 60
Starting epoch 61
Starting epoch 62
Starting epoch 63
Starting epoch 64
Starting epoch 65
Starting epoch 66
Starting epoch 67
Starting epoch 68
Starting epoch 69
Starting epoch 70
Starting epoch 71
Starting epoch 72
Starting epoch 73
Starting epoch 74
Starting epoch 75
Starting epoch 76
Starting epoch 77
Starting epoch 78
Starting epoch 79
Starting epoch 80
Starting epoch 81
Starting epoch 82
Starting epoch 83
Starting epoch 84
Starting epoch 85
Starting epoch 86
Starting epoch 87
Starting epoch 88
Starting epoch 89
Starting epoch 90
Starting epoch 91
Starting epoch 92
Starting epoch 93
Starting epoch 94
Starting epoch 95
Starting epoch 96
Starting epoch 97
Starting epoch 98
Starting epoch 99
Starting epoch 100
Starting epoch 101
Starting epoch 102
Starting epoch 103
Starting epoch 104
Starting epoch 105
Starting epoch 106
Starting epoch 107
Starting epoch 108
Starting epoch 109
Starting epoch 110
Starting epoch 111
Starting epoch 112
Starting epoch 113
Starting epoch 114
Starting epoch 115
Starting epoch 116
Starting epoch 117
Starting epoch 118
Starting epoch 119
Starting epoch 120
Starting epoch 121
Starting epoch 122
Starting epoch 123
Starting epoch 124
Starting epoch 125
Starting epoch 126
Starting epoch 127
Starting epoch 128
Starting epoch 129
Starting epoch 130
Starting epoch 131
Starting epoch 132
Starting epoch 133
Starting epoch 134
Starting epoch 135
Starting epoch 136
Starting epoch 137
Starting epoch 138
Starting epoch 139
Starting epoch 140
Starting epoch 141
Starting epoch 142
Starting epoch 143
Starting epoch 144
Starting epoch 145
Starting epoch 146
Starting epoch 147
Starting epoch 148
Starting epoch 149
Starting epoch 150
Starting epoch 151
Starting epoch 152
Starting epoch 153
Starting epoch 154
Starting epoch 155
Starting epoch 156
Starting epoch 157
Starting epoch 158
Starting epoch 159
Starting epoch 160
Starting epoch 161
Starting epoch 162
Starting epoch 163
Starting epoch 164
Starting epoch 165
Starting epoch 166
Starting epoch 167
Starting epoch 168
Starting epoch 169
Starting epoch 170
Starting epoch 171
Starting epoch 172
Starting epoch 173
Starting epoch 174
Starting epoch 175
Starting epoch 176
Starting epoch 177
Starting epoch 178
Starting epoch 179
Starting epoch 180
Starting epoch 181
Starting epoch 182
Starting epoch 183
Starting epoch 184
Starting epoch 185
Starting epoch 186
Starting epoch 187
Starting epoch 188
Starting epoch 189
Starting epoch 190
Starting epoch 191
Starting epoch 192
Starting epoch 193
Starting epoch 194
Starting epoch 195
Starting epoch 196
Starting epoch 197
Starting epoch 198
Starting epoch 199
Starting epoch 200
Starting epoch 201
Starting epoch 202
Starting epoch 203
Starting epoch 204
Starting epoch 205
Starting epoch 206
Starting epoch 207
Starting epoch 208
Starting epoch 209
Starting epoch 210
Starting epoch 211
Starting epoch 212
Starting epoch 213
Starting epoch 214
Starting epoch 215
Starting epoch 216
Starting epoch 217
Starting epoch 218
Starting epoch 219
Starting epoch 220
Starting epoch 221
Starting epoch 222
Starting epoch 223
Starting epoch 224
Starting epoch 225
Starting epoch 226
Starting epoch 227
Starting epoch 228
Starting epoch 229
Starting epoch 230
Starting epoch 231
Starting epoch 232
Starting epoch 233
Starting epoch 234
Starting epoch 235
Starting epoch 236
Starting epoch 237
Starting epoch 238
Starting epoch 239
Starting epoch 240
Starting epoch 241
Starting epoch 242
Starting epoch 243
Starting epoch 244
Starting epoch 245
Starting epoch 246
Starting epoch 247
Starting epoch 248
Starting epoch 249
Starting epoch 250
Starting epoch 251
Starting epoch 252
Starting epoch 253
Starting epoch 254
Starting epoch 255
Starting epoch 256
Starting epoch 257
Starting epoch 258
Starting epoch 259
Starting epoch 260
Starting epoch 261
Starting epoch 262
Starting epoch 263
Starting epoch 264
Starting epoch 265
Starting epoch 266
Starting epoch 267
Starting epoch 268
Starting epoch 269
Starting epoch 270
Starting epoch 271
Starting epoch 272
Starting epoch 273
Starting epoch 274
Starting epoch 275
Starting epoch 276
Starting epoch 277
Starting epoch 278
Starting epoch 279
Starting epoch 280
Starting epoch 281
Starting epoch 282
Starting epoch 283
Starting epoch 284
Starting epoch 285
Starting epoch 286
Starting epoch 287
Starting epoch 288
Starting epoch 289
Starting epoch 290
Starting epoch 291
Starting epoch 292
Starting epoch 293
Starting epoch 294
Starting epoch 295
Starting epoch 296
Starting epoch 297
Starting epoch 298
Starting epoch 299
Starting epoch 300
Starting epoch 301
Starting epoch 302
Starting epoch 303
Starting epoch 304
Starting epoch 305
Starting epoch 306
Starting epoch 307
Starting epoch 308
Starting epoch 309
Starting epoch 310
Starting epoch 311
Starting epoch 312
Starting epoch 313
Starting epoch 314
Starting epoch 315
Starting epoch 316
Starting epoch 317
Starting epoch 318
Starting epoch 319
Starting epoch 320
Starting epoch 321
Starting epoch 322
Starting epoch 323
Starting epoch 324
Starting epoch 325
Starting epoch 326
Starting epoch 327
Starting epoch 328
Starting epoch 329
Starting epoch 330
Starting epoch 331
Starting epoch 332
Starting epoch 333
Starting epoch 334
Starting epoch 335
Starting epoch 336
Starting epoch 337
Starting epoch 338
Starting epoch 339
Starting epoch 340
Starting epoch 341
Starting epoch 342
Starting epoch 343
Starting epoch 344
Starting epoch 345
Starting epoch 346
Starting epoch 347
Starting epoch 348
Starting epoch 349
Starting epoch 350
Starting epoch 351
Starting epoch 352
Starting epoch 353
Starting epoch 354
Starting epoch 355
Starting epoch 356
Starting epoch 357
Starting epoch 358
Starting epoch 359
Starting epoch 360
Starting epoch 361
Starting epoch 362
Starting epoch 363
Starting epoch 364
Starting epoch 365
Starting epoch 366
Starting epoch 367
Starting epoch 368
Starting epoch 369
Starting epoch 370
Starting epoch 371
Starting epoch 372
Starting epoch 373
Starting epoch 374
Starting epoch 375
Starting epoch 376
Starting epoch 377
Starting epoch 378
Starting epoch 379
Starting epoch 380
Starting epoch 381
Starting epoch 382
Starting epoch 383
Starting epoch 384
Starting epoch 385
Starting epoch 386
Starting epoch 387
Starting epoch 388
Starting epoch 389
Starting epoch 390
Starting epoch 391
Starting epoch 392
Starting epoch 393
Starting epoch 394
Starting epoch 395
Starting epoch 396
Starting epoch 397
Starting epoch 398
Starting epoch 399
Starting epoch 400
Starting epoch 401
Starting epoch 402
Starting epoch 403
Starting epoch 404
Starting epoch 405
Starting epoch 406
Starting epoch 407
Starting epoch 408
Starting epoch 409
Starting epoch 410
Starting epoch 411
Starting epoch 412
Starting epoch 413
Starting epoch 414
Starting epoch 415
Starting epoch 416
Starting epoch 417
Starting epoch 418
Starting epoch 419
Starting epoch 420
Starting epoch 421
Starting epoch 422
Starting epoch 423
Starting epoch 424
Starting epoch 425
Starting epoch 426
Starting epoch 427
Starting epoch 428
Starting epoch 429
Starting epoch 430
Starting epoch 431
Starting epoch 432
Starting epoch 433
Starting epoch 434
Starting epoch 435
Starting epoch 436
Starting epoch 437
Starting epoch 438
Starting epoch 439
Starting epoch 440
Starting epoch 441
Starting epoch 442
Starting epoch 443
Starting epoch 444
Starting epoch 445
Starting epoch 446
Starting epoch 447
Starting epoch 448
Starting epoch 449
Starting epoch 450
Starting epoch 451
Starting epoch 452
Starting epoch 453
Starting epoch 454
Starting epoch 455
Starting epoch 456
Starting epoch 457
Starting epoch 458
Starting epoch 459
Starting epoch 460
Starting epoch 461
Starting epoch 462
Starting epoch 463
Starting epoch 464
Starting epoch 465
Starting epoch 466
Starting epoch 467
Starting epoch 468
Starting epoch 469
Starting epoch 470
Starting epoch 471
Starting epoch 472
Starting epoch 473
Starting epoch 474
Starting epoch 475
Starting epoch 476
Starting epoch 477
Starting epoch 478
Starting epoch 479
Starting epoch 480
Starting epoch 481
Starting epoch 482
Starting epoch 483
Starting epoch 484
Starting epoch 485
Starting epoch 486
Starting epoch 487
Starting epoch 488
Starting epoch 489
Starting epoch 490
Starting epoch 491
Starting epoch 492
Starting epoch 493
Starting epoch 494
Starting epoch 495
Starting epoch 496
Starting epoch 497
Starting epoch 498
Starting epoch 499
