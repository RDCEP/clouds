Parsing Inputs...
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_0.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 8.57sec, accelerator: 0us, total: 8.57sec (96.01%)
top 2 operation type: Conv2D, cpu: 165.19ms, accelerator: 27.21ms, total: 192.41ms (2.15%)
top 3 operation type: Conv2DBackpropFilter, cpu: 28.84ms, accelerator: 32.65ms, total: 61.49ms (0.69%)
top 1 graph node: IteratorGetNext, cpu: 8.57sec, accelerator: 0us, total: 8.57sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 8.61sec, accelerator: 0us, total: 8.61sec
  iterator_ops.py:373:get_next, cpu: 8.57sec, accelerator: 0us, total: 8.57sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 33.85ms, accelerator: 0us, total: 33.85ms
train2.py:342:<module>, cpu: 169.45ms, accelerator: 35.25ms, total: 204.72ms
train2.py:342:<module> (gradient), cpu: 47.17ms, accelerator: 62.63ms, total: 109.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_1000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_1250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_1500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_1750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 4.33sec, accelerator: 0us, total: 4.33sec (95.47%)
top 2 operation type: Conv2D, cpu: 83.07ms, accelerator: 18.01ms, total: 101.09ms (2.23%)
top 3 operation type: Conv2DBackpropFilter, cpu: 14.97ms, accelerator: 20.98ms, total: 35.96ms (0.79%)
top 1 graph node: IteratorGetNext, cpu: 4.33sec, accelerator: 0us, total: 4.33sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 4.34sec, accelerator: 0us, total: 4.34sec
  iterator_ops.py:373:get_next, cpu: 4.33sec, accelerator: 0us, total: 4.33sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 16.93ms, accelerator: 0us, total: 16.93ms
train2.py:342:<module>, cpu: 85.44ms, accelerator: 24.99ms, total: 110.45ms
train2.py:342:<module> (gradient), cpu: 24.89ms, accelerator: 43.18ms, total: 68.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_2000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_2250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_2500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_2750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 2.90sec, accelerator: 0us, total: 2.90sec (94.94%)
top 2 operation type: Conv2D, cpu: 55.70ms, accelerator: 15.06ms, total: 70.76ms (2.31%)
top 3 operation type: Conv2DBackpropFilter, cpu: 10.36ms, accelerator: 16.61ms, total: 26.97ms (0.88%)
top 1 graph node: IteratorGetNext, cpu: 2.90sec, accelerator: 0us, total: 2.90sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 2.91sec, accelerator: 0us, total: 2.91sec
  iterator_ops.py:373:get_next, cpu: 2.90sec, accelerator: 0us, total: 2.90sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 11.29ms, accelerator: 0us, total: 11.29ms
train2.py:342:<module>, cpu: 57.44ms, accelerator: 21.57ms, total: 79.03ms
train2.py:342:<module> (gradient), cpu: 17.46ms, accelerator: 35.57ms, total: 53.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_3000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_3250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_3500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_3750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 2.19sec, accelerator: 0us, total: 2.19sec (94.44%)
top 2 operation type: Conv2D, cpu: 42.00ms, accelerator: 13.38ms, total: 55.39ms (2.39%)
top 3 operation type: Conv2DBackpropFilter, cpu: 8.04ms, accelerator: 14.47ms, total: 22.52ms (0.97%)
top 1 graph node: IteratorGetNext, cpu: 2.19sec, accelerator: 0us, total: 2.19sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 2.20sec, accelerator: 0us, total: 2.20sec
  iterator_ops.py:373:get_next, cpu: 2.19sec, accelerator: 0us, total: 2.19sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 8.47ms, accelerator: 0us, total: 8.47ms
train2.py:342:<module>, cpu: 43.42ms, accelerator: 19.29ms, total: 62.73ms
train2.py:342:<module> (gradient), cpu: 13.74ms, accelerator: 31.98ms, total: 45.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_4000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_4250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_4500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_4750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 1.76sec, accelerator: 0us, total: 1.76sec (93.93%)
top 2 operation type: Conv2D, cpu: 33.79ms, accelerator: 12.11ms, total: 45.91ms (2.45%)
top 3 operation type: Conv2DBackpropFilter, cpu: 6.65ms, accelerator: 13.24ms, total: 19.90ms (1.06%)
top 1 graph node: IteratorGetNext, cpu: 1.76sec, accelerator: 0us, total: 1.76sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 1.77sec, accelerator: 0us, total: 1.77sec
  iterator_ops.py:373:get_next, cpu: 1.76sec, accelerator: 0us, total: 1.76sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 6.78ms, accelerator: 0us, total: 6.78ms
train2.py:342:<module>, cpu: 35.02ms, accelerator: 18.06ms, total: 53.10ms
train2.py:342:<module> (gradient), cpu: 11.50ms, accelerator: 29.83ms, total: 41.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_5000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_5250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_5500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_5750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 1.48sec, accelerator: 0us, total: 1.48sec (93.44%)
top 2 operation type: Conv2D, cpu: 28.31ms, accelerator: 11.64ms, total: 39.96ms (2.53%)
top 3 operation type: Conv2DBackpropFilter, cpu: 5.73ms, accelerator: 12.88ms, total: 18.61ms (1.18%)
top 1 graph node: IteratorGetNext, cpu: 1.48sec, accelerator: 0us, total: 1.48sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 1.48sec, accelerator: 0us, total: 1.48sec
  iterator_ops.py:373:get_next, cpu: 1.48sec, accelerator: 0us, total: 1.48sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 5.65ms, accelerator: 0us, total: 5.65ms
train2.py:342:<module>, cpu: 29.40ms, accelerator: 17.72ms, total: 47.14ms
train2.py:342:<module> (gradient), cpu: 10.01ms, accelerator: 29.24ms, total: 39.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.53
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_6000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_6250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_6500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_6750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 1.28sec, accelerator: 0us, total: 1.28sec (92.97%)
top 2 operation type: Conv2D, cpu: 24.40ms, accelerator: 11.47ms, total: 35.87ms (2.61%)
top 3 operation type: Conv2DBackpropInput, cpu: 3.88ms, accelerator: 13.88ms, total: 17.77ms (1.29%)
top 1 graph node: IteratorGetNext, cpu: 1.28sec, accelerator: 0us, total: 1.28sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 1.28sec, accelerator: 0us, total: 1.28sec
  iterator_ops.py:373:get_next, cpu: 1.28sec, accelerator: 0us, total: 1.28sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 4.84ms, accelerator: 0us, total: 4.84ms
train2.py:342:<module>, cpu: 25.40ms, accelerator: 17.38ms, total: 42.80ms
train2.py:342:<module> (gradient), cpu: 8.94ms, accelerator: 28.96ms, total: 37.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_7000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_7250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_7500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_7750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 1.13sec, accelerator: 0us, total: 1.13sec (92.54%)
top 2 operation type: Conv2D, cpu: 21.47ms, accelerator: 11.13ms, total: 32.60ms (2.67%)
top 3 operation type: Conv2DBackpropInput, cpu: 3.51ms, accelerator: 13.44ms, total: 16.95ms (1.39%)
top 1 graph node: IteratorGetNext, cpu: 1.13sec, accelerator: 0us, total: 1.13sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 1.13sec, accelerator: 0us, total: 1.13sec
  iterator_ops.py:373:get_next, cpu: 1.13sec, accelerator: 0us, total: 1.13sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 4.24ms, accelerator: 0us, total: 4.24ms
train2.py:342:<module>, cpu: 22.41ms, accelerator: 16.89ms, total: 39.32ms
train2.py:342:<module> (gradient), cpu: 8.14ms, accelerator: 28.08ms, total: 36.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_8000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_8250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_8500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_8750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 1.01sec, accelerator: 0us, total: 1.01sec (92.12%)
top 2 operation type: Conv2D, cpu: 19.18ms, accelerator: 10.70ms, total: 29.89ms (2.73%)
top 3 operation type: Conv2DBackpropInput, cpu: 3.23ms, accelerator: 12.59ms, total: 15.83ms (1.44%)
top 1 graph node: IteratorGetNext, cpu: 1.01sec, accelerator: 0us, total: 1.01sec
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 1.01sec, accelerator: 0us, total: 1.01sec
  iterator_ops.py:373:get_next, cpu: 1.01sec, accelerator: 0us, total: 1.01sec
  dataset_ops.py:168:make_one_shot_ite..., cpu: 3.77ms, accelerator: 0us, total: 3.77ms
train2.py:342:<module>, cpu: 20.07ms, accelerator: 16.21ms, total: 36.31ms
train2.py:342:<module> (gradient), cpu: 7.52ms, accelerator: 26.76ms, total: 34.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_9000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_9250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_9500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_9750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 915.54ms, accelerator: 0us, total: 915.54ms (91.68%)
top 2 operation type: Conv2D, cpu: 17.36ms, accelerator: 10.52ms, total: 27.89ms (2.79%)
top 3 operation type: Conv2DBackpropInput, cpu: 3.00ms, accelerator: 12.69ms, total: 15.70ms (1.57%)
top 1 graph node: IteratorGetNext, cpu: 915.54ms, accelerator: 0us, total: 915.54ms
top 2 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 918.93ms, accelerator: 0us, total: 918.93ms
  iterator_ops.py:373:get_next, cpu: 915.54ms, accelerator: 0us, total: 915.54ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 3.39ms, accelerator: 0us, total: 3.39ms
train2.py:342:<module>, cpu: 18.21ms, accelerator: 16.06ms, total: 34.29ms
train2.py:342:<module> (gradient), cpu: 7.03ms, accelerator: 26.60ms, total: 33.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_10000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_10250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_10500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_10750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 838.80ms, accelerator: 0us, total: 838.80ms (91.25%)
top 2 operation type: Conv2D, cpu: 15.87ms, accelerator: 10.30ms, total: 26.17ms (2.85%)
top 3 operation type: Conv2DBackpropInput, cpu: 2.81ms, accelerator: 12.36ms, total: 15.17ms (1.65%)
top 1 graph node: IteratorGetNext, cpu: 838.80ms, accelerator: 0us, total: 838.80ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 841.88ms, accelerator: 0us, total: 841.88ms
  iterator_ops.py:373:get_next, cpu: 838.80ms, accelerator: 0us, total: 838.80ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 3.08ms, accelerator: 0us, total: 3.08ms
train2.py:342:<module> (gradient), cpu: 6.62ms, accelerator: 26.09ms, total: 32.73ms
train2.py:342:<module>, cpu: 16.68ms, accelerator: 15.78ms, total: 32.48ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_11000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_11250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_11500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_11750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 773.23ms, accelerator: 0us, total: 773.23ms (90.82%)
top 2 operation type: Conv2D, cpu: 14.62ms, accelerator: 10.24ms, total: 24.87ms (2.92%)
top 3 operation type: Conv2DBackpropInput, cpu: 2.66ms, accelerator: 12.24ms, total: 14.91ms (1.75%)
top 1 graph node: IteratorGetNext, cpu: 773.23ms, accelerator: 0us, total: 773.23ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 776.06ms, accelerator: 0us, total: 776.06ms
  iterator_ops.py:373:get_next, cpu: 773.23ms, accelerator: 0us, total: 773.23ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.83ms, accelerator: 0us, total: 2.83ms
train2.py:342:<module> (gradient), cpu: 6.28ms, accelerator: 25.87ms, total: 32.17ms
train2.py:342:<module>, cpu: 15.41ms, accelerator: 15.63ms, total: 31.06ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_12000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_12250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_12500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_12750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 717.65ms, accelerator: 0us, total: 717.65ms (90.42%)
top 2 operation type: Conv2D, cpu: 13.57ms, accelerator: 10.07ms, total: 23.65ms (2.98%)
top 3 operation type: Conv2DBackpropInput, cpu: 2.52ms, accelerator: 12.01ms, total: 14.54ms (1.83%)
top 1 graph node: IteratorGetNext, cpu: 717.65ms, accelerator: 0us, total: 717.65ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 720.26ms, accelerator: 0us, total: 720.26ms
  iterator_ops.py:373:get_next, cpu: 717.65ms, accelerator: 0us, total: 717.65ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.61ms, accelerator: 0us, total: 2.61ms
train2.py:342:<module> (gradient), cpu: 5.99ms, accelerator: 25.31ms, total: 31.33ms
train2.py:342:<module>, cpu: 14.33ms, accelerator: 15.47ms, total: 29.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_13000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_13250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_13500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_13750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 669.56ms, accelerator: 0us, total: 669.56ms (90.02%)
top 2 operation type: Conv2D, cpu: 12.67ms, accelerator: 9.83ms, total: 22.50ms (3.03%)
top 3 operation type: Conv2DBackpropInput, cpu: 2.41ms, accelerator: 11.61ms, total: 14.03ms (1.89%)
top 1 graph node: IteratorGetNext, cpu: 669.56ms, accelerator: 0us, total: 669.56ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 671.99ms, accelerator: 0us, total: 671.99ms
  iterator_ops.py:373:get_next, cpu: 669.56ms, accelerator: 0us, total: 669.56ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.42ms, accelerator: 0us, total: 2.42ms
train2.py:342:<module> (gradient), cpu: 5.75ms, accelerator: 24.82ms, total: 30.59ms
train2.py:342:<module>, cpu: 13.41ms, accelerator: 15.26ms, total: 28.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_14000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_14250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_14500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_14750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 630.27ms, accelerator: 0us, total: 630.27ms (89.64%)
top 2 operation type: Conv2D, cpu: 11.89ms, accelerator: 9.64ms, total: 21.54ms (3.06%)
top 3 operation type: Conv2DBackpropInput, cpu: 2.31ms, accelerator: 11.51ms, total: 13.83ms (1.97%)
top 1 graph node: IteratorGetNext, cpu: 630.27ms, accelerator: 0us, total: 630.27ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 632.53ms, accelerator: 0us, total: 632.53ms
  iterator_ops.py:373:get_next, cpu: 630.27ms, accelerator: 0us, total: 630.27ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.26ms, accelerator: 0us, total: 2.26ms
train2.py:342:<module> (gradient), cpu: 5.54ms, accelerator: 24.56ms, total: 30.13ms
train2.py:342:<module>, cpu: 12.61ms, accelerator: 15.12ms, total: 27.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_15000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_15250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_15500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_15750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 595.38ms, accelerator: 0us, total: 595.38ms (89.28%)
top 2 operation type: Conv2D, cpu: 11.21ms, accelerator: 9.45ms, total: 20.67ms (3.10%)
top 3 operation type: Conv2DBackpropInput, cpu: 2.23ms, accelerator: 11.43ms, total: 13.66ms (2.05%)
top 1 graph node: IteratorGetNext, cpu: 595.38ms, accelerator: 0us, total: 595.38ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 597.50ms, accelerator: 0us, total: 597.50ms
  iterator_ops.py:373:get_next, cpu: 595.38ms, accelerator: 0us, total: 595.38ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.12ms, accelerator: 0us, total: 2.12ms
train2.py:342:<module> (gradient), cpu: 5.36ms, accelerator: 24.39ms, total: 29.77ms
train2.py:342:<module>, cpu: 11.91ms, accelerator: 15.11ms, total: 27.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_16000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_16250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_16500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_16750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 563.77ms, accelerator: 0us, total: 563.77ms (88.93%)
top 2 operation type: Conv2D, cpu: 10.60ms, accelerator: 9.30ms, total: 19.91ms (3.14%)
top 3 operation type: Conv2DBackpropInput, cpu: 2.15ms, accelerator: 11.16ms, total: 13.32ms (2.10%)
top 1 graph node: IteratorGetNext, cpu: 563.77ms, accelerator: 0us, total: 563.77ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 565.76ms, accelerator: 0us, total: 565.76ms
  iterator_ops.py:373:get_next, cpu: 563.77ms, accelerator: 0us, total: 563.77ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 2.00ms, accelerator: 0us, total: 2.00ms
train2.py:342:<module> (gradient), cpu: 5.18ms, accelerator: 23.99ms, total: 29.20ms
train2.py:342:<module>, cpu: 11.30ms, accelerator: 14.98ms, total: 26.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_17000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_17250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_17500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_17750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 535.46ms, accelerator: 0us, total: 535.46ms (88.55%)
top 2 operation type: Conv2D, cpu: 10.07ms, accelerator: 9.16ms, total: 19.23ms (3.18%)
top 3 operation type: Conv2DBackpropInput, cpu: 2.09ms, accelerator: 11.15ms, total: 13.25ms (2.19%)
top 1 graph node: IteratorGetNext, cpu: 535.46ms, accelerator: 0us, total: 535.46ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 537.34ms, accelerator: 0us, total: 537.34ms
  iterator_ops.py:373:get_next, cpu: 535.46ms, accelerator: 0us, total: 535.46ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.89ms, accelerator: 0us, total: 1.89ms
train2.py:342:<module> (gradient), cpu: 5.04ms, accelerator: 23.86ms, total: 28.93ms
train2.py:342:<module>, cpu: 10.75ms, accelerator: 14.96ms, total: 25.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_18000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_18250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_18500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_18750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 510.32ms, accelerator: 0us, total: 510.32ms (88.21%)
top 2 operation type: Conv2D, cpu: 9.59ms, accelerator: 9.12ms, total: 18.71ms (3.23%)
top 3 operation type: Conv2DBackpropInput, cpu: 2.03ms, accelerator: 11.15ms, total: 13.18ms (2.28%)
top 1 graph node: IteratorGetNext, cpu: 510.32ms, accelerator: 0us, total: 510.32ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 512.10ms, accelerator: 0us, total: 512.10ms
  iterator_ops.py:373:get_next, cpu: 510.32ms, accelerator: 0us, total: 510.32ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.79ms, accelerator: 0us, total: 1.79ms
train2.py:342:<module> (gradient), cpu: 4.91ms, accelerator: 23.81ms, total: 28.75ms
train2.py:342:<module>, cpu: 10.26ms, accelerator: 14.95ms, total: 25.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_19000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_19250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_19500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_19750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 489.42ms, accelerator: 0us, total: 489.42ms (87.89%)
top 2 operation type: Conv2D, cpu: 9.15ms, accelerator: 9.15ms, total: 18.31ms (3.29%)
top 3 operation type: Conv2DBackpropInput, cpu: 1.97ms, accelerator: 11.23ms, total: 13.21ms (2.37%)
top 1 graph node: IteratorGetNext, cpu: 489.42ms, accelerator: 0us, total: 489.42ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 491.12ms, accelerator: 0us, total: 491.12ms
  iterator_ops.py:373:get_next, cpu: 489.42ms, accelerator: 0us, total: 489.42ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.70ms, accelerator: 0us, total: 1.70ms
train2.py:342:<module> (gradient), cpu: 4.79ms, accelerator: 23.82ms, total: 28.64ms
train2.py:342:<module>, cpu: 9.81ms, accelerator: 14.94ms, total: 24.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_20000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_20250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_20500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_20750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 469.92ms, accelerator: 0us, total: 469.92ms (87.57%)
top 2 operation type: Conv2D, cpu: 8.76ms, accelerator: 9.05ms, total: 17.82ms (3.32%)
top 3 operation type: Conv2DBackpropInput, cpu: 1.92ms, accelerator: 11.10ms, total: 13.03ms (2.43%)
top 1 graph node: IteratorGetNext, cpu: 469.92ms, accelerator: 0us, total: 469.92ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 471.54ms, accelerator: 0us, total: 471.54ms
  iterator_ops.py:373:get_next, cpu: 469.92ms, accelerator: 0us, total: 469.92ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.62ms, accelerator: 0us, total: 1.62ms
train2.py:342:<module> (gradient), cpu: 4.68ms, accelerator: 23.60ms, total: 28.31ms
train2.py:342:<module>, cpu: 9.41ms, accelerator: 14.77ms, total: 24.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.29
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_21000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_21250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_21500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_21750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 452.79ms, accelerator: 0us, total: 452.79ms (87.27%)
top 2 operation type: Conv2D, cpu: 8.40ms, accelerator: 9.08ms, total: 17.49ms (3.37%)
top 3 operation type: Conv2DBackpropInput, cpu: 1.88ms, accelerator: 11.10ms, total: 12.98ms (2.50%)
top 1 graph node: IteratorGetNext, cpu: 452.79ms, accelerator: 0us, total: 452.79ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 454.33ms, accelerator: 0us, total: 454.33ms
  iterator_ops.py:373:get_next, cpu: 452.79ms, accelerator: 0us, total: 452.79ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.54ms, accelerator: 0us, total: 1.54ms
train2.py:342:<module> (gradient), cpu: 4.59ms, accelerator: 23.59ms, total: 28.20ms
train2.py:342:<module>, cpu: 9.05ms, accelerator: 14.73ms, total: 23.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_22000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_22250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_22500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_22750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 436.89ms, accelerator: 0us, total: 436.89ms (86.96%)
top 2 operation type: Conv2D, cpu: 8.08ms, accelerator: 9.04ms, total: 17.13ms (3.41%)
top 3 operation type: Conv2DBackpropInput, cpu: 1.84ms, accelerator: 11.01ms, total: 12.86ms (2.56%)
top 1 graph node: IteratorGetNext, cpu: 436.89ms, accelerator: 0us, total: 436.89ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 438.37ms, accelerator: 0us, total: 438.37ms
  iterator_ops.py:373:get_next, cpu: 436.89ms, accelerator: 0us, total: 436.89ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.48ms, accelerator: 0us, total: 1.48ms
train2.py:342:<module> (gradient), cpu: 4.50ms, accelerator: 23.37ms, total: 27.89ms
train2.py:342:<module>, cpu: 8.72ms, accelerator: 14.65ms, total: 23.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_23000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_23250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_23500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_23750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 421.02ms, accelerator: 0us, total: 421.02ms (86.65%)
top 2 operation type: Conv2D, cpu: 7.78ms, accelerator: 8.92ms, total: 16.70ms (3.44%)
top 3 operation type: Conv2DBackpropInput, cpu: 1.80ms, accelerator: 10.87ms, total: 12.68ms (2.61%)
top 1 graph node: IteratorGetNext, cpu: 421.02ms, accelerator: 0us, total: 421.02ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 422.44ms, accelerator: 0us, total: 422.44ms
  iterator_ops.py:373:get_next, cpu: 421.02ms, accelerator: 0us, total: 421.02ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.42ms, accelerator: 0us, total: 1.42ms
train2.py:342:<module> (gradient), cpu: 4.42ms, accelerator: 23.10ms, total: 27.54ms
train2.py:342:<module>, cpu: 8.41ms, accelerator: 14.51ms, total: 22.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_24000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_24250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_24500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_24750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 406.19ms, accelerator: 0us, total: 406.19ms (86.34%)
top 2 operation type: Conv2D, cpu: 7.51ms, accelerator: 8.84ms, total: 16.35ms (3.48%)
top 3 operation type: Conv2DBackpropInput, cpu: 1.77ms, accelerator: 10.66ms, total: 12.44ms (2.64%)
top 1 graph node: IteratorGetNext, cpu: 406.19ms, accelerator: 0us, total: 406.19ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 407.55ms, accelerator: 0us, total: 407.55ms
  iterator_ops.py:373:get_next, cpu: 406.19ms, accelerator: 0us, total: 406.19ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.36ms, accelerator: 0us, total: 1.36ms
train2.py:342:<module> (gradient), cpu: 4.35ms, accelerator: 22.89ms, total: 27.26ms
train2.py:342:<module>, cpu: 8.13ms, accelerator: 14.40ms, total: 22.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_25000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_25250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_25500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_25750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 392.61ms, accelerator: 0us, total: 392.61ms (86.02%)
top 2 operation type: Conv2D, cpu: 7.25ms, accelerator: 8.76ms, total: 16.02ms (3.51%)
top 3 operation type: Conv2DBackpropInput, cpu: 1.74ms, accelerator: 10.64ms, total: 12.38ms (2.71%)
top 1 graph node: IteratorGetNext, cpu: 392.61ms, accelerator: 0us, total: 392.61ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 393.92ms, accelerator: 0us, total: 393.92ms
  iterator_ops.py:373:get_next, cpu: 392.61ms, accelerator: 0us, total: 392.61ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.31ms, accelerator: 0us, total: 1.31ms
train2.py:342:<module> (gradient), cpu: 4.27ms, accelerator: 22.81ms, total: 27.11ms
train2.py:342:<module>, cpu: 7.87ms, accelerator: 14.34ms, total: 22.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_26000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_26250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_26500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_26750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 381.41ms, accelerator: 0us, total: 381.41ms (85.74%)
top 2 operation type: Conv2D, cpu: 7.02ms, accelerator: 8.76ms, total: 15.78ms (3.55%)
top 3 operation type: Conv2DBackpropInput, cpu: 1.71ms, accelerator: 10.66ms, total: 12.38ms (2.78%)
top 1 graph node: IteratorGetNext, cpu: 381.41ms, accelerator: 0us, total: 381.41ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 382.67ms, accelerator: 0us, total: 382.67ms
  iterator_ops.py:373:get_next, cpu: 381.41ms, accelerator: 0us, total: 381.41ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.26ms, accelerator: 0us, total: 1.26ms
train2.py:342:<module> (gradient), cpu: 4.21ms, accelerator: 22.80ms, total: 27.03ms
train2.py:342:<module>, cpu: 7.63ms, accelerator: 14.30ms, total: 21.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_27000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_27250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_27500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_27750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 369.99ms, accelerator: 0us, total: 369.99ms (85.45%)
top 2 operation type: Conv2D, cpu: 6.80ms, accelerator: 8.70ms, total: 15.51ms (3.58%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.53ms, total: 12.56ms (2.90%)
top 1 graph node: IteratorGetNext, cpu: 369.99ms, accelerator: 0us, total: 369.99ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 371.20ms, accelerator: 0us, total: 371.20ms
  iterator_ops.py:373:get_next, cpu: 369.99ms, accelerator: 0us, total: 369.99ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.21ms, accelerator: 0us, total: 1.21ms
train2.py:342:<module> (gradient), cpu: 4.15ms, accelerator: 22.58ms, total: 26.76ms
train2.py:342:<module>, cpu: 7.41ms, accelerator: 14.18ms, total: 21.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_28000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_28250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_28500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_28750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 359.93ms, accelerator: 0us, total: 359.93ms (85.18%)
top 2 operation type: Conv2D, cpu: 6.60ms, accelerator: 8.65ms, total: 15.26ms (3.61%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.73ms, total: 12.77ms (3.02%)
top 1 graph node: IteratorGetNext, cpu: 359.93ms, accelerator: 0us, total: 359.93ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 361.10ms, accelerator: 0us, total: 361.10ms
  iterator_ops.py:373:get_next, cpu: 359.93ms, accelerator: 0us, total: 359.93ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.17ms, accelerator: 0us, total: 1.17ms
train2.py:342:<module> (gradient), cpu: 4.09ms, accelerator: 22.39ms, total: 26.51ms
train2.py:342:<module>, cpu: 7.20ms, accelerator: 14.06ms, total: 21.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_29000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_29250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_29500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_29750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 350.36ms, accelerator: 0us, total: 350.36ms (84.90%)
top 2 operation type: Conv2D, cpu: 6.41ms, accelerator: 8.63ms, total: 15.05ms (3.65%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.76ms, total: 12.80ms (3.10%)
top 1 graph node: IteratorGetNext, cpu: 350.36ms, accelerator: 0us, total: 350.36ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 351.49ms, accelerator: 0us, total: 351.49ms
  iterator_ops.py:373:get_next, cpu: 350.36ms, accelerator: 0us, total: 350.36ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.13ms, accelerator: 0us, total: 1.13ms
train2.py:342:<module> (gradient), cpu: 4.04ms, accelerator: 22.39ms, total: 26.46ms
train2.py:342:<module>, cpu: 7.01ms, accelerator: 14.04ms, total: 21.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_30000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_30250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_30500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_30750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 341.49ms, accelerator: 0us, total: 341.49ms (84.65%)
top 2 operation type: Conv2D, cpu: 6.23ms, accelerator: 8.55ms, total: 14.79ms (3.67%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.04ms, total: 13.08ms (3.24%)
top 1 graph node: IteratorGetNext, cpu: 341.49ms, accelerator: 0us, total: 341.49ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 342.59ms, accelerator: 0us, total: 342.59ms
  iterator_ops.py:373:get_next, cpu: 341.49ms, accelerator: 0us, total: 341.49ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.10ms, accelerator: 0us, total: 1.10ms
train2.py:342:<module> (gradient), cpu: 4.00ms, accelerator: 22.11ms, total: 26.13ms
train2.py:342:<module>, cpu: 6.83ms, accelerator: 13.92ms, total: 20.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_31000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_31250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_31500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_31750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 332.40ms, accelerator: 0us, total: 332.40ms (84.34%)
top 2 operation type: Conv2D, cpu: 6.07ms, accelerator: 8.61ms, total: 14.69ms (3.73%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.87ms, total: 12.90ms (3.27%)
top 1 graph node: IteratorGetNext, cpu: 332.40ms, accelerator: 0us, total: 332.40ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 333.47ms, accelerator: 0us, total: 333.47ms
  iterator_ops.py:373:get_next, cpu: 332.40ms, accelerator: 0us, total: 332.40ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.06ms, accelerator: 0us, total: 1.06ms
train2.py:342:<module> (gradient), cpu: 3.95ms, accelerator: 22.27ms, total: 26.25ms
train2.py:342:<module>, cpu: 6.66ms, accelerator: 13.96ms, total: 20.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_32000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_32250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_32500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_32750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.53

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 323.81ms, accelerator: 0us, total: 323.81ms (84.04%)
top 2 operation type: Conv2D, cpu: 5.91ms, accelerator: 8.62ms, total: 14.54ms (3.77%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.83ms, total: 12.87ms (3.34%)
top 1 graph node: IteratorGetNext, cpu: 323.81ms, accelerator: 0us, total: 323.81ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 324.84ms, accelerator: 0us, total: 324.84ms
  iterator_ops.py:373:get_next, cpu: 323.81ms, accelerator: 0us, total: 323.81ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.03ms, accelerator: 0us, total: 1.03ms
train2.py:342:<module> (gradient), cpu: 3.91ms, accelerator: 22.30ms, total: 26.23ms
train2.py:342:<module>, cpu: 6.49ms, accelerator: 13.99ms, total: 20.50ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_33000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_33250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_33500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_33750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 316.11ms, accelerator: 0us, total: 316.11ms (83.78%)
top 2 operation type: Conv2D, cpu: 5.76ms, accelerator: 8.61ms, total: 14.38ms (3.81%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.82ms, total: 12.86ms (3.41%)
top 1 graph node: IteratorGetNext, cpu: 316.11ms, accelerator: 0us, total: 316.11ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 317.11ms, accelerator: 0us, total: 317.11ms
  iterator_ops.py:373:get_next, cpu: 316.11ms, accelerator: 0us, total: 316.11ms
  dataset_ops.py:168:make_one_shot_ite..., cpu: 1.00ms, accelerator: 0us, total: 1.00ms
train2.py:342:<module> (gradient), cpu: 3.87ms, accelerator: 22.26ms, total: 26.15ms
train2.py:342:<module>, cpu: 6.34ms, accelerator: 13.99ms, total: 20.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_34000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_34250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_34500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_34750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 309.14ms, accelerator: 0us, total: 309.14ms (83.54%)
top 2 operation type: Conv2D, cpu: 5.63ms, accelerator: 8.52ms, total: 14.15ms (3.82%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.97ms, total: 13.01ms (3.52%)
top 1 graph node: IteratorGetNext, cpu: 309.14ms, accelerator: 0us, total: 309.14ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 310.11ms, accelerator: 0us, total: 310.11ms
  iterator_ops.py:373:get_next, cpu: 309.14ms, accelerator: 0us, total: 309.14ms
train2.py:342:<module> (gradient), cpu: 3.83ms, accelerator: 22.11ms, total: 25.96ms
train2.py:342:<module>, cpu: 6.21ms, accelerator: 13.89ms, total: 20.12ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_35000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_35250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_35500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_35750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 302.01ms, accelerator: 0us, total: 302.01ms (83.29%)
top 2 operation type: Conv2D, cpu: 5.50ms, accelerator: 8.51ms, total: 14.01ms (3.86%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.00ms, total: 13.04ms (3.59%)
top 1 graph node: IteratorGetNext, cpu: 302.01ms, accelerator: 0us, total: 302.01ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 302.96ms, accelerator: 0us, total: 302.96ms
  iterator_ops.py:373:get_next, cpu: 302.01ms, accelerator: 0us, total: 302.01ms
train2.py:342:<module> (gradient), cpu: 3.80ms, accelerator: 21.99ms, total: 25.82ms
train2.py:342:<module>, cpu: 6.07ms, accelerator: 13.85ms, total: 19.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_36000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_36250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_36500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_36750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 295.89ms, accelerator: 0us, total: 295.89ms (83.06%)
top 2 operation type: Conv2D, cpu: 5.37ms, accelerator: 8.46ms, total: 13.84ms (3.88%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.10ms, total: 13.14ms (3.69%)
top 1 graph node: IteratorGetNext, cpu: 295.89ms, accelerator: 0us, total: 295.89ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 296.81ms, accelerator: 0us, total: 296.81ms
  iterator_ops.py:373:get_next, cpu: 295.89ms, accelerator: 0us, total: 295.89ms
train2.py:342:<module> (gradient), cpu: 3.77ms, accelerator: 21.88ms, total: 25.66ms
train2.py:342:<module>, cpu: 5.95ms, accelerator: 13.78ms, total: 19.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_37000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_37250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_37500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_37750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 289.75ms, accelerator: 0us, total: 289.75ms (82.83%)
top 2 operation type: Conv2D, cpu: 5.26ms, accelerator: 8.47ms, total: 13.73ms (3.92%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.11ms, total: 13.14ms (3.76%)
top 1 graph node: IteratorGetNext, cpu: 289.75ms, accelerator: 0us, total: 289.75ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 290.64ms, accelerator: 0us, total: 290.64ms
  iterator_ops.py:373:get_next, cpu: 289.75ms, accelerator: 0us, total: 289.75ms
train2.py:342:<module> (gradient), cpu: 3.73ms, accelerator: 21.81ms, total: 25.56ms
train2.py:342:<module>, cpu: 5.83ms, accelerator: 13.76ms, total: 19.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_38000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_38250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_38500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_38750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 283.63ms, accelerator: 0us, total: 283.63ms (82.56%)
top 2 operation type: Conv2D, cpu: 5.14ms, accelerator: 8.48ms, total: 13.63ms (3.97%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.06ms, total: 13.09ms (3.81%)
top 1 graph node: IteratorGetNext, cpu: 283.63ms, accelerator: 0us, total: 283.63ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 284.50ms, accelerator: 0us, total: 284.50ms
  iterator_ops.py:373:get_next, cpu: 283.63ms, accelerator: 0us, total: 283.63ms
train2.py:342:<module> (gradient), cpu: 3.70ms, accelerator: 21.86ms, total: 25.58ms
train2.py:342:<module>, cpu: 5.71ms, accelerator: 13.78ms, total: 19.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_39000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_39250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_39500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_39750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 278.28ms, accelerator: 0us, total: 278.28ms (82.33%)
top 2 operation type: Conv2D, cpu: 5.04ms, accelerator: 8.49ms, total: 13.53ms (4.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.07ms, total: 13.10ms (3.88%)
top 1 graph node: IteratorGetNext, cpu: 278.28ms, accelerator: 0us, total: 278.28ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 279.13ms, accelerator: 0us, total: 279.13ms
  iterator_ops.py:373:get_next, cpu: 278.28ms, accelerator: 0us, total: 278.28ms
train2.py:342:<module> (gradient), cpu: 3.67ms, accelerator: 21.80ms, total: 25.50ms
train2.py:342:<module>, cpu: 5.60ms, accelerator: 13.76ms, total: 19.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_40000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_40250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_40500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_40750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 273.16ms, accelerator: 0us, total: 273.16ms (82.11%)
top 2 operation type: Conv2D, cpu: 4.94ms, accelerator: 8.47ms, total: 13.42ms (4.03%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.09ms, total: 13.13ms (3.95%)
top 1 graph node: IteratorGetNext, cpu: 273.16ms, accelerator: 0us, total: 273.16ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 273.99ms, accelerator: 0us, total: 273.99ms
  iterator_ops.py:373:get_next, cpu: 273.16ms, accelerator: 0us, total: 273.16ms
train2.py:342:<module> (gradient), cpu: 3.65ms, accelerator: 21.75ms, total: 25.42ms
train2.py:342:<module>, cpu: 5.50ms, accelerator: 13.74ms, total: 19.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_41000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_41250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_41500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_41750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 268.69ms, accelerator: 0us, total: 268.69ms (81.90%)
top 2 operation type: Conv2D, cpu: 4.84ms, accelerator: 8.44ms, total: 13.29ms (4.05%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.18ms, total: 13.21ms (4.03%)
top 1 graph node: IteratorGetNext, cpu: 268.69ms, accelerator: 0us, total: 268.69ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 269.50ms, accelerator: 0us, total: 269.50ms
  iterator_ops.py:373:get_next, cpu: 268.69ms, accelerator: 0us, total: 268.69ms
train2.py:342:<module> (gradient), cpu: 3.62ms, accelerator: 21.68ms, total: 25.32ms
train2.py:342:<module>, cpu: 5.40ms, accelerator: 13.73ms, total: 19.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_42000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_42250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_42500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_42750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 263.71ms, accelerator: 0us, total: 263.71ms (81.67%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.26ms, total: 13.29ms (4.12%)
top 3 operation type: Conv2D, cpu: 4.75ms, accelerator: 8.41ms, total: 13.17ms (4.08%)
top 1 graph node: IteratorGetNext, cpu: 263.71ms, accelerator: 0us, total: 263.71ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 264.50ms, accelerator: 0us, total: 264.50ms
  iterator_ops.py:373:get_next, cpu: 263.71ms, accelerator: 0us, total: 263.71ms
train2.py:342:<module> (gradient), cpu: 3.60ms, accelerator: 21.61ms, total: 25.23ms
train2.py:342:<module>, cpu: 5.31ms, accelerator: 13.69ms, total: 19.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_43000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_43250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_43500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_43750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 259.40ms, accelerator: 0us, total: 259.40ms (81.45%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.16ms, total: 13.20ms (4.14%)
top 3 operation type: Conv2D, cpu: 4.67ms, accelerator: 8.42ms, total: 13.10ms (4.11%)
top 1 graph node: IteratorGetNext, cpu: 259.40ms, accelerator: 0us, total: 259.40ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 260.17ms, accelerator: 0us, total: 260.17ms
  iterator_ops.py:373:get_next, cpu: 259.40ms, accelerator: 0us, total: 259.40ms
train2.py:342:<module> (gradient), cpu: 3.57ms, accelerator: 21.69ms, total: 25.28ms
train2.py:342:<module>, cpu: 5.22ms, accelerator: 13.71ms, total: 18.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_44000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_44250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_44500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_44750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 254.66ms, accelerator: 0us, total: 254.66ms (81.20%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.11ms, total: 13.15ms (4.19%)
top 3 operation type: Conv2D, cpu: 4.58ms, accelerator: 8.43ms, total: 13.02ms (4.15%)
top 1 graph node: IteratorGetNext, cpu: 254.66ms, accelerator: 0us, total: 254.66ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 255.41ms, accelerator: 0us, total: 255.41ms
  iterator_ops.py:373:get_next, cpu: 254.66ms, accelerator: 0us, total: 254.66ms
train2.py:342:<module> (gradient), cpu: 3.55ms, accelerator: 21.75ms, total: 25.32ms
train2.py:342:<module>, cpu: 5.14ms, accelerator: 13.70ms, total: 18.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_45000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_45250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_45500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_45750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 250.25ms, accelerator: 0us, total: 250.25ms (80.96%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.06ms, total: 13.09ms (4.24%)
top 3 operation type: Conv2D, cpu: 4.50ms, accelerator: 8.44ms, total: 12.95ms (4.19%)
top 1 graph node: IteratorGetNext, cpu: 250.25ms, accelerator: 0us, total: 250.25ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 250.99ms, accelerator: 0us, total: 250.99ms
  iterator_ops.py:373:get_next, cpu: 250.25ms, accelerator: 0us, total: 250.25ms
train2.py:342:<module> (gradient), cpu: 3.52ms, accelerator: 21.82ms, total: 25.36ms
train2.py:342:<module>, cpu: 5.05ms, accelerator: 13.71ms, total: 18.78ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_46000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_46250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_46500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_46750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 246.03ms, accelerator: 0us, total: 246.03ms (80.73%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.97ms, total: 13.01ms (4.27%)
top 3 operation type: Conv2D, cpu: 4.43ms, accelerator: 8.49ms, total: 12.92ms (4.24%)
top 1 graph node: IteratorGetNext, cpu: 246.03ms, accelerator: 0us, total: 246.03ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 246.76ms, accelerator: 0us, total: 246.76ms
  iterator_ops.py:373:get_next, cpu: 246.03ms, accelerator: 0us, total: 246.03ms
train2.py:342:<module> (gradient), cpu: 3.50ms, accelerator: 21.87ms, total: 25.39ms
train2.py:342:<module>, cpu: 4.98ms, accelerator: 13.74ms, total: 18.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_47000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_47250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_47500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_47750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 242.58ms, accelerator: 0us, total: 242.58ms (80.55%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.98ms, total: 13.02ms (4.32%)
top 3 operation type: Conv2D, cpu: 4.36ms, accelerator: 8.46ms, total: 12.82ms (4.26%)
top 1 graph node: IteratorGetNext, cpu: 242.58ms, accelerator: 0us, total: 242.58ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 243.29ms, accelerator: 0us, total: 243.29ms
  iterator_ops.py:373:get_next, cpu: 242.58ms, accelerator: 0us, total: 242.58ms
train2.py:342:<module> (gradient), cpu: 3.49ms, accelerator: 21.85ms, total: 25.36ms
train2.py:342:<module>, cpu: 4.90ms, accelerator: 13.71ms, total: 18.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_48000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_48250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_48500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_48750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 238.98ms, accelerator: 0us, total: 238.98ms (80.34%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.98ms, total: 13.02ms (4.38%)
top 3 operation type: Conv2D, cpu: 4.29ms, accelerator: 8.46ms, total: 12.76ms (4.29%)
top 1 graph node: IteratorGetNext, cpu: 238.98ms, accelerator: 0us, total: 238.98ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 239.68ms, accelerator: 0us, total: 239.68ms
  iterator_ops.py:373:get_next, cpu: 238.98ms, accelerator: 0us, total: 238.98ms
train2.py:342:<module> (gradient), cpu: 3.47ms, accelerator: 21.87ms, total: 25.36ms
train2.py:342:<module>, cpu: 4.83ms, accelerator: 13.70ms, total: 18.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_49000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_49250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_49500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_49750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 235.43ms, accelerator: 0us, total: 235.43ms (80.14%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.06ms, total: 13.10ms (4.46%)
top 3 operation type: Conv2D, cpu: 4.22ms, accelerator: 8.44ms, total: 12.66ms (4.31%)
top 1 graph node: IteratorGetNext, cpu: 235.43ms, accelerator: 0us, total: 235.43ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 236.12ms, accelerator: 0us, total: 236.12ms
  iterator_ops.py:373:get_next, cpu: 235.43ms, accelerator: 0us, total: 235.43ms
train2.py:342:<module> (gradient), cpu: 3.45ms, accelerator: 21.75ms, total: 25.22ms
train2.py:342:<module>, cpu: 4.76ms, accelerator: 13.67ms, total: 18.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_50000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_50250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_50500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_50750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 231.88ms, accelerator: 0us, total: 231.88ms (79.93%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.09ms, total: 13.13ms (4.53%)
top 3 operation type: Conv2D, cpu: 4.16ms, accelerator: 8.41ms, total: 12.57ms (4.33%)
top 1 graph node: IteratorGetNext, cpu: 231.88ms, accelerator: 0us, total: 231.88ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 232.55ms, accelerator: 0us, total: 232.55ms
  iterator_ops.py:373:get_next, cpu: 231.88ms, accelerator: 0us, total: 231.88ms
train2.py:342:<module> (gradient), cpu: 3.43ms, accelerator: 21.72ms, total: 25.18ms
train2.py:342:<module>, cpu: 4.70ms, accelerator: 13.65ms, total: 18.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_51000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_51250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_51500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_51750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 228.47ms, accelerator: 0us, total: 228.47ms (79.72%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.12ms, total: 13.15ms (4.59%)
top 3 operation type: Conv2D, cpu: 4.09ms, accelerator: 8.41ms, total: 12.51ms (4.36%)
top 1 graph node: IteratorGetNext, cpu: 228.47ms, accelerator: 0us, total: 228.47ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 229.12ms, accelerator: 0us, total: 229.12ms
  iterator_ops.py:373:get_next, cpu: 228.47ms, accelerator: 0us, total: 228.47ms
train2.py:342:<module> (gradient), cpu: 3.42ms, accelerator: 21.68ms, total: 25.12ms
train2.py:342:<module>, cpu: 4.64ms, accelerator: 13.64ms, total: 18.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_52000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_52250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_52500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_52750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 225.50ms, accelerator: 0us, total: 225.50ms (79.54%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.14ms, total: 13.17ms (4.65%)
top 3 operation type: Conv2D, cpu: 4.04ms, accelerator: 8.40ms, total: 12.44ms (4.39%)
top 1 graph node: IteratorGetNext, cpu: 225.50ms, accelerator: 0us, total: 225.50ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 226.14ms, accelerator: 0us, total: 226.14ms
  iterator_ops.py:373:get_next, cpu: 225.50ms, accelerator: 0us, total: 225.50ms
train2.py:342:<module> (gradient), cpu: 3.40ms, accelerator: 21.65ms, total: 25.07ms
train2.py:342:<module>, cpu: 4.58ms, accelerator: 13.65ms, total: 18.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_53000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_53250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_53500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_53750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 222.39ms, accelerator: 0us, total: 222.39ms (79.35%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.17ms, total: 13.21ms (4.71%)
top 3 operation type: Conv2D, cpu: 3.98ms, accelerator: 8.38ms, total: 12.36ms (4.41%)
top 1 graph node: IteratorGetNext, cpu: 222.39ms, accelerator: 0us, total: 222.39ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 223.02ms, accelerator: 0us, total: 223.02ms
  iterator_ops.py:373:get_next, cpu: 222.39ms, accelerator: 0us, total: 222.39ms
train2.py:342:<module> (gradient), cpu: 3.39ms, accelerator: 21.57ms, total: 24.98ms
train2.py:342:<module>, cpu: 4.52ms, accelerator: 13.62ms, total: 18.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_54000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_54250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_54500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_54750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 219.42ms, accelerator: 0us, total: 219.42ms (79.17%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.25ms, total: 13.29ms (4.79%)
top 3 operation type: Conv2D, cpu: 3.92ms, accelerator: 8.34ms, total: 12.27ms (4.43%)
top 1 graph node: IteratorGetNext, cpu: 219.42ms, accelerator: 0us, total: 219.42ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 220.04ms, accelerator: 0us, total: 220.04ms
  iterator_ops.py:373:get_next, cpu: 219.42ms, accelerator: 0us, total: 219.42ms
train2.py:342:<module> (gradient), cpu: 3.37ms, accelerator: 21.47ms, total: 24.86ms
train2.py:342:<module>, cpu: 4.46ms, accelerator: 13.59ms, total: 18.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_55000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_55250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_55500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_55750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 216.40ms, accelerator: 0us, total: 216.40ms (78.97%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.19ms, total: 13.23ms (4.83%)
top 3 operation type: Conv2D, cpu: 3.87ms, accelerator: 8.32ms, total: 12.20ms (4.45%)
top 1 graph node: IteratorGetNext, cpu: 216.40ms, accelerator: 0us, total: 216.40ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 217.01ms, accelerator: 0us, total: 217.01ms
  iterator_ops.py:373:get_next, cpu: 216.40ms, accelerator: 0us, total: 216.40ms
train2.py:342:<module> (gradient), cpu: 3.36ms, accelerator: 21.48ms, total: 24.87ms
train2.py:342:<module>, cpu: 4.41ms, accelerator: 13.61ms, total: 18.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_56000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_56250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_56500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_56750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 214.04ms, accelerator: 0us, total: 214.04ms (78.82%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.21ms, total: 13.24ms (4.88%)
top 3 operation type: Conv2D, cpu: 3.82ms, accelerator: 8.30ms, total: 12.12ms (4.46%)
top 1 graph node: IteratorGetNext, cpu: 214.04ms, accelerator: 0us, total: 214.04ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 214.64ms, accelerator: 0us, total: 214.64ms
  iterator_ops.py:373:get_next, cpu: 214.04ms, accelerator: 0us, total: 214.04ms
train2.py:342:<module> (gradient), cpu: 3.34ms, accelerator: 21.49ms, total: 24.86ms
train2.py:342:<module>, cpu: 4.35ms, accelerator: 13.58ms, total: 17.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_57000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_57250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_57500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_57750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 211.47ms, accelerator: 0us, total: 211.47ms (78.64%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.30ms, total: 13.33ms (4.96%)
top 3 operation type: Conv2D, cpu: 3.77ms, accelerator: 8.28ms, total: 12.05ms (4.48%)
top 1 graph node: IteratorGetNext, cpu: 211.47ms, accelerator: 0us, total: 211.47ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 212.06ms, accelerator: 0us, total: 212.06ms
  iterator_ops.py:373:get_next, cpu: 211.47ms, accelerator: 0us, total: 211.47ms
train2.py:342:<module> (gradient), cpu: 3.33ms, accelerator: 21.42ms, total: 24.78ms
train2.py:342:<module>, cpu: 4.30ms, accelerator: 13.54ms, total: 17.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_58000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_58250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_58500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_58750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 208.77ms, accelerator: 0us, total: 208.77ms (78.47%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.32ms, total: 13.36ms (5.02%)
top 3 operation type: Conv2D, cpu: 3.72ms, accelerator: 8.28ms, total: 12.00ms (4.51%)
top 1 graph node: IteratorGetNext, cpu: 208.77ms, accelerator: 0us, total: 208.77ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 209.34ms, accelerator: 0us, total: 209.34ms
  iterator_ops.py:373:get_next, cpu: 208.77ms, accelerator: 0us, total: 208.77ms
train2.py:342:<module> (gradient), cpu: 3.31ms, accelerator: 21.34ms, total: 24.68ms
train2.py:342:<module>, cpu: 4.25ms, accelerator: 13.53ms, total: 17.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_59000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_59250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_59500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_59750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 206.10ms, accelerator: 0us, total: 206.10ms (78.27%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.29ms, total: 13.33ms (5.06%)
top 3 operation type: Conv2D, cpu: 3.67ms, accelerator: 8.25ms, total: 11.93ms (4.53%)
top 1 graph node: IteratorGetNext, cpu: 206.10ms, accelerator: 0us, total: 206.10ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 206.67ms, accelerator: 0us, total: 206.67ms
  iterator_ops.py:373:get_next, cpu: 206.10ms, accelerator: 0us, total: 206.10ms
train2.py:342:<module> (gradient), cpu: 3.30ms, accelerator: 21.35ms, total: 24.68ms
train2.py:342:<module>, cpu: 4.21ms, accelerator: 13.52ms, total: 17.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_60000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_60250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_60500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_60750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 204.11ms, accelerator: 0us, total: 204.11ms (78.13%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.26ms, total: 13.30ms (5.09%)
top 3 operation type: Conv2D, cpu: 3.63ms, accelerator: 8.24ms, total: 11.88ms (4.55%)
top 1 graph node: IteratorGetNext, cpu: 204.11ms, accelerator: 0us, total: 204.11ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 204.67ms, accelerator: 0us, total: 204.67ms
  iterator_ops.py:373:get_next, cpu: 204.11ms, accelerator: 0us, total: 204.11ms
train2.py:342:<module> (gradient), cpu: 3.29ms, accelerator: 21.39ms, total: 24.70ms
train2.py:342:<module>, cpu: 4.16ms, accelerator: 13.52ms, total: 17.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_61000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_61250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_61500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_61750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 201.65ms, accelerator: 0us, total: 201.65ms (77.94%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.24ms, total: 13.28ms (5.13%)
top 3 operation type: Conv2D, cpu: 3.59ms, accelerator: 8.24ms, total: 11.84ms (4.57%)
top 1 graph node: IteratorGetNext, cpu: 201.65ms, accelerator: 0us, total: 201.65ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 202.20ms, accelerator: 0us, total: 202.20ms
  iterator_ops.py:373:get_next, cpu: 201.65ms, accelerator: 0us, total: 201.65ms
train2.py:342:<module> (gradient), cpu: 3.27ms, accelerator: 21.42ms, total: 24.73ms
train2.py:342:<module>, cpu: 4.12ms, accelerator: 13.52ms, total: 17.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_62000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_62250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_62500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_62750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 199.38ms, accelerator: 0us, total: 199.38ms (77.77%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.33ms, total: 13.37ms (5.22%)
top 3 operation type: Conv2D, cpu: 3.54ms, accelerator: 8.23ms, total: 11.78ms (4.60%)
top 1 graph node: IteratorGetNext, cpu: 199.38ms, accelerator: 0us, total: 199.38ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 199.92ms, accelerator: 0us, total: 199.92ms
  iterator_ops.py:373:get_next, cpu: 199.38ms, accelerator: 0us, total: 199.38ms
train2.py:342:<module> (gradient), cpu: 3.27ms, accelerator: 21.32ms, total: 24.61ms
train2.py:342:<module>, cpu: 4.08ms, accelerator: 13.47ms, total: 17.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_63000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_63250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_63500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_63750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 197.37ms, accelerator: 0us, total: 197.37ms (77.62%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.32ms, total: 13.36ms (5.25%)
top 3 operation type: Conv2D, cpu: 3.50ms, accelerator: 8.24ms, total: 11.75ms (4.62%)
top 1 graph node: IteratorGetNext, cpu: 197.37ms, accelerator: 0us, total: 197.37ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 197.91ms, accelerator: 0us, total: 197.91ms
  iterator_ops.py:373:get_next, cpu: 197.37ms, accelerator: 0us, total: 197.37ms
train2.py:342:<module> (gradient), cpu: 3.26ms, accelerator: 21.32ms, total: 24.60ms
train2.py:342:<module>, cpu: 4.03ms, accelerator: 13.47ms, total: 17.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_64000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_64250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_64500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_64750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 195.47ms, accelerator: 0us, total: 195.47ms (77.48%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.42ms, total: 13.46ms (5.34%)
top 3 operation type: Conv2D, cpu: 3.46ms, accelerator: 8.20ms, total: 11.67ms (4.63%)
top 1 graph node: IteratorGetNext, cpu: 195.47ms, accelerator: 0us, total: 195.47ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 195.99ms, accelerator: 0us, total: 195.99ms
  iterator_ops.py:373:get_next, cpu: 195.47ms, accelerator: 0us, total: 195.47ms
train2.py:342:<module> (gradient), cpu: 3.25ms, accelerator: 21.23ms, total: 24.50ms
train2.py:342:<module>, cpu: 3.99ms, accelerator: 13.41ms, total: 17.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_65000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_65250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_65500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_65750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 193.46ms, accelerator: 0us, total: 193.46ms (77.32%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.43ms, total: 13.46ms (5.38%)
top 3 operation type: Conv2D, cpu: 3.43ms, accelerator: 8.20ms, total: 11.63ms (4.65%)
top 1 graph node: IteratorGetNext, cpu: 193.46ms, accelerator: 0us, total: 193.46ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 193.98ms, accelerator: 0us, total: 193.98ms
  iterator_ops.py:373:get_next, cpu: 193.46ms, accelerator: 0us, total: 193.46ms
train2.py:342:<module> (gradient), cpu: 3.23ms, accelerator: 21.23ms, total: 24.48ms
train2.py:342:<module>, cpu: 3.95ms, accelerator: 13.44ms, total: 17.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_66000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_66250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_66500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_66750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 191.93ms, accelerator: 0us, total: 191.93ms (77.19%)
top 2 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 12.34ms, total: 13.38ms (5.38%)
top 3 operation type: Conv2D, cpu: 3.39ms, accelerator: 8.22ms, total: 11.61ms (4.67%)
top 1 graph node: IteratorGetNext, cpu: 191.93ms, accelerator: 0us, total: 191.93ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 192.44ms, accelerator: 0us, total: 192.44ms
  iterator_ops.py:373:get_next, cpu: 191.93ms, accelerator: 0us, total: 191.93ms
train2.py:342:<module> (gradient), cpu: 3.23ms, accelerator: 21.29ms, total: 24.54ms
train2.py:342:<module>, cpu: 3.92ms, accelerator: 13.45ms, total: 17.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.29
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_67000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_67250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_67500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_67750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 190.04ms, accelerator: 0us, total: 190.04ms (77.03%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.31ms, total: 13.35ms (5.41%)
top 3 operation type: Conv2D, cpu: 3.35ms, accelerator: 8.23ms, total: 11.59ms (4.70%)
top 1 graph node: IteratorGetNext, cpu: 190.04ms, accelerator: 0us, total: 190.04ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 190.54ms, accelerator: 0us, total: 190.54ms
  iterator_ops.py:373:get_next, cpu: 190.04ms, accelerator: 0us, total: 190.04ms
train2.py:342:<module> (gradient), cpu: 3.21ms, accelerator: 21.33ms, total: 24.57ms
train2.py:342:<module>, cpu: 3.88ms, accelerator: 13.46ms, total: 17.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_68000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_68250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_68500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_68750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 188.36ms, accelerator: 0us, total: 188.36ms (76.89%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.31ms, total: 13.34ms (5.45%)
top 3 operation type: Conv2D, cpu: 3.32ms, accelerator: 8.24ms, total: 11.56ms (4.72%)
top 1 graph node: IteratorGetNext, cpu: 188.36ms, accelerator: 0us, total: 188.36ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 188.86ms, accelerator: 0us, total: 188.86ms
  iterator_ops.py:373:get_next, cpu: 188.36ms, accelerator: 0us, total: 188.36ms
train2.py:342:<module> (gradient), cpu: 3.20ms, accelerator: 21.35ms, total: 24.58ms
train2.py:342:<module>, cpu: 3.84ms, accelerator: 13.46ms, total: 17.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_69000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_69250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_69500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_69750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 186.60ms, accelerator: 0us, total: 186.60ms (76.75%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.39ms, total: 13.42ms (5.52%)
top 3 operation type: Conv2D, cpu: 3.29ms, accelerator: 8.22ms, total: 11.51ms (4.74%)
top 1 graph node: IteratorGetNext, cpu: 186.60ms, accelerator: 0us, total: 186.60ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 187.09ms, accelerator: 0us, total: 187.09ms
  iterator_ops.py:373:get_next, cpu: 186.60ms, accelerator: 0us, total: 186.60ms
train2.py:342:<module> (gradient), cpu: 3.19ms, accelerator: 21.26ms, total: 24.47ms
train2.py:342:<module>, cpu: 3.81ms, accelerator: 13.42ms, total: 17.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_70000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_70250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_70500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_70750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: IteratorGetNext, cpu: 184.90ms, accelerator: 0us, total: 184.90ms (76.60%)
top 2 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.31ms, total: 13.34ms (5.53%)
top 3 operation type: Conv2D, cpu: 3.25ms, accelerator: 8.25ms, total: 11.51ms (4.77%)
top 1 graph node: IteratorGetNext, cpu: 184.90ms, accelerator: 0us, total: 184.90ms
top 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:307:<module>, cpu: 185.38ms, accelerator: 0us, total: 185.38ms
  iterator_ops.py:373:get_next, cpu: 184.90ms, accelerator: 0us, total: 184.90ms
train2.py:342:<module> (gradient), cpu: 3.19ms, accelerator: 21.34ms, total: 24.55ms
train2.py:342:<module>, cpu: 3.77ms, accelerator: 13.45ms, total: 17.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_71000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_71250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_71500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_71750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.23ms, accelerator: 64051194.48sec, total: 64051194.48sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 183.32ms, accelerator: 0us, total: 183.32ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.29ms, total: 13.33ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 183.32ms, accelerator: 0us, total: 183.32ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.18ms, accelerator: 64051194.49sec, total: 64051194.49sec
train2.py:307:<module>, cpu: 183.80ms, accelerator: 0us, total: 183.80ms
  iterator_ops.py:373:get_next, cpu: 183.32ms, accelerator: 0us, total: 183.32ms
train2.py:342:<module>, cpu: 3.74ms, accelerator: 13.45ms, total: 17.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_72000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_72250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_72500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_72750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.24ms, accelerator: 63173780.86sec, total: 63173780.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 181.53ms, accelerator: 0us, total: 181.53ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.31ms, total: 13.35ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 181.53ms, accelerator: 0us, total: 181.53ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.17ms, accelerator: 63173780.87sec, total: 63173780.87sec
train2.py:307:<module>, cpu: 182.00ms, accelerator: 0us, total: 182.00ms
  iterator_ops.py:373:get_next, cpu: 181.53ms, accelerator: 0us, total: 181.53ms
train2.py:342:<module>, cpu: 3.71ms, accelerator: 13.42ms, total: 17.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_73000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_73250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_73500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_73750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.23ms, accelerator: 62320081.11sec, total: 62320081.12sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 179.79ms, accelerator: 0us, total: 179.79ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.26ms, total: 13.30ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 179.79ms, accelerator: 0us, total: 179.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.17ms, accelerator: 62320081.13sec, total: 62320081.13sec
train2.py:307:<module>, cpu: 180.25ms, accelerator: 0us, total: 180.25ms
  iterator_ops.py:373:get_next, cpu: 179.79ms, accelerator: 0us, total: 179.79ms
train2.py:342:<module>, cpu: 3.68ms, accelerator: 13.45ms, total: 17.15ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_74000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_74250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_74500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_74750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.23ms, accelerator: 61489146.70sec, total: 61489146.70sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 178.25ms, accelerator: 0us, total: 178.25ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.29ms, total: 13.33ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 178.25ms, accelerator: 0us, total: 178.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.16ms, accelerator: 61489146.71sec, total: 61489146.71sec
train2.py:307:<module>, cpu: 178.70ms, accelerator: 0us, total: 178.70ms
  iterator_ops.py:373:get_next, cpu: 178.25ms, accelerator: 0us, total: 178.25ms
train2.py:342:<module>, cpu: 3.65ms, accelerator: 13.43ms, total: 17.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_75000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_75250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_75500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_75750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.22ms, accelerator: 60680078.98sec, total: 60680078.98sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 176.90ms, accelerator: 0us, total: 176.90ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.19ms, total: 13.22ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 176.90ms, accelerator: 0us, total: 176.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.15ms, accelerator: 60680078.99sec, total: 60680078.99sec
train2.py:307:<module>, cpu: 177.35ms, accelerator: 0us, total: 177.35ms
  iterator_ops.py:373:get_next, cpu: 176.90ms, accelerator: 0us, total: 176.90ms
train2.py:342:<module>, cpu: 3.62ms, accelerator: 13.47ms, total: 17.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_76000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_76250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_76500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_76750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.31

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.22ms, accelerator: 59892026.01sec, total: 59892026.01sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 175.50ms, accelerator: 0us, total: 175.50ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.08ms, total: 13.11ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 175.50ms, accelerator: 0us, total: 175.50ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.14ms, accelerator: 59892026.02sec, total: 59892026.02sec
train2.py:307:<module>, cpu: 175.94ms, accelerator: 0us, total: 175.94ms
  iterator_ops.py:373:get_next, cpu: 175.50ms, accelerator: 0us, total: 175.50ms
train2.py:342:<module>, cpu: 3.59ms, accelerator: 13.50ms, total: 17.10ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_77000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_77250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_77500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_77750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.22ms, accelerator: 59124179.52sec, total: 59124179.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 174.00ms, accelerator: 0us, total: 174.00ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.10ms, total: 13.14ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 174.00ms, accelerator: 0us, total: 174.00ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.13ms, accelerator: 59124179.53sec, total: 59124179.53sec
train2.py:307:<module>, cpu: 174.43ms, accelerator: 0us, total: 174.43ms
  iterator_ops.py:373:get_next, cpu: 174.00ms, accelerator: 0us, total: 174.00ms
train2.py:342:<module>, cpu: 3.56ms, accelerator: 13.48ms, total: 17.06ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_78000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_78250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_78500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_78750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.21ms, accelerator: 58375772.18sec, total: 58375772.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 172.50ms, accelerator: 0us, total: 172.50ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.07ms, total: 13.11ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 172.50ms, accelerator: 0us, total: 172.50ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.12ms, accelerator: 58375772.20sec, total: 58375772.20sec
train2.py:307:<module>, cpu: 172.94ms, accelerator: 0us, total: 172.94ms
  iterator_ops.py:373:get_next, cpu: 172.50ms, accelerator: 0us, total: 172.50ms
train2.py:342:<module>, cpu: 3.53ms, accelerator: 13.50ms, total: 17.05ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_79000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_79250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_79500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_79750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.21ms, accelerator: 57646075.03sec, total: 57646075.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 171.02ms, accelerator: 0us, total: 171.02ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.05ms, total: 13.08ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 171.02ms, accelerator: 0us, total: 171.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.11ms, accelerator: 57646075.04sec, total: 57646075.05sec
train2.py:307:<module>, cpu: 171.45ms, accelerator: 0us, total: 171.45ms
  iterator_ops.py:373:get_next, cpu: 171.02ms, accelerator: 0us, total: 171.02ms
train2.py:342:<module>, cpu: 3.50ms, accelerator: 13.49ms, total: 17.02ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_80000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_80250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_80500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_80750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.20ms, accelerator: 56934395.09sec, total: 56934395.09sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 169.70ms, accelerator: 0us, total: 169.70ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.98ms, total: 13.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 169.70ms, accelerator: 0us, total: 169.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.10ms, accelerator: 56934395.10sec, total: 56934395.11sec
train2.py:307:<module>, cpu: 170.12ms, accelerator: 0us, total: 170.12ms
  iterator_ops.py:373:get_next, cpu: 169.70ms, accelerator: 0us, total: 169.70ms
train2.py:342:<module>, cpu: 3.47ms, accelerator: 13.52ms, total: 17.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.29
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_81000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_81250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_81500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_81750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.20ms, accelerator: 56240073.20sec, total: 56240073.20sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 168.23ms, accelerator: 0us, total: 168.23ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.03ms, total: 13.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 168.23ms, accelerator: 0us, total: 168.23ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.10ms, accelerator: 56240073.21sec, total: 56240073.22sec
train2.py:307:<module>, cpu: 168.65ms, accelerator: 0us, total: 168.65ms
  iterator_ops.py:373:get_next, cpu: 168.23ms, accelerator: 0us, total: 168.23ms
train2.py:342:<module>, cpu: 3.45ms, accelerator: 13.50ms, total: 16.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_82000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_82250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_82500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_82750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.20ms, accelerator: 55562481.96sec, total: 55562481.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 167.13ms, accelerator: 0us, total: 167.13ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.97ms, total: 13.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 167.13ms, accelerator: 0us, total: 167.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.09ms, accelerator: 55562481.97sec, total: 55562481.97sec
train2.py:307:<module>, cpu: 167.55ms, accelerator: 0us, total: 167.55ms
  iterator_ops.py:373:get_next, cpu: 167.13ms, accelerator: 0us, total: 167.13ms
train2.py:342:<module>, cpu: 3.42ms, accelerator: 13.51ms, total: 16.95ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_83000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_83250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_83500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_83750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.19ms, accelerator: 54901023.84sec, total: 54901023.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 165.83ms, accelerator: 0us, total: 165.83ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.04ms, total: 13.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 165.83ms, accelerator: 0us, total: 165.83ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.08ms, accelerator: 54901023.85sec, total: 54901023.85sec
train2.py:307:<module>, cpu: 166.23ms, accelerator: 0us, total: 166.23ms
  iterator_ops.py:373:get_next, cpu: 165.83ms, accelerator: 0us, total: 165.83ms
train2.py:342:<module>, cpu: 3.40ms, accelerator: 13.47ms, total: 16.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_84000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_84250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_84500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_84750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.19ms, accelerator: 54255129.44sec, total: 54255129.44sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 164.68ms, accelerator: 0us, total: 164.68ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 11.95ms, total: 12.98ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 164.68ms, accelerator: 0us, total: 164.68ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.07ms, accelerator: 54255129.45sec, total: 54255129.46sec
train2.py:307:<module>, cpu: 165.08ms, accelerator: 0us, total: 165.08ms
  iterator_ops.py:373:get_next, cpu: 164.68ms, accelerator: 0us, total: 164.68ms
train2.py:342:<module>, cpu: 3.38ms, accelerator: 13.50ms, total: 16.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.59
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_85000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_85250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_85500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_85750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.18ms, accelerator: 53624255.84sec, total: 53624255.85sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 163.58ms, accelerator: 0us, total: 163.58ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 11.98ms, total: 13.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 163.58ms, accelerator: 0us, total: 163.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.07ms, accelerator: 53624255.86sec, total: 53624255.86sec
train2.py:307:<module>, cpu: 163.98ms, accelerator: 0us, total: 163.98ms
  iterator_ops.py:373:get_next, cpu: 163.58ms, accelerator: 0us, total: 163.58ms
train2.py:342:<module>, cpu: 3.35ms, accelerator: 13.48ms, total: 16.85ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_86000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_86250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_86500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_86750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.18ms, accelerator: 53007885.09sec, total: 53007885.09sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 162.41ms, accelerator: 0us, total: 162.41ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.06ms, total: 13.10ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 162.41ms, accelerator: 0us, total: 162.41ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.06ms, accelerator: 53007885.10sec, total: 53007885.10sec
train2.py:307:<module>, cpu: 162.80ms, accelerator: 0us, total: 162.80ms
  iterator_ops.py:373:get_next, cpu: 162.41ms, accelerator: 0us, total: 162.41ms
train2.py:342:<module>, cpu: 3.33ms, accelerator: 13.45ms, total: 16.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_87000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_87250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_87500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_87750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.18ms, accelerator: 52405522.76sec, total: 52405522.76sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 161.33ms, accelerator: 0us, total: 161.33ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.10ms, total: 13.13ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 161.33ms, accelerator: 0us, total: 161.33ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.05ms, accelerator: 52405522.77sec, total: 52405522.77sec
train2.py:307:<module>, cpu: 161.72ms, accelerator: 0us, total: 161.72ms
  iterator_ops.py:373:get_next, cpu: 161.33ms, accelerator: 0us, total: 161.33ms
train2.py:342:<module>, cpu: 3.31ms, accelerator: 13.44ms, total: 16.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_88000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_88250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_88500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_88750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.17ms, accelerator: 51816696.66sec, total: 51816696.66sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 160.32ms, accelerator: 0us, total: 160.32ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.11ms, total: 13.13ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 160.32ms, accelerator: 0us, total: 160.32ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.04ms, accelerator: 51816696.67sec, total: 51816696.67sec
train2.py:307:<module>, cpu: 160.70ms, accelerator: 0us, total: 160.70ms
  iterator_ops.py:373:get_next, cpu: 160.32ms, accelerator: 0us, total: 160.32ms
train2.py:342:<module>, cpu: 3.28ms, accelerator: 13.42ms, total: 16.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_89000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_89250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_89500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_89750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.17ms, accelerator: 51240955.58sec, total: 51240955.59sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 159.15ms, accelerator: 0us, total: 159.15ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.09ms, total: 13.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 159.15ms, accelerator: 0us, total: 159.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.04ms, accelerator: 51240955.60sec, total: 51240955.60sec
train2.py:307:<module>, cpu: 159.53ms, accelerator: 0us, total: 159.53ms
  iterator_ops.py:373:get_next, cpu: 159.15ms, accelerator: 0us, total: 159.15ms
train2.py:342:<module>, cpu: 3.26ms, accelerator: 13.43ms, total: 16.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_90000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_90250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_90500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_90750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.17ms, accelerator: 50677868.16sec, total: 50677868.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 157.95ms, accelerator: 0us, total: 157.95ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.11ms, total: 13.13ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 157.95ms, accelerator: 0us, total: 157.95ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.03ms, accelerator: 50677868.17sec, total: 50677868.18sec
train2.py:307:<module>, cpu: 158.33ms, accelerator: 0us, total: 158.33ms
  iterator_ops.py:373:get_next, cpu: 157.95ms, accelerator: 0us, total: 157.95ms
train2.py:342:<module>, cpu: 3.24ms, accelerator: 13.44ms, total: 16.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_91000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_91250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_91500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_91750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.17ms, accelerator: 50127021.77sec, total: 50127021.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 156.86ms, accelerator: 0us, total: 156.86ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.17ms, total: 13.19ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 156.86ms, accelerator: 0us, total: 156.86ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.03ms, accelerator: 50127021.78sec, total: 50127021.78sec
train2.py:307:<module>, cpu: 157.23ms, accelerator: 0us, total: 157.23ms
  iterator_ops.py:373:get_next, cpu: 156.86ms, accelerator: 0us, total: 156.86ms
train2.py:342:<module>, cpu: 3.22ms, accelerator: 13.42ms, total: 16.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_92000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_92250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_92500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_92750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.16ms, accelerator: 49588021.53sec, total: 49588021.54sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 155.79ms, accelerator: 0us, total: 155.79ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.24ms, total: 13.27ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 155.79ms, accelerator: 0us, total: 155.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.02ms, accelerator: 49588021.55sec, total: 49588021.55sec
train2.py:307:<module>, cpu: 156.16ms, accelerator: 0us, total: 156.16ms
  iterator_ops.py:373:get_next, cpu: 155.79ms, accelerator: 0us, total: 155.79ms
train2.py:342:<module>, cpu: 3.20ms, accelerator: 13.39ms, total: 16.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_93000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_93250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_93500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_93750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.16ms, accelerator: 49060489.39sec, total: 49060489.39sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 154.76ms, accelerator: 0us, total: 154.76ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.23ms, total: 13.26ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 154.76ms, accelerator: 0us, total: 154.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.01ms, accelerator: 49060489.40sec, total: 49060489.40sec
train2.py:307:<module>, cpu: 155.13ms, accelerator: 0us, total: 155.13ms
  iterator_ops.py:373:get_next, cpu: 154.76ms, accelerator: 0us, total: 154.76ms
train2.py:342:<module>, cpu: 3.18ms, accelerator: 13.39ms, total: 16.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_94000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_94250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_94500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_94750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.16ms, accelerator: 48544063.19sec, total: 48544063.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 153.58ms, accelerator: 0us, total: 153.58ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.24ms, total: 13.27ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 153.58ms, accelerator: 0us, total: 153.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.01ms, accelerator: 48544063.20sec, total: 48544063.20sec
train2.py:307:<module>, cpu: 153.94ms, accelerator: 0us, total: 153.94ms
  iterator_ops.py:373:get_next, cpu: 153.58ms, accelerator: 0us, total: 153.58ms
train2.py:342:<module>, cpu: 3.16ms, accelerator: 13.39ms, total: 16.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_95000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_95250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_95500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_95750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.16ms, accelerator: 48038395.86sec, total: 48038395.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 152.69ms, accelerator: 0us, total: 152.69ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.24ms, total: 13.27ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 152.69ms, accelerator: 0us, total: 152.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 3.00ms, accelerator: 48038395.87sec, total: 48038395.88sec
train2.py:307:<module>, cpu: 153.05ms, accelerator: 0us, total: 153.05ms
  iterator_ops.py:373:get_next, cpu: 152.69ms, accelerator: 0us, total: 152.69ms
train2.py:342:<module>, cpu: 3.14ms, accelerator: 13.39ms, total: 16.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_96000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_96250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_96500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_96750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.15ms, accelerator: 47543154.67sec, total: 47543154.67sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 151.65ms, accelerator: 0us, total: 151.65ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.26ms, total: 13.29ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 151.65ms, accelerator: 0us, total: 151.65ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.99ms, accelerator: 47543154.68sec, total: 47543154.68sec
train2.py:307:<module>, cpu: 152.01ms, accelerator: 0us, total: 152.01ms
  iterator_ops.py:373:get_next, cpu: 151.65ms, accelerator: 0us, total: 151.65ms
train2.py:342:<module>, cpu: 3.12ms, accelerator: 13.39ms, total: 16.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_97000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_97250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_97500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_97750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.15ms, accelerator: 47058020.44sec, total: 47058020.44sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 150.70ms, accelerator: 0us, total: 150.70ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.27ms, total: 13.29ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 150.70ms, accelerator: 0us, total: 150.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.99ms, accelerator: 47058020.45sec, total: 47058020.45sec
train2.py:307:<module>, cpu: 151.05ms, accelerator: 0us, total: 151.05ms
  iterator_ops.py:373:get_next, cpu: 150.70ms, accelerator: 0us, total: 150.70ms
train2.py:342:<module>, cpu: 3.10ms, accelerator: 13.38ms, total: 16.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_98000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_98250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_98500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_98750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.15ms, accelerator: 46582686.90sec, total: 46582686.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 155.71ms, accelerator: 0us, total: 155.71ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.25ms, total: 13.28ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 155.71ms, accelerator: 0us, total: 155.71ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.98ms, accelerator: 46582686.91sec, total: 46582686.91sec
train2.py:307:<module>, cpu: 156.05ms, accelerator: 0us, total: 156.05ms
  iterator_ops.py:373:get_next, cpu: 155.71ms, accelerator: 0us, total: 155.71ms
train2.py:342:<module>, cpu: 3.09ms, accelerator: 13.38ms, total: 16.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_99000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_99250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_99500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_99750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.14ms, accelerator: 46116860.03sec, total: 46116860.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 154.63ms, accelerator: 0us, total: 154.63ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.23ms, total: 13.26ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 154.63ms, accelerator: 0us, total: 154.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.98ms, accelerator: 46116860.04sec, total: 46116860.04sec
train2.py:307:<module>, cpu: 154.97ms, accelerator: 0us, total: 154.97ms
  iterator_ops.py:373:get_next, cpu: 154.63ms, accelerator: 0us, total: 154.63ms
train2.py:342:<module>, cpu: 3.07ms, accelerator: 13.39ms, total: 16.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.53
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_100000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_100250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_100500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_100750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.14ms, accelerator: 45660257.45sec, total: 45660257.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 153.49ms, accelerator: 0us, total: 153.49ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.20ms, total: 13.23ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 153.49ms, accelerator: 0us, total: 153.49ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.97ms, accelerator: 45660257.46sec, total: 45660257.47sec
train2.py:307:<module>, cpu: 153.83ms, accelerator: 0us, total: 153.83ms
  iterator_ops.py:373:get_next, cpu: 153.49ms, accelerator: 0us, total: 153.49ms
train2.py:342:<module>, cpu: 3.05ms, accelerator: 13.40ms, total: 16.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_101000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_101250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_101500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_101750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.14ms, accelerator: 45212607.87sec, total: 45212607.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 152.84ms, accelerator: 0us, total: 152.84ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.20ms, total: 13.23ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 152.84ms, accelerator: 0us, total: 152.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.97ms, accelerator: 45212607.88sec, total: 45212607.88sec
train2.py:307:<module>, cpu: 153.18ms, accelerator: 0us, total: 153.18ms
  iterator_ops.py:373:get_next, cpu: 152.84ms, accelerator: 0us, total: 152.84ms
train2.py:342:<module>, cpu: 3.03ms, accelerator: 13.40ms, total: 16.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_102000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_102250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_102500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_102750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.14ms, accelerator: 44773650.51sec, total: 44773650.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 152.09ms, accelerator: 0us, total: 152.09ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.18ms, total: 13.20ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 152.09ms, accelerator: 0us, total: 152.09ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.96ms, accelerator: 44773650.52sec, total: 44773650.53sec
train2.py:307:<module>, cpu: 152.42ms, accelerator: 0us, total: 152.42ms
  iterator_ops.py:373:get_next, cpu: 152.09ms, accelerator: 0us, total: 152.09ms
train2.py:342:<module>, cpu: 3.02ms, accelerator: 13.41ms, total: 16.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.29
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_103000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_103250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_103500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_103750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.14ms, accelerator: 44343134.64sec, total: 44343134.64sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 151.17ms, accelerator: 0us, total: 151.17ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.22ms, total: 13.24ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 151.17ms, accelerator: 0us, total: 151.17ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.96ms, accelerator: 44343134.65sec, total: 44343134.66sec
train2.py:307:<module>, cpu: 151.50ms, accelerator: 0us, total: 151.50ms
  iterator_ops.py:373:get_next, cpu: 151.17ms, accelerator: 0us, total: 151.17ms
train2.py:342:<module>, cpu: 3.00ms, accelerator: 13.41ms, total: 16.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_104000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_104250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_104500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_104750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.13ms, accelerator: 43920819.07sec, total: 43920819.08sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 160.64ms, accelerator: 0us, total: 160.64ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.22ms, total: 13.24ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 160.64ms, accelerator: 0us, total: 160.64ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.95ms, accelerator: 43920819.09sec, total: 43920819.09sec
train2.py:307:<module>, cpu: 160.97ms, accelerator: 0us, total: 160.97ms
  iterator_ops.py:373:get_next, cpu: 160.64ms, accelerator: 0us, total: 160.64ms
train2.py:342:<module>, cpu: 2.99ms, accelerator: 13.42ms, total: 16.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_105000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_105250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_105500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_105750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.13ms, accelerator: 43506471.72sec, total: 43506471.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 159.56ms, accelerator: 0us, total: 159.56ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.20ms, total: 13.22ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 159.56ms, accelerator: 0us, total: 159.56ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.95ms, accelerator: 43506471.74sec, total: 43506471.74sec
train2.py:307:<module>, cpu: 159.89ms, accelerator: 0us, total: 159.89ms
  iterator_ops.py:373:get_next, cpu: 159.56ms, accelerator: 0us, total: 159.56ms
train2.py:342:<module>, cpu: 2.97ms, accelerator: 13.43ms, total: 16.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_106000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_106250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_106500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_106750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.13ms, accelerator: 43099869.19sec, total: 43099869.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 159.05ms, accelerator: 0us, total: 159.05ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.17ms, total: 13.20ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 159.05ms, accelerator: 0us, total: 159.05ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.95ms, accelerator: 43099869.20sec, total: 43099869.20sec
train2.py:307:<module>, cpu: 159.37ms, accelerator: 0us, total: 159.37ms
  iterator_ops.py:373:get_next, cpu: 159.05ms, accelerator: 0us, total: 159.05ms
train2.py:342:<module>, cpu: 2.96ms, accelerator: 13.44ms, total: 16.41ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_107000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_107250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_107500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_107750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.13ms, accelerator: 42700796.32sec, total: 42700796.32sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 158.04ms, accelerator: 0us, total: 158.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.20ms, total: 13.22ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 158.04ms, accelerator: 0us, total: 158.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.95ms, accelerator: 42700796.33sec, total: 42700796.34sec
train2.py:307:<module>, cpu: 158.36ms, accelerator: 0us, total: 158.36ms
  iterator_ops.py:373:get_next, cpu: 158.04ms, accelerator: 0us, total: 158.04ms
train2.py:342:<module>, cpu: 2.94ms, accelerator: 13.43ms, total: 16.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_108000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_108250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_108500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_108750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.13ms, accelerator: 42309045.90sec, total: 42309045.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 166.06ms, accelerator: 0us, total: 166.06ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.16ms, total: 13.19ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 166.06ms, accelerator: 0us, total: 166.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.94ms, accelerator: 42309045.91sec, total: 42309045.91sec
train2.py:307:<module>, cpu: 166.37ms, accelerator: 0us, total: 166.37ms
  iterator_ops.py:373:get_next, cpu: 166.06ms, accelerator: 0us, total: 166.06ms
train2.py:342:<module>, cpu: 2.93ms, accelerator: 13.44ms, total: 16.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_109000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_109250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_109500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_109750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.13ms, accelerator: 41924418.21sec, total: 41924418.21sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 165.27ms, accelerator: 0us, total: 165.27ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.12ms, total: 13.14ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 165.27ms, accelerator: 0us, total: 165.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.94ms, accelerator: 41924418.22sec, total: 41924418.22sec
train2.py:307:<module>, cpu: 165.58ms, accelerator: 0us, total: 165.58ms
  iterator_ops.py:373:get_next, cpu: 165.27ms, accelerator: 0us, total: 165.27ms
train2.py:342:<module>, cpu: 2.92ms, accelerator: 13.45ms, total: 16.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_110000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_110250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_110500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_110750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.13ms, accelerator: 41546720.75sec, total: 41546720.75sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 164.40ms, accelerator: 0us, total: 164.40ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.08ms, total: 13.10ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 164.40ms, accelerator: 0us, total: 164.40ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.94ms, accelerator: 41546720.76sec, total: 41546720.76sec
train2.py:307:<module>, cpu: 164.71ms, accelerator: 0us, total: 164.71ms
  iterator_ops.py:373:get_next, cpu: 164.40ms, accelerator: 0us, total: 164.40ms
train2.py:342:<module>, cpu: 2.90ms, accelerator: 13.47ms, total: 16.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_111000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_111250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_111500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_111750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.13ms, accelerator: 41175767.88sec, total: 41175767.88sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 173.67ms, accelerator: 0us, total: 173.67ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.00ms, total: 13.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 173.67ms, accelerator: 0us, total: 173.67ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.93ms, accelerator: 41175767.89sec, total: 41175767.90sec
train2.py:307:<module>, cpu: 173.97ms, accelerator: 0us, total: 173.97ms
  iterator_ops.py:373:get_next, cpu: 173.67ms, accelerator: 0us, total: 173.67ms
train2.py:342:<module>, cpu: 2.89ms, accelerator: 13.49ms, total: 16.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_112000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_112250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_112500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_112750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.12ms, accelerator: 40811380.56sec, total: 40811380.56sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 172.67ms, accelerator: 0us, total: 172.67ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.03ms, total: 13.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 172.67ms, accelerator: 0us, total: 172.67ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.93ms, accelerator: 40811380.57sec, total: 40811380.57sec
train2.py:307:<module>, cpu: 172.97ms, accelerator: 0us, total: 172.97ms
  iterator_ops.py:373:get_next, cpu: 172.67ms, accelerator: 0us, total: 172.67ms
train2.py:342:<module>, cpu: 2.88ms, accelerator: 13.48ms, total: 16.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_113000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_113250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_113500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_113750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.12ms, accelerator: 40453385.99sec, total: 40453385.99sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 171.64ms, accelerator: 0us, total: 171.64ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 11.99ms, total: 13.02ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 171.64ms, accelerator: 0us, total: 171.64ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.93ms, accelerator: 40453386.00sec, total: 40453386.00sec
train2.py:307:<module>, cpu: 171.94ms, accelerator: 0us, total: 171.94ms
  iterator_ops.py:373:get_next, cpu: 171.64ms, accelerator: 0us, total: 171.64ms
train2.py:342:<module>, cpu: 2.86ms, accelerator: 13.49ms, total: 16.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_114000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_114250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_114500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_114750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.12ms, accelerator: 40101617.42sec, total: 40101617.42sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 171.35ms, accelerator: 0us, total: 171.35ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 11.97ms, total: 12.99ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 171.35ms, accelerator: 0us, total: 171.35ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.93ms, accelerator: 40101617.43sec, total: 40101617.43sec
train2.py:307:<module>, cpu: 171.65ms, accelerator: 0us, total: 171.65ms
  iterator_ops.py:373:get_next, cpu: 171.35ms, accelerator: 0us, total: 171.35ms
train2.py:342:<module>, cpu: 2.85ms, accelerator: 13.50ms, total: 16.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_115000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_115250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_115500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_115750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.12ms, accelerator: 39755913.82sec, total: 39755913.82sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 170.55ms, accelerator: 0us, total: 170.55ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 11.99ms, total: 13.02ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 170.55ms, accelerator: 0us, total: 170.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.92ms, accelerator: 39755913.83sec, total: 39755913.83sec
train2.py:307:<module>, cpu: 170.85ms, accelerator: 0us, total: 170.85ms
  iterator_ops.py:373:get_next, cpu: 170.55ms, accelerator: 0us, total: 170.55ms
train2.py:342:<module>, cpu: 2.84ms, accelerator: 13.47ms, total: 16.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_116000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_116250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_116500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_116750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.12ms, accelerator: 39416119.68sec, total: 39416119.68sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 178.62ms, accelerator: 0us, total: 178.62ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.02ms, total: 13.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 178.62ms, accelerator: 0us, total: 178.62ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.92ms, accelerator: 39416119.69sec, total: 39416119.70sec
train2.py:307:<module>, cpu: 178.92ms, accelerator: 0us, total: 178.92ms
  iterator_ops.py:373:get_next, cpu: 178.62ms, accelerator: 0us, total: 178.62ms
train2.py:342:<module>, cpu: 2.83ms, accelerator: 13.46ms, total: 16.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_117000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_117250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_117500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_117750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.12ms, accelerator: 39082084.77sec, total: 39082084.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 177.79ms, accelerator: 0us, total: 177.79ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.01ms, total: 13.04ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 177.79ms, accelerator: 0us, total: 177.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.92ms, accelerator: 39082084.78sec, total: 39082084.78sec
train2.py:307:<module>, cpu: 178.08ms, accelerator: 0us, total: 178.08ms
  iterator_ops.py:373:get_next, cpu: 177.79ms, accelerator: 0us, total: 177.79ms
train2.py:342:<module>, cpu: 2.82ms, accelerator: 13.46ms, total: 16.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_118000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_118250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_118500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_118750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.12ms, accelerator: 38753663.89sec, total: 38753663.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 176.84ms, accelerator: 0us, total: 176.84ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.06ms, total: 13.09ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 176.84ms, accelerator: 0us, total: 176.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.91ms, accelerator: 38753663.90sec, total: 38753663.90sec
train2.py:307:<module>, cpu: 177.13ms, accelerator: 0us, total: 177.13ms
  iterator_ops.py:373:get_next, cpu: 176.84ms, accelerator: 0us, total: 176.84ms
train2.py:342:<module>, cpu: 2.81ms, accelerator: 13.44ms, total: 16.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_119000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_119250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_119500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_119750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.12ms, accelerator: 38430716.69sec, total: 38430716.69sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 175.91ms, accelerator: 0us, total: 175.91ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.01ms, accelerator: 12.05ms, total: 13.08ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 175.91ms, accelerator: 0us, total: 175.91ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.91ms, accelerator: 38430716.70sec, total: 38430716.71sec
train2.py:307:<module>, cpu: 176.19ms, accelerator: 0us, total: 176.19ms
  iterator_ops.py:373:get_next, cpu: 175.91ms, accelerator: 0us, total: 175.91ms
train2.py:342:<module>, cpu: 2.80ms, accelerator: 13.43ms, total: 16.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_120000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_120250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_120500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_120750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.12ms, accelerator: 38113107.46sec, total: 38113107.46sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 174.93ms, accelerator: 0us, total: 174.93ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.09ms, total: 13.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 174.93ms, accelerator: 0us, total: 174.93ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.91ms, accelerator: 38113107.47sec, total: 38113107.48sec
train2.py:307:<module>, cpu: 175.22ms, accelerator: 0us, total: 175.22ms
  iterator_ops.py:373:get_next, cpu: 174.93ms, accelerator: 0us, total: 174.93ms
train2.py:342:<module>, cpu: 2.78ms, accelerator: 13.44ms, total: 16.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_121000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_121250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_121500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_121750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 37800704.94sec, total: 37800704.94sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 174.02ms, accelerator: 0us, total: 174.02ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.08ms, total: 13.11ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 174.02ms, accelerator: 0us, total: 174.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.91ms, accelerator: 37800704.95sec, total: 37800704.96sec
train2.py:307:<module>, cpu: 174.30ms, accelerator: 0us, total: 174.30ms
  iterator_ops.py:373:get_next, cpu: 174.02ms, accelerator: 0us, total: 174.02ms
train2.py:342:<module>, cpu: 2.77ms, accelerator: 13.44ms, total: 16.23ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_122000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_122250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_122500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_122750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 37493382.14sec, total: 37493382.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 173.20ms, accelerator: 0us, total: 173.20ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.10ms, total: 13.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 173.20ms, accelerator: 0us, total: 173.20ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.90ms, accelerator: 37493382.15sec, total: 37493382.15sec
train2.py:307:<module>, cpu: 173.48ms, accelerator: 0us, total: 173.48ms
  iterator_ops.py:373:get_next, cpu: 173.20ms, accelerator: 0us, total: 173.20ms
train2.py:342:<module>, cpu: 2.76ms, accelerator: 13.43ms, total: 16.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_123000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_123250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_123500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_123750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 37191016.15sec, total: 37191016.15sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 172.48ms, accelerator: 0us, total: 172.48ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.07ms, total: 13.10ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 172.48ms, accelerator: 0us, total: 172.48ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.90ms, accelerator: 37191016.16sec, total: 37191016.17sec
train2.py:307:<module>, cpu: 172.76ms, accelerator: 0us, total: 172.76ms
  iterator_ops.py:373:get_next, cpu: 172.48ms, accelerator: 0us, total: 172.48ms
train2.py:342:<module>, cpu: 2.75ms, accelerator: 13.43ms, total: 16.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_124000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_124250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_124500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_124750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 36893488.02sec, total: 36893488.02sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 171.50ms, accelerator: 0us, total: 171.50ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.12ms, total: 13.15ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 171.50ms, accelerator: 0us, total: 171.50ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.90ms, accelerator: 36893488.04sec, total: 36893488.04sec
train2.py:307:<module>, cpu: 171.77ms, accelerator: 0us, total: 171.77ms
  iterator_ops.py:373:get_next, cpu: 171.50ms, accelerator: 0us, total: 171.50ms
train2.py:342:<module>, cpu: 2.74ms, accelerator: 13.41ms, total: 16.17ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_125000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_125250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_125500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_125750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 36600682.56sec, total: 36600682.56sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 170.53ms, accelerator: 0us, total: 170.53ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.13ms, total: 13.16ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 170.53ms, accelerator: 0us, total: 170.53ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.90ms, accelerator: 36600682.57sec, total: 36600682.58sec
train2.py:307:<module>, cpu: 170.80ms, accelerator: 0us, total: 170.80ms
  iterator_ops.py:373:get_next, cpu: 170.53ms, accelerator: 0us, total: 170.53ms
train2.py:342:<module>, cpu: 2.73ms, accelerator: 13.42ms, total: 16.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_126000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_126250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_126500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_126750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 36312488.21sec, total: 36312488.21sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 169.83ms, accelerator: 0us, total: 169.83ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.10ms, total: 13.13ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 169.83ms, accelerator: 0us, total: 169.83ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.89ms, accelerator: 36312488.22sec, total: 36312488.23sec
train2.py:307:<module>, cpu: 170.10ms, accelerator: 0us, total: 170.10ms
  iterator_ops.py:373:get_next, cpu: 169.83ms, accelerator: 0us, total: 169.83ms
train2.py:342:<module>, cpu: 2.72ms, accelerator: 13.42ms, total: 16.16ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_127000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_127250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_127500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_127750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 36028796.90sec, total: 36028796.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 169.08ms, accelerator: 0us, total: 169.08ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.10ms, total: 13.13ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 169.08ms, accelerator: 0us, total: 169.08ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.89ms, accelerator: 36028796.91sec, total: 36028796.91sec
train2.py:307:<module>, cpu: 169.34ms, accelerator: 0us, total: 169.34ms
  iterator_ops.py:373:get_next, cpu: 169.08ms, accelerator: 0us, total: 169.08ms
train2.py:342:<module>, cpu: 2.71ms, accelerator: 13.41ms, total: 16.14ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_128000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_128250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_128500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_128750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 35749503.90sec, total: 35749503.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 168.28ms, accelerator: 0us, total: 168.28ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.16ms, total: 13.19ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 168.28ms, accelerator: 0us, total: 168.28ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.89ms, accelerator: 35749503.91sec, total: 35749503.91sec
train2.py:307:<module>, cpu: 168.55ms, accelerator: 0us, total: 168.55ms
  iterator_ops.py:373:get_next, cpu: 168.28ms, accelerator: 0us, total: 168.28ms
train2.py:342:<module>, cpu: 2.71ms, accelerator: 13.39ms, total: 16.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_129000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_129250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_129500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_129750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 35474507.72sec, total: 35474507.72sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 167.41ms, accelerator: 0us, total: 167.41ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.15ms, total: 13.18ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 167.41ms, accelerator: 0us, total: 167.41ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.88ms, accelerator: 35474507.73sec, total: 35474507.73sec
train2.py:307:<module>, cpu: 167.68ms, accelerator: 0us, total: 167.68ms
  iterator_ops.py:373:get_next, cpu: 167.41ms, accelerator: 0us, total: 167.41ms
train2.py:342:<module>, cpu: 2.69ms, accelerator: 13.39ms, total: 16.11ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_130000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_130250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_130500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_130750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 35203709.95sec, total: 35203709.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 166.58ms, accelerator: 0us, total: 166.58ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.13ms, total: 13.17ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 166.58ms, accelerator: 0us, total: 166.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.89ms, accelerator: 35203709.96sec, total: 35203709.96sec
train2.py:307:<module>, cpu: 166.84ms, accelerator: 0us, total: 166.84ms
  iterator_ops.py:373:get_next, cpu: 166.58ms, accelerator: 0us, total: 166.58ms
train2.py:342:<module>, cpu: 2.68ms, accelerator: 13.39ms, total: 16.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_131000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_131250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_131500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_131750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.11ms, accelerator: 34937015.17sec, total: 34937015.18sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 165.88ms, accelerator: 0us, total: 165.88ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.08ms, total: 13.11ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 165.88ms, accelerator: 0us, total: 165.88ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.88ms, accelerator: 34937015.19sec, total: 34937015.19sec
train2.py:307:<module>, cpu: 166.14ms, accelerator: 0us, total: 166.14ms
  iterator_ops.py:373:get_next, cpu: 165.88ms, accelerator: 0us, total: 165.88ms
train2.py:342:<module>, cpu: 2.67ms, accelerator: 13.41ms, total: 16.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_132000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_132250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_132500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_132750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.10ms, accelerator: 34674330.85sec, total: 34674330.85sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 165.19ms, accelerator: 0us, total: 165.19ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.07ms, total: 13.10ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 165.19ms, accelerator: 0us, total: 165.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.88ms, accelerator: 34674330.86sec, total: 34674330.86sec
train2.py:307:<module>, cpu: 165.45ms, accelerator: 0us, total: 165.45ms
  iterator_ops.py:373:get_next, cpu: 165.19ms, accelerator: 0us, total: 165.19ms
train2.py:342:<module>, cpu: 2.66ms, accelerator: 13.41ms, total: 16.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_133000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_133250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_133500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_133750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.10ms, accelerator: 34415567.19sec, total: 34415567.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 164.47ms, accelerator: 0us, total: 164.47ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.03ms, total: 13.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 164.47ms, accelerator: 0us, total: 164.47ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.88ms, accelerator: 34415567.20sec, total: 34415567.20sec
train2.py:307:<module>, cpu: 164.72ms, accelerator: 0us, total: 164.72ms
  iterator_ops.py:373:get_next, cpu: 164.47ms, accelerator: 0us, total: 164.47ms
train2.py:342:<module>, cpu: 2.65ms, accelerator: 13.42ms, total: 16.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_134000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_134250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_134500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_134750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.10ms, accelerator: 34160637.06sec, total: 34160637.06sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 163.81ms, accelerator: 0us, total: 163.81ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.04ms, total: 13.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 163.81ms, accelerator: 0us, total: 163.81ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.87ms, accelerator: 34160637.07sec, total: 34160637.07sec
train2.py:307:<module>, cpu: 164.06ms, accelerator: 0us, total: 164.06ms
  iterator_ops.py:373:get_next, cpu: 163.81ms, accelerator: 0us, total: 163.81ms
train2.py:342:<module>, cpu: 2.64ms, accelerator: 13.42ms, total: 16.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_135000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_135250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_135500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_135750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.10ms, accelerator: 33909455.91sec, total: 33909455.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 163.02ms, accelerator: 0us, total: 163.02ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.01ms, total: 13.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 163.02ms, accelerator: 0us, total: 163.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.87ms, accelerator: 33909455.92sec, total: 33909455.92sec
train2.py:307:<module>, cpu: 163.28ms, accelerator: 0us, total: 163.28ms
  iterator_ops.py:373:get_next, cpu: 163.02ms, accelerator: 0us, total: 163.02ms
train2.py:342:<module>, cpu: 2.63ms, accelerator: 13.43ms, total: 16.09ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_136000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_136250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_136500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_136750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.10ms, accelerator: 33661941.63sec, total: 33661941.63sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 162.28ms, accelerator: 0us, total: 162.28ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.96ms, total: 12.99ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 162.28ms, accelerator: 0us, total: 162.28ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.87ms, accelerator: 33661941.64sec, total: 33661941.64sec
train2.py:307:<module>, cpu: 162.54ms, accelerator: 0us, total: 162.54ms
  iterator_ops.py:373:get_next, cpu: 162.28ms, accelerator: 0us, total: 162.28ms
train2.py:342:<module>, cpu: 2.63ms, accelerator: 13.44ms, total: 16.10ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.31
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_137000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_137250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_137500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_137750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.10ms, accelerator: 33418014.52sec, total: 33418014.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 169.19ms, accelerator: 0us, total: 169.19ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.01ms, total: 13.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 169.19ms, accelerator: 0us, total: 169.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.87ms, accelerator: 33418014.53sec, total: 33418014.53sec
train2.py:307:<module>, cpu: 169.44ms, accelerator: 0us, total: 169.44ms
  iterator_ops.py:373:get_next, cpu: 169.19ms, accelerator: 0us, total: 169.19ms
train2.py:342:<module>, cpu: 2.62ms, accelerator: 13.44ms, total: 16.08ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_138000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_138250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_138500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_138750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.10ms, accelerator: 33177597.14sec, total: 33177597.15sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 168.48ms, accelerator: 0us, total: 168.48ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.00ms, total: 13.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 168.48ms, accelerator: 0us, total: 168.48ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.87ms, accelerator: 33177597.16sec, total: 33177597.16sec
train2.py:307:<module>, cpu: 168.72ms, accelerator: 0us, total: 168.72ms
  iterator_ops.py:373:get_next, cpu: 168.48ms, accelerator: 0us, total: 168.48ms
train2.py:342:<module>, cpu: 2.61ms, accelerator: 13.44ms, total: 16.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_139000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_139250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_139500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_139750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 32940614.31sec, total: 32940614.31sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 167.66ms, accelerator: 0us, total: 167.66ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.00ms, total: 13.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 167.66ms, accelerator: 0us, total: 167.66ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.86ms, accelerator: 32940614.32sec, total: 32940614.32sec
train2.py:307:<module>, cpu: 167.91ms, accelerator: 0us, total: 167.91ms
  iterator_ops.py:373:get_next, cpu: 167.66ms, accelerator: 0us, total: 167.66ms
train2.py:342:<module>, cpu: 2.60ms, accelerator: 13.44ms, total: 16.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_140000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_140250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_140500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_140750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 32706992.93sec, total: 32706992.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 166.95ms, accelerator: 0us, total: 166.95ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.95ms, total: 12.98ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 166.95ms, accelerator: 0us, total: 166.95ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.86ms, accelerator: 32706992.94sec, total: 32706992.94sec
train2.py:307:<module>, cpu: 167.19ms, accelerator: 0us, total: 167.19ms
  iterator_ops.py:373:get_next, cpu: 166.95ms, accelerator: 0us, total: 166.95ms
train2.py:342:<module>, cpu: 2.59ms, accelerator: 13.46ms, total: 16.07ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_141000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_141250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_141500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_141750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 32476661.99sec, total: 32476662.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 166.37ms, accelerator: 0us, total: 166.37ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.99ms, total: 13.02ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 166.37ms, accelerator: 0us, total: 166.37ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.86ms, accelerator: 32476662.01sec, total: 32476662.01sec
train2.py:307:<module>, cpu: 166.61ms, accelerator: 0us, total: 166.61ms
  iterator_ops.py:373:get_next, cpu: 166.37ms, accelerator: 0us, total: 166.37ms
train2.py:342:<module>, cpu: 2.58ms, accelerator: 13.44ms, total: 16.04ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_142000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_142250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_142500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_142750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 32249552.47sec, total: 32249552.47sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 165.58ms, accelerator: 0us, total: 165.58ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.00ms, total: 13.04ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 165.58ms, accelerator: 0us, total: 165.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.86ms, accelerator: 32249552.48sec, total: 32249552.48sec
train2.py:307:<module>, cpu: 165.82ms, accelerator: 0us, total: 165.82ms
  iterator_ops.py:373:get_next, cpu: 165.58ms, accelerator: 0us, total: 165.58ms
train2.py:342:<module>, cpu: 2.58ms, accelerator: 13.43ms, total: 16.03ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_143000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_143250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_143500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_143750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 32025597.24sec, total: 32025597.25sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 164.88ms, accelerator: 0us, total: 164.88ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.03ms, total: 13.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 164.88ms, accelerator: 0us, total: 164.88ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.86ms, accelerator: 32025597.26sec, total: 32025597.26sec
train2.py:307:<module>, cpu: 165.12ms, accelerator: 0us, total: 165.12ms
  iterator_ops.py:373:get_next, cpu: 164.88ms, accelerator: 0us, total: 164.88ms
train2.py:342:<module>, cpu: 2.57ms, accelerator: 13.42ms, total: 16.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_144000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_144250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_144500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_144750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 31804731.06sec, total: 31804731.06sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 164.86ms, accelerator: 0us, total: 164.86ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.04ms, total: 13.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 164.86ms, accelerator: 0us, total: 164.86ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.86ms, accelerator: 31804731.07sec, total: 31804731.07sec
train2.py:307:<module>, cpu: 165.10ms, accelerator: 0us, total: 165.10ms
  iterator_ops.py:373:get_next, cpu: 164.86ms, accelerator: 0us, total: 164.86ms
train2.py:342:<module>, cpu: 2.56ms, accelerator: 13.43ms, total: 16.01ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_145000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_145250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_145500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_145750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 31586890.43sec, total: 31586890.43sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 164.17ms, accelerator: 0us, total: 164.17ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.05ms, total: 13.08ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 164.17ms, accelerator: 0us, total: 164.17ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.85ms, accelerator: 31586890.44sec, total: 31586890.45sec
train2.py:307:<module>, cpu: 164.41ms, accelerator: 0us, total: 164.41ms
  iterator_ops.py:373:get_next, cpu: 164.17ms, accelerator: 0us, total: 164.17ms
train2.py:342:<module>, cpu: 2.55ms, accelerator: 13.41ms, total: 15.99ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_146000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_146250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_146500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_146750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 31372013.63sec, total: 31372013.63sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 163.44ms, accelerator: 0us, total: 163.44ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.03ms, total: 13.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 163.44ms, accelerator: 0us, total: 163.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.85ms, accelerator: 31372013.64sec, total: 31372013.64sec
train2.py:307:<module>, cpu: 163.67ms, accelerator: 0us, total: 163.67ms
  iterator_ops.py:373:get_next, cpu: 163.44ms, accelerator: 0us, total: 163.44ms
train2.py:342:<module>, cpu: 2.55ms, accelerator: 13.44ms, total: 16.00ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_147000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_147250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_147500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_147750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 31160040.56sec, total: 31160040.56sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 162.69ms, accelerator: 0us, total: 162.69ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.06ms, total: 13.10ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 162.69ms, accelerator: 0us, total: 162.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.85ms, accelerator: 31160040.57sec, total: 31160040.58sec
train2.py:307:<module>, cpu: 162.93ms, accelerator: 0us, total: 162.93ms
  iterator_ops.py:373:get_next, cpu: 162.69ms, accelerator: 0us, total: 162.69ms
train2.py:342:<module>, cpu: 2.54ms, accelerator: 13.42ms, total: 15.98ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_148000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_148250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_148500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_148750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 30950912.77sec, total: 30950912.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 162.06ms, accelerator: 0us, total: 162.06ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.09ms, total: 13.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 162.06ms, accelerator: 0us, total: 162.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.85ms, accelerator: 30950912.78sec, total: 30950912.79sec
train2.py:307:<module>, cpu: 162.29ms, accelerator: 0us, total: 162.29ms
  iterator_ops.py:373:get_next, cpu: 162.06ms, accelerator: 0us, total: 162.06ms
train2.py:342:<module>, cpu: 2.53ms, accelerator: 13.40ms, total: 15.96ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_149000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_149250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_149500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_149750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 30744573.35sec, total: 30744573.36sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 161.45ms, accelerator: 0us, total: 161.45ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.10ms, total: 13.14ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 161.45ms, accelerator: 0us, total: 161.45ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.85ms, accelerator: 30744573.37sec, total: 30744573.37sec
train2.py:307:<module>, cpu: 161.68ms, accelerator: 0us, total: 161.68ms
  iterator_ops.py:373:get_next, cpu: 161.45ms, accelerator: 0us, total: 161.45ms
train2.py:342:<module>, cpu: 2.52ms, accelerator: 13.39ms, total: 15.94ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_150000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_150250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_150500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_150750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 30540966.91sec, total: 30540966.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 160.78ms, accelerator: 0us, total: 160.78ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.13ms, total: 13.17ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 160.78ms, accelerator: 0us, total: 160.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.84ms, accelerator: 30540966.92sec, total: 30540966.92sec
train2.py:307:<module>, cpu: 161.00ms, accelerator: 0us, total: 161.00ms
  iterator_ops.py:373:get_next, cpu: 160.78ms, accelerator: 0us, total: 160.78ms
train2.py:342:<module>, cpu: 2.52ms, accelerator: 13.39ms, total: 15.93ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_151000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_151250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_151500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_151750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.09ms, accelerator: 30340039.49sec, total: 30340039.50sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 160.16ms, accelerator: 0us, total: 160.16ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.13ms, total: 13.16ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 160.16ms, accelerator: 0us, total: 160.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.84ms, accelerator: 30340039.51sec, total: 30340039.51sec
train2.py:307:<module>, cpu: 160.39ms, accelerator: 0us, total: 160.39ms
  iterator_ops.py:373:get_next, cpu: 160.16ms, accelerator: 0us, total: 160.16ms
train2.py:342:<module>, cpu: 2.51ms, accelerator: 13.39ms, total: 15.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_152000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_152250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_152500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_152750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 30141738.58sec, total: 30141738.58sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 159.48ms, accelerator: 0us, total: 159.48ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.15ms, total: 13.19ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 159.48ms, accelerator: 0us, total: 159.48ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.84ms, accelerator: 30141738.59sec, total: 30141738.60sec
train2.py:307:<module>, cpu: 159.71ms, accelerator: 0us, total: 159.71ms
  iterator_ops.py:373:get_next, cpu: 159.48ms, accelerator: 0us, total: 159.48ms
train2.py:342:<module>, cpu: 2.50ms, accelerator: 13.39ms, total: 15.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_153000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_153250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_153500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_153750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 29946013.01sec, total: 29946013.01sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 158.72ms, accelerator: 0us, total: 158.72ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.12ms, total: 13.15ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 158.72ms, accelerator: 0us, total: 158.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.84ms, accelerator: 29946013.02sec, total: 29946013.02sec
train2.py:307:<module>, cpu: 158.94ms, accelerator: 0us, total: 158.94ms
  iterator_ops.py:373:get_next, cpu: 158.72ms, accelerator: 0us, total: 158.72ms
train2.py:342:<module>, cpu: 2.50ms, accelerator: 13.40ms, total: 15.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_154000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_154250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_154500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_154750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 29752812.92sec, total: 29752812.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 158.03ms, accelerator: 0us, total: 158.03ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.10ms, total: 13.14ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 158.03ms, accelerator: 0us, total: 158.03ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.83ms, accelerator: 29752812.94sec, total: 29752812.94sec
train2.py:307:<module>, cpu: 158.26ms, accelerator: 0us, total: 158.26ms
  iterator_ops.py:373:get_next, cpu: 158.03ms, accelerator: 0us, total: 158.03ms
train2.py:342:<module>, cpu: 2.49ms, accelerator: 13.40ms, total: 15.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_155000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_155250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_155500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_155750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 29562089.76sec, total: 29562089.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 157.49ms, accelerator: 0us, total: 157.49ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.09ms, total: 13.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 157.49ms, accelerator: 0us, total: 157.49ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.83ms, accelerator: 29562089.78sec, total: 29562089.78sec
train2.py:307:<module>, cpu: 157.71ms, accelerator: 0us, total: 157.71ms
  iterator_ops.py:373:get_next, cpu: 157.49ms, accelerator: 0us, total: 157.49ms
train2.py:342:<module>, cpu: 2.48ms, accelerator: 13.42ms, total: 15.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_156000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_156250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_156500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_156750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 29373796.20sec, total: 29373796.20sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 156.96ms, accelerator: 0us, total: 156.96ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.08ms, total: 13.12ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 156.96ms, accelerator: 0us, total: 156.96ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.83ms, accelerator: 29373796.21sec, total: 29373796.21sec
train2.py:307:<module>, cpu: 157.18ms, accelerator: 0us, total: 157.18ms
  iterator_ops.py:373:get_next, cpu: 156.96ms, accelerator: 0us, total: 156.96ms
train2.py:342:<module>, cpu: 2.47ms, accelerator: 13.41ms, total: 15.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_157000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_157250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_157500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_157750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 29187886.10sec, total: 29187886.10sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 156.46ms, accelerator: 0us, total: 156.46ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.07ms, total: 13.11ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 156.46ms, accelerator: 0us, total: 156.46ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.83ms, accelerator: 29187886.11sec, total: 29187886.11sec
train2.py:307:<module>, cpu: 156.68ms, accelerator: 0us, total: 156.68ms
  iterator_ops.py:373:get_next, cpu: 156.46ms, accelerator: 0us, total: 156.46ms
train2.py:342:<module>, cpu: 2.47ms, accelerator: 13.42ms, total: 15.91ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_158000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_158250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_158500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_158750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 29004314.49sec, total: 29004314.49sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 156.01ms, accelerator: 0us, total: 156.01ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.03ms, total: 13.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 156.01ms, accelerator: 0us, total: 156.01ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.83ms, accelerator: 29004314.50sec, total: 29004314.50sec
train2.py:307:<module>, cpu: 156.23ms, accelerator: 0us, total: 156.23ms
  iterator_ops.py:373:get_next, cpu: 156.01ms, accelerator: 0us, total: 156.01ms
train2.py:342:<module>, cpu: 2.46ms, accelerator: 13.44ms, total: 15.92ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.31
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_159000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_159250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_159500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_159750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 28823037.52sec, total: 28823037.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 155.40ms, accelerator: 0us, total: 155.40ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.05ms, total: 13.08ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 155.40ms, accelerator: 0us, total: 155.40ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.83ms, accelerator: 28823037.53sec, total: 28823037.54sec
train2.py:307:<module>, cpu: 155.61ms, accelerator: 0us, total: 155.61ms
  iterator_ops.py:373:get_next, cpu: 155.40ms, accelerator: 0us, total: 155.40ms
train2.py:342:<module>, cpu: 2.45ms, accelerator: 13.43ms, total: 15.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_160000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_160250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_160500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_160750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 28644012.44sec, total: 28644012.44sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 154.75ms, accelerator: 0us, total: 154.75ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.04ms, total: 13.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 154.75ms, accelerator: 0us, total: 154.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.83ms, accelerator: 28644012.45sec, total: 28644012.46sec
train2.py:307:<module>, cpu: 154.97ms, accelerator: 0us, total: 154.97ms
  iterator_ops.py:373:get_next, cpu: 154.75ms, accelerator: 0us, total: 154.75ms
train2.py:342:<module>, cpu: 2.45ms, accelerator: 13.43ms, total: 15.90ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_161000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_161250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_161500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_161750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 28467197.55sec, total: 28467197.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 154.25ms, accelerator: 0us, total: 154.25ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.03ms, total: 13.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 154.25ms, accelerator: 0us, total: 154.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.83ms, accelerator: 28467197.56sec, total: 28467197.57sec
train2.py:307:<module>, cpu: 154.46ms, accelerator: 0us, total: 154.46ms
  iterator_ops.py:373:get_next, cpu: 154.25ms, accelerator: 0us, total: 154.25ms
train2.py:342:<module>, cpu: 2.44ms, accelerator: 13.43ms, total: 15.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_162000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_162250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_162500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_162750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 28292552.17sec, total: 28292552.17sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 153.78ms, accelerator: 0us, total: 153.78ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.00ms, total: 13.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 153.78ms, accelerator: 0us, total: 153.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.83ms, accelerator: 28292552.18sec, total: 28292552.18sec
train2.py:307:<module>, cpu: 153.99ms, accelerator: 0us, total: 153.99ms
  iterator_ops.py:373:get_next, cpu: 153.78ms, accelerator: 0us, total: 153.78ms
train2.py:342:<module>, cpu: 2.44ms, accelerator: 13.44ms, total: 15.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_163000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_163250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_163500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_163750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 28120036.61sec, total: 28120036.61sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 153.37ms, accelerator: 0us, total: 153.37ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.01ms, total: 13.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 153.37ms, accelerator: 0us, total: 153.37ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.83ms, accelerator: 28120036.62sec, total: 28120036.62sec
train2.py:307:<module>, cpu: 153.58ms, accelerator: 0us, total: 153.58ms
  iterator_ops.py:373:get_next, cpu: 153.37ms, accelerator: 0us, total: 153.37ms
train2.py:342:<module>, cpu: 2.43ms, accelerator: 13.44ms, total: 15.89ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_164000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_164250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_164500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_164750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.08ms, accelerator: 27949612.14sec, total: 27949612.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 152.87ms, accelerator: 0us, total: 152.87ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.04ms, total: 13.08ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 152.87ms, accelerator: 0us, total: 152.87ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.82ms, accelerator: 27949612.15sec, total: 27949612.16sec
train2.py:307:<module>, cpu: 153.08ms, accelerator: 0us, total: 153.08ms
  iterator_ops.py:373:get_next, cpu: 152.87ms, accelerator: 0us, total: 152.87ms
train2.py:342:<module>, cpu: 2.43ms, accelerator: 13.43ms, total: 15.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_165000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_165250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_165500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_165750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 27781240.98sec, total: 27781240.99sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 152.37ms, accelerator: 0us, total: 152.37ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.02ms, total: 13.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 152.37ms, accelerator: 0us, total: 152.37ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.82ms, accelerator: 27781241.00sec, total: 27781241.00sec
train2.py:307:<module>, cpu: 152.58ms, accelerator: 0us, total: 152.58ms
  iterator_ops.py:373:get_next, cpu: 152.37ms, accelerator: 0us, total: 152.37ms
train2.py:342:<module>, cpu: 2.42ms, accelerator: 13.43ms, total: 15.87ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_166000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_166250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_166500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_166750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 27614886.25sec, total: 27614886.25sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 151.75ms, accelerator: 0us, total: 151.75ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.02ms, total: 13.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 151.75ms, accelerator: 0us, total: 151.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.82ms, accelerator: 27614886.26sec, total: 27614886.26sec
train2.py:307:<module>, cpu: 151.96ms, accelerator: 0us, total: 151.96ms
  iterator_ops.py:373:get_next, cpu: 151.75ms, accelerator: 0us, total: 151.75ms
train2.py:342:<module>, cpu: 2.41ms, accelerator: 13.43ms, total: 15.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_167000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_167250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_167500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_167750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 27450511.93sec, total: 27450511.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 157.59ms, accelerator: 0us, total: 157.59ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.01ms, total: 13.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 157.59ms, accelerator: 0us, total: 157.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.82ms, accelerator: 27450511.94sec, total: 27450511.94sec
train2.py:307:<module>, cpu: 157.79ms, accelerator: 0us, total: 157.79ms
  iterator_ops.py:373:get_next, cpu: 157.59ms, accelerator: 0us, total: 157.59ms
train2.py:342:<module>, cpu: 2.41ms, accelerator: 13.44ms, total: 15.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_168000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_168250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_168500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_168750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 27288082.86sec, total: 27288082.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 157.06ms, accelerator: 0us, total: 157.06ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.00ms, total: 13.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 157.06ms, accelerator: 0us, total: 157.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.82ms, accelerator: 27288082.87sec, total: 27288082.87sec
train2.py:307:<module>, cpu: 157.27ms, accelerator: 0us, total: 157.27ms
  iterator_ops.py:373:get_next, cpu: 157.06ms, accelerator: 0us, total: 157.06ms
train2.py:342:<module>, cpu: 2.40ms, accelerator: 13.43ms, total: 15.86ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_169000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_169250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_169500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_169750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 27127564.73sec, total: 27127564.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 156.44ms, accelerator: 0us, total: 156.44ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.03ms, total: 13.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 156.44ms, accelerator: 0us, total: 156.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.82ms, accelerator: 27127564.74sec, total: 27127564.74sec
train2.py:307:<module>, cpu: 156.64ms, accelerator: 0us, total: 156.64ms
  iterator_ops.py:373:get_next, cpu: 156.44ms, accelerator: 0us, total: 156.44ms
train2.py:342:<module>, cpu: 2.40ms, accelerator: 13.42ms, total: 15.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_170000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_170250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_170500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_170750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 26968924.00sec, total: 26968924.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 156.01ms, accelerator: 0us, total: 156.01ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.02ms, total: 13.05ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 156.01ms, accelerator: 0us, total: 156.01ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.82ms, accelerator: 26968924.01sec, total: 26968924.01sec
train2.py:307:<module>, cpu: 156.21ms, accelerator: 0us, total: 156.21ms
  iterator_ops.py:373:get_next, cpu: 156.01ms, accelerator: 0us, total: 156.01ms
train2.py:342:<module>, cpu: 2.39ms, accelerator: 13.42ms, total: 15.83ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_171000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_171250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_171500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_171750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 26812127.93sec, total: 26812127.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 155.42ms, accelerator: 0us, total: 155.42ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.03ms, total: 13.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 155.42ms, accelerator: 0us, total: 155.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 26812127.94sec, total: 26812127.94sec
train2.py:307:<module>, cpu: 155.62ms, accelerator: 0us, total: 155.62ms
  iterator_ops.py:373:get_next, cpu: 155.42ms, accelerator: 0us, total: 155.42ms
train2.py:342:<module>, cpu: 2.39ms, accelerator: 13.41ms, total: 15.82ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_172000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_172250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_172500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_172750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 26657144.53sec, total: 26657144.53sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 154.79ms, accelerator: 0us, total: 154.79ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.03ms, total: 13.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 154.79ms, accelerator: 0us, total: 154.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 26657144.54sec, total: 26657144.54sec
train2.py:307:<module>, cpu: 154.99ms, accelerator: 0us, total: 154.99ms
  iterator_ops.py:373:get_next, cpu: 154.79ms, accelerator: 0us, total: 154.79ms
train2.py:342:<module>, cpu: 2.38ms, accelerator: 13.40ms, total: 15.81ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_173000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_173250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_173500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_173750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 26503942.55sec, total: 26503942.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 154.29ms, accelerator: 0us, total: 154.29ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.02ms, total: 13.06ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 154.29ms, accelerator: 0us, total: 154.29ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 26503942.56sec, total: 26503942.56sec
train2.py:307:<module>, cpu: 154.49ms, accelerator: 0us, total: 154.49ms
  iterator_ops.py:373:get_next, cpu: 154.29ms, accelerator: 0us, total: 154.29ms
train2.py:342:<module>, cpu: 2.38ms, accelerator: 13.41ms, total: 15.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_174000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_174250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_174500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_174750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 26352491.45sec, total: 26352491.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 153.72ms, accelerator: 0us, total: 153.72ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.03ms, total: 13.07ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 153.72ms, accelerator: 0us, total: 153.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 26352491.46sec, total: 26352491.46sec
train2.py:307:<module>, cpu: 153.92ms, accelerator: 0us, total: 153.92ms
  iterator_ops.py:373:get_next, cpu: 153.72ms, accelerator: 0us, total: 153.72ms
train2.py:342:<module>, cpu: 2.37ms, accelerator: 13.41ms, total: 15.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_175000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_175250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_175500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_175750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 26202761.38sec, total: 26202761.38sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 154.44ms, accelerator: 0us, total: 154.44ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.06ms, total: 13.09ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 154.44ms, accelerator: 0us, total: 154.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 26202761.39sec, total: 26202761.40sec
train2.py:307:<module>, cpu: 154.63ms, accelerator: 0us, total: 154.63ms
  iterator_ops.py:373:get_next, cpu: 154.44ms, accelerator: 0us, total: 154.44ms
train2.py:342:<module>, cpu: 2.37ms, accelerator: 13.40ms, total: 15.79ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_176000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_176250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_176500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_176750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 26054723.18sec, total: 26054723.18sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 154.04ms, accelerator: 0us, total: 154.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.00ms, total: 13.04ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 154.04ms, accelerator: 0us, total: 154.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 26054723.19sec, total: 26054723.20sec
train2.py:307:<module>, cpu: 154.24ms, accelerator: 0us, total: 154.24ms
  iterator_ops.py:373:get_next, cpu: 154.04ms, accelerator: 0us, total: 154.04ms
train2.py:342:<module>, cpu: 2.36ms, accelerator: 13.43ms, total: 15.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_177000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_177250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_177500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_177750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 25908348.33sec, total: 25908348.34sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 153.58ms, accelerator: 0us, total: 153.58ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.96ms, total: 13.00ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 153.58ms, accelerator: 0us, total: 153.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 25908348.35sec, total: 25908348.35sec
train2.py:307:<module>, cpu: 153.77ms, accelerator: 0us, total: 153.77ms
  iterator_ops.py:373:get_next, cpu: 153.58ms, accelerator: 0us, total: 153.58ms
train2.py:342:<module>, cpu: 2.35ms, accelerator: 13.43ms, total: 15.80ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_178000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_178250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_178500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_178750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 25763608.96sec, total: 25763608.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 153.06ms, accelerator: 0us, total: 153.06ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.98ms, total: 13.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 153.06ms, accelerator: 0us, total: 153.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 25763608.97sec, total: 25763608.97sec
train2.py:307:<module>, cpu: 153.26ms, accelerator: 0us, total: 153.26ms
  iterator_ops.py:373:get_next, cpu: 153.06ms, accelerator: 0us, total: 153.06ms
train2.py:342:<module>, cpu: 2.35ms, accelerator: 13.41ms, total: 15.78ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_179000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_179250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_179500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_179750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 25620477.80sec, total: 25620477.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 152.55ms, accelerator: 0us, total: 152.55ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 12.00ms, total: 13.03ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 152.55ms, accelerator: 0us, total: 152.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 25620477.81sec, total: 25620477.81sec
train2.py:307:<module>, cpu: 152.74ms, accelerator: 0us, total: 152.74ms
  iterator_ops.py:373:get_next, cpu: 152.55ms, accelerator: 0us, total: 152.55ms
train2.py:342:<module>, cpu: 2.34ms, accelerator: 13.40ms, total: 15.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_180000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_180250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_180500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_180750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.07ms, accelerator: 25478928.20sec, total: 25478928.20sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 152.14ms, accelerator: 0us, total: 152.14ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.98ms, total: 13.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 152.14ms, accelerator: 0us, total: 152.14ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 25478928.21sec, total: 25478928.21sec
train2.py:307:<module>, cpu: 152.33ms, accelerator: 0us, total: 152.33ms
  iterator_ops.py:373:get_next, cpu: 152.14ms, accelerator: 0us, total: 152.14ms
train2.py:342:<module>, cpu: 2.34ms, accelerator: 13.41ms, total: 15.77ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_181000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_181250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_181500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_181750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 25338934.09sec, total: 25338934.09sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 151.69ms, accelerator: 0us, total: 151.69ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.97ms, total: 13.01ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 151.69ms, accelerator: 0us, total: 151.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.81ms, accelerator: 25338934.10sec, total: 25338934.10sec
train2.py:307:<module>, cpu: 151.88ms, accelerator: 0us, total: 151.88ms
  iterator_ops.py:373:get_next, cpu: 151.69ms, accelerator: 0us, total: 151.69ms
train2.py:342:<module>, cpu: 2.33ms, accelerator: 13.41ms, total: 15.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_182000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_182250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_182500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_182750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 25200469.96sec, total: 25200469.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 151.29ms, accelerator: 0us, total: 151.29ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.96ms, total: 13.00ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 151.29ms, accelerator: 0us, total: 151.29ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.80ms, accelerator: 25200469.98sec, total: 25200469.98sec
train2.py:307:<module>, cpu: 151.48ms, accelerator: 0us, total: 151.48ms
  iterator_ops.py:373:get_next, cpu: 151.29ms, accelerator: 0us, total: 151.29ms
train2.py:342:<module>, cpu: 2.33ms, accelerator: 13.41ms, total: 15.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_183000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_183250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_183500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_183750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 25063510.89sec, total: 25063510.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 150.98ms, accelerator: 0us, total: 150.98ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.95ms, total: 12.99ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 150.98ms, accelerator: 0us, total: 150.98ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.80ms, accelerator: 25063510.90sec, total: 25063510.90sec
train2.py:307:<module>, cpu: 151.17ms, accelerator: 0us, total: 151.17ms
  iterator_ops.py:373:get_next, cpu: 150.98ms, accelerator: 0us, total: 150.98ms
train2.py:342:<module>, cpu: 2.32ms, accelerator: 13.42ms, total: 15.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_184000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_184250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_184500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_184750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 24928032.45sec, total: 24928032.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 150.59ms, accelerator: 0us, total: 150.59ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.96ms, total: 13.00ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 150.59ms, accelerator: 0us, total: 150.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.80ms, accelerator: 24928032.46sec, total: 24928032.47sec
train2.py:307:<module>, cpu: 150.78ms, accelerator: 0us, total: 150.78ms
  iterator_ops.py:373:get_next, cpu: 150.59ms, accelerator: 0us, total: 150.59ms
train2.py:342:<module>, cpu: 2.32ms, accelerator: 13.42ms, total: 15.76ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_185000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_185250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_185500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_185750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 24794010.77sec, total: 24794010.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 155.48ms, accelerator: 0us, total: 155.48ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.96ms, total: 13.00ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 155.48ms, accelerator: 0us, total: 155.48ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.80ms, accelerator: 24794010.78sec, total: 24794010.79sec
train2.py:307:<module>, cpu: 155.67ms, accelerator: 0us, total: 155.67ms
  iterator_ops.py:373:get_next, cpu: 155.48ms, accelerator: 0us, total: 155.48ms
train2.py:342:<module>, cpu: 2.31ms, accelerator: 13.41ms, total: 15.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_186000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_186250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_186500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_186750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 24661422.48sec, total: 24661422.48sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 155.02ms, accelerator: 0us, total: 155.02ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.95ms, total: 12.99ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 155.02ms, accelerator: 0us, total: 155.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.80ms, accelerator: 24661422.49sec, total: 24661422.49sec
train2.py:307:<module>, cpu: 155.21ms, accelerator: 0us, total: 155.21ms
  iterator_ops.py:373:get_next, cpu: 155.02ms, accelerator: 0us, total: 155.02ms
train2.py:342:<module>, cpu: 2.31ms, accelerator: 13.41ms, total: 15.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_187000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_187250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_187500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_187750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 24530244.70sec, total: 24530244.70sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 154.73ms, accelerator: 0us, total: 154.73ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.02ms, accelerator: 11.94ms, total: 12.98ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 154.73ms, accelerator: 0us, total: 154.73ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.80ms, accelerator: 24530244.71sec, total: 24530244.71sec
train2.py:307:<module>, cpu: 154.92ms, accelerator: 0us, total: 154.92ms
  iterator_ops.py:373:get_next, cpu: 154.73ms, accelerator: 0us, total: 154.73ms
train2.py:342:<module>, cpu: 2.31ms, accelerator: 13.42ms, total: 15.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.26
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_188000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_188250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_188500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_188750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 24400455.05sec, total: 24400455.05sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 154.29ms, accelerator: 0us, total: 154.29ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.92ms, total: 12.96ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 154.29ms, accelerator: 0us, total: 154.29ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.80ms, accelerator: 24400455.06sec, total: 24400455.06sec
train2.py:307:<module>, cpu: 154.47ms, accelerator: 0us, total: 154.47ms
  iterator_ops.py:373:get_next, cpu: 154.29ms, accelerator: 0us, total: 154.29ms
train2.py:342:<module>, cpu: 2.30ms, accelerator: 13.43ms, total: 15.75ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_189000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_189250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_189500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_189750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 24272031.60sec, total: 24272031.60sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 153.98ms, accelerator: 0us, total: 153.98ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 153.98ms, accelerator: 0us, total: 153.98ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.79ms, accelerator: 24272031.61sec, total: 24272031.61sec
train2.py:307:<module>, cpu: 154.16ms, accelerator: 0us, total: 154.16ms
  iterator_ops.py:373:get_next, cpu: 153.98ms, accelerator: 0us, total: 153.98ms
train2.py:342:<module>, cpu: 2.30ms, accelerator: 13.43ms, total: 15.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_190000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_190250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_190500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_190750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 24144952.90sec, total: 24144952.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 153.49ms, accelerator: 0us, total: 153.49ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.93ms, total: 12.97ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 153.49ms, accelerator: 0us, total: 153.49ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.79ms, accelerator: 24144952.91sec, total: 24144952.91sec
train2.py:307:<module>, cpu: 153.68ms, accelerator: 0us, total: 153.68ms
  iterator_ops.py:373:get_next, cpu: 153.49ms, accelerator: 0us, total: 153.49ms
train2.py:342:<module>, cpu: 2.29ms, accelerator: 13.42ms, total: 15.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_191000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_191250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_191500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_191750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 24019197.94sec, total: 24019197.94sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 153.05ms, accelerator: 0us, total: 153.05ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.94ms, total: 12.98ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 153.05ms, accelerator: 0us, total: 153.05ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.79ms, accelerator: 24019197.95sec, total: 24019197.95sec
train2.py:307:<module>, cpu: 153.23ms, accelerator: 0us, total: 153.23ms
  iterator_ops.py:373:get_next, cpu: 153.05ms, accelerator: 0us, total: 153.05ms
train2.py:342:<module>, cpu: 2.29ms, accelerator: 13.41ms, total: 15.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_192000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_192250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_192500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_192750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 23894746.13sec, total: 23894746.13sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 152.70ms, accelerator: 0us, total: 152.70ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.94ms, total: 12.98ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 152.70ms, accelerator: 0us, total: 152.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.79ms, accelerator: 23894746.14sec, total: 23894746.15sec
train2.py:307:<module>, cpu: 152.88ms, accelerator: 0us, total: 152.88ms
  iterator_ops.py:373:get_next, cpu: 152.70ms, accelerator: 0us, total: 152.70ms
train2.py:342:<module>, cpu: 2.28ms, accelerator: 13.41ms, total: 15.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_193000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_193250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_193500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_193750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 23771577.34sec, total: 23771577.34sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 152.25ms, accelerator: 0us, total: 152.25ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 152.25ms, accelerator: 0us, total: 152.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.79ms, accelerator: 23771577.35sec, total: 23771577.35sec
train2.py:307:<module>, cpu: 152.43ms, accelerator: 0us, total: 152.43ms
  iterator_ops.py:373:get_next, cpu: 152.25ms, accelerator: 0us, total: 152.25ms
train2.py:342:<module>, cpu: 2.28ms, accelerator: 13.43ms, total: 15.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_194000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_194250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_194500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_194750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 23649671.81sec, total: 23649671.81sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 151.86ms, accelerator: 0us, total: 151.86ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 151.86ms, accelerator: 0us, total: 151.86ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.79ms, accelerator: 23649671.83sec, total: 23649671.83sec
train2.py:307:<module>, cpu: 152.04ms, accelerator: 0us, total: 152.04ms
  iterator_ops.py:373:get_next, cpu: 151.86ms, accelerator: 0us, total: 151.86ms
train2.py:342:<module>, cpu: 2.27ms, accelerator: 13.44ms, total: 15.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_195000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_195250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_195500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_195750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 23529010.22sec, total: 23529010.22sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 151.45ms, accelerator: 0us, total: 151.45ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 151.45ms, accelerator: 0us, total: 151.45ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.79ms, accelerator: 23529010.23sec, total: 23529010.24sec
train2.py:307:<module>, cpu: 151.63ms, accelerator: 0us, total: 151.63ms
  iterator_ops.py:373:get_next, cpu: 151.45ms, accelerator: 0us, total: 151.45ms
train2.py:342:<module>, cpu: 2.27ms, accelerator: 13.45ms, total: 15.74ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_196000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_196250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_196500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_196750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 23409573.62sec, total: 23409573.62sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 151.08ms, accelerator: 0us, total: 151.08ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 151.08ms, accelerator: 0us, total: 151.08ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.79ms, accelerator: 23409573.63sec, total: 23409573.64sec
train2.py:307:<module>, cpu: 151.26ms, accelerator: 0us, total: 151.26ms
  iterator_ops.py:373:get_next, cpu: 151.08ms, accelerator: 0us, total: 151.08ms
train2.py:342:<module>, cpu: 2.26ms, accelerator: 13.44ms, total: 15.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.26
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_197000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_197250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_197500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_197750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 23291343.45sec, total: 23291343.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 150.72ms, accelerator: 0us, total: 150.72ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 150.72ms, accelerator: 0us, total: 150.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 23291343.46sec, total: 23291343.47sec
train2.py:307:<module>, cpu: 150.89ms, accelerator: 0us, total: 150.89ms
  iterator_ops.py:373:get_next, cpu: 150.72ms, accelerator: 0us, total: 150.72ms
train2.py:342:<module>, cpu: 2.26ms, accelerator: 13.44ms, total: 15.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_198000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_198250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_198500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_198750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 23174301.53sec, total: 23174301.53sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 150.28ms, accelerator: 0us, total: 150.28ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 150.28ms, accelerator: 0us, total: 150.28ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 23174301.54sec, total: 23174301.54sec
train2.py:307:<module>, cpu: 150.45ms, accelerator: 0us, total: 150.45ms
  iterator_ops.py:373:get_next, cpu: 150.28ms, accelerator: 0us, total: 150.28ms
train2.py:342:<module>, cpu: 2.26ms, accelerator: 13.45ms, total: 15.73ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_199000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_199250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_199500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_199750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 23058430.02sec, total: 23058430.02sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 149.84ms, accelerator: 0us, total: 149.84ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 149.84ms, accelerator: 0us, total: 149.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 23058430.03sec, total: 23058430.03sec
train2.py:307:<module>, cpu: 150.01ms, accelerator: 0us, total: 150.01ms
  iterator_ops.py:373:get_next, cpu: 149.84ms, accelerator: 0us, total: 149.84ms
train2.py:342:<module>, cpu: 2.25ms, accelerator: 13.45ms, total: 15.72ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_200000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_200250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_200500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_200750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.06ms, accelerator: 22943711.46sec, total: 22943711.46sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 149.44ms, accelerator: 0us, total: 149.44ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 149.44ms, accelerator: 0us, total: 149.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 22943711.47sec, total: 22943711.48sec
train2.py:307:<module>, cpu: 149.62ms, accelerator: 0us, total: 149.62ms
  iterator_ops.py:373:get_next, cpu: 149.44ms, accelerator: 0us, total: 149.44ms
train2.py:342:<module>, cpu: 2.25ms, accelerator: 13.44ms, total: 15.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_201000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_201250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_201500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_201750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 22830128.73sec, total: 22830128.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 148.95ms, accelerator: 0us, total: 148.95ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 148.95ms, accelerator: 0us, total: 148.95ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 22830128.74sec, total: 22830128.75sec
train2.py:307:<module>, cpu: 149.12ms, accelerator: 0us, total: 149.12ms
  iterator_ops.py:373:get_next, cpu: 148.95ms, accelerator: 0us, total: 148.95ms
train2.py:342:<module>, cpu: 2.25ms, accelerator: 13.43ms, total: 15.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_202000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_202250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_202500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_202750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 22717665.04sec, total: 22717665.04sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 148.59ms, accelerator: 0us, total: 148.59ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 148.59ms, accelerator: 0us, total: 148.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 22717665.05sec, total: 22717665.06sec
train2.py:307:<module>, cpu: 148.76ms, accelerator: 0us, total: 148.76ms
  iterator_ops.py:373:get_next, cpu: 148.59ms, accelerator: 0us, total: 148.59ms
train2.py:342:<module>, cpu: 2.24ms, accelerator: 13.44ms, total: 15.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_203000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_203250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_203500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_203750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 22606303.94sec, total: 22606303.94sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 148.21ms, accelerator: 0us, total: 148.21ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 148.21ms, accelerator: 0us, total: 148.21ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 22606303.95sec, total: 22606303.95sec
train2.py:307:<module>, cpu: 148.38ms, accelerator: 0us, total: 148.38ms
  iterator_ops.py:373:get_next, cpu: 148.21ms, accelerator: 0us, total: 148.21ms
train2.py:342:<module>, cpu: 2.24ms, accelerator: 13.44ms, total: 15.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_204000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_204250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_204500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_204750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 22496029.29sec, total: 22496029.29sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 147.73ms, accelerator: 0us, total: 147.73ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 147.73ms, accelerator: 0us, total: 147.73ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 22496029.30sec, total: 22496029.30sec
train2.py:307:<module>, cpu: 147.90ms, accelerator: 0us, total: 147.90ms
  iterator_ops.py:373:get_next, cpu: 147.73ms, accelerator: 0us, total: 147.73ms
train2.py:342:<module>, cpu: 2.23ms, accelerator: 13.44ms, total: 15.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_205000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_205250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_205500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_205750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 22386825.26sec, total: 22386825.26sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 147.28ms, accelerator: 0us, total: 147.28ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 147.28ms, accelerator: 0us, total: 147.28ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 22386825.27sec, total: 22386825.28sec
train2.py:307:<module>, cpu: 147.45ms, accelerator: 0us, total: 147.45ms
  iterator_ops.py:373:get_next, cpu: 147.28ms, accelerator: 0us, total: 147.28ms
train2.py:342:<module>, cpu: 2.23ms, accelerator: 13.43ms, total: 15.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_206000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_206250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_206500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_206750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 22278676.35sec, total: 22278676.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 147.03ms, accelerator: 0us, total: 147.03ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 147.03ms, accelerator: 0us, total: 147.03ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 22278676.36sec, total: 22278676.36sec
train2.py:307:<module>, cpu: 147.19ms, accelerator: 0us, total: 147.19ms
  iterator_ops.py:373:get_next, cpu: 147.03ms, accelerator: 0us, total: 147.03ms
train2.py:342:<module>, cpu: 2.22ms, accelerator: 13.45ms, total: 15.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_207000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_207250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_207500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_207750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 22171567.33sec, total: 22171567.33sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 146.70ms, accelerator: 0us, total: 146.70ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 146.70ms, accelerator: 0us, total: 146.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 22171567.34sec, total: 22171567.34sec
train2.py:307:<module>, cpu: 146.86ms, accelerator: 0us, total: 146.86ms
  iterator_ops.py:373:get_next, cpu: 146.70ms, accelerator: 0us, total: 146.70ms
train2.py:342:<module>, cpu: 2.22ms, accelerator: 13.45ms, total: 15.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_208000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_208250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_208500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_208750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 22065483.27sec, total: 22065483.27sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 146.36ms, accelerator: 0us, total: 146.36ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 146.36ms, accelerator: 0us, total: 146.36ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 22065483.28sec, total: 22065483.29sec
train2.py:307:<module>, cpu: 146.53ms, accelerator: 0us, total: 146.53ms
  iterator_ops.py:373:get_next, cpu: 146.36ms, accelerator: 0us, total: 146.36ms
train2.py:342:<module>, cpu: 2.22ms, accelerator: 13.45ms, total: 15.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_209000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_209250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_209500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_209750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 21960409.54sec, total: 21960409.54sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 146.01ms, accelerator: 0us, total: 146.01ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 146.01ms, accelerator: 0us, total: 146.01ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 21960409.55sec, total: 21960409.56sec
train2.py:307:<module>, cpu: 146.18ms, accelerator: 0us, total: 146.18ms
  iterator_ops.py:373:get_next, cpu: 146.01ms, accelerator: 0us, total: 146.01ms
train2.py:342:<module>, cpu: 2.21ms, accelerator: 13.46ms, total: 15.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_210000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_210250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_210500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_210750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 21856331.77sec, total: 21856331.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 145.61ms, accelerator: 0us, total: 145.61ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 145.61ms, accelerator: 0us, total: 145.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 21856331.78sec, total: 21856331.79sec
train2.py:307:<module>, cpu: 145.78ms, accelerator: 0us, total: 145.78ms
  iterator_ops.py:373:get_next, cpu: 145.61ms, accelerator: 0us, total: 145.61ms
train2.py:342:<module>, cpu: 2.21ms, accelerator: 13.46ms, total: 15.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_211000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_211250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_211500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_211750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 21753235.87sec, total: 21753235.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 145.24ms, accelerator: 0us, total: 145.24ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.78ms, total: 12.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 145.24ms, accelerator: 0us, total: 145.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.78ms, accelerator: 21753235.88sec, total: 21753235.88sec
train2.py:307:<module>, cpu: 145.40ms, accelerator: 0us, total: 145.40ms
  iterator_ops.py:373:get_next, cpu: 145.24ms, accelerator: 0us, total: 145.24ms
train2.py:342:<module>, cpu: 2.21ms, accelerator: 13.47ms, total: 15.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_212000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_212250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_212500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_212750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 21651108.00sec, total: 21651108.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 145.01ms, accelerator: 0us, total: 145.01ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.74ms, total: 12.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 145.01ms, accelerator: 0us, total: 145.01ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 21651108.01sec, total: 21651108.01sec
train2.py:307:<module>, cpu: 145.18ms, accelerator: 0us, total: 145.18ms
  iterator_ops.py:373:get_next, cpu: 145.01ms, accelerator: 0us, total: 145.01ms
train2.py:342:<module>, cpu: 2.20ms, accelerator: 13.48ms, total: 15.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_213000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_213250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_213500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_213750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 21549934.60sec, total: 21549934.60sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 144.69ms, accelerator: 0us, total: 144.69ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.75ms, total: 12.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 144.69ms, accelerator: 0us, total: 144.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 21549934.61sec, total: 21549934.61sec
train2.py:307:<module>, cpu: 144.85ms, accelerator: 0us, total: 144.85ms
  iterator_ops.py:373:get_next, cpu: 144.69ms, accelerator: 0us, total: 144.69ms
train2.py:342:<module>, cpu: 2.20ms, accelerator: 13.48ms, total: 15.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_214000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_214250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_214500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_214750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 21449702.34sec, total: 21449702.34sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 144.34ms, accelerator: 0us, total: 144.34ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.70ms, total: 12.74ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 144.34ms, accelerator: 0us, total: 144.34ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 21449702.36sec, total: 21449702.36sec
train2.py:307:<module>, cpu: 144.50ms, accelerator: 0us, total: 144.50ms
  iterator_ops.py:373:get_next, cpu: 144.34ms, accelerator: 0us, total: 144.34ms
train2.py:342:<module>, cpu: 2.20ms, accelerator: 13.49ms, total: 15.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_215000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_215250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_215500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_215750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 21350398.17sec, total: 21350398.17sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 143.99ms, accelerator: 0us, total: 143.99ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.69ms, total: 12.73ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 143.99ms, accelerator: 0us, total: 143.99ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 21350398.18sec, total: 21350398.18sec
train2.py:307:<module>, cpu: 144.16ms, accelerator: 0us, total: 144.16ms
  iterator_ops.py:373:get_next, cpu: 143.99ms, accelerator: 0us, total: 143.99ms
train2.py:342:<module>, cpu: 2.19ms, accelerator: 13.50ms, total: 15.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_216000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_216250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_216500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_216750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 21252009.23sec, total: 21252009.24sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 143.69ms, accelerator: 0us, total: 143.69ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.67ms, total: 12.71ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 143.69ms, accelerator: 0us, total: 143.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 21252009.25sec, total: 21252009.25sec
train2.py:307:<module>, cpu: 143.85ms, accelerator: 0us, total: 143.85ms
  iterator_ops.py:373:get_next, cpu: 143.69ms, accelerator: 0us, total: 143.69ms
train2.py:342:<module>, cpu: 2.19ms, accelerator: 13.51ms, total: 15.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_217000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_217250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_217500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_217750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 21154522.95sec, total: 21154522.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 143.42ms, accelerator: 0us, total: 143.42ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.68ms, total: 12.72ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 143.42ms, accelerator: 0us, total: 143.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 21154522.97sec, total: 21154522.97sec
train2.py:307:<module>, cpu: 143.58ms, accelerator: 0us, total: 143.58ms
  iterator_ops.py:373:get_next, cpu: 143.42ms, accelerator: 0us, total: 143.42ms
train2.py:342:<module>, cpu: 2.19ms, accelerator: 13.50ms, total: 15.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_218000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_218250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_218500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_218750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 21057926.96sec, total: 21057926.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 143.11ms, accelerator: 0us, total: 143.11ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.67ms, total: 12.71ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 143.11ms, accelerator: 0us, total: 143.11ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 21057926.97sec, total: 21057926.97sec
train2.py:307:<module>, cpu: 143.27ms, accelerator: 0us, total: 143.27ms
  iterator_ops.py:373:get_next, cpu: 143.11ms, accelerator: 0us, total: 143.11ms
train2.py:342:<module>, cpu: 2.19ms, accelerator: 13.50ms, total: 15.71ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_219000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_219250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_219500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_219750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 20962209.11sec, total: 20962209.11sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 142.72ms, accelerator: 0us, total: 142.72ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.68ms, total: 12.73ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 142.72ms, accelerator: 0us, total: 142.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 20962209.12sec, total: 20962209.12sec
train2.py:307:<module>, cpu: 142.88ms, accelerator: 0us, total: 142.88ms
  iterator_ops.py:373:get_next, cpu: 142.72ms, accelerator: 0us, total: 142.72ms
train2.py:342:<module>, cpu: 2.18ms, accelerator: 13.50ms, total: 15.70ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_220000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_220250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_220500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_220750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 20867357.48sec, total: 20867357.49sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 142.45ms, accelerator: 0us, total: 142.45ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.72ms, total: 12.77ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 142.45ms, accelerator: 0us, total: 142.45ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 20867357.50sec, total: 20867357.50sec
train2.py:307:<module>, cpu: 142.61ms, accelerator: 0us, total: 142.61ms
  iterator_ops.py:373:get_next, cpu: 142.45ms, accelerator: 0us, total: 142.45ms
train2.py:342:<module>, cpu: 2.18ms, accelerator: 13.48ms, total: 15.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_221000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_221250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_221500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_221750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 20773360.38sec, total: 20773360.38sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 142.09ms, accelerator: 0us, total: 142.09ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.74ms, total: 12.78ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 142.09ms, accelerator: 0us, total: 142.09ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 20773360.39sec, total: 20773360.39sec
train2.py:307:<module>, cpu: 142.25ms, accelerator: 0us, total: 142.25ms
  iterator_ops.py:373:get_next, cpu: 142.09ms, accelerator: 0us, total: 142.09ms
train2.py:342:<module>, cpu: 2.18ms, accelerator: 13.48ms, total: 15.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_222000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_222250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_222500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_222750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 20680206.30sec, total: 20680206.30sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 141.66ms, accelerator: 0us, total: 141.66ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.70ms, total: 12.75ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 141.66ms, accelerator: 0us, total: 141.66ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 20680206.31sec, total: 20680206.31sec
train2.py:307:<module>, cpu: 141.82ms, accelerator: 0us, total: 141.82ms
  iterator_ops.py:373:get_next, cpu: 141.66ms, accelerator: 0us, total: 141.66ms
train2.py:342:<module>, cpu: 2.17ms, accelerator: 13.49ms, total: 15.69ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_223000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_223250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_223500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_223750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 20587883.95sec, total: 20587883.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 141.32ms, accelerator: 0us, total: 141.32ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.72ms, total: 12.77ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 141.32ms, accelerator: 0us, total: 141.32ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 20587883.96sec, total: 20587883.96sec
train2.py:307:<module>, cpu: 141.47ms, accelerator: 0us, total: 141.47ms
  iterator_ops.py:373:get_next, cpu: 141.32ms, accelerator: 0us, total: 141.32ms
train2.py:342:<module>, cpu: 2.17ms, accelerator: 13.49ms, total: 15.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_224000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_224250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_224500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_224750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 20496382.24sec, total: 20496382.24sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 141.02ms, accelerator: 0us, total: 141.02ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.71ms, total: 12.75ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 141.02ms, accelerator: 0us, total: 141.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.77ms, accelerator: 20496382.25sec, total: 20496382.25sec
train2.py:307:<module>, cpu: 141.18ms, accelerator: 0us, total: 141.18ms
  iterator_ops.py:373:get_next, cpu: 141.02ms, accelerator: 0us, total: 141.02ms
train2.py:342:<module>, cpu: 2.16ms, accelerator: 13.50ms, total: 15.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_225000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_225250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_225500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_225750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 20405690.28sec, total: 20405690.28sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 140.80ms, accelerator: 0us, total: 140.80ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.71ms, total: 12.76ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 140.80ms, accelerator: 0us, total: 140.80ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.76ms, accelerator: 20405690.29sec, total: 20405690.30sec
train2.py:307:<module>, cpu: 140.96ms, accelerator: 0us, total: 140.96ms
  iterator_ops.py:373:get_next, cpu: 140.80ms, accelerator: 0us, total: 140.80ms
train2.py:342:<module>, cpu: 2.16ms, accelerator: 13.50ms, total: 15.68ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_226000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_226250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_226500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_226750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.05ms, accelerator: 20315797.37sec, total: 20315797.38sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 140.51ms, accelerator: 0us, total: 140.51ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.74ms, total: 12.78ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 140.51ms, accelerator: 0us, total: 140.51ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.76ms, accelerator: 20315797.39sec, total: 20315797.39sec
train2.py:307:<module>, cpu: 140.66ms, accelerator: 0us, total: 140.66ms
  iterator_ops.py:373:get_next, cpu: 140.51ms, accelerator: 0us, total: 140.51ms
train2.py:342:<module>, cpu: 2.16ms, accelerator: 13.49ms, total: 15.67ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_227000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_227250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_227500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_227750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 20226693.00sec, total: 20226693.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 140.15ms, accelerator: 0us, total: 140.15ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.74ms, total: 12.78ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 140.15ms, accelerator: 0us, total: 140.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.76ms, accelerator: 20226693.01sec, total: 20226693.01sec
train2.py:307:<module>, cpu: 140.30ms, accelerator: 0us, total: 140.30ms
  iterator_ops.py:373:get_next, cpu: 140.15ms, accelerator: 0us, total: 140.15ms
train2.py:342:<module>, cpu: 2.15ms, accelerator: 13.49ms, total: 15.66ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_228000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_228250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_228500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_228750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 20138366.83sec, total: 20138366.83sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 139.77ms, accelerator: 0us, total: 139.77ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.76ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 139.77ms, accelerator: 0us, total: 139.77ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.76ms, accelerator: 20138366.84sec, total: 20138366.84sec
train2.py:307:<module>, cpu: 139.92ms, accelerator: 0us, total: 139.92ms
  iterator_ops.py:373:get_next, cpu: 139.77ms, accelerator: 0us, total: 139.77ms
train2.py:342:<module>, cpu: 2.15ms, accelerator: 13.48ms, total: 15.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_229000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_229250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_229500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_229750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 20050808.71sec, total: 20050808.71sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 139.42ms, accelerator: 0us, total: 139.42ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.77ms, total: 12.81ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 139.42ms, accelerator: 0us, total: 139.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.76ms, accelerator: 20050808.72sec, total: 20050808.73sec
train2.py:307:<module>, cpu: 139.57ms, accelerator: 0us, total: 139.57ms
  iterator_ops.py:373:get_next, cpu: 139.42ms, accelerator: 0us, total: 139.42ms
train2.py:342:<module>, cpu: 2.15ms, accelerator: 13.48ms, total: 15.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_230000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_230250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_230500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_230750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19964008.68sec, total: 19964008.68sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 139.15ms, accelerator: 0us, total: 139.15ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.76ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 139.15ms, accelerator: 0us, total: 139.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.76ms, accelerator: 19964008.69sec, total: 19964008.69sec
train2.py:307:<module>, cpu: 139.30ms, accelerator: 0us, total: 139.30ms
  iterator_ops.py:373:get_next, cpu: 139.15ms, accelerator: 0us, total: 139.15ms
train2.py:342:<module>, cpu: 2.15ms, accelerator: 13.48ms, total: 15.65ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_231000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_231250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_231500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_231750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19877956.91sec, total: 19877956.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 138.81ms, accelerator: 0us, total: 138.81ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.77ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 138.81ms, accelerator: 0us, total: 138.81ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.76ms, accelerator: 19877956.93sec, total: 19877956.93sec
train2.py:307:<module>, cpu: 138.96ms, accelerator: 0us, total: 138.96ms
  iterator_ops.py:373:get_next, cpu: 138.81ms, accelerator: 0us, total: 138.81ms
train2.py:342:<module>, cpu: 2.14ms, accelerator: 13.47ms, total: 15.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_232000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_232250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_232500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_232750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19792643.79sec, total: 19792643.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 138.49ms, accelerator: 0us, total: 138.49ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.76ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 138.49ms, accelerator: 0us, total: 138.49ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.76ms, accelerator: 19792643.81sec, total: 19792643.81sec
train2.py:307:<module>, cpu: 138.63ms, accelerator: 0us, total: 138.63ms
  iterator_ops.py:373:get_next, cpu: 138.49ms, accelerator: 0us, total: 138.49ms
train2.py:342:<module>, cpu: 2.14ms, accelerator: 13.47ms, total: 15.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_233000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_233250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_233500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_233750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19708059.85sec, total: 19708059.85sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 138.16ms, accelerator: 0us, total: 138.16ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.75ms, total: 12.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 138.16ms, accelerator: 0us, total: 138.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.76ms, accelerator: 19708059.86sec, total: 19708059.86sec
train2.py:307:<module>, cpu: 138.31ms, accelerator: 0us, total: 138.31ms
  iterator_ops.py:373:get_next, cpu: 138.16ms, accelerator: 0us, total: 138.16ms
train2.py:342:<module>, cpu: 2.14ms, accelerator: 13.48ms, total: 15.64ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_234000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_234250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_234500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_234750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19624195.76sec, total: 19624195.76sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 137.80ms, accelerator: 0us, total: 137.80ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.75ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 137.80ms, accelerator: 0us, total: 137.80ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 19624195.77sec, total: 19624195.78sec
train2.py:307:<module>, cpu: 137.95ms, accelerator: 0us, total: 137.95ms
  iterator_ops.py:373:get_next, cpu: 137.80ms, accelerator: 0us, total: 137.80ms
train2.py:342:<module>, cpu: 2.13ms, accelerator: 13.49ms, total: 15.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_235000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_235250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_235500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_235750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19541042.39sec, total: 19541042.39sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 137.51ms, accelerator: 0us, total: 137.51ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.73ms, total: 12.78ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 137.51ms, accelerator: 0us, total: 137.51ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 19541042.40sec, total: 19541042.40sec
train2.py:307:<module>, cpu: 137.66ms, accelerator: 0us, total: 137.66ms
  iterator_ops.py:373:get_next, cpu: 137.51ms, accelerator: 0us, total: 137.51ms
train2.py:342:<module>, cpu: 2.13ms, accelerator: 13.49ms, total: 15.64ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_236000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_236250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_236500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_236750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19458590.73sec, total: 19458590.74sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 137.21ms, accelerator: 0us, total: 137.21ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.76ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 137.21ms, accelerator: 0us, total: 137.21ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 19458590.75sec, total: 19458590.75sec
train2.py:307:<module>, cpu: 137.36ms, accelerator: 0us, total: 137.36ms
  iterator_ops.py:373:get_next, cpu: 137.21ms, accelerator: 0us, total: 137.21ms
train2.py:342:<module>, cpu: 2.13ms, accelerator: 13.48ms, total: 15.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_237000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_237250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_237500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_237750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19376831.95sec, total: 19376831.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 136.87ms, accelerator: 0us, total: 136.87ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.77ms, total: 12.81ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 136.87ms, accelerator: 0us, total: 136.87ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 19376831.96sec, total: 19376831.96sec
train2.py:307:<module>, cpu: 137.02ms, accelerator: 0us, total: 137.02ms
  iterator_ops.py:373:get_next, cpu: 136.87ms, accelerator: 0us, total: 136.87ms
train2.py:342:<module>, cpu: 2.12ms, accelerator: 13.48ms, total: 15.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_238000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_238250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_238500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_238750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19295757.34sec, total: 19295757.34sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 136.63ms, accelerator: 0us, total: 136.63ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.75ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 136.63ms, accelerator: 0us, total: 136.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 19295757.35sec, total: 19295757.35sec
train2.py:307:<module>, cpu: 136.78ms, accelerator: 0us, total: 136.78ms
  iterator_ops.py:373:get_next, cpu: 136.63ms, accelerator: 0us, total: 136.63ms
train2.py:342:<module>, cpu: 2.12ms, accelerator: 13.48ms, total: 15.63ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_239000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_239250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_239500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_239750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19215358.35sec, total: 19215358.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 136.31ms, accelerator: 0us, total: 136.31ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.76ms, total: 12.81ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 136.31ms, accelerator: 0us, total: 136.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 19215358.36sec, total: 19215358.36sec
train2.py:307:<module>, cpu: 136.45ms, accelerator: 0us, total: 136.45ms
  iterator_ops.py:373:get_next, cpu: 136.31ms, accelerator: 0us, total: 136.31ms
train2.py:342:<module>, cpu: 2.12ms, accelerator: 13.48ms, total: 15.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_240000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_240250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_240500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_240750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19135626.57sec, total: 19135626.57sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 135.99ms, accelerator: 0us, total: 135.99ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.77ms, total: 12.81ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 135.99ms, accelerator: 0us, total: 135.99ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 19135626.58sec, total: 19135626.59sec
train2.py:307:<module>, cpu: 136.13ms, accelerator: 0us, total: 136.13ms
  iterator_ops.py:373:get_next, cpu: 135.99ms, accelerator: 0us, total: 135.99ms
train2.py:342:<module>, cpu: 2.12ms, accelerator: 13.48ms, total: 15.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_241000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_241250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_241500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_241750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 19056553.74sec, total: 19056553.74sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 135.67ms, accelerator: 0us, total: 135.67ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.78ms, total: 12.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 135.67ms, accelerator: 0us, total: 135.67ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 19056553.75sec, total: 19056553.75sec
train2.py:307:<module>, cpu: 135.81ms, accelerator: 0us, total: 135.81ms
  iterator_ops.py:373:get_next, cpu: 135.67ms, accelerator: 0us, total: 135.67ms
train2.py:342:<module>, cpu: 2.12ms, accelerator: 13.48ms, total: 15.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_242000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_242250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_242500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_242750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18978131.70sec, total: 18978131.71sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 135.43ms, accelerator: 0us, total: 135.43ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.76ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 135.43ms, accelerator: 0us, total: 135.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18978131.72sec, total: 18978131.72sec
train2.py:307:<module>, cpu: 135.57ms, accelerator: 0us, total: 135.57ms
  iterator_ops.py:373:get_next, cpu: 135.43ms, accelerator: 0us, total: 135.43ms
train2.py:342:<module>, cpu: 2.11ms, accelerator: 13.48ms, total: 15.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_243000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_243250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_243500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_243750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18900352.48sec, total: 18900352.48sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 135.15ms, accelerator: 0us, total: 135.15ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.74ms, total: 12.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 135.15ms, accelerator: 0us, total: 135.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18900352.49sec, total: 18900352.49sec
train2.py:307:<module>, cpu: 135.29ms, accelerator: 0us, total: 135.29ms
  iterator_ops.py:373:get_next, cpu: 135.15ms, accelerator: 0us, total: 135.15ms
train2.py:342:<module>, cpu: 2.11ms, accelerator: 13.49ms, total: 15.62ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_244000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_244250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_244500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_244750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18823208.18sec, total: 18823208.18sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 134.84ms, accelerator: 0us, total: 134.84ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.76ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 134.84ms, accelerator: 0us, total: 134.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18823208.19sec, total: 18823208.19sec
train2.py:307:<module>, cpu: 134.98ms, accelerator: 0us, total: 134.98ms
  iterator_ops.py:373:get_next, cpu: 134.84ms, accelerator: 0us, total: 134.84ms
train2.py:342:<module>, cpu: 2.11ms, accelerator: 13.48ms, total: 15.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_245000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_245250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_245500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_245750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18746691.07sec, total: 18746691.08sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 134.51ms, accelerator: 0us, total: 134.51ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.75ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 134.51ms, accelerator: 0us, total: 134.51ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18746691.09sec, total: 18746691.09sec
train2.py:307:<module>, cpu: 134.66ms, accelerator: 0us, total: 134.66ms
  iterator_ops.py:373:get_next, cpu: 134.51ms, accelerator: 0us, total: 134.51ms
train2.py:342:<module>, cpu: 2.10ms, accelerator: 13.49ms, total: 15.61ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_246000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_246250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_246500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_246750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18670793.54sec, total: 18670793.54sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 134.21ms, accelerator: 0us, total: 134.21ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.75ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 134.21ms, accelerator: 0us, total: 134.21ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18670793.55sec, total: 18670793.55sec
train2.py:307:<module>, cpu: 134.35ms, accelerator: 0us, total: 134.35ms
  iterator_ops.py:373:get_next, cpu: 134.21ms, accelerator: 0us, total: 134.21ms
train2.py:342:<module>, cpu: 2.10ms, accelerator: 13.48ms, total: 15.60ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_247000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_247250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_247500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_247750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18595508.08sec, total: 18595508.08sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 133.91ms, accelerator: 0us, total: 133.91ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.76ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 133.91ms, accelerator: 0us, total: 133.91ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18595508.09sec, total: 18595508.10sec
train2.py:307:<module>, cpu: 134.05ms, accelerator: 0us, total: 134.05ms
  iterator_ops.py:373:get_next, cpu: 133.91ms, accelerator: 0us, total: 133.91ms
train2.py:342:<module>, cpu: 2.10ms, accelerator: 13.48ms, total: 15.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_248000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_248250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_248500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_248750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18520827.33sec, total: 18520827.33sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 133.61ms, accelerator: 0us, total: 133.61ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.78ms, total: 12.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 133.61ms, accelerator: 0us, total: 133.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18520827.34sec, total: 18520827.34sec
train2.py:307:<module>, cpu: 133.75ms, accelerator: 0us, total: 133.75ms
  iterator_ops.py:373:get_next, cpu: 133.61ms, accelerator: 0us, total: 133.61ms
train2.py:342:<module>, cpu: 2.10ms, accelerator: 13.46ms, total: 15.58ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_249000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_249250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_249500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_249750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18446744.02sec, total: 18446744.02sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 133.27ms, accelerator: 0us, total: 133.27ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.75ms, total: 12.79ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 133.27ms, accelerator: 0us, total: 133.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18446744.03sec, total: 18446744.03sec
train2.py:307:<module>, cpu: 133.41ms, accelerator: 0us, total: 133.41ms
  iterator_ops.py:373:get_next, cpu: 133.27ms, accelerator: 0us, total: 133.27ms
train2.py:342:<module>, cpu: 2.09ms, accelerator: 13.47ms, total: 15.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_250000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_250250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_250500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_250750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18373251.01sec, total: 18373251.01sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 133.04ms, accelerator: 0us, total: 133.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.76ms, total: 12.80ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 133.04ms, accelerator: 0us, total: 133.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18373251.02sec, total: 18373251.03sec
train2.py:307:<module>, cpu: 133.18ms, accelerator: 0us, total: 133.18ms
  iterator_ops.py:373:get_next, cpu: 133.04ms, accelerator: 0us, total: 133.04ms
train2.py:342:<module>, cpu: 2.09ms, accelerator: 13.48ms, total: 15.59ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_251000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_251250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_251500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_251750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18300341.29sec, total: 18300341.29sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 132.83ms, accelerator: 0us, total: 132.83ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.78ms, total: 12.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 132.83ms, accelerator: 0us, total: 132.83ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18300341.30sec, total: 18300341.30sec
train2.py:307:<module>, cpu: 132.97ms, accelerator: 0us, total: 132.97ms
  iterator_ops.py:373:get_next, cpu: 132.83ms, accelerator: 0us, total: 132.83ms
train2.py:342:<module>, cpu: 2.09ms, accelerator: 13.47ms, total: 15.58ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_252000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_252250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_252500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_252750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18228007.92sec, total: 18228007.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 132.52ms, accelerator: 0us, total: 132.52ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.83ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 132.52ms, accelerator: 0us, total: 132.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18228007.93sec, total: 18228007.94sec
train2.py:307:<module>, cpu: 132.66ms, accelerator: 0us, total: 132.66ms
  iterator_ops.py:373:get_next, cpu: 132.52ms, accelerator: 0us, total: 132.52ms
train2.py:342:<module>, cpu: 2.09ms, accelerator: 13.47ms, total: 15.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_253000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_253250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_253500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_253750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18156244.11sec, total: 18156244.11sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 132.33ms, accelerator: 0us, total: 132.33ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 132.33ms, accelerator: 0us, total: 132.33ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18156244.12sec, total: 18156244.13sec
train2.py:307:<module>, cpu: 132.46ms, accelerator: 0us, total: 132.46ms
  iterator_ops.py:373:get_next, cpu: 132.33ms, accelerator: 0us, total: 132.33ms
train2.py:342:<module>, cpu: 2.08ms, accelerator: 13.46ms, total: 15.57ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_254000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_254250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_254500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_254750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18085043.15sec, total: 18085043.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 132.09ms, accelerator: 0us, total: 132.09ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.83ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 132.09ms, accelerator: 0us, total: 132.09ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.75ms, accelerator: 18085043.17sec, total: 18085043.17sec
train2.py:307:<module>, cpu: 132.23ms, accelerator: 0us, total: 132.23ms
  iterator_ops.py:373:get_next, cpu: 132.09ms, accelerator: 0us, total: 132.09ms
train2.py:342:<module>, cpu: 2.08ms, accelerator: 13.47ms, total: 15.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.34
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_255000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_255250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_255500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_255750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 18014398.45sec, total: 18014398.46sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 131.78ms, accelerator: 0us, total: 131.78ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 131.78ms, accelerator: 0us, total: 131.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 18014398.47sec, total: 18014398.47sec
train2.py:307:<module>, cpu: 131.91ms, accelerator: 0us, total: 131.91ms
  iterator_ops.py:373:get_next, cpu: 131.78ms, accelerator: 0us, total: 131.78ms
train2.py:342:<module>, cpu: 2.08ms, accelerator: 13.46ms, total: 15.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_256000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_256250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_256500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_256750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 17944303.52sec, total: 17944303.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 131.47ms, accelerator: 0us, total: 131.47ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 131.47ms, accelerator: 0us, total: 131.47ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17944303.53sec, total: 17944303.53sec
train2.py:307:<module>, cpu: 131.61ms, accelerator: 0us, total: 131.61ms
  iterator_ops.py:373:get_next, cpu: 131.47ms, accelerator: 0us, total: 131.47ms
train2.py:342:<module>, cpu: 2.08ms, accelerator: 13.46ms, total: 15.56ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_257000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_257250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_257500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_257750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.04ms, accelerator: 17874751.95sec, total: 17874751.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 131.30ms, accelerator: 0us, total: 131.30ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.83ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 131.30ms, accelerator: 0us, total: 131.30ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17874751.97sec, total: 17874751.97sec
train2.py:307:<module>, cpu: 131.43ms, accelerator: 0us, total: 131.43ms
  iterator_ops.py:373:get_next, cpu: 131.30ms, accelerator: 0us, total: 131.30ms
train2.py:342:<module>, cpu: 2.08ms, accelerator: 13.47ms, total: 15.56ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_258000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_258250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_258500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_258750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17805737.47sec, total: 17805737.47sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 131.04ms, accelerator: 0us, total: 131.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 131.04ms, accelerator: 0us, total: 131.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17805737.48sec, total: 17805737.48sec
train2.py:307:<module>, cpu: 131.18ms, accelerator: 0us, total: 131.18ms
  iterator_ops.py:373:get_next, cpu: 131.04ms, accelerator: 0us, total: 131.04ms
train2.py:342:<module>, cpu: 2.07ms, accelerator: 13.46ms, total: 15.55ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_259000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_259250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_259500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_259750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17737253.86sec, total: 17737253.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 130.81ms, accelerator: 0us, total: 130.81ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 130.81ms, accelerator: 0us, total: 130.81ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17737253.87sec, total: 17737253.88sec
train2.py:307:<module>, cpu: 130.95ms, accelerator: 0us, total: 130.95ms
  iterator_ops.py:373:get_next, cpu: 130.81ms, accelerator: 0us, total: 130.81ms
train2.py:342:<module>, cpu: 2.07ms, accelerator: 13.47ms, total: 15.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_260000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_260250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_260500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_260750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17669295.04sec, total: 17669295.04sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 130.60ms, accelerator: 0us, total: 130.60ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 130.60ms, accelerator: 0us, total: 130.60ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17669295.05sec, total: 17669295.05sec
train2.py:307:<module>, cpu: 130.74ms, accelerator: 0us, total: 130.74ms
  iterator_ops.py:373:get_next, cpu: 130.60ms, accelerator: 0us, total: 130.60ms
train2.py:342:<module>, cpu: 2.07ms, accelerator: 13.46ms, total: 15.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_261000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_261250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_261500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_261750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17601854.98sec, total: 17601854.98sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 130.34ms, accelerator: 0us, total: 130.34ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 130.34ms, accelerator: 0us, total: 130.34ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17601854.99sec, total: 17601854.99sec
train2.py:307:<module>, cpu: 130.47ms, accelerator: 0us, total: 130.47ms
  iterator_ops.py:373:get_next, cpu: 130.34ms, accelerator: 0us, total: 130.34ms
train2.py:342:<module>, cpu: 2.06ms, accelerator: 13.46ms, total: 15.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_262000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_262250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_262500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_262750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17534927.77sec, total: 17534927.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 130.05ms, accelerator: 0us, total: 130.05ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 130.05ms, accelerator: 0us, total: 130.05ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17534927.78sec, total: 17534927.79sec
train2.py:307:<module>, cpu: 130.19ms, accelerator: 0us, total: 130.19ms
  iterator_ops.py:373:get_next, cpu: 130.05ms, accelerator: 0us, total: 130.05ms
train2.py:342:<module>, cpu: 2.06ms, accelerator: 13.47ms, total: 15.55ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_263000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_263250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_263500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_263750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17468507.59sec, total: 17468507.59sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 130.00ms, accelerator: 0us, total: 130.00ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 130.00ms, accelerator: 0us, total: 130.00ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17468507.60sec, total: 17468507.61sec
train2.py:307:<module>, cpu: 130.13ms, accelerator: 0us, total: 130.13ms
  iterator_ops.py:373:get_next, cpu: 130.00ms, accelerator: 0us, total: 130.00ms
train2.py:342:<module>, cpu: 2.06ms, accelerator: 13.47ms, total: 15.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.26
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_264000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_264250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_264500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_264750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17402588.70sec, total: 17402588.70sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 129.72ms, accelerator: 0us, total: 129.72ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 129.72ms, accelerator: 0us, total: 129.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17402588.71sec, total: 17402588.71sec
train2.py:307:<module>, cpu: 129.86ms, accelerator: 0us, total: 129.86ms
  iterator_ops.py:373:get_next, cpu: 129.72ms, accelerator: 0us, total: 129.72ms
train2.py:342:<module>, cpu: 2.06ms, accelerator: 13.46ms, total: 15.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_265000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_265250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_265500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_265750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17337165.43sec, total: 17337165.43sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 129.44ms, accelerator: 0us, total: 129.44ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 129.44ms, accelerator: 0us, total: 129.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17337165.44sec, total: 17337165.44sec
train2.py:307:<module>, cpu: 129.57ms, accelerator: 0us, total: 129.57ms
  iterator_ops.py:373:get_next, cpu: 129.44ms, accelerator: 0us, total: 129.44ms
train2.py:342:<module>, cpu: 2.05ms, accelerator: 13.47ms, total: 15.54ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_266000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_266250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_266500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_266750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17272232.23sec, total: 17272232.23sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 129.26ms, accelerator: 0us, total: 129.26ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 129.26ms, accelerator: 0us, total: 129.26ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17272232.24sec, total: 17272232.24sec
train2.py:307:<module>, cpu: 129.39ms, accelerator: 0us, total: 129.39ms
  iterator_ops.py:373:get_next, cpu: 129.26ms, accelerator: 0us, total: 129.26ms
train2.py:342:<module>, cpu: 2.05ms, accelerator: 13.46ms, total: 15.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_267000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_267250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_267500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_267750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17207783.60sec, total: 17207783.60sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 129.04ms, accelerator: 0us, total: 129.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 129.04ms, accelerator: 0us, total: 129.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17207783.61sec, total: 17207783.61sec
train2.py:307:<module>, cpu: 129.17ms, accelerator: 0us, total: 129.17ms
  iterator_ops.py:373:get_next, cpu: 129.04ms, accelerator: 0us, total: 129.04ms
train2.py:342:<module>, cpu: 2.05ms, accelerator: 13.46ms, total: 15.53ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_268000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_268250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_268500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_268750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17143814.14sec, total: 17143814.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.97ms, accelerator: 0us, total: 128.97ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.97ms, accelerator: 0us, total: 128.97ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17143814.15sec, total: 17143814.16sec
train2.py:307:<module>, cpu: 129.10ms, accelerator: 0us, total: 129.10ms
  iterator_ops.py:373:get_next, cpu: 128.97ms, accelerator: 0us, total: 128.97ms
train2.py:342:<module>, cpu: 2.05ms, accelerator: 13.47ms, total: 15.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_269000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_269250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_269500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_269750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17080318.53sec, total: 17080318.54sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.72ms, accelerator: 0us, total: 128.72ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.72ms, accelerator: 0us, total: 128.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17080318.55sec, total: 17080318.55sec
train2.py:307:<module>, cpu: 128.85ms, accelerator: 0us, total: 128.85ms
  iterator_ops.py:373:get_next, cpu: 128.72ms, accelerator: 0us, total: 128.72ms
train2.py:342:<module>, cpu: 2.04ms, accelerator: 13.46ms, total: 15.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_270000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_270250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_270500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_270750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 17017291.53sec, total: 17017291.53sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.52ms, accelerator: 0us, total: 128.52ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.52ms, accelerator: 0us, total: 128.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 17017291.54sec, total: 17017291.54sec
train2.py:307:<module>, cpu: 128.65ms, accelerator: 0us, total: 128.65ms
  iterator_ops.py:373:get_next, cpu: 128.52ms, accelerator: 0us, total: 128.52ms
train2.py:342:<module>, cpu: 2.04ms, accelerator: 13.46ms, total: 15.53ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_271000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_271250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_271500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_271750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 16954727.96sec, total: 16954727.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.26ms, accelerator: 0us, total: 128.26ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.26ms, accelerator: 0us, total: 128.26ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 16954727.97sec, total: 16954727.97sec
train2.py:307:<module>, cpu: 128.39ms, accelerator: 0us, total: 128.39ms
  iterator_ops.py:373:get_next, cpu: 128.26ms, accelerator: 0us, total: 128.26ms
train2.py:342:<module>, cpu: 2.04ms, accelerator: 13.46ms, total: 15.52ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_272000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_272250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_272500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_272750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 16892622.73sec, total: 16892622.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.02ms, accelerator: 0us, total: 128.02ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.02ms, accelerator: 0us, total: 128.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 16892622.74sec, total: 16892622.74sec
train2.py:307:<module>, cpu: 128.15ms, accelerator: 0us, total: 128.15ms
  iterator_ops.py:373:get_next, cpu: 128.02ms, accelerator: 0us, total: 128.02ms
train2.py:342:<module>, cpu: 2.04ms, accelerator: 13.46ms, total: 15.52ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_273000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_273250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_273500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_273750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 16830970.82sec, total: 16830970.82sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.75ms, accelerator: 0us, total: 127.75ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.75ms, accelerator: 0us, total: 127.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 16830970.83sec, total: 16830970.83sec
train2.py:307:<module>, cpu: 127.88ms, accelerator: 0us, total: 127.88ms
  iterator_ops.py:373:get_next, cpu: 127.75ms, accelerator: 0us, total: 127.75ms
train2.py:342:<module>, cpu: 2.03ms, accelerator: 13.46ms, total: 15.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_274000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_274250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_274500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_274750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 16769767.29sec, total: 16769767.29sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.55ms, accelerator: 0us, total: 127.55ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.55ms, accelerator: 0us, total: 127.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 16769767.30sec, total: 16769767.30sec
train2.py:307:<module>, cpu: 127.68ms, accelerator: 0us, total: 127.68ms
  iterator_ops.py:373:get_next, cpu: 127.55ms, accelerator: 0us, total: 127.55ms
train2.py:342:<module>, cpu: 2.03ms, accelerator: 13.45ms, total: 15.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_275000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_275250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_275500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_275750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 16709007.26sec, total: 16709007.26sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.30ms, accelerator: 0us, total: 127.30ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.30ms, accelerator: 0us, total: 127.30ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 16709007.27sec, total: 16709007.28sec
train2.py:307:<module>, cpu: 127.43ms, accelerator: 0us, total: 127.43ms
  iterator_ops.py:373:get_next, cpu: 127.30ms, accelerator: 0us, total: 127.30ms
train2.py:342:<module>, cpu: 2.03ms, accelerator: 13.46ms, total: 15.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_276000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_276250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_276500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_276750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 16648685.94sec, total: 16648685.94sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.07ms, accelerator: 0us, total: 127.07ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.07ms, accelerator: 0us, total: 127.07ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 16648685.95sec, total: 16648685.95sec
train2.py:307:<module>, cpu: 127.20ms, accelerator: 0us, total: 127.20ms
  iterator_ops.py:373:get_next, cpu: 127.07ms, accelerator: 0us, total: 127.07ms
train2.py:342:<module>, cpu: 2.03ms, accelerator: 13.46ms, total: 15.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_277000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_277250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_277500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_277750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 16588798.58sec, total: 16588798.58sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 126.91ms, accelerator: 0us, total: 126.91ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 126.91ms, accelerator: 0us, total: 126.91ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 16588798.59sec, total: 16588798.59sec
train2.py:307:<module>, cpu: 127.03ms, accelerator: 0us, total: 127.03ms
  iterator_ops.py:373:get_next, cpu: 126.91ms, accelerator: 0us, total: 126.91ms
train2.py:342:<module>, cpu: 2.03ms, accelerator: 13.46ms, total: 15.51ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_278000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_278250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_278500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_278750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 16529340.52sec, total: 16529340.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 126.63ms, accelerator: 0us, total: 126.63ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 126.63ms, accelerator: 0us, total: 126.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 16529340.53sec, total: 16529340.53sec
train2.py:307:<module>, cpu: 126.76ms, accelerator: 0us, total: 126.76ms
  iterator_ops.py:373:get_next, cpu: 126.63ms, accelerator: 0us, total: 126.63ms
train2.py:342:<module>, cpu: 2.03ms, accelerator: 13.45ms, total: 15.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_279000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_279250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_279500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_279750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 16470307.16sec, total: 16470307.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 126.41ms, accelerator: 0us, total: 126.41ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 126.41ms, accelerator: 0us, total: 126.41ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 16470307.17sec, total: 16470307.17sec
train2.py:307:<module>, cpu: 126.53ms, accelerator: 0us, total: 126.53ms
  iterator_ops.py:373:get_next, cpu: 126.41ms, accelerator: 0us, total: 126.41ms
train2.py:342:<module>, cpu: 2.02ms, accelerator: 13.45ms, total: 15.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_280000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_280250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_280500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_280750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 32823387.93sec, total: 32823387.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 126.16ms, accelerator: 0us, total: 126.16ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 126.16ms, accelerator: 0us, total: 126.16ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 32823387.94sec, total: 32823387.94sec
train2.py:307:<module>, cpu: 126.29ms, accelerator: 0us, total: 126.29ms
  iterator_ops.py:373:get_next, cpu: 126.16ms, accelerator: 0us, total: 126.16ms
train2.py:342:<module>, cpu: 2.02ms, accelerator: 13.46ms, total: 15.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_281000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_281250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_281500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_281750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 32706992.93sec, total: 32706992.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 125.94ms, accelerator: 0us, total: 125.94ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 125.94ms, accelerator: 0us, total: 125.94ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 32706992.94sec, total: 32706992.95sec
train2.py:307:<module>, cpu: 126.07ms, accelerator: 0us, total: 126.07ms
  iterator_ops.py:373:get_next, cpu: 125.94ms, accelerator: 0us, total: 125.94ms
train2.py:342:<module>, cpu: 2.02ms, accelerator: 13.45ms, total: 15.50ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_282000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_282250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_282500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_282750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 32591420.52sec, total: 32591420.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 129.59ms, accelerator: 0us, total: 129.59ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 129.59ms, accelerator: 0us, total: 129.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 32591420.53sec, total: 32591420.53sec
train2.py:307:<module>, cpu: 129.71ms, accelerator: 0us, total: 129.71ms
  iterator_ops.py:373:get_next, cpu: 129.59ms, accelerator: 0us, total: 129.59ms
train2.py:342:<module>, cpu: 2.02ms, accelerator: 13.45ms, total: 15.49ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_283000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_283250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_283500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_283750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 32476662.00sec, total: 32476662.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 129.47ms, accelerator: 0us, total: 129.47ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 129.47ms, accelerator: 0us, total: 129.47ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 32476662.01sec, total: 32476662.01sec
train2.py:307:<module>, cpu: 129.60ms, accelerator: 0us, total: 129.60ms
  iterator_ops.py:373:get_next, cpu: 129.47ms, accelerator: 0us, total: 129.47ms
train2.py:342:<module>, cpu: 2.02ms, accelerator: 13.44ms, total: 15.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_284000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_284250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_284500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_284750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 32362708.80sec, total: 32362708.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 129.21ms, accelerator: 0us, total: 129.21ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 129.21ms, accelerator: 0us, total: 129.21ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.74ms, accelerator: 32362708.81sec, total: 32362708.81sec
train2.py:307:<module>, cpu: 129.33ms, accelerator: 0us, total: 129.33ms
  iterator_ops.py:373:get_next, cpu: 129.21ms, accelerator: 0us, total: 129.21ms
train2.py:342:<module>, cpu: 2.02ms, accelerator: 13.44ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_285000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_285250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_285500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_285750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 32249552.47sec, total: 32249552.47sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 129.03ms, accelerator: 0us, total: 129.03ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 129.03ms, accelerator: 0us, total: 129.03ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 32249552.48sec, total: 32249552.49sec
train2.py:307:<module>, cpu: 129.15ms, accelerator: 0us, total: 129.15ms
  iterator_ops.py:373:get_next, cpu: 129.03ms, accelerator: 0us, total: 129.03ms
train2.py:342:<module>, cpu: 2.01ms, accelerator: 13.44ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_286000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_286250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_286500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_286750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 32137184.69sec, total: 32137184.69sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.81ms, accelerator: 0us, total: 128.81ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.81ms, accelerator: 0us, total: 128.81ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 32137184.71sec, total: 32137184.71sec
train2.py:307:<module>, cpu: 128.94ms, accelerator: 0us, total: 128.94ms
  iterator_ops.py:373:get_next, cpu: 128.81ms, accelerator: 0us, total: 128.81ms
train2.py:342:<module>, cpu: 2.01ms, accelerator: 13.44ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_287000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_287250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_287500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_287750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 32025597.25sec, total: 32025597.25sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.70ms, accelerator: 0us, total: 128.70ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.70ms, accelerator: 0us, total: 128.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 32025597.26sec, total: 32025597.26sec
train2.py:307:<module>, cpu: 128.82ms, accelerator: 0us, total: 128.82ms
  iterator_ops.py:373:get_next, cpu: 128.70ms, accelerator: 0us, total: 128.70ms
train2.py:342:<module>, cpu: 2.01ms, accelerator: 13.45ms, total: 15.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_288000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_288250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_288500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_288750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 31914782.03sec, total: 31914782.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.46ms, accelerator: 0us, total: 128.46ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.46ms, accelerator: 0us, total: 128.46ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 31914782.04sec, total: 31914782.05sec
train2.py:307:<module>, cpu: 128.58ms, accelerator: 0us, total: 128.58ms
  iterator_ops.py:373:get_next, cpu: 128.46ms, accelerator: 0us, total: 128.46ms
train2.py:342:<module>, cpu: 2.01ms, accelerator: 13.45ms, total: 15.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_289000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_289250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_289500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_289750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 31804731.06sec, total: 31804731.06sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.31ms, accelerator: 0us, total: 128.31ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.31ms, accelerator: 0us, total: 128.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 31804731.07sec, total: 31804731.07sec
train2.py:307:<module>, cpu: 128.44ms, accelerator: 0us, total: 128.44ms
  iterator_ops.py:373:get_next, cpu: 128.31ms, accelerator: 0us, total: 128.31ms
train2.py:342:<module>, cpu: 2.01ms, accelerator: 13.46ms, total: 15.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_290000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_290250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_290500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_290750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 31695436.45sec, total: 31695436.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 128.17ms, accelerator: 0us, total: 128.17ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 128.17ms, accelerator: 0us, total: 128.17ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 31695436.46sec, total: 31695436.46sec
train2.py:307:<module>, cpu: 128.29ms, accelerator: 0us, total: 128.29ms
  iterator_ops.py:373:get_next, cpu: 128.17ms, accelerator: 0us, total: 128.17ms
train2.py:342:<module>, cpu: 2.00ms, accelerator: 13.45ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_291000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_291250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_291500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_291750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 31586890.44sec, total: 31586890.44sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.96ms, accelerator: 0us, total: 127.96ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.96ms, accelerator: 0us, total: 127.96ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 31586890.45sec, total: 31586890.45sec
train2.py:307:<module>, cpu: 128.08ms, accelerator: 0us, total: 128.08ms
  iterator_ops.py:373:get_next, cpu: 127.96ms, accelerator: 0us, total: 127.96ms
train2.py:342:<module>, cpu: 2.00ms, accelerator: 13.45ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_292000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_292250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_292500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_292750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 31479085.35sec, total: 31479085.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.80ms, accelerator: 0us, total: 127.80ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.80ms, accelerator: 0us, total: 127.80ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 31479085.36sec, total: 31479085.36sec
train2.py:307:<module>, cpu: 127.92ms, accelerator: 0us, total: 127.92ms
  iterator_ops.py:373:get_next, cpu: 127.80ms, accelerator: 0us, total: 127.80ms
train2.py:342:<module>, cpu: 2.00ms, accelerator: 13.45ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_293000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_293250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_293500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_293750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 31372013.63sec, total: 31372013.63sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.60ms, accelerator: 0us, total: 127.60ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.60ms, accelerator: 0us, total: 127.60ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 31372013.64sec, total: 31372013.64sec
train2.py:307:<module>, cpu: 127.72ms, accelerator: 0us, total: 127.72ms
  iterator_ops.py:373:get_next, cpu: 127.60ms, accelerator: 0us, total: 127.60ms
train2.py:342:<module>, cpu: 2.00ms, accelerator: 13.45ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_294000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_294250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_294500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_294750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 31265667.82sec, total: 31265667.82sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.44ms, accelerator: 0us, total: 127.44ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.44ms, accelerator: 0us, total: 127.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 31265667.83sec, total: 31265667.84sec
train2.py:307:<module>, cpu: 127.56ms, accelerator: 0us, total: 127.56ms
  iterator_ops.py:373:get_next, cpu: 127.44ms, accelerator: 0us, total: 127.44ms
train2.py:342:<module>, cpu: 2.00ms, accelerator: 13.46ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_295000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_295250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_295500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_295750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 31160040.56sec, total: 31160040.57sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.27ms, accelerator: 0us, total: 127.27ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.27ms, accelerator: 0us, total: 127.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 31160040.58sec, total: 31160040.58sec
train2.py:307:<module>, cpu: 127.39ms, accelerator: 0us, total: 127.39ms
  iterator_ops.py:373:get_next, cpu: 127.27ms, accelerator: 0us, total: 127.27ms
train2.py:342:<module>, cpu: 1.99ms, accelerator: 13.47ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_296000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_296250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_296500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_296750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 31055124.60sec, total: 31055124.60sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 127.02ms, accelerator: 0us, total: 127.02ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.77ms, total: 12.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 127.02ms, accelerator: 0us, total: 127.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 31055124.61sec, total: 31055124.62sec
train2.py:307:<module>, cpu: 127.14ms, accelerator: 0us, total: 127.14ms
  iterator_ops.py:373:get_next, cpu: 127.02ms, accelerator: 0us, total: 127.02ms
train2.py:342:<module>, cpu: 1.99ms, accelerator: 13.47ms, total: 15.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_297000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_297250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_297500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_297750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 30950912.78sec, total: 30950912.78sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 126.84ms, accelerator: 0us, total: 126.84ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.78ms, total: 12.83ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 126.84ms, accelerator: 0us, total: 126.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 30950912.79sec, total: 30950912.79sec
train2.py:307:<module>, cpu: 126.95ms, accelerator: 0us, total: 126.95ms
  iterator_ops.py:373:get_next, cpu: 126.84ms, accelerator: 0us, total: 126.84ms
train2.py:342:<module>, cpu: 1.99ms, accelerator: 13.47ms, total: 15.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_298000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_298250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_298500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_298750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 30847398.02sec, total: 30847398.02sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 126.56ms, accelerator: 0us, total: 126.56ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.78ms, total: 12.82ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 126.56ms, accelerator: 0us, total: 126.56ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 30847398.03sec, total: 30847398.03sec
train2.py:307:<module>, cpu: 126.68ms, accelerator: 0us, total: 126.68ms
  iterator_ops.py:373:get_next, cpu: 126.56ms, accelerator: 0us, total: 126.56ms
train2.py:342:<module>, cpu: 1.99ms, accelerator: 13.47ms, total: 15.48ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_299000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_299250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_299500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_299750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 30744573.36sec, total: 30744573.36sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 126.45ms, accelerator: 0us, total: 126.45ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.80ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 126.45ms, accelerator: 0us, total: 126.45ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 30744573.37sec, total: 30744573.37sec
train2.py:307:<module>, cpu: 126.57ms, accelerator: 0us, total: 126.57ms
  iterator_ops.py:373:get_next, cpu: 126.45ms, accelerator: 0us, total: 126.45ms
train2.py:342:<module>, cpu: 1.99ms, accelerator: 13.47ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_300000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_300250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_300500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_300750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 30642431.92sec, total: 30642431.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 126.24ms, accelerator: 0us, total: 126.24ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.80ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 126.24ms, accelerator: 0us, total: 126.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 30642431.93sec, total: 30642431.93sec
train2.py:307:<module>, cpu: 126.36ms, accelerator: 0us, total: 126.36ms
  iterator_ops.py:373:get_next, cpu: 126.24ms, accelerator: 0us, total: 126.24ms
train2.py:342:<module>, cpu: 1.99ms, accelerator: 13.46ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_301000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_301250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_301500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_301750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 30540966.91sec, total: 30540966.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 126.04ms, accelerator: 0us, total: 126.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.80ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 126.04ms, accelerator: 0us, total: 126.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 30540966.92sec, total: 30540966.93sec
train2.py:307:<module>, cpu: 126.15ms, accelerator: 0us, total: 126.15ms
  iterator_ops.py:373:get_next, cpu: 126.04ms, accelerator: 0us, total: 126.04ms
train2.py:342:<module>, cpu: 1.98ms, accelerator: 13.46ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_302000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_302250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_302500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_302750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 30440171.64sec, total: 30440171.64sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 125.82ms, accelerator: 0us, total: 125.82ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.81ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 125.82ms, accelerator: 0us, total: 125.82ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 30440171.65sec, total: 30440171.66sec
train2.py:307:<module>, cpu: 125.94ms, accelerator: 0us, total: 125.94ms
  iterator_ops.py:373:get_next, cpu: 125.82ms, accelerator: 0us, total: 125.82ms
train2.py:342:<module>, cpu: 1.98ms, accelerator: 13.47ms, total: 15.47ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_303000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_303250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_303500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_303750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 30340039.50sec, total: 30340039.50sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 125.66ms, accelerator: 0us, total: 125.66ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 125.66ms, accelerator: 0us, total: 125.66ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 30340039.51sec, total: 30340039.51sec
train2.py:307:<module>, cpu: 125.78ms, accelerator: 0us, total: 125.78ms
  iterator_ops.py:373:get_next, cpu: 125.66ms, accelerator: 0us, total: 125.66ms
train2.py:342:<module>, cpu: 1.98ms, accelerator: 13.46ms, total: 15.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_304000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_304250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_304500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_304750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 30240563.96sec, total: 30240563.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 125.43ms, accelerator: 0us, total: 125.43ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 125.43ms, accelerator: 0us, total: 125.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 30240563.97sec, total: 30240563.97sec
train2.py:307:<module>, cpu: 125.55ms, accelerator: 0us, total: 125.55ms
  iterator_ops.py:373:get_next, cpu: 125.43ms, accelerator: 0us, total: 125.43ms
train2.py:342:<module>, cpu: 1.98ms, accelerator: 13.47ms, total: 15.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_305000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_305250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_305500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_305750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 30141738.59sec, total: 30141738.59sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 125.29ms, accelerator: 0us, total: 125.29ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 125.29ms, accelerator: 0us, total: 125.29ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 30141738.60sec, total: 30141738.60sec
train2.py:307:<module>, cpu: 125.41ms, accelerator: 0us, total: 125.41ms
  iterator_ops.py:373:get_next, cpu: 125.29ms, accelerator: 0us, total: 125.29ms
train2.py:342:<module>, cpu: 1.98ms, accelerator: 13.46ms, total: 15.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_306000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_306250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_306500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_306750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 30043557.03sec, total: 30043557.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 125.08ms, accelerator: 0us, total: 125.08ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 125.08ms, accelerator: 0us, total: 125.08ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 30043557.04sec, total: 30043557.04sec
train2.py:307:<module>, cpu: 125.19ms, accelerator: 0us, total: 125.19ms
  iterator_ops.py:373:get_next, cpu: 125.08ms, accelerator: 0us, total: 125.08ms
train2.py:342:<module>, cpu: 1.98ms, accelerator: 13.46ms, total: 15.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_307000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_307250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_307500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_307750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 29946013.01sec, total: 29946013.01sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 124.90ms, accelerator: 0us, total: 124.90ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 124.90ms, accelerator: 0us, total: 124.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 29946013.02sec, total: 29946013.02sec
train2.py:307:<module>, cpu: 125.01ms, accelerator: 0us, total: 125.01ms
  iterator_ops.py:373:get_next, cpu: 124.90ms, accelerator: 0us, total: 124.90ms
train2.py:342:<module>, cpu: 1.97ms, accelerator: 13.46ms, total: 15.46ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_308000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_308250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_308500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_308750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 29849100.35sec, total: 29849100.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 124.69ms, accelerator: 0us, total: 124.69ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 124.69ms, accelerator: 0us, total: 124.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 29849100.36sec, total: 29849100.36sec
train2.py:307:<module>, cpu: 124.80ms, accelerator: 0us, total: 124.80ms
  iterator_ops.py:373:get_next, cpu: 124.69ms, accelerator: 0us, total: 124.69ms
train2.py:342:<module>, cpu: 1.97ms, accelerator: 13.46ms, total: 15.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_309000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_309250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_309500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_309750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 29752812.93sec, total: 29752812.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 124.55ms, accelerator: 0us, total: 124.55ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 124.55ms, accelerator: 0us, total: 124.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 29752812.94sec, total: 29752812.94sec
train2.py:307:<module>, cpu: 124.66ms, accelerator: 0us, total: 124.66ms
  iterator_ops.py:373:get_next, cpu: 124.55ms, accelerator: 0us, total: 124.55ms
train2.py:342:<module>, cpu: 1.97ms, accelerator: 13.46ms, total: 15.45ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_310000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_310250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_310500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_310750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 29657144.72sec, total: 29657144.72sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 124.34ms, accelerator: 0us, total: 124.34ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 124.34ms, accelerator: 0us, total: 124.34ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 29657144.73sec, total: 29657144.73sec
train2.py:307:<module>, cpu: 124.46ms, accelerator: 0us, total: 124.46ms
  iterator_ops.py:373:get_next, cpu: 124.34ms, accelerator: 0us, total: 124.34ms
train2.py:342:<module>, cpu: 1.97ms, accelerator: 13.46ms, total: 15.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_311000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_311250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_311500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_311750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.03ms, accelerator: 29562089.77sec, total: 29562089.77sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 124.15ms, accelerator: 0us, total: 124.15ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.85ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 124.15ms, accelerator: 0us, total: 124.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.73ms, accelerator: 29562089.78sec, total: 29562089.78sec
train2.py:307:<module>, cpu: 124.26ms, accelerator: 0us, total: 124.26ms
  iterator_ops.py:373:get_next, cpu: 124.15ms, accelerator: 0us, total: 124.15ms
train2.py:342:<module>, cpu: 1.97ms, accelerator: 13.45ms, total: 15.44ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_312000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_312250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_312500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_312750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 29467642.20sec, total: 29467642.20sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 124.00ms, accelerator: 0us, total: 124.00ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 124.00ms, accelerator: 0us, total: 124.00ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 29467642.21sec, total: 29467642.21sec
train2.py:307:<module>, cpu: 124.11ms, accelerator: 0us, total: 124.11ms
  iterator_ops.py:373:get_next, cpu: 124.00ms, accelerator: 0us, total: 124.00ms
train2.py:342:<module>, cpu: 1.96ms, accelerator: 13.45ms, total: 15.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_313000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_313250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_313500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_313750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 29373796.20sec, total: 29373796.20sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 123.80ms, accelerator: 0us, total: 123.80ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 123.80ms, accelerator: 0us, total: 123.80ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 29373796.21sec, total: 29373796.22sec
train2.py:307:<module>, cpu: 123.92ms, accelerator: 0us, total: 123.92ms
  iterator_ops.py:373:get_next, cpu: 123.80ms, accelerator: 0us, total: 123.80ms
train2.py:342:<module>, cpu: 1.96ms, accelerator: 13.44ms, total: 15.43ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_314000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_314250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_314500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_314750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 29280546.06sec, total: 29280546.06sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 123.67ms, accelerator: 0us, total: 123.67ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.85ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 123.67ms, accelerator: 0us, total: 123.67ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 29280546.07sec, total: 29280546.07sec
train2.py:307:<module>, cpu: 123.78ms, accelerator: 0us, total: 123.78ms
  iterator_ops.py:373:get_next, cpu: 123.67ms, accelerator: 0us, total: 123.67ms
train2.py:342:<module>, cpu: 1.96ms, accelerator: 13.45ms, total: 15.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_315000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_315250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_315500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_315750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 29187886.10sec, total: 29187886.10sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 123.55ms, accelerator: 0us, total: 123.55ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.85ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 123.55ms, accelerator: 0us, total: 123.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 29187886.11sec, total: 29187886.11sec
train2.py:307:<module>, cpu: 123.67ms, accelerator: 0us, total: 123.67ms
  iterator_ops.py:373:get_next, cpu: 123.55ms, accelerator: 0us, total: 123.55ms
train2.py:342:<module>, cpu: 1.96ms, accelerator: 13.44ms, total: 15.42ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_316000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_316250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_316500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_316750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 29095810.75sec, total: 29095810.75sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 123.42ms, accelerator: 0us, total: 123.42ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 123.42ms, accelerator: 0us, total: 123.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 29095810.76sec, total: 29095810.76sec
train2.py:307:<module>, cpu: 123.53ms, accelerator: 0us, total: 123.53ms
  iterator_ops.py:373:get_next, cpu: 123.42ms, accelerator: 0us, total: 123.42ms
train2.py:342:<module>, cpu: 1.96ms, accelerator: 13.43ms, total: 15.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_317000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_317250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_317500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_317750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 29004314.49sec, total: 29004314.49sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 123.25ms, accelerator: 0us, total: 123.25ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 123.25ms, accelerator: 0us, total: 123.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 29004314.50sec, total: 29004314.50sec
train2.py:307:<module>, cpu: 123.36ms, accelerator: 0us, total: 123.36ms
  iterator_ops.py:373:get_next, cpu: 123.25ms, accelerator: 0us, total: 123.25ms
train2.py:342:<module>, cpu: 1.96ms, accelerator: 13.43ms, total: 15.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_318000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_318250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_318500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_318750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28913391.87sec, total: 28913391.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 123.10ms, accelerator: 0us, total: 123.10ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 123.10ms, accelerator: 0us, total: 123.10ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28913391.88sec, total: 28913391.89sec
train2.py:307:<module>, cpu: 123.22ms, accelerator: 0us, total: 123.22ms
  iterator_ops.py:373:get_next, cpu: 123.10ms, accelerator: 0us, total: 123.10ms
train2.py:342:<module>, cpu: 1.96ms, accelerator: 13.43ms, total: 15.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_319000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_319250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_319500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_319750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28823037.52sec, total: 28823037.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 122.95ms, accelerator: 0us, total: 122.95ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.86ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 122.95ms, accelerator: 0us, total: 122.95ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28823037.53sec, total: 28823037.54sec
train2.py:307:<module>, cpu: 123.06ms, accelerator: 0us, total: 123.06ms
  iterator_ops.py:373:get_next, cpu: 122.95ms, accelerator: 0us, total: 122.95ms
train2.py:342:<module>, cpu: 1.95ms, accelerator: 13.44ms, total: 15.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_320000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_320250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_320500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_320750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28733246.13sec, total: 28733246.13sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 122.75ms, accelerator: 0us, total: 122.75ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 122.75ms, accelerator: 0us, total: 122.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28733246.14sec, total: 28733246.14sec
train2.py:307:<module>, cpu: 122.86ms, accelerator: 0us, total: 122.86ms
  iterator_ops.py:373:get_next, cpu: 122.75ms, accelerator: 0us, total: 122.75ms
train2.py:342:<module>, cpu: 1.95ms, accelerator: 13.43ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_321000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_321250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_321500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_321750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28644012.45sec, total: 28644012.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 122.59ms, accelerator: 0us, total: 122.59ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 122.59ms, accelerator: 0us, total: 122.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28644012.46sec, total: 28644012.46sec
train2.py:307:<module>, cpu: 122.70ms, accelerator: 0us, total: 122.70ms
  iterator_ops.py:373:get_next, cpu: 122.59ms, accelerator: 0us, total: 122.59ms
train2.py:342:<module>, cpu: 1.95ms, accelerator: 13.43ms, total: 15.40ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_322000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_322250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_322500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_322750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28555331.29sec, total: 28555331.29sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 122.52ms, accelerator: 0us, total: 122.52ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 122.52ms, accelerator: 0us, total: 122.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28555331.30sec, total: 28555331.31sec
train2.py:307:<module>, cpu: 122.62ms, accelerator: 0us, total: 122.62ms
  iterator_ops.py:373:get_next, cpu: 122.52ms, accelerator: 0us, total: 122.52ms
train2.py:342:<module>, cpu: 1.95ms, accelerator: 13.42ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_323000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_323250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_323500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_323750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28467197.55sec, total: 28467197.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 122.35ms, accelerator: 0us, total: 122.35ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 122.35ms, accelerator: 0us, total: 122.35ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28467197.57sec, total: 28467197.57sec
train2.py:307:<module>, cpu: 122.45ms, accelerator: 0us, total: 122.45ms
  iterator_ops.py:373:get_next, cpu: 122.35ms, accelerator: 0us, total: 122.35ms
train2.py:342:<module>, cpu: 1.95ms, accelerator: 13.42ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_324000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_324250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_324500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_324750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28379606.18sec, total: 28379606.18sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 122.19ms, accelerator: 0us, total: 122.19ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 122.19ms, accelerator: 0us, total: 122.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28379606.19sec, total: 28379606.19sec
train2.py:307:<module>, cpu: 122.30ms, accelerator: 0us, total: 122.30ms
  iterator_ops.py:373:get_next, cpu: 122.19ms, accelerator: 0us, total: 122.19ms
train2.py:342:<module>, cpu: 1.95ms, accelerator: 13.42ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_325000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_325250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_325500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_325750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28292552.17sec, total: 28292552.17sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 122.03ms, accelerator: 0us, total: 122.03ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 122.03ms, accelerator: 0us, total: 122.03ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28292552.18sec, total: 28292552.18sec
train2.py:307:<module>, cpu: 122.14ms, accelerator: 0us, total: 122.14ms
  iterator_ops.py:373:get_next, cpu: 122.03ms, accelerator: 0us, total: 122.03ms
train2.py:342:<module>, cpu: 1.95ms, accelerator: 13.43ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_326000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_326250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_326500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_326750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28206030.60sec, total: 28206030.61sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 121.84ms, accelerator: 0us, total: 121.84ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 121.84ms, accelerator: 0us, total: 121.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28206030.62sec, total: 28206030.62sec
train2.py:307:<module>, cpu: 121.95ms, accelerator: 0us, total: 121.95ms
  iterator_ops.py:373:get_next, cpu: 121.84ms, accelerator: 0us, total: 121.84ms
train2.py:342:<module>, cpu: 1.94ms, accelerator: 13.43ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_327000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_327250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_327500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_327750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28120036.61sec, total: 28120036.61sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 121.63ms, accelerator: 0us, total: 121.63ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.89ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 121.63ms, accelerator: 0us, total: 121.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28120036.62sec, total: 28120036.62sec
train2.py:307:<module>, cpu: 121.74ms, accelerator: 0us, total: 121.74ms
  iterator_ops.py:373:get_next, cpu: 121.63ms, accelerator: 0us, total: 121.63ms
train2.py:342:<module>, cpu: 1.94ms, accelerator: 13.42ms, total: 15.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_328000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_328250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_328500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_328750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 28034565.37sec, total: 28034565.37sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 121.44ms, accelerator: 0us, total: 121.44ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.89ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 121.44ms, accelerator: 0us, total: 121.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 28034565.38sec, total: 28034565.39sec
train2.py:307:<module>, cpu: 121.55ms, accelerator: 0us, total: 121.55ms
  iterator_ops.py:373:get_next, cpu: 121.44ms, accelerator: 0us, total: 121.44ms
train2.py:342:<module>, cpu: 1.94ms, accelerator: 13.43ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_329000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_329250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_329500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_329750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27949612.14sec, total: 27949612.15sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 121.34ms, accelerator: 0us, total: 121.34ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 121.34ms, accelerator: 0us, total: 121.34ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 27949612.16sec, total: 27949612.16sec
train2.py:307:<module>, cpu: 121.45ms, accelerator: 0us, total: 121.45ms
  iterator_ops.py:373:get_next, cpu: 121.34ms, accelerator: 0us, total: 121.34ms
train2.py:342:<module>, cpu: 1.94ms, accelerator: 13.43ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_330000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_330250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_330500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_330750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27865172.23sec, total: 27865172.23sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 121.14ms, accelerator: 0us, total: 121.14ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 121.14ms, accelerator: 0us, total: 121.14ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 27865172.24sec, total: 27865172.24sec
train2.py:307:<module>, cpu: 121.25ms, accelerator: 0us, total: 121.25ms
  iterator_ops.py:373:get_next, cpu: 121.14ms, accelerator: 0us, total: 121.14ms
train2.py:342:<module>, cpu: 1.94ms, accelerator: 13.43ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_331000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_331250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_331500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_331750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27781240.99sec, total: 27781240.99sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 120.97ms, accelerator: 0us, total: 120.97ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.86ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 120.97ms, accelerator: 0us, total: 120.97ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 27781241.00sec, total: 27781241.00sec
train2.py:307:<module>, cpu: 121.07ms, accelerator: 0us, total: 121.07ms
  iterator_ops.py:373:get_next, cpu: 120.97ms, accelerator: 0us, total: 120.97ms
train2.py:342:<module>, cpu: 1.94ms, accelerator: 13.43ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_332000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_332250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_332500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_332750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27697813.84sec, total: 27697813.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 120.89ms, accelerator: 0us, total: 120.89ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.86ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 120.89ms, accelerator: 0us, total: 120.89ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 27697813.85sec, total: 27697813.85sec
train2.py:307:<module>, cpu: 121.00ms, accelerator: 0us, total: 121.00ms
  iterator_ops.py:373:get_next, cpu: 120.89ms, accelerator: 0us, total: 120.89ms
train2.py:342:<module>, cpu: 1.94ms, accelerator: 13.43ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.31
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_333000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_333250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_333500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_333750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27614886.25sec, total: 27614886.25sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 120.76ms, accelerator: 0us, total: 120.76ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.85ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 120.76ms, accelerator: 0us, total: 120.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 27614886.26sec, total: 27614886.26sec
train2.py:307:<module>, cpu: 120.86ms, accelerator: 0us, total: 120.86ms
  iterator_ops.py:373:get_next, cpu: 120.76ms, accelerator: 0us, total: 120.76ms
train2.py:342:<module>, cpu: 1.94ms, accelerator: 13.44ms, total: 15.39ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_334000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_334250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_334500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_334750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27532453.75sec, total: 27532453.76sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 120.54ms, accelerator: 0us, total: 120.54ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 120.54ms, accelerator: 0us, total: 120.54ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 27532453.77sec, total: 27532453.77sec
train2.py:307:<module>, cpu: 120.65ms, accelerator: 0us, total: 120.65ms
  iterator_ops.py:373:get_next, cpu: 120.54ms, accelerator: 0us, total: 120.54ms
train2.py:342:<module>, cpu: 1.93ms, accelerator: 13.43ms, total: 15.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_335000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_335250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_335500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_335750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27450511.93sec, total: 27450511.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 120.33ms, accelerator: 0us, total: 120.33ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 120.33ms, accelerator: 0us, total: 120.33ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.72ms, accelerator: 27450511.94sec, total: 27450511.94sec
train2.py:307:<module>, cpu: 120.44ms, accelerator: 0us, total: 120.44ms
  iterator_ops.py:373:get_next, cpu: 120.33ms, accelerator: 0us, total: 120.33ms
train2.py:342:<module>, cpu: 1.93ms, accelerator: 13.43ms, total: 15.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_336000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_336250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_336500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_336750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27369056.40sec, total: 27369056.40sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 120.14ms, accelerator: 0us, total: 120.14ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 120.14ms, accelerator: 0us, total: 120.14ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 27369056.41sec, total: 27369056.42sec
train2.py:307:<module>, cpu: 120.24ms, accelerator: 0us, total: 120.24ms
  iterator_ops.py:373:get_next, cpu: 120.14ms, accelerator: 0us, total: 120.14ms
train2.py:342:<module>, cpu: 1.93ms, accelerator: 13.43ms, total: 15.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_337000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_337250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_337500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_337750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27288082.86sec, total: 27288082.86sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 120.04ms, accelerator: 0us, total: 120.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 120.04ms, accelerator: 0us, total: 120.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 27288082.87sec, total: 27288082.88sec
train2.py:307:<module>, cpu: 120.14ms, accelerator: 0us, total: 120.14ms
  iterator_ops.py:373:get_next, cpu: 120.04ms, accelerator: 0us, total: 120.04ms
train2.py:342:<module>, cpu: 1.93ms, accelerator: 13.43ms, total: 15.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.29
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_338000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_338250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_338500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_338750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27207587.04sec, total: 27207587.04sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 119.91ms, accelerator: 0us, total: 119.91ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 119.91ms, accelerator: 0us, total: 119.91ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 27207587.05sec, total: 27207587.06sec
train2.py:307:<module>, cpu: 120.02ms, accelerator: 0us, total: 120.02ms
  iterator_ops.py:373:get_next, cpu: 119.91ms, accelerator: 0us, total: 119.91ms
train2.py:342:<module>, cpu: 1.92ms, accelerator: 13.44ms, total: 15.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_339000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_339250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_339500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_339750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27127564.73sec, total: 27127564.73sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 119.75ms, accelerator: 0us, total: 119.75ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 119.75ms, accelerator: 0us, total: 119.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 27127564.74sec, total: 27127564.74sec
train2.py:307:<module>, cpu: 119.85ms, accelerator: 0us, total: 119.85ms
  iterator_ops.py:373:get_next, cpu: 119.75ms, accelerator: 0us, total: 119.75ms
train2.py:342:<module>, cpu: 1.92ms, accelerator: 13.44ms, total: 15.38ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_340000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_340250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_340500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_340750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 27048011.75sec, total: 27048011.75sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 119.56ms, accelerator: 0us, total: 119.56ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 119.56ms, accelerator: 0us, total: 119.56ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 27048011.76sec, total: 27048011.77sec
train2.py:307:<module>, cpu: 119.66ms, accelerator: 0us, total: 119.66ms
  iterator_ops.py:373:get_next, cpu: 119.56ms, accelerator: 0us, total: 119.56ms
train2.py:342:<module>, cpu: 1.92ms, accelerator: 13.43ms, total: 15.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_341000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_341250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_341500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_341750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26968924.00sec, total: 26968924.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 119.34ms, accelerator: 0us, total: 119.34ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 119.34ms, accelerator: 0us, total: 119.34ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 26968924.01sec, total: 26968924.01sec
train2.py:307:<module>, cpu: 119.44ms, accelerator: 0us, total: 119.44ms
  iterator_ops.py:373:get_next, cpu: 119.34ms, accelerator: 0us, total: 119.34ms
train2.py:342:<module>, cpu: 1.92ms, accelerator: 13.43ms, total: 15.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_342000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_342250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_342500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_342750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26890297.40sec, total: 26890297.40sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 119.18ms, accelerator: 0us, total: 119.18ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 119.18ms, accelerator: 0us, total: 119.18ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 26890297.41sec, total: 26890297.41sec
train2.py:307:<module>, cpu: 119.28ms, accelerator: 0us, total: 119.28ms
  iterator_ops.py:373:get_next, cpu: 119.18ms, accelerator: 0us, total: 119.18ms
train2.py:342:<module>, cpu: 1.92ms, accelerator: 13.43ms, total: 15.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_343000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_343250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_343500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_343750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26812127.93sec, total: 26812127.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 119.00ms, accelerator: 0us, total: 119.00ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 119.00ms, accelerator: 0us, total: 119.00ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 26812127.94sec, total: 26812127.94sec
train2.py:307:<module>, cpu: 119.10ms, accelerator: 0us, total: 119.10ms
  iterator_ops.py:373:get_next, cpu: 119.00ms, accelerator: 0us, total: 119.00ms
train2.py:342:<module>, cpu: 1.92ms, accelerator: 13.43ms, total: 15.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.32
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_344000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_344250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_344500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_344750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26734411.62sec, total: 26734411.62sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 118.90ms, accelerator: 0us, total: 118.90ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 118.90ms, accelerator: 0us, total: 118.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 26734411.63sec, total: 26734411.63sec
train2.py:307:<module>, cpu: 119.00ms, accelerator: 0us, total: 119.00ms
  iterator_ops.py:373:get_next, cpu: 118.90ms, accelerator: 0us, total: 118.90ms
train2.py:342:<module>, cpu: 1.92ms, accelerator: 13.43ms, total: 15.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.29
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_345000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_345250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_345500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_345750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26657144.53sec, total: 26657144.53sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 118.78ms, accelerator: 0us, total: 118.78ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 118.78ms, accelerator: 0us, total: 118.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 26657144.54sec, total: 26657144.55sec
train2.py:307:<module>, cpu: 118.88ms, accelerator: 0us, total: 118.88ms
  iterator_ops.py:373:get_next, cpu: 118.78ms, accelerator: 0us, total: 118.78ms
train2.py:342:<module>, cpu: 1.91ms, accelerator: 13.43ms, total: 15.37ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_346000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_346250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_346500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_346750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26580322.79sec, total: 26580322.79sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 118.61ms, accelerator: 0us, total: 118.61ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.89ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 118.61ms, accelerator: 0us, total: 118.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 26580322.80sec, total: 26580322.80sec
train2.py:307:<module>, cpu: 118.71ms, accelerator: 0us, total: 118.71ms
  iterator_ops.py:373:get_next, cpu: 118.61ms, accelerator: 0us, total: 118.61ms
train2.py:342:<module>, cpu: 1.91ms, accelerator: 13.42ms, total: 15.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_347000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_347250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_347500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_347750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26503942.55sec, total: 26503942.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 118.47ms, accelerator: 0us, total: 118.47ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.89ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 118.47ms, accelerator: 0us, total: 118.47ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 26503942.56sec, total: 26503942.57sec
train2.py:307:<module>, cpu: 118.57ms, accelerator: 0us, total: 118.57ms
  iterator_ops.py:373:get_next, cpu: 118.47ms, accelerator: 0us, total: 118.47ms
train2.py:342:<module>, cpu: 1.91ms, accelerator: 13.43ms, total: 15.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_348000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_348250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_348500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_348750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26428000.02sec, total: 26428000.02sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 118.33ms, accelerator: 0us, total: 118.33ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.89ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 118.33ms, accelerator: 0us, total: 118.33ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 26428000.03sec, total: 26428000.04sec
train2.py:307:<module>, cpu: 118.43ms, accelerator: 0us, total: 118.43ms
  iterator_ops.py:373:get_next, cpu: 118.33ms, accelerator: 0us, total: 118.33ms
train2.py:342:<module>, cpu: 1.91ms, accelerator: 13.43ms, total: 15.36ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_349000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_349250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_349500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_349750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26352491.45sec, total: 26352491.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 118.14ms, accelerator: 0us, total: 118.14ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.89ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 118.14ms, accelerator: 0us, total: 118.14ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.71ms, accelerator: 26352491.46sec, total: 26352491.46sec
train2.py:307:<module>, cpu: 118.24ms, accelerator: 0us, total: 118.24ms
  iterator_ops.py:373:get_next, cpu: 118.14ms, accelerator: 0us, total: 118.14ms
train2.py:342:<module>, cpu: 1.91ms, accelerator: 13.43ms, total: 15.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_350000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_350250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_350500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_350750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26277413.13sec, total: 26277413.13sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 117.95ms, accelerator: 0us, total: 117.95ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 117.95ms, accelerator: 0us, total: 117.95ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 26277413.14sec, total: 26277413.14sec
train2.py:307:<module>, cpu: 118.05ms, accelerator: 0us, total: 118.05ms
  iterator_ops.py:373:get_next, cpu: 117.95ms, accelerator: 0us, total: 117.95ms
train2.py:342:<module>, cpu: 1.91ms, accelerator: 13.43ms, total: 15.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.57
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_351000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_351250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_351500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_351750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26202761.39sec, total: 26202761.39sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 117.76ms, accelerator: 0us, total: 117.76ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.04ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 117.76ms, accelerator: 0us, total: 117.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 26202761.40sec, total: 26202761.40sec
train2.py:307:<module>, cpu: 117.86ms, accelerator: 0us, total: 117.86ms
  iterator_ops.py:373:get_next, cpu: 117.76ms, accelerator: 0us, total: 117.76ms
train2.py:342:<module>, cpu: 1.91ms, accelerator: 13.43ms, total: 15.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_352000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_352250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_352500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_352750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26128532.60sec, total: 26128532.60sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 117.62ms, accelerator: 0us, total: 117.62ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 117.62ms, accelerator: 0us, total: 117.62ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 26128532.61sec, total: 26128532.61sec
train2.py:307:<module>, cpu: 117.72ms, accelerator: 0us, total: 117.72ms
  iterator_ops.py:373:get_next, cpu: 117.62ms, accelerator: 0us, total: 117.62ms
train2.py:342:<module>, cpu: 1.90ms, accelerator: 13.43ms, total: 15.35ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_353000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_353250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_353500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_353750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 26054723.19sec, total: 26054723.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 117.55ms, accelerator: 0us, total: 117.55ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 117.55ms, accelerator: 0us, total: 117.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 26054723.20sec, total: 26054723.20sec
train2.py:307:<module>, cpu: 117.65ms, accelerator: 0us, total: 117.65ms
  iterator_ops.py:373:get_next, cpu: 117.55ms, accelerator: 0us, total: 117.55ms
train2.py:342:<module>, cpu: 1.90ms, accelerator: 13.44ms, total: 15.36ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.31
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_354000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_354250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_354500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_354750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 25981329.60sec, total: 25981329.60sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 117.43ms, accelerator: 0us, total: 117.43ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 117.43ms, accelerator: 0us, total: 117.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25981329.61sec, total: 25981329.61sec
train2.py:307:<module>, cpu: 117.53ms, accelerator: 0us, total: 117.53ms
  iterator_ops.py:373:get_next, cpu: 117.43ms, accelerator: 0us, total: 117.43ms
train2.py:342:<module>, cpu: 1.90ms, accelerator: 13.43ms, total: 15.35ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_355000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_355250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_355500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_355750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 25908348.34sec, total: 25908348.34sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 117.27ms, accelerator: 0us, total: 117.27ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 117.27ms, accelerator: 0us, total: 117.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25908348.35sec, total: 25908348.35sec
train2.py:307:<module>, cpu: 117.37ms, accelerator: 0us, total: 117.37ms
  iterator_ops.py:373:get_next, cpu: 117.27ms, accelerator: 0us, total: 117.27ms
train2.py:342:<module>, cpu: 1.90ms, accelerator: 13.43ms, total: 15.35ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_356000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_356250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_356500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_356750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 25835775.93sec, total: 25835775.93sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 117.15ms, accelerator: 0us, total: 117.15ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 117.15ms, accelerator: 0us, total: 117.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25835775.94sec, total: 25835775.95sec
train2.py:307:<module>, cpu: 117.25ms, accelerator: 0us, total: 117.25ms
  iterator_ops.py:373:get_next, cpu: 117.15ms, accelerator: 0us, total: 117.15ms
train2.py:342:<module>, cpu: 1.90ms, accelerator: 13.43ms, total: 15.35ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_357000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_357250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_357500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_357750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 25763608.96sec, total: 25763608.96sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.98ms, accelerator: 0us, total: 116.98ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.98ms, accelerator: 0us, total: 116.98ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25763608.97sec, total: 25763608.97sec
train2.py:307:<module>, cpu: 117.08ms, accelerator: 0us, total: 117.08ms
  iterator_ops.py:373:get_next, cpu: 116.98ms, accelerator: 0us, total: 116.98ms
train2.py:342:<module>, cpu: 1.90ms, accelerator: 13.43ms, total: 15.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_358000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_358250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_358500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_358750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.02ms, accelerator: 25691844.03sec, total: 25691844.03sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.80ms, accelerator: 0us, total: 116.80ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.80ms, accelerator: 0us, total: 116.80ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25691844.04sec, total: 25691844.05sec
train2.py:307:<module>, cpu: 116.90ms, accelerator: 0us, total: 116.90ms
  iterator_ops.py:373:get_next, cpu: 116.80ms, accelerator: 0us, total: 116.80ms
train2.py:342:<module>, cpu: 1.90ms, accelerator: 13.43ms, total: 15.35ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_359000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_359250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_359500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_359750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 25620477.80sec, total: 25620477.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.63ms, accelerator: 0us, total: 116.63ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.89ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.63ms, accelerator: 0us, total: 116.63ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25620477.81sec, total: 25620477.81sec
train2.py:307:<module>, cpu: 116.73ms, accelerator: 0us, total: 116.73ms
  iterator_ops.py:373:get_next, cpu: 116.63ms, accelerator: 0us, total: 116.63ms
train2.py:342:<module>, cpu: 1.90ms, accelerator: 13.42ms, total: 15.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_360000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_360250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_360500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_360750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 25549506.95sec, total: 25549506.95sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.48ms, accelerator: 0us, total: 116.48ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.95ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.48ms, accelerator: 0us, total: 116.48ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25549506.96sec, total: 25549506.96sec
train2.py:307:<module>, cpu: 116.58ms, accelerator: 0us, total: 116.58ms
  iterator_ops.py:373:get_next, cpu: 116.48ms, accelerator: 0us, total: 116.48ms
train2.py:342:<module>, cpu: 1.89ms, accelerator: 13.42ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_361000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_361250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_361500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_361750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 25478928.20sec, total: 25478928.20sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.31ms, accelerator: 0us, total: 116.31ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.95ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.31ms, accelerator: 0us, total: 116.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25478928.21sec, total: 25478928.21sec
train2.py:307:<module>, cpu: 116.41ms, accelerator: 0us, total: 116.41ms
  iterator_ops.py:373:get_next, cpu: 116.31ms, accelerator: 0us, total: 116.31ms
train2.py:342:<module>, cpu: 1.89ms, accelerator: 13.42ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_362000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_362250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_362500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_362750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 25408738.31sec, total: 25408738.31sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.19ms, accelerator: 0us, total: 116.19ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.89ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.19ms, accelerator: 0us, total: 116.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25408738.33sec, total: 25408738.33sec
train2.py:307:<module>, cpu: 116.29ms, accelerator: 0us, total: 116.29ms
  iterator_ops.py:373:get_next, cpu: 116.19ms, accelerator: 0us, total: 116.19ms
train2.py:342:<module>, cpu: 1.89ms, accelerator: 13.42ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_363000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_363250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_363500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_363750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 25338934.09sec, total: 25338934.09sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.06ms, accelerator: 0us, total: 116.06ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.06ms, accelerator: 0us, total: 116.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25338934.10sec, total: 25338934.10sec
train2.py:307:<module>, cpu: 116.16ms, accelerator: 0us, total: 116.16ms
  iterator_ops.py:373:get_next, cpu: 116.06ms, accelerator: 0us, total: 116.06ms
train2.py:342:<module>, cpu: 1.89ms, accelerator: 13.42ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_364000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_364250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_364500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_364750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 25269512.35sec, total: 25269512.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.92ms, accelerator: 0us, total: 115.92ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.92ms, accelerator: 0us, total: 115.92ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25269512.36sec, total: 25269512.36sec
train2.py:307:<module>, cpu: 116.02ms, accelerator: 0us, total: 116.02ms
  iterator_ops.py:373:get_next, cpu: 115.92ms, accelerator: 0us, total: 115.92ms
train2.py:342:<module>, cpu: 1.89ms, accelerator: 13.42ms, total: 15.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_365000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_365250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_365500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_365750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 25200469.97sec, total: 25200469.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.73ms, accelerator: 0us, total: 115.73ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.95ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.73ms, accelerator: 0us, total: 115.73ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.70ms, accelerator: 25200469.98sec, total: 25200469.98sec
train2.py:307:<module>, cpu: 115.83ms, accelerator: 0us, total: 115.83ms
  iterator_ops.py:373:get_next, cpu: 115.73ms, accelerator: 0us, total: 115.73ms
train2.py:342:<module>, cpu: 1.89ms, accelerator: 13.42ms, total: 15.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_366000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_366250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_366500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_366750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 25131803.84sec, total: 25131803.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.60ms, accelerator: 0us, total: 115.60ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.89ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.60ms, accelerator: 0us, total: 115.60ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 25131803.85sec, total: 25131803.85sec
train2.py:307:<module>, cpu: 115.70ms, accelerator: 0us, total: 115.70ms
  iterator_ops.py:373:get_next, cpu: 115.60ms, accelerator: 0us, total: 115.60ms
train2.py:342:<module>, cpu: 1.88ms, accelerator: 13.42ms, total: 15.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_367000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_367250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_367500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_367750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 25063510.89sec, total: 25063510.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.46ms, accelerator: 0us, total: 115.46ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.89ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.46ms, accelerator: 0us, total: 115.46ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 25063510.90sec, total: 25063510.91sec
train2.py:307:<module>, cpu: 115.55ms, accelerator: 0us, total: 115.55ms
  iterator_ops.py:373:get_next, cpu: 115.46ms, accelerator: 0us, total: 115.46ms
train2.py:342:<module>, cpu: 1.88ms, accelerator: 13.42ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_368000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_368250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_368500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_368750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24995588.10sec, total: 24995588.10sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.30ms, accelerator: 0us, total: 115.30ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.30ms, accelerator: 0us, total: 115.30ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24995588.11sec, total: 24995588.11sec
train2.py:307:<module>, cpu: 115.39ms, accelerator: 0us, total: 115.39ms
  iterator_ops.py:373:get_next, cpu: 115.30ms, accelerator: 0us, total: 115.30ms
train2.py:342:<module>, cpu: 1.88ms, accelerator: 13.43ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_369000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_369250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_369500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_369750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24928032.45sec, total: 24928032.45sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.17ms, accelerator: 0us, total: 115.17ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.17ms, accelerator: 0us, total: 115.17ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24928032.47sec, total: 24928032.47sec
train2.py:307:<module>, cpu: 115.26ms, accelerator: 0us, total: 115.26ms
  iterator_ops.py:373:get_next, cpu: 115.17ms, accelerator: 0us, total: 115.17ms
train2.py:342:<module>, cpu: 1.88ms, accelerator: 13.43ms, total: 15.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_370000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_370250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_370500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_370750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24860840.99sec, total: 24860840.99sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.00ms, accelerator: 0us, total: 115.00ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.00ms, accelerator: 0us, total: 115.00ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24860841.00sec, total: 24860841.01sec
train2.py:307:<module>, cpu: 115.09ms, accelerator: 0us, total: 115.09ms
  iterator_ops.py:373:get_next, cpu: 115.00ms, accelerator: 0us, total: 115.00ms
train2.py:342:<module>, cpu: 1.88ms, accelerator: 13.43ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_371000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_371250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_371500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_371750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24794010.77sec, total: 24794010.78sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.83ms, accelerator: 0us, total: 114.83ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.83ms, accelerator: 0us, total: 114.83ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24794010.79sec, total: 24794010.79sec
train2.py:307:<module>, cpu: 114.92ms, accelerator: 0us, total: 114.92ms
  iterator_ops.py:373:get_next, cpu: 114.83ms, accelerator: 0us, total: 114.83ms
train2.py:342:<module>, cpu: 1.88ms, accelerator: 13.43ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.56
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_372000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_372250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_372500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_372750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24727538.90sec, total: 24727538.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.68ms, accelerator: 0us, total: 114.68ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.68ms, accelerator: 0us, total: 114.68ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24727538.91sec, total: 24727538.91sec
train2.py:307:<module>, cpu: 114.77ms, accelerator: 0us, total: 114.77ms
  iterator_ops.py:373:get_next, cpu: 114.68ms, accelerator: 0us, total: 114.68ms
train2.py:342:<module>, cpu: 1.88ms, accelerator: 13.43ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_373000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_373250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_373500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_373750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24661422.48sec, total: 24661422.48sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 117.13ms, accelerator: 0us, total: 117.13ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 117.13ms, accelerator: 0us, total: 117.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24661422.49sec, total: 24661422.50sec
train2.py:307:<module>, cpu: 117.23ms, accelerator: 0us, total: 117.23ms
  iterator_ops.py:373:get_next, cpu: 117.13ms, accelerator: 0us, total: 117.13ms
train2.py:342:<module>, cpu: 1.88ms, accelerator: 13.43ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_374000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_374250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_374500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_374750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24595658.69sec, total: 24595658.69sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.99ms, accelerator: 0us, total: 116.99ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.99ms, accelerator: 0us, total: 116.99ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24595658.70sec, total: 24595658.70sec
train2.py:307:<module>, cpu: 117.09ms, accelerator: 0us, total: 117.09ms
  iterator_ops.py:373:get_next, cpu: 116.99ms, accelerator: 0us, total: 116.99ms
train2.py:342:<module>, cpu: 1.88ms, accelerator: 13.44ms, total: 15.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_375000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_375250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_375500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_375750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24530244.70sec, total: 24530244.70sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.81ms, accelerator: 0us, total: 116.81ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.81ms, accelerator: 0us, total: 116.81ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24530244.71sec, total: 24530244.72sec
train2.py:307:<module>, cpu: 116.91ms, accelerator: 0us, total: 116.91ms
  iterator_ops.py:373:get_next, cpu: 116.81ms, accelerator: 0us, total: 116.81ms
train2.py:342:<module>, cpu: 1.87ms, accelerator: 13.44ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_376000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_376250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_376500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_376750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24465177.74sec, total: 24465177.74sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.68ms, accelerator: 0us, total: 116.68ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.68ms, accelerator: 0us, total: 116.68ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24465177.75sec, total: 24465177.75sec
train2.py:307:<module>, cpu: 116.77ms, accelerator: 0us, total: 116.77ms
  iterator_ops.py:373:get_next, cpu: 116.68ms, accelerator: 0us, total: 116.68ms
train2.py:342:<module>, cpu: 1.87ms, accelerator: 13.44ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_377000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_377250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_377500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_377750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24400455.05sec, total: 24400455.05sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.53ms, accelerator: 0us, total: 116.53ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.53ms, accelerator: 0us, total: 116.53ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24400455.06sec, total: 24400455.06sec
train2.py:307:<module>, cpu: 116.63ms, accelerator: 0us, total: 116.63ms
  iterator_ops.py:373:get_next, cpu: 116.53ms, accelerator: 0us, total: 116.53ms
train2.py:342:<module>, cpu: 1.87ms, accelerator: 13.44ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_378000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_378250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_378500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_378750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24336073.90sec, total: 24336073.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.53ms, accelerator: 0us, total: 116.53ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.53ms, accelerator: 0us, total: 116.53ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24336073.91sec, total: 24336073.91sec
train2.py:307:<module>, cpu: 116.62ms, accelerator: 0us, total: 116.62ms
  iterator_ops.py:373:get_next, cpu: 116.53ms, accelerator: 0us, total: 116.53ms
train2.py:342:<module>, cpu: 1.87ms, accelerator: 13.44ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_379000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_379250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_379500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_379750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24272031.60sec, total: 24272031.60sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.44ms, accelerator: 0us, total: 116.44ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.44ms, accelerator: 0us, total: 116.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.69ms, accelerator: 24272031.61sec, total: 24272031.61sec
train2.py:307:<module>, cpu: 116.53ms, accelerator: 0us, total: 116.53ms
  iterator_ops.py:373:get_next, cpu: 116.44ms, accelerator: 0us, total: 116.44ms
train2.py:342:<module>, cpu: 1.87ms, accelerator: 13.44ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_380000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_380250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_380500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_380750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24208325.48sec, total: 24208325.48sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.31ms, accelerator: 0us, total: 116.31ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.31ms, accelerator: 0us, total: 116.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 24208325.49sec, total: 24208325.49sec
train2.py:307:<module>, cpu: 116.41ms, accelerator: 0us, total: 116.41ms
  iterator_ops.py:373:get_next, cpu: 116.31ms, accelerator: 0us, total: 116.31ms
train2.py:342:<module>, cpu: 1.87ms, accelerator: 13.44ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_381000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_381250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_381500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_381750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24144952.90sec, total: 24144952.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 116.15ms, accelerator: 0us, total: 116.15ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 116.15ms, accelerator: 0us, total: 116.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 24144952.91sec, total: 24144952.91sec
train2.py:307:<module>, cpu: 116.25ms, accelerator: 0us, total: 116.25ms
  iterator_ops.py:373:get_next, cpu: 116.15ms, accelerator: 0us, total: 116.15ms
train2.py:342:<module>, cpu: 1.87ms, accelerator: 13.44ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_382000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_382250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_382500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_382750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24081911.25sec, total: 24081911.25sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.96ms, accelerator: 0us, total: 115.96ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.96ms, accelerator: 0us, total: 115.96ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 24081911.26sec, total: 24081911.26sec
train2.py:307:<module>, cpu: 116.06ms, accelerator: 0us, total: 116.06ms
  iterator_ops.py:373:get_next, cpu: 115.96ms, accelerator: 0us, total: 115.96ms
train2.py:342:<module>, cpu: 1.86ms, accelerator: 13.44ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_383000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_383250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_383500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_383750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 24019197.94sec, total: 24019197.94sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.84ms, accelerator: 0us, total: 115.84ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.84ms, accelerator: 0us, total: 115.84ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 24019197.95sec, total: 24019197.95sec
train2.py:307:<module>, cpu: 115.93ms, accelerator: 0us, total: 115.93ms
  iterator_ops.py:373:get_next, cpu: 115.84ms, accelerator: 0us, total: 115.84ms
train2.py:342:<module>, cpu: 1.86ms, accelerator: 13.45ms, total: 15.33ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_384000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_384250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_384500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_384750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23956810.41sec, total: 23956810.41sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.78ms, accelerator: 0us, total: 115.78ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.78ms, accelerator: 0us, total: 115.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23956810.42sec, total: 23956810.42sec
train2.py:307:<module>, cpu: 115.87ms, accelerator: 0us, total: 115.87ms
  iterator_ops.py:373:get_next, cpu: 115.78ms, accelerator: 0us, total: 115.78ms
train2.py:342:<module>, cpu: 1.86ms, accelerator: 13.45ms, total: 15.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_385000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_385250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_385500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_385750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23894746.14sec, total: 23894746.14sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.62ms, accelerator: 0us, total: 115.62ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.83ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.62ms, accelerator: 0us, total: 115.62ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23894746.15sec, total: 23894746.15sec
train2.py:307:<module>, cpu: 115.72ms, accelerator: 0us, total: 115.72ms
  iterator_ops.py:373:get_next, cpu: 115.62ms, accelerator: 0us, total: 115.62ms
train2.py:342:<module>, cpu: 1.86ms, accelerator: 13.46ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_386000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_386250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_386500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_386750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23833002.60sec, total: 23833002.61sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.52ms, accelerator: 0us, total: 115.52ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.52ms, accelerator: 0us, total: 115.52ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23833002.62sec, total: 23833002.62sec
train2.py:307:<module>, cpu: 115.61ms, accelerator: 0us, total: 115.61ms
  iterator_ops.py:373:get_next, cpu: 115.52ms, accelerator: 0us, total: 115.52ms
train2.py:342:<module>, cpu: 1.86ms, accelerator: 13.45ms, total: 15.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_387000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_387250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_387500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_387750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23771577.34sec, total: 23771577.34sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.35ms, accelerator: 0us, total: 115.35ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.83ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.35ms, accelerator: 0us, total: 115.35ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23771577.35sec, total: 23771577.35sec
train2.py:307:<module>, cpu: 115.44ms, accelerator: 0us, total: 115.44ms
  iterator_ops.py:373:get_next, cpu: 115.35ms, accelerator: 0us, total: 115.35ms
train2.py:342:<module>, cpu: 1.86ms, accelerator: 13.45ms, total: 15.34ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_388000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_388250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_388500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_388750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23710467.89sec, total: 23710467.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.20ms, accelerator: 0us, total: 115.20ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.83ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.20ms, accelerator: 0us, total: 115.20ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23710467.90sec, total: 23710467.90sec
train2.py:307:<module>, cpu: 115.30ms, accelerator: 0us, total: 115.30ms
  iterator_ops.py:373:get_next, cpu: 115.20ms, accelerator: 0us, total: 115.20ms
train2.py:342:<module>, cpu: 1.86ms, accelerator: 13.46ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_389000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_389250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_389500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_389750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23649671.82sec, total: 23649671.82sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 115.04ms, accelerator: 0us, total: 115.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 115.04ms, accelerator: 0us, total: 115.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23649671.83sec, total: 23649671.83sec
train2.py:307:<module>, cpu: 115.13ms, accelerator: 0us, total: 115.13ms
  iterator_ops.py:373:get_next, cpu: 115.04ms, accelerator: 0us, total: 115.04ms
train2.py:342:<module>, cpu: 1.86ms, accelerator: 13.45ms, total: 15.33ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_390000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_390250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_390500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_390750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23589186.72sec, total: 23589186.72sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.89ms, accelerator: 0us, total: 114.89ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.89ms, accelerator: 0us, total: 114.89ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23589186.73sec, total: 23589186.74sec
train2.py:307:<module>, cpu: 114.98ms, accelerator: 0us, total: 114.98ms
  iterator_ops.py:373:get_next, cpu: 114.89ms, accelerator: 0us, total: 114.89ms
train2.py:342:<module>, cpu: 1.86ms, accelerator: 13.45ms, total: 15.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_391000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_391250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_391500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_391750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23529010.22sec, total: 23529010.23sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.72ms, accelerator: 0us, total: 114.72ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.72ms, accelerator: 0us, total: 114.72ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23529010.24sec, total: 23529010.24sec
train2.py:307:<module>, cpu: 114.82ms, accelerator: 0us, total: 114.82ms
  iterator_ops.py:373:get_next, cpu: 114.72ms, accelerator: 0us, total: 114.72ms
train2.py:342:<module>, cpu: 1.86ms, accelerator: 13.45ms, total: 15.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_392000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_392250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_392500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_392750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23469139.97sec, total: 23469139.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.55ms, accelerator: 0us, total: 114.55ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.79ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.55ms, accelerator: 0us, total: 114.55ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23469139.98sec, total: 23469139.98sec
train2.py:307:<module>, cpu: 114.64ms, accelerator: 0us, total: 114.64ms
  iterator_ops.py:373:get_next, cpu: 114.55ms, accelerator: 0us, total: 114.55ms
train2.py:342:<module>, cpu: 1.85ms, accelerator: 13.45ms, total: 15.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_393000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_393250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_393500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_393750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23409573.62sec, total: 23409573.63sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.42ms, accelerator: 0us, total: 114.42ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.42ms, accelerator: 0us, total: 114.42ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23409573.64sec, total: 23409573.64sec
train2.py:307:<module>, cpu: 114.51ms, accelerator: 0us, total: 114.51ms
  iterator_ops.py:373:get_next, cpu: 114.42ms, accelerator: 0us, total: 114.42ms
train2.py:342:<module>, cpu: 1.85ms, accelerator: 13.45ms, total: 15.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_394000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_394250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_394500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_394750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23350308.88sec, total: 23350308.88sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.27ms, accelerator: 0us, total: 114.27ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.27ms, accelerator: 0us, total: 114.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23350308.89sec, total: 23350308.90sec
train2.py:307:<module>, cpu: 114.36ms, accelerator: 0us, total: 114.36ms
  iterator_ops.py:373:get_next, cpu: 114.27ms, accelerator: 0us, total: 114.27ms
train2.py:342:<module>, cpu: 1.85ms, accelerator: 13.45ms, total: 15.32ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_395000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_395250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_395500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_395750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.01ms, accelerator: 23291343.46sec, total: 23291343.46sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.13ms, accelerator: 0us, total: 114.13ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.13ms, accelerator: 0us, total: 114.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23291343.47sec, total: 23291343.47sec
train2.py:307:<module>, cpu: 114.22ms, accelerator: 0us, total: 114.22ms
  iterator_ops.py:373:get_next, cpu: 114.13ms, accelerator: 0us, total: 114.13ms
train2.py:342:<module>, cpu: 1.85ms, accelerator: 13.44ms, total: 15.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_396000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_396250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_396500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_396750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 23232675.08sec, total: 23232675.08sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.09ms, accelerator: 0us, total: 114.09ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.09ms, accelerator: 0us, total: 114.09ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 23232675.10sec, total: 23232675.10sec
train2.py:307:<module>, cpu: 114.18ms, accelerator: 0us, total: 114.18ms
  iterator_ops.py:373:get_next, cpu: 114.09ms, accelerator: 0us, total: 114.09ms
train2.py:342:<module>, cpu: 1.85ms, accelerator: 13.44ms, total: 15.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_397000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_397250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_397500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_397750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 34761452.27sec, total: 34761452.27sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 114.04ms, accelerator: 0us, total: 114.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 114.04ms, accelerator: 0us, total: 114.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 34761452.28sec, total: 34761452.29sec
train2.py:307:<module>, cpu: 114.13ms, accelerator: 0us, total: 114.13ms
  iterator_ops.py:373:get_next, cpu: 114.04ms, accelerator: 0us, total: 114.04ms
train2.py:342:<module>, cpu: 1.85ms, accelerator: 13.44ms, total: 15.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_398000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_398250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_398500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_398750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 34674330.84sec, total: 34674330.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.86ms, accelerator: 0us, total: 113.86ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.86ms, accelerator: 0us, total: 113.86ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 34674330.85sec, total: 34674330.85sec
train2.py:307:<module>, cpu: 113.95ms, accelerator: 0us, total: 113.95ms
  iterator_ops.py:373:get_next, cpu: 113.86ms, accelerator: 0us, total: 113.86ms
train2.py:342:<module>, cpu: 1.85ms, accelerator: 13.44ms, total: 15.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_399000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_399250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_399500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_399750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.30

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 34587645.01sec, total: 34587645.01sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.78ms, accelerator: 0us, total: 113.78ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.78ms, accelerator: 0us, total: 113.78ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 34587645.02sec, total: 34587645.03sec
train2.py:307:<module>, cpu: 113.87ms, accelerator: 0us, total: 113.87ms
  iterator_ops.py:373:get_next, cpu: 113.78ms, accelerator: 0us, total: 113.78ms
train2.py:342:<module>, cpu: 1.85ms, accelerator: 13.45ms, total: 15.31ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_400000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_400250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_400500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_400750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 34501391.53sec, total: 34501391.53sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.65ms, accelerator: 0us, total: 113.65ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.65ms, accelerator: 0us, total: 113.65ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 34501391.54sec, total: 34501391.55sec
train2.py:307:<module>, cpu: 113.74ms, accelerator: 0us, total: 113.74ms
  iterator_ops.py:373:get_next, cpu: 113.65ms, accelerator: 0us, total: 113.65ms
train2.py:342:<module>, cpu: 1.84ms, accelerator: 13.45ms, total: 15.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_401000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_401250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_401500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_401750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 34415567.18sec, total: 34415567.18sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.49ms, accelerator: 0us, total: 113.49ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.49ms, accelerator: 0us, total: 113.49ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 34415567.19sec, total: 34415567.19sec
train2.py:307:<module>, cpu: 113.58ms, accelerator: 0us, total: 113.58ms
  iterator_ops.py:373:get_next, cpu: 113.49ms, accelerator: 0us, total: 113.49ms
train2.py:342:<module>, cpu: 1.84ms, accelerator: 13.44ms, total: 15.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_402000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_402250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_402500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_402750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 34330168.75sec, total: 34330168.75sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.36ms, accelerator: 0us, total: 113.36ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.36ms, accelerator: 0us, total: 113.36ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.68ms, accelerator: 34330168.76sec, total: 34330168.76sec
train2.py:307:<module>, cpu: 113.45ms, accelerator: 0us, total: 113.45ms
  iterator_ops.py:373:get_next, cpu: 113.36ms, accelerator: 0us, total: 113.36ms
train2.py:342:<module>, cpu: 1.84ms, accelerator: 13.44ms, total: 15.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_403000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_403250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_403500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_403750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 34245193.08sec, total: 34245193.08sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.25ms, accelerator: 0us, total: 113.25ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.25ms, accelerator: 0us, total: 113.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 34245193.09sec, total: 34245193.09sec
train2.py:307:<module>, cpu: 113.34ms, accelerator: 0us, total: 113.34ms
  iterator_ops.py:373:get_next, cpu: 113.25ms, accelerator: 0us, total: 113.25ms
train2.py:342:<module>, cpu: 1.84ms, accelerator: 13.44ms, total: 15.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_404000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_404250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_404500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_404750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 34160637.05sec, total: 34160637.05sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 113.10ms, accelerator: 0us, total: 113.10ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 113.10ms, accelerator: 0us, total: 113.10ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 34160637.06sec, total: 34160637.06sec
train2.py:307:<module>, cpu: 113.19ms, accelerator: 0us, total: 113.19ms
  iterator_ops.py:373:get_next, cpu: 113.10ms, accelerator: 0us, total: 113.10ms
train2.py:342:<module>, cpu: 1.84ms, accelerator: 13.45ms, total: 15.31ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_405000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_405250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_405500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_405750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 34076497.55sec, total: 34076497.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.99ms, accelerator: 0us, total: 112.99ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.99ms, accelerator: 0us, total: 112.99ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 34076497.56sec, total: 34076497.56sec
train2.py:307:<module>, cpu: 113.08ms, accelerator: 0us, total: 113.08ms
  iterator_ops.py:373:get_next, cpu: 112.99ms, accelerator: 0us, total: 112.99ms
train2.py:342:<module>, cpu: 1.84ms, accelerator: 13.45ms, total: 15.31ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_406000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_406250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_406500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_406750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33992771.51sec, total: 33992771.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.90ms, accelerator: 0us, total: 112.90ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.90ms, accelerator: 0us, total: 112.90ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33992771.52sec, total: 33992771.52sec
train2.py:307:<module>, cpu: 112.99ms, accelerator: 0us, total: 112.99ms
  iterator_ops.py:373:get_next, cpu: 112.90ms, accelerator: 0us, total: 112.90ms
train2.py:342:<module>, cpu: 1.84ms, accelerator: 13.45ms, total: 15.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_407000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_407250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_407500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_407750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33909455.89sec, total: 33909455.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.76ms, accelerator: 0us, total: 112.76ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.76ms, accelerator: 0us, total: 112.76ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33909455.91sec, total: 33909455.91sec
train2.py:307:<module>, cpu: 112.84ms, accelerator: 0us, total: 112.84ms
  iterator_ops.py:373:get_next, cpu: 112.76ms, accelerator: 0us, total: 112.76ms
train2.py:342:<module>, cpu: 1.84ms, accelerator: 13.45ms, total: 15.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_408000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_408250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_408500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_408750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33826547.69sec, total: 33826547.69sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.61ms, accelerator: 0us, total: 112.61ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.61ms, accelerator: 0us, total: 112.61ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33826547.70sec, total: 33826547.70sec
train2.py:307:<module>, cpu: 112.70ms, accelerator: 0us, total: 112.70ms
  iterator_ops.py:373:get_next, cpu: 112.61ms, accelerator: 0us, total: 112.61ms
train2.py:342:<module>, cpu: 1.83ms, accelerator: 13.44ms, total: 15.30ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_409000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_409250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_409500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_409750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33744043.91sec, total: 33744043.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.46ms, accelerator: 0us, total: 112.46ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.46ms, accelerator: 0us, total: 112.46ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33744043.93sec, total: 33744043.93sec
train2.py:307:<module>, cpu: 112.55ms, accelerator: 0us, total: 112.55ms
  iterator_ops.py:373:get_next, cpu: 112.46ms, accelerator: 0us, total: 112.46ms
train2.py:342:<module>, cpu: 1.83ms, accelerator: 13.43ms, total: 15.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_410000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_410250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_410500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_410750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33661941.62sec, total: 33661941.62sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.31ms, accelerator: 0us, total: 112.31ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.31ms, accelerator: 0us, total: 112.31ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33661941.63sec, total: 33661941.63sec
train2.py:307:<module>, cpu: 112.40ms, accelerator: 0us, total: 112.40ms
  iterator_ops.py:373:get_next, cpu: 112.31ms, accelerator: 0us, total: 112.31ms
train2.py:342:<module>, cpu: 1.83ms, accelerator: 13.43ms, total: 15.29ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_411000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_411250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_411500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_411750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33580237.88sec, total: 33580237.88sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.21ms, accelerator: 0us, total: 112.21ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.21ms, accelerator: 0us, total: 112.21ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33580237.89sec, total: 33580237.89sec
train2.py:307:<module>, cpu: 112.29ms, accelerator: 0us, total: 112.29ms
  iterator_ops.py:373:get_next, cpu: 112.21ms, accelerator: 0us, total: 112.21ms
train2.py:342:<module>, cpu: 1.83ms, accelerator: 13.44ms, total: 15.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_412000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_412250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_412500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_412750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33498929.79sec, total: 33498929.79sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 112.06ms, accelerator: 0us, total: 112.06ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 112.06ms, accelerator: 0us, total: 112.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33498929.80sec, total: 33498929.81sec
train2.py:307:<module>, cpu: 112.15ms, accelerator: 0us, total: 112.15ms
  iterator_ops.py:373:get_next, cpu: 112.06ms, accelerator: 0us, total: 112.06ms
train2.py:342:<module>, cpu: 1.83ms, accelerator: 13.43ms, total: 15.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_413000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_413250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_413500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_413750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33418014.50sec, total: 33418014.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.93ms, accelerator: 0us, total: 111.93ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.93ms, accelerator: 0us, total: 111.93ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33418014.52sec, total: 33418014.52sec
train2.py:307:<module>, cpu: 112.02ms, accelerator: 0us, total: 112.02ms
  iterator_ops.py:373:get_next, cpu: 111.93ms, accelerator: 0us, total: 111.93ms
train2.py:342:<module>, cpu: 1.83ms, accelerator: 13.43ms, total: 15.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_414000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_414250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_414500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_414750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33337489.17sec, total: 33337489.17sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.79ms, accelerator: 0us, total: 111.79ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.79ms, accelerator: 0us, total: 111.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33337489.18sec, total: 33337489.18sec
train2.py:307:<module>, cpu: 111.88ms, accelerator: 0us, total: 111.88ms
  iterator_ops.py:373:get_next, cpu: 111.79ms, accelerator: 0us, total: 111.79ms
train2.py:342:<module>, cpu: 1.83ms, accelerator: 13.43ms, total: 15.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_415000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_415250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_415500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_415750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33257350.97sec, total: 33257350.97sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.65ms, accelerator: 0us, total: 111.65ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.65ms, accelerator: 0us, total: 111.65ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33257350.98sec, total: 33257350.99sec
train2.py:307:<module>, cpu: 111.74ms, accelerator: 0us, total: 111.74ms
  iterator_ops.py:373:get_next, cpu: 111.65ms, accelerator: 0us, total: 111.65ms
train2.py:342:<module>, cpu: 1.83ms, accelerator: 13.43ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_416000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_416250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_416500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_416750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33177597.13sec, total: 33177597.13sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.53ms, accelerator: 0us, total: 111.53ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.53ms, accelerator: 0us, total: 111.53ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33177597.15sec, total: 33177597.15sec
train2.py:307:<module>, cpu: 111.61ms, accelerator: 0us, total: 111.61ms
  iterator_ops.py:373:get_next, cpu: 111.53ms, accelerator: 0us, total: 111.53ms
train2.py:342:<module>, cpu: 1.83ms, accelerator: 13.43ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_417000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_417250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_417500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_417750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33098224.89sec, total: 33098224.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.39ms, accelerator: 0us, total: 111.39ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.39ms, accelerator: 0us, total: 111.39ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33098224.90sec, total: 33098224.91sec
train2.py:307:<module>, cpu: 111.48ms, accelerator: 0us, total: 111.48ms
  iterator_ops.py:373:get_next, cpu: 111.39ms, accelerator: 0us, total: 111.39ms
train2.py:342:<module>, cpu: 1.82ms, accelerator: 13.42ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_418000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_418250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_418500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_418750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 33019231.51sec, total: 33019231.52sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.27ms, accelerator: 0us, total: 111.27ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.27ms, accelerator: 0us, total: 111.27ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 33019231.53sec, total: 33019231.53sec
train2.py:307:<module>, cpu: 111.36ms, accelerator: 0us, total: 111.36ms
  iterator_ops.py:373:get_next, cpu: 111.27ms, accelerator: 0us, total: 111.27ms
train2.py:342:<module>, cpu: 1.82ms, accelerator: 13.43ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_419000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_419250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_419500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_419750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 1.00ms, accelerator: 32940614.30sec, total: 32940614.30sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.17ms, accelerator: 0us, total: 111.17ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.17ms, accelerator: 0us, total: 111.17ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 32940614.31sec, total: 32940614.31sec
train2.py:307:<module>, cpu: 111.25ms, accelerator: 0us, total: 111.25ms
  iterator_ops.py:373:get_next, cpu: 111.17ms, accelerator: 0us, total: 111.17ms
train2.py:342:<module>, cpu: 1.82ms, accelerator: 13.43ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_420000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_420250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_420500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_420750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 999us, accelerator: 32862370.56sec, total: 32862370.56sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 111.04ms, accelerator: 0us, total: 111.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 111.04ms, accelerator: 0us, total: 111.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 32862370.57sec, total: 32862370.57sec
train2.py:307:<module>, cpu: 111.12ms, accelerator: 0us, total: 111.12ms
  iterator_ops.py:373:get_next, cpu: 111.04ms, accelerator: 0us, total: 111.04ms
train2.py:342:<module>, cpu: 1.82ms, accelerator: 13.43ms, total: 15.27ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_421000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_421250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_421500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_421750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 999us, accelerator: 32784497.64sec, total: 32784497.64sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.98ms, accelerator: 0us, total: 110.98ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.98ms, accelerator: 0us, total: 110.98ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 32784497.65sec, total: 32784497.66sec
train2.py:307:<module>, cpu: 111.06ms, accelerator: 0us, total: 111.06ms
  iterator_ops.py:373:get_next, cpu: 110.98ms, accelerator: 0us, total: 110.98ms
train2.py:342:<module>, cpu: 1.82ms, accelerator: 13.43ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_422000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_422250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_422500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_422750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 999us, accelerator: 32706992.92sec, total: 32706992.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.87ms, accelerator: 0us, total: 110.87ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.87ms, accelerator: 0us, total: 110.87ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 32706992.93sec, total: 32706992.93sec
train2.py:307:<module>, cpu: 110.95ms, accelerator: 0us, total: 110.95ms
  iterator_ops.py:373:get_next, cpu: 110.87ms, accelerator: 0us, total: 110.87ms
train2.py:342:<module>, cpu: 1.82ms, accelerator: 13.43ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_423000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_423250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_423500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_423750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 999us, accelerator: 32629853.78sec, total: 32629853.79sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.75ms, accelerator: 0us, total: 110.75ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.75ms, accelerator: 0us, total: 110.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.67ms, accelerator: 32629853.80sec, total: 32629853.80sec
train2.py:307:<module>, cpu: 110.83ms, accelerator: 0us, total: 110.83ms
  iterator_ops.py:373:get_next, cpu: 110.75ms, accelerator: 0us, total: 110.75ms
train2.py:342:<module>, cpu: 1.82ms, accelerator: 13.43ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_424000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_424250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_424500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_424750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 999us, accelerator: 32553077.66sec, total: 32553077.66sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.62ms, accelerator: 0us, total: 110.62ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.62ms, accelerator: 0us, total: 110.62ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 32553077.67sec, total: 32553077.67sec
train2.py:307:<module>, cpu: 110.70ms, accelerator: 0us, total: 110.70ms
  iterator_ops.py:373:get_next, cpu: 110.62ms, accelerator: 0us, total: 110.62ms
train2.py:342:<module>, cpu: 1.82ms, accelerator: 13.43ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_425000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_425250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_425500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_425750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 999us, accelerator: 32476661.98sec, total: 32476661.98sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.57ms, accelerator: 0us, total: 110.57ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.57ms, accelerator: 0us, total: 110.57ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 32476661.99sec, total: 32476662.00sec
train2.py:307:<module>, cpu: 110.66ms, accelerator: 0us, total: 110.66ms
  iterator_ops.py:373:get_next, cpu: 110.57ms, accelerator: 0us, total: 110.57ms
train2.py:342:<module>, cpu: 1.82ms, accelerator: 13.43ms, total: 15.27ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_426000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_426250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_426500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_426750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 998us, accelerator: 32400604.23sec, total: 32400604.23sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.46ms, accelerator: 0us, total: 110.46ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.46ms, accelerator: 0us, total: 110.46ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 32400604.24sec, total: 32400604.24sec
train2.py:307:<module>, cpu: 110.55ms, accelerator: 0us, total: 110.55ms
  iterator_ops.py:373:get_next, cpu: 110.46ms, accelerator: 0us, total: 110.46ms
train2.py:342:<module>, cpu: 1.81ms, accelerator: 13.44ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_427000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_427250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_427500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_427750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 998us, accelerator: 32324901.88sec, total: 32324901.88sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.38ms, accelerator: 0us, total: 110.38ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.38ms, accelerator: 0us, total: 110.38ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 32324901.89sec, total: 32324901.89sec
train2.py:307:<module>, cpu: 110.46ms, accelerator: 0us, total: 110.46ms
  iterator_ops.py:373:get_next, cpu: 110.38ms, accelerator: 0us, total: 110.38ms
train2.py:342:<module>, cpu: 1.81ms, accelerator: 13.44ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_428000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_428250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_428500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_428750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 997us, accelerator: 32249552.46sec, total: 32249552.46sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.23ms, accelerator: 0us, total: 110.23ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.23ms, accelerator: 0us, total: 110.23ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 32249552.47sec, total: 32249552.47sec
train2.py:307:<module>, cpu: 110.31ms, accelerator: 0us, total: 110.31ms
  iterator_ops.py:373:get_next, cpu: 110.23ms, accelerator: 0us, total: 110.23ms
train2.py:342:<module>, cpu: 1.81ms, accelerator: 13.43ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_429000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_429250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_429500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_429750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 997us, accelerator: 32174553.50sec, total: 32174553.50sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.15ms, accelerator: 0us, total: 110.15ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.15ms, accelerator: 0us, total: 110.15ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 32174553.51sec, total: 32174553.51sec
train2.py:307:<module>, cpu: 110.23ms, accelerator: 0us, total: 110.23ms
  iterator_ops.py:373:get_next, cpu: 110.15ms, accelerator: 0us, total: 110.15ms
train2.py:342:<module>, cpu: 1.81ms, accelerator: 13.44ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_430000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_430250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_430500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_430750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 997us, accelerator: 32099902.56sec, total: 32099902.56sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.02ms, accelerator: 0us, total: 110.02ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.02ms, accelerator: 0us, total: 110.02ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 32099902.57sec, total: 32099902.58sec
train2.py:307:<module>, cpu: 110.11ms, accelerator: 0us, total: 110.11ms
  iterator_ops.py:373:get_next, cpu: 110.02ms, accelerator: 0us, total: 110.02ms
train2.py:342:<module>, cpu: 1.81ms, accelerator: 13.44ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.58
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_431000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_431250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_431500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_431750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 997us, accelerator: 32025597.23sec, total: 32025597.23sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.93ms, accelerator: 0us, total: 109.93ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.93ms, accelerator: 0us, total: 109.93ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 32025597.24sec, total: 32025597.25sec
train2.py:307:<module>, cpu: 110.01ms, accelerator: 0us, total: 110.01ms
  iterator_ops.py:373:get_next, cpu: 109.93ms, accelerator: 0us, total: 109.93ms
train2.py:342:<module>, cpu: 1.81ms, accelerator: 13.45ms, total: 15.27ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_432000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_432250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_432500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_432750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 997us, accelerator: 31951635.12sec, total: 31951635.12sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.79ms, accelerator: 0us, total: 109.79ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.79ms, accelerator: 0us, total: 109.79ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31951635.13sec, total: 31951635.13sec
train2.py:307:<module>, cpu: 109.88ms, accelerator: 0us, total: 109.88ms
  iterator_ops.py:373:get_next, cpu: 109.79ms, accelerator: 0us, total: 109.79ms
train2.py:342:<module>, cpu: 1.81ms, accelerator: 13.44ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_433000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_433250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_433500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_433750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 997us, accelerator: 31878013.84sec, total: 31878013.84sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.66ms, accelerator: 0us, total: 109.66ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.66ms, accelerator: 0us, total: 109.66ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31878013.85sec, total: 31878013.85sec
train2.py:307:<module>, cpu: 109.74ms, accelerator: 0us, total: 109.74ms
  iterator_ops.py:373:get_next, cpu: 109.66ms, accelerator: 0us, total: 109.66ms
train2.py:342:<module>, cpu: 1.81ms, accelerator: 13.44ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_434000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_434250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_434500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_434750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 997us, accelerator: 31804731.05sec, total: 31804731.05sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.59ms, accelerator: 0us, total: 109.59ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.85ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.59ms, accelerator: 0us, total: 109.59ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31804731.06sec, total: 31804731.06sec
train2.py:307:<module>, cpu: 109.67ms, accelerator: 0us, total: 109.67ms
  iterator_ops.py:373:get_next, cpu: 109.59ms, accelerator: 0us, total: 109.59ms
train2.py:342:<module>, cpu: 1.81ms, accelerator: 13.45ms, total: 15.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.32
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_435000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_435250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_435500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_435750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 996us, accelerator: 31731784.42sec, total: 31731784.42sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.44ms, accelerator: 0us, total: 109.44ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.80ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.44ms, accelerator: 0us, total: 109.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31731784.43sec, total: 31731784.43sec
train2.py:307:<module>, cpu: 109.53ms, accelerator: 0us, total: 109.53ms
  iterator_ops.py:373:get_next, cpu: 109.44ms, accelerator: 0us, total: 109.44ms
train2.py:342:<module>, cpu: 1.81ms, accelerator: 13.45ms, total: 15.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_436000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_436250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_436500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_436750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 996us, accelerator: 31659171.64sec, total: 31659171.64sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.34ms, accelerator: 0us, total: 109.34ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.81ms, total: 12.84ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.34ms, accelerator: 0us, total: 109.34ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31659171.65sec, total: 31659171.65sec
train2.py:307:<module>, cpu: 109.42ms, accelerator: 0us, total: 109.42ms
  iterator_ops.py:373:get_next, cpu: 109.34ms, accelerator: 0us, total: 109.34ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.45ms, total: 15.28ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_437000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_437250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_437500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_437750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 996us, accelerator: 31586890.42sec, total: 31586890.42sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.23ms, accelerator: 0us, total: 109.23ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.23ms, accelerator: 0us, total: 109.23ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31586890.43sec, total: 31586890.44sec
train2.py:307:<module>, cpu: 109.31ms, accelerator: 0us, total: 109.31ms
  iterator_ops.py:373:get_next, cpu: 109.23ms, accelerator: 0us, total: 109.23ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.45ms, total: 15.27ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_438000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_438250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_438500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_438750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 995us, accelerator: 31514938.51sec, total: 31514938.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.12ms, accelerator: 0us, total: 109.12ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.12ms, accelerator: 0us, total: 109.12ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31514938.52sec, total: 31514938.52sec
train2.py:307:<module>, cpu: 109.20ms, accelerator: 0us, total: 109.20ms
  iterator_ops.py:373:get_next, cpu: 109.12ms, accelerator: 0us, total: 109.12ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.44ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_439000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_439250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_439500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_439750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 995us, accelerator: 31443313.65sec, total: 31443313.65sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.03ms, accelerator: 0us, total: 109.03ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.03ms, accelerator: 0us, total: 109.03ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31443313.66sec, total: 31443313.66sec
train2.py:307:<module>, cpu: 109.12ms, accelerator: 0us, total: 109.12ms
  iterator_ops.py:373:get_next, cpu: 109.03ms, accelerator: 0us, total: 109.03ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.44ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_440000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_440250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_440500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_440750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 995us, accelerator: 31372013.62sec, total: 31372013.62sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.92ms, accelerator: 0us, total: 108.92ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.82ms, total: 12.86ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.92ms, accelerator: 0us, total: 108.92ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31372013.63sec, total: 31372013.63sec
train2.py:307:<module>, cpu: 109.00ms, accelerator: 0us, total: 109.00ms
  iterator_ops.py:373:get_next, cpu: 108.92ms, accelerator: 0us, total: 108.92ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.44ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_441000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_441250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_441500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_441750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 995us, accelerator: 31301036.21sec, total: 31301036.21sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.85ms, accelerator: 0us, total: 108.85ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.85ms, accelerator: 0us, total: 108.85ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31301036.22sec, total: 31301036.22sec
train2.py:307:<module>, cpu: 108.93ms, accelerator: 0us, total: 108.93ms
  iterator_ops.py:373:get_next, cpu: 108.85ms, accelerator: 0us, total: 108.85ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.44ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_442000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_442250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_442500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_442750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 995us, accelerator: 31230379.24sec, total: 31230379.24sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.77ms, accelerator: 0us, total: 108.77ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.77ms, accelerator: 0us, total: 108.77ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31230379.26sec, total: 31230379.26sec
train2.py:307:<module>, cpu: 108.86ms, accelerator: 0us, total: 108.86ms
  iterator_ops.py:373:get_next, cpu: 108.77ms, accelerator: 0us, total: 108.77ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.44ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_443000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_443250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_443500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_443750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 994us, accelerator: 31160040.55sec, total: 31160040.55sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.69ms, accelerator: 0us, total: 108.69ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.69ms, accelerator: 0us, total: 108.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 31160040.56sec, total: 31160040.57sec
train2.py:307:<module>, cpu: 108.77ms, accelerator: 0us, total: 108.77ms
  iterator_ops.py:373:get_next, cpu: 108.69ms, accelerator: 0us, total: 108.69ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.44ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_444000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_444250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_444500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_444750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 995us, accelerator: 31090017.99sec, total: 31090017.99sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.65ms, accelerator: 0us, total: 108.65ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.65ms, accelerator: 0us, total: 108.65ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.66ms, accelerator: 31090018.00sec, total: 31090018.00sec
train2.py:307:<module>, cpu: 108.73ms, accelerator: 0us, total: 108.73ms
  iterator_ops.py:373:get_next, cpu: 108.65ms, accelerator: 0us, total: 108.65ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.44ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_445000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_445250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_445500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_445750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 994us, accelerator: 31020309.43sec, total: 31020309.43sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.53ms, accelerator: 0us, total: 108.53ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.53ms, accelerator: 0us, total: 108.53ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 31020309.44sec, total: 31020309.44sec
train2.py:307:<module>, cpu: 108.61ms, accelerator: 0us, total: 108.61ms
  iterator_ops.py:373:get_next, cpu: 108.53ms, accelerator: 0us, total: 108.53ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.44ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_446000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_446250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_446500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_446750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 994us, accelerator: 30950912.76sec, total: 30950912.76sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.44ms, accelerator: 0us, total: 108.44ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.44ms, accelerator: 0us, total: 108.44ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30950912.77sec, total: 30950912.78sec
train2.py:307:<module>, cpu: 108.53ms, accelerator: 0us, total: 108.53ms
  iterator_ops.py:373:get_next, cpu: 108.44ms, accelerator: 0us, total: 108.44ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.45ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_447000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_447250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_447500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_447750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 994us, accelerator: 30881825.90sec, total: 30881825.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.36ms, accelerator: 0us, total: 108.36ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.83ms, total: 12.87ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.36ms, accelerator: 0us, total: 108.36ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30881825.92sec, total: 30881825.92sec
train2.py:307:<module>, cpu: 108.44ms, accelerator: 0us, total: 108.44ms
  iterator_ops.py:373:get_next, cpu: 108.36ms, accelerator: 0us, total: 108.36ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.45ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_448000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_448250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_448500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_448750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 994us, accelerator: 30813046.78sec, total: 30813046.78sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.24ms, accelerator: 0us, total: 108.24ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.84ms, total: 12.88ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.24ms, accelerator: 0us, total: 108.24ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30813046.79sec, total: 30813046.80sec
train2.py:307:<module>, cpu: 108.32ms, accelerator: 0us, total: 108.32ms
  iterator_ops.py:373:get_next, cpu: 108.24ms, accelerator: 0us, total: 108.24ms
train2.py:342:<module>, cpu: 1.80ms, accelerator: 13.44ms, total: 15.26ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_449000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_449250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_449500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_449750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 994us, accelerator: 30744573.34sec, total: 30744573.35sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.20ms, accelerator: 0us, total: 108.20ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.20ms, accelerator: 0us, total: 108.20ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30744573.36sec, total: 30744573.36sec
train2.py:307:<module>, cpu: 108.28ms, accelerator: 0us, total: 108.28ms
  iterator_ops.py:373:get_next, cpu: 108.20ms, accelerator: 0us, total: 108.20ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_450000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_450250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_450500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_450750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 994us, accelerator: 30676403.56sec, total: 30676403.56sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.36ms, accelerator: 0us, total: 110.36ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.36ms, accelerator: 0us, total: 110.36ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30676403.57sec, total: 30676403.57sec
train2.py:307:<module>, cpu: 110.44ms, accelerator: 0us, total: 110.44ms
  iterator_ops.py:373:get_next, cpu: 110.36ms, accelerator: 0us, total: 110.36ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_451000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_451250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_451500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_451750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 993us, accelerator: 30608535.41sec, total: 30608535.41sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.25ms, accelerator: 0us, total: 110.25ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.25ms, accelerator: 0us, total: 110.25ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30608535.42sec, total: 30608535.42sec
train2.py:307:<module>, cpu: 110.33ms, accelerator: 0us, total: 110.33ms
  iterator_ops.py:373:get_next, cpu: 110.25ms, accelerator: 0us, total: 110.25ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_452000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_452250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_452500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_452750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 992us, accelerator: 30540966.90sec, total: 30540966.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.19ms, accelerator: 0us, total: 110.19ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.19ms, accelerator: 0us, total: 110.19ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30540966.91sec, total: 30540966.91sec
train2.py:307:<module>, cpu: 110.27ms, accelerator: 0us, total: 110.27ms
  iterator_ops.py:373:get_next, cpu: 110.19ms, accelerator: 0us, total: 110.19ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_453000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_453250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_453500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_453750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 992us, accelerator: 30473696.05sec, total: 30473696.05sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.13ms, accelerator: 0us, total: 110.13ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.13ms, accelerator: 0us, total: 110.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30473696.06sec, total: 30473696.06sec
train2.py:307:<module>, cpu: 110.21ms, accelerator: 0us, total: 110.21ms
  iterator_ops.py:373:get_next, cpu: 110.13ms, accelerator: 0us, total: 110.13ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_454000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_454250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_454500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_454750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 992us, accelerator: 30406720.89sec, total: 30406720.89sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 110.06ms, accelerator: 0us, total: 110.06ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 110.06ms, accelerator: 0us, total: 110.06ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30406720.90sec, total: 30406720.90sec
train2.py:307:<module>, cpu: 110.14ms, accelerator: 0us, total: 110.14ms
  iterator_ops.py:373:get_next, cpu: 110.06ms, accelerator: 0us, total: 110.06ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_455000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_455250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_455500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_455750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 30340039.48sec, total: 30340039.49sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.94ms, accelerator: 0us, total: 109.94ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.94ms, accelerator: 0us, total: 109.94ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30340039.50sec, total: 30340039.50sec
train2.py:307:<module>, cpu: 110.02ms, accelerator: 0us, total: 110.02ms
  iterator_ops.py:373:get_next, cpu: 109.94ms, accelerator: 0us, total: 109.94ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_456000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_456250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_456500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_456750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 30273649.90sec, total: 30273649.90sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.86ms, accelerator: 0us, total: 109.86ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.85ms, total: 12.89ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.86ms, accelerator: 0us, total: 109.86ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30273649.91sec, total: 30273649.92sec
train2.py:307:<module>, cpu: 109.94ms, accelerator: 0us, total: 109.94ms
  iterator_ops.py:373:get_next, cpu: 109.86ms, accelerator: 0us, total: 109.86ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.29
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_457000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_457250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_457500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_457750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 30207550.23sec, total: 30207550.23sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.75ms, accelerator: 0us, total: 109.75ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.75ms, accelerator: 0us, total: 109.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30207550.24sec, total: 30207550.24sec
train2.py:307:<module>, cpu: 109.83ms, accelerator: 0us, total: 109.83ms
  iterator_ops.py:373:get_next, cpu: 109.75ms, accelerator: 0us, total: 109.75ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_458000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_458250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_458500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_458750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 30141738.57sec, total: 30141738.57sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.64ms, accelerator: 0us, total: 109.64ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.64ms, accelerator: 0us, total: 109.64ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30141738.58sec, total: 30141738.59sec
train2.py:307:<module>, cpu: 109.71ms, accelerator: 0us, total: 109.71ms
  iterator_ops.py:373:get_next, cpu: 109.64ms, accelerator: 0us, total: 109.64ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.25ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_459000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_459250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_459500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_459750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 30076213.05sec, total: 30076213.06sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.57ms, accelerator: 0us, total: 109.57ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.57ms, accelerator: 0us, total: 109.57ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30076213.07sec, total: 30076213.07sec
train2.py:307:<module>, cpu: 109.65ms, accelerator: 0us, total: 109.65ms
  iterator_ops.py:373:get_next, cpu: 109.57ms, accelerator: 0us, total: 109.57ms
train2.py:342:<module>, cpu: 1.79ms, accelerator: 13.44ms, total: 15.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_460000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_460250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_460500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_460750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.30

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 30010971.81sec, total: 30010971.81sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.49ms, accelerator: 0us, total: 109.49ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.86ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.49ms, accelerator: 0us, total: 109.49ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 30010971.82sec, total: 30010971.83sec
train2.py:307:<module>, cpu: 109.57ms, accelerator: 0us, total: 109.57ms
  iterator_ops.py:373:get_next, cpu: 109.49ms, accelerator: 0us, total: 109.49ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.44ms, total: 15.24ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_461000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_461250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_461500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_461750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 29946013.00sec, total: 29946013.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.40ms, accelerator: 0us, total: 109.40ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.40ms, accelerator: 0us, total: 109.40ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 29946013.01sec, total: 29946013.01sec
train2.py:307:<module>, cpu: 109.47ms, accelerator: 0us, total: 109.47ms
  iterator_ops.py:373:get_next, cpu: 109.40ms, accelerator: 0us, total: 109.40ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.44ms, total: 15.24ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_462000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_462250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_462500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_462750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 29881334.78sec, total: 29881334.79sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.28ms, accelerator: 0us, total: 109.28ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.28ms, accelerator: 0us, total: 109.28ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 29881334.80sec, total: 29881334.80sec
train2.py:307:<module>, cpu: 109.35ms, accelerator: 0us, total: 109.35ms
  iterator_ops.py:373:get_next, cpu: 109.28ms, accelerator: 0us, total: 109.28ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.43ms, total: 15.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_463000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_463250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_463500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_463750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 29816935.36sec, total: 29816935.36sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.21ms, accelerator: 0us, total: 109.21ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.89ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.21ms, accelerator: 0us, total: 109.21ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 29816935.37sec, total: 29816935.37sec
train2.py:307:<module>, cpu: 109.28ms, accelerator: 0us, total: 109.28ms
  iterator_ops.py:373:get_next, cpu: 109.21ms, accelerator: 0us, total: 109.21ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.42ms, total: 15.22ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_464000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_464250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_464500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_464750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 29752812.91sec, total: 29752812.92sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.13ms, accelerator: 0us, total: 109.13ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.90ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.13ms, accelerator: 0us, total: 109.13ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 29752812.93sec, total: 29752812.93sec
train2.py:307:<module>, cpu: 109.21ms, accelerator: 0us, total: 109.21ms
  iterator_ops.py:373:get_next, cpu: 109.13ms, accelerator: 0us, total: 109.13ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.43ms, total: 15.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.30
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_465000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_465250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_465500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_465750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 29688965.68sec, total: 29688965.68sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 109.01ms, accelerator: 0us, total: 109.01ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.89ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 109.01ms, accelerator: 0us, total: 109.01ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 29688965.69sec, total: 29688965.69sec
train2.py:307:<module>, cpu: 109.09ms, accelerator: 0us, total: 109.09ms
  iterator_ops.py:373:get_next, cpu: 109.01ms, accelerator: 0us, total: 109.01ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.42ms, total: 15.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_466000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_466250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_466500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_466750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 29625391.87sec, total: 29625391.88sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.95ms, accelerator: 0us, total: 108.95ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.95ms, accelerator: 0us, total: 108.95ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 29625391.89sec, total: 29625391.89sec
train2.py:307:<module>, cpu: 109.03ms, accelerator: 0us, total: 109.03ms
  iterator_ops.py:373:get_next, cpu: 108.95ms, accelerator: 0us, total: 108.95ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.43ms, total: 15.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_467000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_467250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_467500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_467750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 29562089.75sec, total: 29562089.76sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.85ms, accelerator: 0us, total: 108.85ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.85ms, accelerator: 0us, total: 108.85ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 29562089.77sec, total: 29562089.77sec
train2.py:307:<module>, cpu: 108.92ms, accelerator: 0us, total: 108.92ms
  iterator_ops.py:373:get_next, cpu: 108.85ms, accelerator: 0us, total: 108.85ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.43ms, total: 15.23ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_468000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_468250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_468500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_468750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 29499057.58sec, total: 29499057.58sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.75ms, accelerator: 0us, total: 108.75ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.75ms, accelerator: 0us, total: 108.75ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 29499057.59sec, total: 29499057.59sec
train2.py:307:<module>, cpu: 108.83ms, accelerator: 0us, total: 108.83ms
  iterator_ops.py:373:get_next, cpu: 108.75ms, accelerator: 0us, total: 108.75ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.43ms, total: 15.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.54
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_469000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_469250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_469500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_469750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 29436293.63sec, total: 29436293.63sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.69ms, accelerator: 0us, total: 108.69ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.69ms, accelerator: 0us, total: 108.69ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 29436293.64sec, total: 29436293.64sec
train2.py:307:<module>, cpu: 108.77ms, accelerator: 0us, total: 108.77ms
  iterator_ops.py:373:get_next, cpu: 108.69ms, accelerator: 0us, total: 108.69ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.42ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_470000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_470250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_470500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_470750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 991us, accelerator: 29373796.19sec, total: 29373796.19sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.68ms, accelerator: 0us, total: 108.68ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.68ms, accelerator: 0us, total: 108.68ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.65ms, accelerator: 29373796.20sec, total: 29373796.20sec
train2.py:307:<module>, cpu: 108.76ms, accelerator: 0us, total: 108.76ms
  iterator_ops.py:373:get_next, cpu: 108.68ms, accelerator: 0us, total: 108.68ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.42ms, total: 15.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.27
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_471000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_471250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_471500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_471750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 990us, accelerator: 29311563.57sec, total: 29311563.57sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.58ms, accelerator: 0us, total: 108.58ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.58ms, accelerator: 0us, total: 108.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 29311563.58sec, total: 29311563.58sec
train2.py:307:<module>, cpu: 108.65ms, accelerator: 0us, total: 108.65ms
  iterator_ops.py:373:get_next, cpu: 108.58ms, accelerator: 0us, total: 108.58ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.42ms, total: 15.22ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_472000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_472250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_472500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_472750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 990us, accelerator: 29249594.09sec, total: 29249594.09sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.49ms, accelerator: 0us, total: 108.49ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.49ms, accelerator: 0us, total: 108.49ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 29249594.10sec, total: 29249594.11sec
train2.py:307:<module>, cpu: 108.57ms, accelerator: 0us, total: 108.57ms
  iterator_ops.py:373:get_next, cpu: 108.49ms, accelerator: 0us, total: 108.49ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.41ms, total: 15.21ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_473000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_473250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_473500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_473750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.29

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 990us, accelerator: 29187886.09sec, total: 29187886.09sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.46ms, accelerator: 0us, total: 108.46ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.87ms, total: 12.91ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.46ms, accelerator: 0us, total: 108.46ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 29187886.10sec, total: 29187886.10sec
train2.py:307:<module>, cpu: 108.53ms, accelerator: 0us, total: 108.53ms
  iterator_ops.py:373:get_next, cpu: 108.46ms, accelerator: 0us, total: 108.46ms
train2.py:342:<module>, cpu: 1.78ms, accelerator: 13.42ms, total: 15.22ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_474000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_474250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_474500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_474750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 990us, accelerator: 29126437.91sec, total: 29126437.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.37ms, accelerator: 0us, total: 108.37ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.37ms, accelerator: 0us, total: 108.37ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 29126437.92sec, total: 29126437.92sec
train2.py:307:<module>, cpu: 108.44ms, accelerator: 0us, total: 108.44ms
  iterator_ops.py:373:get_next, cpu: 108.37ms, accelerator: 0us, total: 108.37ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.42ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_475000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_475250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_475500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_475750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 990us, accelerator: 29065247.91sec, total: 29065247.91sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.28ms, accelerator: 0us, total: 108.28ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.28ms, accelerator: 0us, total: 108.28ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 29065247.92sec, total: 29065247.92sec
train2.py:307:<module>, cpu: 108.36ms, accelerator: 0us, total: 108.36ms
  iterator_ops.py:373:get_next, cpu: 108.28ms, accelerator: 0us, total: 108.28ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.42ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_476000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_476250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_476500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_476750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 29004314.48sec, total: 29004314.48sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.17ms, accelerator: 0us, total: 108.17ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.89ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.17ms, accelerator: 0us, total: 108.17ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 29004314.49sec, total: 29004314.49sec
train2.py:307:<module>, cpu: 108.25ms, accelerator: 0us, total: 108.25ms
  iterator_ops.py:373:get_next, cpu: 108.17ms, accelerator: 0us, total: 108.17ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.42ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_477000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_477250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_477500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_477750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28943635.99sec, total: 28943636.00sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.11ms, accelerator: 0us, total: 108.11ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.88ms, total: 12.92ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.11ms, accelerator: 0us, total: 108.11ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28943636.01sec, total: 28943636.01sec
train2.py:307:<module>, cpu: 108.18ms, accelerator: 0us, total: 108.18ms
  iterator_ops.py:373:get_next, cpu: 108.11ms, accelerator: 0us, total: 108.11ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.42ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.29
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_478000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_478250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_478500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_478750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28883210.87sec, total: 28883210.87sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 108.04ms, accelerator: 0us, total: 108.04ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.89ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 108.04ms, accelerator: 0us, total: 108.04ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28883210.88sec, total: 28883210.88sec
train2.py:307:<module>, cpu: 108.12ms, accelerator: 0us, total: 108.12ms
  iterator_ops.py:373:get_next, cpu: 108.04ms, accelerator: 0us, total: 108.04ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.42ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_479000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_479250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_479500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_479750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28823037.51sec, total: 28823037.51sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.96ms, accelerator: 0us, total: 107.96ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.89ms, total: 12.93ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.96ms, accelerator: 0us, total: 107.96ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28823037.52sec, total: 28823037.53sec
train2.py:307:<module>, cpu: 108.03ms, accelerator: 0us, total: 108.03ms
  iterator_ops.py:373:get_next, cpu: 107.96ms, accelerator: 0us, total: 107.96ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.42ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_480000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_480250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_480500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_480750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28763114.36sec, total: 28763114.36sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.85ms, accelerator: 0us, total: 107.85ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.85ms, accelerator: 0us, total: 107.85ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28763114.37sec, total: 28763114.37sec
train2.py:307:<module>, cpu: 107.92ms, accelerator: 0us, total: 107.92ms
  iterator_ops.py:373:get_next, cpu: 107.85ms, accelerator: 0us, total: 107.85ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.41ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_481000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_481250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_481500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_481750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28703439.85sec, total: 28703439.85sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.74ms, accelerator: 0us, total: 107.74ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.74ms, accelerator: 0us, total: 107.74ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28703439.86sec, total: 28703439.86sec
train2.py:307:<module>, cpu: 107.82ms, accelerator: 0us, total: 107.82ms
  iterator_ops.py:373:get_next, cpu: 107.74ms, accelerator: 0us, total: 107.74ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.42ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_482000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_482250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_482500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_482750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28644012.43sec, total: 28644012.43sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.70ms, accelerator: 0us, total: 107.70ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.91ms, total: 12.95ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.70ms, accelerator: 0us, total: 107.70ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28644012.44sec, total: 28644012.45sec
train2.py:307:<module>, cpu: 107.78ms, accelerator: 0us, total: 107.78ms
  iterator_ops.py:373:get_next, cpu: 107.70ms, accelerator: 0us, total: 107.70ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.42ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_483000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_483250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_483500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_483750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28584830.59sec, total: 28584830.59sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.64ms, accelerator: 0us, total: 107.64ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.91ms, total: 12.95ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.64ms, accelerator: 0us, total: 107.64ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28584830.60sec, total: 28584830.60sec
train2.py:307:<module>, cpu: 107.71ms, accelerator: 0us, total: 107.71ms
  iterator_ops.py:373:get_next, cpu: 107.64ms, accelerator: 0us, total: 107.64ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.42ms, total: 15.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_484000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_484250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_484500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_484750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28525892.79sec, total: 28525892.80sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.58ms, accelerator: 0us, total: 107.58ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.91ms, total: 12.95ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.58ms, accelerator: 0us, total: 107.58ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28525892.81sec, total: 28525892.81sec
train2.py:307:<module>, cpu: 107.65ms, accelerator: 0us, total: 107.65ms
  iterator_ops.py:373:get_next, cpu: 107.58ms, accelerator: 0us, total: 107.58ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.41ms, total: 15.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_485000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_485250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_485500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_485750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28467197.54sec, total: 28467197.54sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.51ms, accelerator: 0us, total: 107.51ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.91ms, total: 12.95ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.51ms, accelerator: 0us, total: 107.51ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28467197.55sec, total: 28467197.56sec
train2.py:307:<module>, cpu: 107.59ms, accelerator: 0us, total: 107.59ms
  iterator_ops.py:373:get_next, cpu: 107.51ms, accelerator: 0us, total: 107.51ms
train2.py:342:<module>, cpu: 1.77ms, accelerator: 13.42ms, total: 15.20ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_486000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_486250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_486500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_486750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.28

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28408743.34sec, total: 28408743.34sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.47ms, accelerator: 0us, total: 107.47ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.89ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.47ms, accelerator: 0us, total: 107.47ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28408743.35sec, total: 28408743.35sec
train2.py:307:<module>, cpu: 107.54ms, accelerator: 0us, total: 107.54ms
  iterator_ops.py:373:get_next, cpu: 107.47ms, accelerator: 0us, total: 107.47ms
train2.py:342:<module>, cpu: 1.76ms, accelerator: 13.43ms, total: 15.21ms
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_487000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_487250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_487500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_487750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28350528.70sec, total: 28350528.70sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.43ms, accelerator: 0us, total: 107.43ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.43ms, accelerator: 0us, total: 107.43ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28350528.71sec, total: 28350528.71sec
train2.py:307:<module>, cpu: 107.50ms, accelerator: 0us, total: 107.50ms
  iterator_ops.py:373:get_next, cpu: 107.43ms, accelerator: 0us, total: 107.43ms
train2.py:342:<module>, cpu: 1.76ms, accelerator: 13.43ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 low utilization: 0.00
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_488000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_488250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_488500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_488750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************

ExpensiveOperationChecker:
top 1 operation type: Conv2DBackpropInput, cpu: 989us, accelerator: 28292552.16sec, total: 28292552.16sec (100.00%)
top 2 operation type: IteratorGetNext, cpu: 107.33ms, accelerator: 0us, total: 107.33ms (0.00%)
top 3 operation type: ResourceApplyAdam, cpu: 1.03ms, accelerator: 11.90ms, total: 12.94ms (0.00%)
top 1 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us
top 2 graph node: IteratorGetNext, cpu: 107.33ms, accelerator: 0us, total: 107.33ms
top 3 graph node: model, cpu: 0us, accelerator: 0us, total: 0us
train2.py:342:<module> (gradient), cpu: 2.64ms, accelerator: 28292552.17sec, total: 28292552.17sec
train2.py:307:<module>, cpu: 107.40ms, accelerator: 0us, total: 107.40ms
  iterator_ops.py:373:get_next, cpu: 107.33ms, accelerator: 0us, total: 107.33ms
train2.py:342:<module>, cpu: 1.76ms, accelerator: 13.43ms, total: 15.21ms

OperationChecker:
Found operation using NHWC data_format on GPU. Maybe NCHW is faster.

AcceleratorUtilizationChecker:
device: /job:localhost/replica:0/task:0/device:gpu:0 utilization: 0.55
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_489000.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_489250.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_489500.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
generating trace file.
/job:localhost/replica:0/task:0/device:gpu:0 peak memory: 106.08 MB

******************************************************
Timeline file is written to out/hdf/m17/timelines/t.json_489750.
Open a Chrome browser, enter URL chrome://tracing and load the timeline file.
******************************************************
