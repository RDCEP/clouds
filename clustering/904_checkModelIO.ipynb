{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.data import parallel_interleave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extractor_resize_fn(filelist,prefetch=1,height=32,width=32,channel=6,read_threads=4, distribute=(1, 0)):\n",
    "    def parser(ser):\n",
    "        \"\"\"\n",
    "        Decode & Pass datast in tf.record\n",
    "        *Cuation*\n",
    "        floating point: tfrecord data ==> tf.float64\n",
    "        \"\"\"\n",
    "        features = {\n",
    "            \"shape\": tf.FixedLenFeature([3], tf.int64),\n",
    "            \"patch\": tf.FixedLenFeature([], tf.string),\n",
    "            \"filename\": tf.FixedLenFeature([], tf.string),\n",
    "            \"coordinate\": tf.FixedLenFeature([2], tf.int64),\n",
    "        }\n",
    "        decoded = tf.parse_single_example(ser, features)\n",
    "        patch = tf.reshape(\n",
    "            tf.decode_raw(decoded[\"patch\"], tf.float64), decoded[\"shape\"]\n",
    "        )\n",
    "        # conversion of tensor\n",
    "        patch = tf.cast(patch, tf.float32)\n",
    "        patch = tf.image.resize_images(patch, (height, width))\n",
    "        return patch\n",
    "    \n",
    "    dataset = (\n",
    "        tf.data.Dataset.list_files(filelist, shuffle=True)\n",
    "            .shard(*distribute)\n",
    "            .apply(\n",
    "            parallel_interleave(\n",
    "                lambda f: tf.data.TFRecordDataset(f).map(parser),\n",
    "                cycle_length=read_threads,\n",
    "                sloppy=True,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    next_element = iterator.get_next()\n",
    "    patches_list = []\n",
    "    with tf.Session() as sess:\n",
    "        try:\n",
    "            while True:\n",
    "                patch = sess.run(next_element)\n",
    "                patches_list.append(patch)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"OutOfRage --> finish process\")\n",
    "            pass\n",
    "    return patches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_model(model_dir, mtype):\n",
    "    #TODO add restart model dir and restart argument?\n",
    "    latest = 0, None\n",
    "    # get trained wegiht \n",
    "    for m in os.listdir(model_dir):\n",
    "        if \".h5\" in m and mtype in m:\n",
    "            epoch = int(m.split(\"-\")[1].replace(\".h5\", \"\"))\n",
    "            latest = max(latest, (epoch, m))\n",
    "\n",
    "    epoch, model_file = latest\n",
    "\n",
    "    if not os.listdir(model_dir):\n",
    "        raise NameError(\"no directory. check model path again\")\n",
    "\n",
    "    print(\" Load {} at {} epoch\".format(mtype, epoch))\n",
    "    model_def = model_dir+'/'+mtype+'.json'\n",
    "    model_weight = model_dir+'/'+mtype+'-'+str(epoch)+'.h5'\n",
    "    with open(model_def, \"r\") as f:\n",
    "        model = tf.keras.models.model_from_json(f.read())\n",
    "    model.load_weights(model_weight)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before update on 09/22/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.6-tf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After first update on 09/22/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_datadir = \"/project2/foster/clouds/data/clouds_laads_multiprocessed_2000_2018_band28_29_31_circle_2\"\n",
    "filelist = glob.glob(os.path.join(tf_datadir, '2-10*.tfrecord'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-9d109b826e66>:30: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /home/tkurihana/.conda/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From <ipython-input-3-9d109b826e66>:34: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "OutOfRage --> finish process\n",
      "NORMAL END\n",
      "(2000, 32, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "## load \n",
    "nfiles = 1\n",
    "fdx = np.random.randint(0,len(filelist),nfiles)\n",
    "patches_list = []\n",
    "for ifile in [filelist[i] for i in fdx]:\n",
    "    patches_list.append(data_extractor_resize_fn([ifile],height=32,width=32,channel=6 ))\n",
    "print(\"NORMAL END\")\n",
    "\n",
    "## get patch\n",
    "height = width = 32\n",
    "channel = 6\n",
    "patches = np.concatenate(\n",
    "    [np.expand_dims(i, axis=0).reshape(1,height,width, channel) for i in patches_list[0]],\n",
    "    axis=0)\n",
    "print(patches.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Encoder and Decoder *Issue happend for decoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Load encoder at 20 epoch\n",
      "WARNING:tensorflow:From /home/tkurihana/.conda/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/tkurihana/.conda/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/tkurihana/.conda/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# 67011582; Best model\n",
    "model_datadir = '/home/tkurihana/rotate_invariant/stepbystep/transform/output_model'\n",
    "expname = 4678889\n",
    "model_dir = os.path.join(model_datadir,str(expname) )\n",
    "encoder = load_latest_model(model_dir, mtype='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'2.2.4-tf'\n"
     ]
    }
   ],
   "source": [
    "### Type of tf.keras in trained model\n",
    "import h5py\n",
    "\n",
    "f = h5py.File(glob.glob(os.path.join(model_dir,'decoder*.h5'))[0], 'r')\n",
    "print(f.attrs.get('keras_version'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Load decoder at 20 epoch\n",
      "WARNING:tensorflow:From /home/tkurihana/.conda/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "decoder = load_latest_model(model_dir, mtype='decoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEMO\n",
    "Problem solved after updating tf version from 1.12-mkl to 1.14 (both cpu and gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
